-framework ./two048Lua.lua -name DQN3_0_1_2048_FULL_Y -env 2048 -env_params useRGB=true -agent NeuralQLearner -agent_params lr=0.0005,ep=1,ep_end=0.1,ep_endt=replay_memory,discount=0.9,hist_len=4,learn_start=50000,replay_memory=1000000,update_freq=4,n_replay=1,network=false,preproc="net_downsample_2x_full_y",state_dim=16,minibatch_size=32,rescale_r=1,ncols=1,bufferSize=512,valid_size=500,target_q=10000,clip_delta=1,min_reward=false,max_reward=false -steps 50000000 -eval_freq 250000 -eval_steps 125000 -prog_freq 10000 -save_freq 125000 -actrep 4 -gpu 0 -random_starts 30 -pool_frms type="max",size=2 -seed 1 -threads 4
Torch Threads:	1	
Using GPU device id:	0	
Torch Seed:	1	
CUTorch Seed:	1791095845	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Reshape(64)
  (2): nn.Linear(64 -> 64)
  (3): nn.Rectifier
  (4): nn.Linear(64 -> 128)
  (5): nn.Rectifier
  (6): nn.Linear(128 -> 256)
  (7): nn.Rectifier
  (8): nn.ConcatTable {
    input
      |`-> (1): nn.Sequential {
      |      [input -> (1) -> (2) -> (3) -> output]
      |      (1): nn.Linear(256 -> 512)
      |      (2): nn.Rectifier
      |      (3): nn.Linear(512 -> 1)
      |    }
      |`-> (2): nn.Sequential {
      |      [input -> (1) -> (2) -> (3) -> output]
      |      (1): nn.Linear(256 -> 512)
      |      (2): nn.Rectifier
      |      (3): nn.Linear(512 -> 4)
      |    }
       ... -> output
  }
  (9): nn.Sequential {
    [input -> (1) -> (2) -> output]
    (1): nn.ParallelTable {
      input
        |`-> (1): nn.Replicate
        |`-> (2): nn.Sequential {
        |      [input -> (1) -> (2) -> output]
        |      (1): nn.ConcatTable {
        |        input
        |          |`-> (1): nn.Identity
        |          |`-> (2): nn.Sequential {
        |          |      [input -> (1) -> (2) -> output]
        |          |      (1): nn.Mean
        |          |      (2): nn.Replicate
        |          |    }
        |           ... -> output
        |      }
        |      (2): nn.CSubTable
        |    }
         ... -> output
    }
    (2): nn.CAddTable
  }
}
Set up Torch using these options:	
eval_steps	125000	
seed	1	
name	DQN3_0_1_2048_FULL_Y	
verbose	2	
network		
pool_frms	{
  type : "max"
  size : 2
}
saveNetworkParams	false	
gpu	1	
eval_freq	250000	
tensorType	torch.FloatTensor	
env_params	{
  useRGB : true
}
steps	50000000	
prog_freq	10000	
agent_params	{
  target_q : 10000
  ncols : 1
  replay_memory : 1000000
  min_reward : false
  discount : 0.9
  bufferSize : 512
  hist_len : 4
  ep : 1
  network : false
  max_reward : false
  gpu : 0
  n_replay : 1
  verbose : 2
  ep_end : 0.1
  lr : 0.0005
  preproc : "net_downsample_2x_full_y"
  valid_size : 500
  update_freq : 4
  minibatch_size : 32
  rescale_r : 1
  clip_delta : 1
  state_dim : 16
  learn_start : 50000
}
save_versions	0	
framework	./two048Lua.lua	
agent	NeuralQLearner	
threads	4	
actrep	4	
random_starts	30	
game_path		
save_freq	125000	
env	2048	
{
  1 : "u"
  2 : "d"
  3 : "l"
  4 : "r"
}
Iteration ..	0	
Steps: 	10000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062444202091015 nn.Linear: 0.062153109751478 nn.Linear: 0.044188271491613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031310062123966 nn.Linear: 0.021907413801841] nn.Sequential: [nn.Linear: 0.031260815004845 nn.Linear: 0.021473448771236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12497140467167 nn.Linear: 0.12498060613871 nn.Linear: 0.088384978473186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.062499914318323 nn.Linear: 0.043803088366985] nn.Sequential: [nn.Linear: 0.062498949468136 nn.Linear: 0.044120226055384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	20000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062444202091015 nn.Linear: 0.062153109751478 nn.Linear: 0.044188271491613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031310062123966 nn.Linear: 0.021907413801841] nn.Sequential: [nn.Linear: 0.031260815004845 nn.Linear: 0.021473448771236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12497140467167 nn.Linear: 0.12498060613871 nn.Linear: 0.088384978473186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.062499914318323 nn.Linear: 0.043803088366985] nn.Sequential: [nn.Linear: 0.062498949468136 nn.Linear: 0.044120226055384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	30000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062444202091015 nn.Linear: 0.062153109751478 nn.Linear: 0.044188271491613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031310062123966 nn.Linear: 0.021907413801841] nn.Sequential: [nn.Linear: 0.031260815004845 nn.Linear: 0.021473448771236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12497140467167 nn.Linear: 0.12498060613871 nn.Linear: 0.088384978473186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.062499914318323 nn.Linear: 0.043803088366985] nn.Sequential: [nn.Linear: 0.062498949468136 nn.Linear: 0.044120226055384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	40000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062444202091015 nn.Linear: 0.062153109751478 nn.Linear: 0.044188271491613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031310062123966 nn.Linear: 0.021907413801841] nn.Sequential: [nn.Linear: 0.031260815004845 nn.Linear: 0.021473448771236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12497140467167 nn.Linear: 0.12498060613871 nn.Linear: 0.088384978473186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.062499914318323 nn.Linear: 0.043803088366985] nn.Sequential: [nn.Linear: 0.062498949468136 nn.Linear: 0.044120226055384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	50000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062444202091015 nn.Linear: 0.062153109751478 nn.Linear: 0.044188271491613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031310062123966 nn.Linear: 0.021907413801841] nn.Sequential: [nn.Linear: 0.031260815004845 nn.Linear: 0.021473448771236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12497140467167 nn.Linear: 0.12498060613871 nn.Linear: 0.088384978473186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.062499914318323 nn.Linear: 0.043803088366985] nn.Sequential: [nn.Linear: 0.062498949468136 nn.Linear: 0.044120226055384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0 nn.Linear: 0 nn.Linear: 0 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0 nn.Linear: 0] nn.Sequential: [nn.Linear: 0 nn.Linear: 0]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	60000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062498000805773 nn.Linear: 0.062175236621911 nn.Linear: 0.044194756615934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031311279336385 nn.Linear: 0.022367964118668] nn.Sequential: [nn.Linear: 0.031262931657426 nn.Linear: 0.021699923354286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.12995167076588 nn.Linear: 0.12718185782433 nn.Linear: 0.091487154364586 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.063896924257278 nn.Linear: 0.053412027657032] nn.Sequential: [nn.Linear: 0.064764343202114 nn.Linear: 0.054965380579233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018979400787365 nn.Linear: 0.00068773486104736 nn.Linear: 0.00039515385918025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022625639510869 nn.Linear: 0.010733835278406] nn.Sequential: [nn.Linear: 0.00013411340276834 nn.Linear: 0.002530306507815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015395901165903 nn.Linear: 0.014666873961687 nn.Linear: 0.0094300797209144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071778991259634 nn.Linear: 0.069099716842175] nn.Sequential: [nn.Linear: 0.0046497937291861 nn.Linear: 0.023776769638062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	70000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062514891940451 nn.Linear: 0.062185836552714 nn.Linear: 0.044198792549782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031313329574971 nn.Linear: 0.023068498416396] nn.Sequential: [nn.Linear: 0.031263152991432 nn.Linear: 0.02172821930523]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.14201073348522 nn.Linear: 0.12891660630703 nn.Linear: 0.09303979575634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.064756654202938 nn.Linear: 0.063826724886894] nn.Sequential: [nn.Linear: 0.065365798771381 nn.Linear: 0.058251619338989]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018488403752535 nn.Linear: 0.00086267476952104 nn.Linear: 0.00043620020128794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024794973872964 nn.Linear: 0.011878121301185] nn.Sequential: [nn.Linear: 0.00015847708468935 nn.Linear: 0.0034423936883088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022007327526808 nn.Linear: 0.021602621302009 nn.Linear: 0.012647261843085 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075401342473924 nn.Linear: 0.068496897816658] nn.Sequential: [nn.Linear: 0.0069862380623817 nn.Linear: 0.025808714330196]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	80000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062508477844569 nn.Linear: 0.062186835747141 nn.Linear: 0.04420008698749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03131440953585 nn.Linear: 0.023492768367262] nn.Sequential: [nn.Linear: 0.031262877393063 nn.Linear: 0.021683063575362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.15226326882839 nn.Linear: 0.13158217072487 nn.Linear: 0.094006307423115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065545216202736 nn.Linear: 0.070353716611862] nn.Sequential: [nn.Linear: 0.065288044512272 nn.Linear: 0.057157225906849]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011826676589662 nn.Linear: 0.00053472752416871 nn.Linear: 0.00025206449752941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0752878578458e-05 nn.Linear: 0.0020359459244803] nn.Sequential: [nn.Linear: 0.00011071966904316 nn.Linear: 0.0016935958900551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089995115995407 nn.Linear: 0.01009701564908 nn.Linear: 0.0059302020817995 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003988235257566 nn.Linear: 0.013262236490846] nn.Sequential: [nn.Linear: 0.0030754923354834 nn.Linear: 0.016211945563555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	90000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062495048979439 nn.Linear: 0.062180447494363 nn.Linear: 0.044199098061475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03131492930723 nn.Linear: 0.023720449520788] nn.Sequential: [nn.Linear: 0.031262194129803 nn.Linear: 0.021611804103358]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.15707589685917 nn.Linear: 0.13346154987812 nn.Linear: 0.094369061291218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065675891935825 nn.Linear: 0.072529964148998] nn.Sequential: [nn.Linear: 0.065058559179306 nn.Linear: 0.055030569434166]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011932366570039 nn.Linear: 0.00055583746418599 nn.Linear: 0.0003089983749689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.6647456528749e-05 nn.Linear: 0.0019984965389817] nn.Sequential: [nn.Linear: 0.00018767329708348 nn.Linear: 0.0034167357021009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083102220669389 nn.Linear: 0.011640476994216 nn.Linear: 0.010002262890339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0026964843273163 nn.Linear: 0.012006319127977] nn.Sequential: [nn.Linear: 0.0068865502253175 nn.Linear: 0.035512838512659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062485886437696 nn.Linear: 0.062182026194933 nn.Linear: 0.044200624127484 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031315426997715 nn.Linear: 0.023855366460111] nn.Sequential: [nn.Linear: 0.031262371575209 nn.Linear: 0.021626267800166]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.16101017594337 nn.Linear: 0.13578125834465 nn.Linear: 0.095038898289204 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.06526655703783 nn.Linear: 0.074200719594955] nn.Sequential: [nn.Linear: 0.065795905888081 nn.Linear: 0.055938355624676]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012232921262481 nn.Linear: 0.0005281071960241 nn.Linear: 0.00025810654302099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012874989563357 nn.Linear: 0.0051384180070955] nn.Sequential: [nn.Linear: 9.1014534207352e-05 nn.Linear: 0.0016749904328635]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012686856091022 nn.Linear: 0.012684632092714 nn.Linear: 0.0071104587987065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004617718514055 nn.Linear: 0.0344163402915] nn.Sequential: [nn.Linear: 0.002662199549377 nn.Linear: 0.015284918248653]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062480456262452 nn.Linear: 0.062185280421641 nn.Linear: 0.044202789831617 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031315856134043 nn.Linear: 0.024065118234191] nn.Sequential: [nn.Linear: 0.031262543985292 nn.Linear: 0.021659981150854]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.16522458195686 nn.Linear: 0.13844648003578 nn.Linear: 0.095634624361992 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065236188471317 nn.Linear: 0.075241275131702] nn.Sequential: [nn.Linear: 0.066392615437508 nn.Linear: 0.057465057820082]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0047386051680996 nn.Linear: 0.0018296580977303 nn.Linear: 0.00099574076315089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0005932370391589 nn.Linear: 0.023753500924673] nn.Sequential: [nn.Linear: 0.00024797775739143 nn.Linear: 0.0050012494790347]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.03604918718338 nn.Linear: 0.058097638189793 nn.Linear: 0.031620848923922 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022608369588852 nn.Linear: 0.15639053285122] nn.Sequential: [nn.Linear: 0.010759060271084 nn.Linear: 0.04686937853694]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062478149472434 nn.Linear: 0.062186447925407 nn.Linear: 0.044204395720015 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031316194929868 nn.Linear: 0.024183904498543] nn.Sequential: [nn.Linear: 0.031262801004166 nn.Linear: 0.021683857426247]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.16865430772305 nn.Linear: 0.13932421803474 nn.Linear: 0.09566892683506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065430268645287 nn.Linear: 0.074993170797825] nn.Sequential: [nn.Linear: 0.066460713744164 nn.Linear: 0.056869994848967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014942035928172 nn.Linear: 0.00053247945176493 nn.Linear: 0.00025169622577628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6302751145003e-05 nn.Linear: 0.0025782653101561] nn.Sequential: [nn.Linear: 9.2203486375102e-05 nn.Linear: 0.0016483049930998]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018018580973148 nn.Linear: 0.013785496354103 nn.Linear: 0.0072282236069441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004217233043164 nn.Linear: 0.020143641158938] nn.Sequential: [nn.Linear: 0.0041273287497461 nn.Linear: 0.012019067071378]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062482394900528 nn.Linear: 0.062191718101762 nn.Linear: 0.044206633299701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031316478299804 nn.Linear: 0.024334982497237] nn.Sequential: [nn.Linear: 0.031263226824058 nn.Linear: 0.021730096924193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.16991567611694 nn.Linear: 0.14070230722427 nn.Linear: 0.095221720635891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065313905477524 nn.Linear: 0.075350008904934] nn.Sequential: [nn.Linear: 0.066880151629448 nn.Linear: 0.058134764432907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001817684044898 nn.Linear: 0.00077295555139427 nn.Linear: 0.00036918959660703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016869769058975 nn.Linear: 0.0060645806878956] nn.Sequential: [nn.Linear: 0.00011676849759877 nn.Linear: 0.0019393764145128]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019150573760271 nn.Linear: 0.019099164754152 nn.Linear: 0.012777878902853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053051793947816 nn.Linear: 0.046411916613579] nn.Sequential: [nn.Linear: 0.0033545109909028 nn.Linear: 0.017106669023633]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062485472418098 nn.Linear: 0.062197349753649 nn.Linear: 0.044208808736668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031316970935212 nn.Linear: 0.024446570525583] nn.Sequential: [nn.Linear: 0.031263496409319 nn.Linear: 0.021771387394228]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.17276468873024 nn.Linear: 0.14298062026501 nn.Linear: 0.095765598118305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065554402768612 nn.Linear: 0.076393328607082] nn.Sequential: [nn.Linear: 0.067260719835758 nn.Linear: 0.057688798755407]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010778331245286 nn.Linear: 0.00048186902151076 nn.Linear: 0.00024744146643064 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1179546279015e-05 nn.Linear: 0.0014680141184864] nn.Sequential: [nn.Linear: 0.00010929112465749 nn.Linear: 0.0017202284478285]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010536230169237 nn.Linear: 0.0077926036901772 nn.Linear: 0.007485827896744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003072191728279 nn.Linear: 0.0080227060243487] nn.Sequential: [nn.Linear: 0.0036300274077803 nn.Linear: 0.01582645252347]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062484444561321 nn.Linear: 0.062204837716108 nn.Linear: 0.044211237701251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031317508263165 nn.Linear: 0.024614804064981] nn.Sequential: [nn.Linear: 0.03126375820398 nn.Linear: 0.02180286531935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.17583213746548 nn.Linear: 0.14408911764622 nn.Linear: 0.095533601939678 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065734080970287 nn.Linear: 0.076696917414665] nn.Sequential: [nn.Linear: 0.067297145724297 nn.Linear: 0.057655245065689]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031944045375334 nn.Linear: 0.0012020816140422 nn.Linear: 0.00057248768762548 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029659384030633 nn.Linear: 0.01083785250207] nn.Sequential: [nn.Linear: 8.6331152292089e-05 nn.Linear: 0.0012438528721203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.02953409217298 nn.Linear: 0.034695405513048 nn.Linear: 0.01896314509213 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010642969980836 nn.Linear: 0.07161208242178] nn.Sequential: [nn.Linear: 0.0030178376473486 nn.Linear: 0.011363101191819]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062487277042348 nn.Linear: 0.062213189452424 nn.Linear: 0.044213542696334 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031317885261046 nn.Linear: 0.024711745256809] nn.Sequential: [nn.Linear: 0.031263885081457 nn.Linear: 0.02181841776483]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.17838680744171 nn.Linear: 0.14379526674747 nn.Linear: 0.09604986011982 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.065987654030323 nn.Linear: 0.077111057937145] nn.Sequential: [nn.Linear: 0.067395240068436 nn.Linear: 0.057891972362995]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015869823498026 nn.Linear: 0.00076963524523216 nn.Linear: 0.00041801291083009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014962611650117 nn.Linear: 0.004450786485043] nn.Sequential: [nn.Linear: 0.00017969749335285 nn.Linear: 0.0033472687468435]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019501756876707 nn.Linear: 0.014649214223027 nn.Linear: 0.0089397178962827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058317207731307 nn.Linear: 0.028224233537912] nn.Sequential: [nn.Linear: 0.0058571011759341 nn.Linear: 0.037738382816315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062491115328124 nn.Linear: 0.062221426878128 nn.Linear: 0.044215731438108 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031318122622938 nn.Linear: 0.024796066213606] nn.Sequential: [nn.Linear: 0.031264308307711 nn.Linear: 0.021859920583628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.18071776628494 nn.Linear: 0.14459151029587 nn.Linear: 0.09635765850544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.066242419183254 nn.Linear: 0.077796198427677] nn.Sequential: [nn.Linear: 0.067579336464405 nn.Linear: 0.057928409427404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012000979866369 nn.Linear: 0.00061401307757102 nn.Linear: 0.00030254518785099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6346521607445e-05 nn.Linear: 0.0025212174729559] nn.Sequential: [nn.Linear: 0.00011507805078996 nn.Linear: 0.0017554662916391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015388261526823 nn.Linear: 0.015484320931137 nn.Linear: 0.0096866311505437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0041875941678882 nn.Linear: 0.01920104585588] nn.Sequential: [nn.Linear: 0.005227412097156 nn.Linear: 0.016724085435271]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062503838117474 nn.Linear: 0.062229624639189 nn.Linear: 0.044218975325458 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031318392648083 nn.Linear: 0.024902445823944] nn.Sequential: [nn.Linear: 0.03126486459917 nn.Linear: 0.021921141246358]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.18298868834972 nn.Linear: 0.14542031288147 nn.Linear: 0.096895344555378 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.066452406346798 nn.Linear: 0.077502995729446] nn.Sequential: [nn.Linear: 0.067619793117046 nn.Linear: 0.058613188564777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0029294867523772 nn.Linear: 0.0012427413715968 nn.Linear: 0.0006447957767373 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033528902401708 nn.Linear: 0.0127516771248] nn.Sequential: [nn.Linear: 0.00017716735462929 nn.Linear: 0.0030782072174483]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023875251412392 nn.Linear: 0.037300489842892 nn.Linear: 0.019148444756866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011110004037619 nn.Linear: 0.076420933008194] nn.Sequential: [nn.Linear: 0.0053303642198443 nn.Linear: 0.031141588464379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062512403343122 nn.Linear: 0.062235618690742 nn.Linear: 0.044221393782877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031318733469143 nn.Linear: 0.025050674515811] nn.Sequential: [nn.Linear: 0.031265354582186 nn.Linear: 0.021963540226845]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.18508139252663 nn.Linear: 0.1467243283987 nn.Linear: 0.097219176590443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.066542334854603 nn.Linear: 0.078671619296074] nn.Sequential: [nn.Linear: 0.067477725446224 nn.Linear: 0.057926867157221]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019703777313066 nn.Linear: 0.00082556268837987 nn.Linear: 0.00045923733059307 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017219856125975 nn.Linear: 0.0054575570587553] nn.Sequential: [nn.Linear: 0.00019140442234977 nn.Linear: 0.0034105552663179]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017085079103708 nn.Linear: 0.017787419259548 nn.Linear: 0.013736076653004 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056408108212054 nn.Linear: 0.037632197141647] nn.Sequential: [nn.Linear: 0.0071431640535593 nn.Linear: 0.036606140434742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062521991569982 nn.Linear: 0.062242371127278 nn.Linear: 0.044223879132993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031318937044727 nn.Linear: 0.025117057875633] nn.Sequential: [nn.Linear: 0.031265804916707 nn.Linear: 0.02200585742962]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.18643248081207 nn.Linear: 0.14654050767422 nn.Linear: 0.097573667764664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.066676899790764 nn.Linear: 0.07942308485508] nn.Sequential: [nn.Linear: 0.067681938409805 nn.Linear: 0.058669447898865]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091548337147316 nn.Linear: 0.00046370450530128 nn.Linear: 0.00026211880258076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010892129876529 nn.Linear: 0.0034069945908548] nn.Sequential: [nn.Linear: 0.00011473747621188 nn.Linear: 0.0021153642855452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01063072681427 nn.Linear: 0.01192625798285 nn.Linear: 0.0085739884525537 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004107064101845 nn.Linear: 0.024967316538095] nn.Sequential: [nn.Linear: 0.0043379934504628 nn.Linear: 0.01670709811151]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062528813418885 nn.Linear: 0.062248453411035 nn.Linear: 0.044227392160222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03131947557741 nn.Linear: 0.025266124187112] nn.Sequential: [nn.Linear: 0.031266279218915 nn.Linear: 0.02205000542603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.18951657414436 nn.Linear: 0.14659261703491 nn.Linear: 0.098638497292995 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.066880747675896 nn.Linear: 0.079884223639965] nn.Sequential: [nn.Linear: 0.067786350846291 nn.Linear: 0.05994575843215]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012430204213042 nn.Linear: 0.00060746237684978 nn.Linear: 0.00031241884856658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013206466672044 nn.Linear: 0.0035944815205363] nn.Sequential: [nn.Linear: 8.6874306836303e-05 nn.Linear: 0.0011603319274655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012015249580145 nn.Linear: 0.013200165703893 nn.Linear: 0.0088400486856699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037344065494835 nn.Linear: 0.025935471057892] nn.Sequential: [nn.Linear: 0.0029285731725395 nn.Linear: 0.011215523816645]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062539194588554 nn.Linear: 0.062255788345305 nn.Linear: 0.044230746822353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031319695697885 nn.Linear: 0.025373733244805] nn.Sequential: [nn.Linear: 0.031266742916919 nn.Linear: 0.022113211655401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19024233520031 nn.Linear: 0.1483740657568 nn.Linear: 0.098982386291027 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.067242801189423 nn.Linear: 0.081666760146618] nn.Sequential: [nn.Linear: 0.068068198859692 nn.Linear: 0.060671124607325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015295353888686 nn.Linear: 0.00077887657496224 nn.Linear: 0.00044460135509751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020331279400099 nn.Linear: 0.0067720511372769] nn.Sequential: [nn.Linear: 0.00016208085837883 nn.Linear: 0.0026410004391455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014188517816365 nn.Linear: 0.016785269603133 nn.Linear: 0.010285040363669 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070986147038639 nn.Linear: 0.045830022543669] nn.Sequential: [nn.Linear: 0.0053199473768473 nn.Linear: 0.024633063003421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062552071288247 nn.Linear: 0.062260307395611 nn.Linear: 0.044233198572066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031320295486517 nn.Linear: 0.025621982121642] nn.Sequential: [nn.Linear: 0.031267099793879 nn.Linear: 0.022138753765218]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19188012182713 nn.Linear: 0.14933227002621 nn.Linear: 0.099271178245544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.067374207079411 nn.Linear: 0.083072081208229] nn.Sequential: [nn.Linear: 0.068108528852463 nn.Linear: 0.060793358832598]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012335464708791 nn.Linear: 0.00059968740959593 nn.Linear: 0.00032073989599243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.8975395578714e-05 nn.Linear: 0.0018183364284892] nn.Sequential: [nn.Linear: 0.00014181922729188 nn.Linear: 0.0025378583761581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012224840000272 nn.Linear: 0.010092587210238 nn.Linear: 0.0075475075282156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037935271393508 nn.Linear: 0.011060451157391] nn.Sequential: [nn.Linear: 0.0045370534062386 nn.Linear: 0.01835685968399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062558242735711 nn.Linear: 0.062268740397369 nn.Linear: 0.044235997042559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031320539909274 nn.Linear: 0.025695780499319] nn.Sequential: [nn.Linear: 0.031267312217063 nn.Linear: 0.022159208736626]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19358645379543 nn.Linear: 0.15085016191006 nn.Linear: 0.10003580152988 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.067642442882061 nn.Linear: 0.082389935851097] nn.Sequential: [nn.Linear: 0.067991338670254 nn.Linear: 0.060832463204861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017779704892388 nn.Linear: 0.00078473065558128 nn.Linear: 0.00041134248332613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011793239713532 nn.Linear: 0.0023570041701482] nn.Sequential: [nn.Linear: 0.00012304658248529 nn.Linear: 0.001704729295198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014358533546329 nn.Linear: 0.020830720663071 nn.Linear: 0.013881328515708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050317919813097 nn.Linear: 0.016579041257501] nn.Sequential: [nn.Linear: 0.0050577102228999 nn.Linear: 0.018428286537528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062571563959461 nn.Linear: 0.062278375368693 nn.Linear: 0.044239355686904 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031320901607716 nn.Linear: 0.025785650561318] nn.Sequential: [nn.Linear: 0.031268061015426 nn.Linear: 0.022212120408163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19649966061115 nn.Linear: 0.15154774487019 nn.Linear: 0.099712692201138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.067756243050098 nn.Linear: 0.082765720784664] nn.Sequential: [nn.Linear: 0.067999258637428 nn.Linear: 0.061766650527716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022387556740992 nn.Linear: 0.0010762906339234 nn.Linear: 0.00060066080279629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028600286918918 nn.Linear: 0.009878529614488] nn.Sequential: [nn.Linear: 0.00015526761895545 nn.Linear: 0.0025866148596631]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021093893796206 nn.Linear: 0.032002724707127 nn.Linear: 0.012652727775276 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099832098931074 nn.Linear: 0.06462175399065] nn.Sequential: [nn.Linear: 0.0049532786943018 nn.Linear: 0.027001725509763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.20339845836163	TD error	0.030289601549506	Qmax	1	

Steps: 250000 (frames: 1000000), score: 1225.39, higheset score: 4252, epsilon: 0.05, lr: 0.0005, training time: 307s, training rate: 3253fps, testing time: 89s, testing rate: 5604fps,  num. ep.: 184,  num. rewards: 8703	
   2    4    8    2
   4    8   16   32
   2   16  512    4
   8   32    4    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062563561966757 nn.Linear: 0.06227598982359 nn.Linear: 0.044239123288735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031320830515607 nn.Linear: 0.025774490612939] nn.Sequential: [nn.Linear: 0.031267885048853 nn.Linear: 0.02219031612276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19760324060917 nn.Linear: 0.15143895149231 nn.Linear: 0.10001066327095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.067973345518112 nn.Linear: 0.081291913986206] nn.Sequential: [nn.Linear: 0.06815529614687 nn.Linear: 0.062158368527889]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014169125978618 nn.Linear: 0.0008042341744627 nn.Linear: 0.00043845719142601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012143339595976 nn.Linear: 0.0030264002491409] nn.Sequential: [nn.Linear: 0.00021218459244357 nn.Linear: 0.0034451472295242]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015959555283189 nn.Linear: 0.020883509889245 nn.Linear: 0.011128376238048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049747214652598 nn.Linear: 0.022117471322417] nn.Sequential: [nn.Linear: 0.006350633688271 nn.Linear: 0.034887570887804]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062568656729159 nn.Linear: 0.062276666286738 nn.Linear: 0.04424008024018 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031320916226137 nn.Linear: 0.025771253409289] nn.Sequential: [nn.Linear: 0.031268057883539 nn.Linear: 0.022198577145224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.19931508600712 nn.Linear: 0.15295915305614 nn.Linear: 0.10020752996206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068085320293903 nn.Linear: 0.081477791070938] nn.Sequential: [nn.Linear: 0.068284370005131 nn.Linear: 0.06219694763422]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012188151707146 nn.Linear: 0.00056172814744218 nn.Linear: 0.00030571432010627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014459189208842 nn.Linear: 0.0048795687563423] nn.Sequential: [nn.Linear: 7.3255090959707e-05 nn.Linear: 0.00081717807545857]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015951430425048 nn.Linear: 0.012778097763658 nn.Linear: 0.0082214046269655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044521735981107 nn.Linear: 0.02897677756846] nn.Sequential: [nn.Linear: 0.0021599158644676 nn.Linear: 0.0061345309950411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062574097983826 nn.Linear: 0.062281405316819 nn.Linear: 0.044241527226798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031321053900156 nn.Linear: 0.025774342940849] nn.Sequential: [nn.Linear: 0.031268322626561 nn.Linear: 0.022224273185033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.20031887292862 nn.Linear: 0.15326088666916 nn.Linear: 0.10053018480539 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068171918392181 nn.Linear: 0.080948121845722] nn.Sequential: [nn.Linear: 0.068239241838455 nn.Linear: 0.063230626285076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011455080164101 nn.Linear: 0.00053651358059968 nn.Linear: 0.000269135417922 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001052689809471 nn.Linear: 0.003069158567415] nn.Sequential: [nn.Linear: 9.2112188527798e-05 nn.Linear: 0.0015034075109138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083074336871505 nn.Linear: 0.0081202629953623 nn.Linear: 0.0052528320811689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035367214586586 nn.Linear: 0.019799746572971] nn.Sequential: [nn.Linear: 0.0026538774836808 nn.Linear: 0.012274946086109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062570383314917 nn.Linear: 0.062285113175457 nn.Linear: 0.044243031867426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03132117201422 nn.Linear: 0.025766003260575] nn.Sequential: [nn.Linear: 0.031268559727535 nn.Linear: 0.022248554767657]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.20247672498226 nn.Linear: 0.15317060053349 nn.Linear: 0.10093322396278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068294495344162 nn.Linear: 0.08186312019825] nn.Sequential: [nn.Linear: 0.068236544728279 nn.Linear: 0.063677571713924]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011240689018737 nn.Linear: 0.00062709510389031 nn.Linear: 0.00032704755058642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001397041821537 nn.Linear: 0.0039959291982044] nn.Sequential: [nn.Linear: 0.00010400882985626 nn.Linear: 0.0016658724994608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013273311778903 nn.Linear: 0.016406912356615 nn.Linear: 0.0089485971257091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042069535702467 nn.Linear: 0.025562571361661] nn.Sequential: [nn.Linear: 0.0029596840031445 nn.Linear: 0.014453817158937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06257817142376 nn.Linear: 0.062288470727713 nn.Linear: 0.044243878069646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031321551804232 nn.Linear: 0.025872042508418] nn.Sequential: [nn.Linear: 0.031268664142167 nn.Linear: 0.022260334563233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.20340883731842 nn.Linear: 0.15341943502426 nn.Linear: 0.10059240460396 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068324021995068 nn.Linear: 0.081955902278423] nn.Sequential: [nn.Linear: 0.068244747817516 nn.Linear: 0.063970878720284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018614077619906 nn.Linear: 0.00078024702024549 nn.Linear: 0.00039319696077408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018087509126223 nn.Linear: 0.0060922176642062] nn.Sequential: [nn.Linear: 0.00011107979870978 nn.Linear: 0.0017516736827531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016837803646922 nn.Linear: 0.019356245175004 nn.Linear: 0.010302262380719 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066895624622703 nn.Linear: 0.036732211709023] nn.Sequential: [nn.Linear: 0.0037087092641741 nn.Linear: 0.017314316704869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062582283328859 nn.Linear: 0.062291789266576 nn.Linear: 0.04424595276108 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322032661958 nn.Linear: 0.025950421586742] nn.Sequential: [nn.Linear: 0.031268958871001 nn.Linear: 0.022280131562081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2047703564167 nn.Linear: 0.15383245050907 nn.Linear: 0.10092311352491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068640001118183 nn.Linear: 0.082425035536289] nn.Sequential: [nn.Linear: 0.067977875471115 nn.Linear: 0.064048491418362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019377673991455 nn.Linear: 0.00077017316167272 nn.Linear: 0.00043216126608981 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017009472800947 nn.Linear: 0.0061711280148173] nn.Sequential: [nn.Linear: 0.00016821714648616 nn.Linear: 0.0028788195229944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023274136707187 nn.Linear: 0.023114884272218 nn.Linear: 0.012410058639944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069099352695048 nn.Linear: 0.042061176151037] nn.Sequential: [nn.Linear: 0.0051069403998554 nn.Linear: 0.028166528791189]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584084839111 nn.Linear: 0.062294892729719 nn.Linear: 0.0442471341876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322244640321 nn.Linear: 0.026001891887717] nn.Sequential: [nn.Linear: 0.031269127024434 nn.Linear: 0.022300657326742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.20619332790375 nn.Linear: 0.15460096299648 nn.Linear: 0.10072461515665 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.068754121661186 nn.Linear: 0.083273030817509] nn.Sequential: [nn.Linear: 0.068032033741474 nn.Linear: 0.064772881567478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021580601124896 nn.Linear: 0.0010942511205238 nn.Linear: 0.00051783203006825 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030305138143839 nn.Linear: 0.011052427173097] nn.Sequential: [nn.Linear: 0.00012316078623181 nn.Linear: 0.0021221694043649]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025859555229545 nn.Linear: 0.027757415547967 nn.Linear: 0.021108189597726 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094970446079969 nn.Linear: 0.065050132572651] nn.Sequential: [nn.Linear: 0.0044776466675103 nn.Linear: 0.021716572344303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06258853471471 nn.Linear: 0.062298223279811 nn.Linear: 0.044248805018124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322196328026 nn.Linear: 0.025984350148264] nn.Sequential: [nn.Linear: 0.031269281892959 nn.Linear: 0.022312335872853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.20717573165894 nn.Linear: 0.15485544502735 nn.Linear: 0.10112592577934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069020964205265 nn.Linear: 0.082012876868248] nn.Sequential: [nn.Linear: 0.067925199866295 nn.Linear: 0.06529325991869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001162097149311 nn.Linear: 0.00060339952830111 nn.Linear: 0.00034597317997885 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2169892216819e-05 nn.Linear: 0.002482393015224] nn.Sequential: [nn.Linear: 0.00014118350779555 nn.Linear: 0.0025384183478509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014170427806675 nn.Linear: 0.013214685954154 nn.Linear: 0.006083978805691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040505900979042 nn.Linear: 0.017007362097502] nn.Sequential: [nn.Linear: 0.0049728346057236 nn.Linear: 0.015364670194685]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581293742332 nn.Linear: 0.062299087639818 nn.Linear: 0.044249689294543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322210175818 nn.Linear: 0.025963317028413] nn.Sequential: [nn.Linear: 0.031269602954687 nn.Linear: 0.022332155582799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2095929980278 nn.Linear: 0.1555537134409 nn.Linear: 0.10092730820179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069035947322845 nn.Linear: 0.082430548965931] nn.Sequential: [nn.Linear: 0.067961379885674 nn.Linear: 0.065751664340496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020317750620843 nn.Linear: 0.00099828587475278 nn.Linear: 0.00045347696203635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019951961575691 nn.Linear: 0.0064111666875242] nn.Sequential: [nn.Linear: 0.00013511705826778 nn.Linear: 0.0024930804973283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017853314056993 nn.Linear: 0.020773092284799 nn.Linear: 0.013449888676405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086154704913497 nn.Linear: 0.043549343943596] nn.Sequential: [nn.Linear: 0.004663382191211 nn.Linear: 0.018630405887961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062582567384123 nn.Linear: 0.062300917086346 nn.Linear: 0.044251511435069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322514396413 nn.Linear: 0.026006934308256] nn.Sequential: [nn.Linear: 0.031269875256495 nn.Linear: 0.022358930287169]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21120248734951 nn.Linear: 0.15546874701977 nn.Linear: 0.10137138515711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.06898707896471 nn.Linear: 0.083108618855476] nn.Sequential: [nn.Linear: 0.068012461066246 nn.Linear: 0.065876208245754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00067840976220493 nn.Linear: 0.00039609292735808 nn.Linear: 0.00024529359549744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.3418316874829e-05 nn.Linear: 0.0015627819888389] nn.Sequential: [nn.Linear: 0.00011109892086597 nn.Linear: 0.0020566640085262]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052779568359256 nn.Linear: 0.0059797097928822 nn.Linear: 0.0046122958883643 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0021632059942931 nn.Linear: 0.009648728184402] nn.Sequential: [nn.Linear: 0.0038387682288885 nn.Linear: 0.011889926157892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581088792044 nn.Linear: 0.062304325150867 nn.Linear: 0.044252548861869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031322731052096 nn.Linear: 0.026055170759562] nn.Sequential: [nn.Linear: 0.031270077645814 nn.Linear: 0.022371636939187]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21158567070961 nn.Linear: 0.1563004553318 nn.Linear: 0.10158124566078 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069390714168549 nn.Linear: 0.083100371062756] nn.Sequential: [nn.Linear: 0.068010181188583 nn.Linear: 0.066153764724731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017444878617621 nn.Linear: 0.00085019028287698 nn.Linear: 0.00045329104211473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021495171970468 nn.Linear: 0.0070129411334102] nn.Sequential: [nn.Linear: 0.00011721585223581 nn.Linear: 0.0019729445089708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012419172562659 nn.Linear: 0.020050745457411 nn.Linear: 0.012253041379154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072617847472429 nn.Linear: 0.044811964035034] nn.Sequential: [nn.Linear: 0.0033948491327465 nn.Linear: 0.019098060205579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062580612724778 nn.Linear: 0.062307262369189 nn.Linear: 0.04425367519137 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03132284412195 nn.Linear: 0.026042209347622] nn.Sequential: [nn.Linear: 0.031270225153363 nn.Linear: 0.022393064373861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21301437914371 nn.Linear: 0.15651525557041 nn.Linear: 0.10159941017628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069399125874043 nn.Linear: 0.083504714071751] nn.Sequential: [nn.Linear: 0.067904874682426 nn.Linear: 0.066580198705196]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010793528706202 nn.Linear: 0.00052012699705604 nn.Linear: 0.00026798588870268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8085809439734e-05 nn.Linear: 0.0018093315359545] nn.Sequential: [nn.Linear: 8.7167718474057e-05 nn.Linear: 0.0012879863901565]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092089390382171 nn.Linear: 0.010237480513752 nn.Linear: 0.0083390967920423 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038379896432161 nn.Linear: 0.013070887885988] nn.Sequential: [nn.Linear: 0.0032381534110755 nn.Linear: 0.013456634245813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581142271661 nn.Linear: 0.062311507728351 nn.Linear: 0.044254870445435 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031323047918313 nn.Linear: 0.026072463810479] nn.Sequential: [nn.Linear: 0.031270684825267 nn.Linear: 0.022418305875146]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21366016566753 nn.Linear: 0.15619817376137 nn.Linear: 0.10093470662832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069176830351353 nn.Linear: 0.083811119198799] nn.Sequential: [nn.Linear: 0.068035706877708 nn.Linear: 0.066683925688267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015673798675545 nn.Linear: 0.00082630320736752 nn.Linear: 0.0004527059260329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013034564865333 nn.Linear: 0.0032510004284881] nn.Sequential: [nn.Linear: 0.00018390480031805 nn.Linear: 0.0029781723353336]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013949266634881 nn.Linear: 0.013917366974056 nn.Linear: 0.01020782161504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049709547311068 nn.Linear: 0.025088422000408] nn.Sequential: [nn.Linear: 0.0064943465404212 nn.Linear: 0.025445966050029]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06257603532837 nn.Linear: 0.062311586590229 nn.Linear: 0.044255844338197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031323173413398 nn.Linear: 0.026061647797874] nn.Sequential: [nn.Linear: 0.031270882736765 nn.Linear: 0.022440852073031]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21469810605049 nn.Linear: 0.1564906835556 nn.Linear: 0.10124687850475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069201342761517 nn.Linear: 0.08387067168951] nn.Sequential: [nn.Linear: 0.067977741360664 nn.Linear: 0.066820785403252]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013495875465709 nn.Linear: 0.00066782949039702 nn.Linear: 0.00032997215004174 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016814276112453 nn.Linear: 0.0058166445864904] nn.Sequential: [nn.Linear: 5.2937636590247e-05 nn.Linear: 0.00074936898965182]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012345896102488 nn.Linear: 0.017612412571907 nn.Linear: 0.0097822621464729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006048284471035 nn.Linear: 0.032965652644634] nn.Sequential: [nn.Linear: 0.001452099531889 nn.Linear: 0.0080182440578938]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062569804550177 nn.Linear: 0.062313157441185 nn.Linear: 0.044257047578839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031323531681973 nn.Linear: 0.026152861355811] nn.Sequential: [nn.Linear: 0.031270865100203 nn.Linear: 0.022448147512552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21548509597778 nn.Linear: 0.15777659416199 nn.Linear: 0.10174722969532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069287814199924 nn.Linear: 0.084089323878288] nn.Sequential: [nn.Linear: 0.067978464066982 nn.Linear: 0.066926173865795]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024756250645684 nn.Linear: 0.0012541614729524 nn.Linear: 0.00062483526324434 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003302907312334 nn.Linear: 0.011653814382668] nn.Sequential: [nn.Linear: 0.00012014730523981 nn.Linear: 0.0017326869373211]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021296832710505 nn.Linear: 0.031635656952858 nn.Linear: 0.016929032281041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010032263584435 nn.Linear: 0.066309243440628] nn.Sequential: [nn.Linear: 0.0029917387291789 nn.Linear: 0.014288539998233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062572481971676 nn.Linear: 0.06231901625223 nn.Linear: 0.04425866244244 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031323893698382 nn.Linear: 0.026218500614164] nn.Sequential: [nn.Linear: 0.031271191113525 nn.Linear: 0.022467689852949]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21661639213562 nn.Linear: 0.15854074060917 nn.Linear: 0.10157500952482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069512583315372 nn.Linear: 0.084021188318729] nn.Sequential: [nn.Linear: 0.067978605628014 nn.Linear: 0.067036263644695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014707785330968 nn.Linear: 0.0006518439974793 nn.Linear: 0.00034615373181486 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014055994436062 nn.Linear: 0.004824955579164] nn.Sequential: [nn.Linear: 0.00011428196182934 nn.Linear: 0.0019541734461569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011667265556753 nn.Linear: 0.014426003210247 nn.Linear: 0.0096070384606719 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050738477148116 nn.Linear: 0.031633891165257] nn.Sequential: [nn.Linear: 0.0040489481762052 nn.Linear: 0.019581072032452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062570486122845 nn.Linear: 0.062321437642541 nn.Linear: 0.044259500356537 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031324093867052 nn.Linear: 0.026257692295943] nn.Sequential: [nn.Linear: 0.031271372286656 nn.Linear: 0.022475009290069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2183736115694 nn.Linear: 0.15849827229977 nn.Linear: 0.10211030393839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069319725036621 nn.Linear: 0.084685899317265] nn.Sequential: [nn.Linear: 0.068059168756008 nn.Linear: 0.067524380981922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013730916729909 nn.Linear: 0.00065918501951203 nn.Linear: 0.00033565623934142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001374925144405 nn.Linear: 0.0035832699326993] nn.Sequential: [nn.Linear: 9.2838427560632e-05 nn.Linear: 0.0013755277854578]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012382922694087 nn.Linear: 0.010632082819939 nn.Linear: 0.0062832050025463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049179047346115 nn.Linear: 0.024256948381662] nn.Sequential: [nn.Linear: 0.002750766929239 nn.Linear: 0.015548611991107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062572447691657 nn.Linear: 0.062323961960208 nn.Linear: 0.044260900278433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031324110995581 nn.Linear: 0.026248772292433] nn.Sequential: [nn.Linear: 0.031271679479791 nn.Linear: 0.022493499485371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21932154893875 nn.Linear: 0.15776327252388 nn.Linear: 0.10192588716745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069155052304268 nn.Linear: 0.085096821188927] nn.Sequential: [nn.Linear: 0.06810637563467 nn.Linear: 0.06744471937418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093261213862646 nn.Linear: 0.00050124792825928 nn.Linear: 0.00025162769150167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.6367406289674e-05 nn.Linear: 0.0021533409409289] nn.Sequential: [nn.Linear: 0.00011246164889522 nn.Linear: 0.0020583753310467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094158751890063 nn.Linear: 0.010859626345336 nn.Linear: 0.0083237830549479 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034314033109695 nn.Linear: 0.012362172827125] nn.Sequential: [nn.Linear: 0.0033773460891098 nn.Linear: 0.018891990184784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062570491363681 nn.Linear: 0.062326236600407 nn.Linear: 0.044261945464202 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031324410085379 nn.Linear: 0.02628501753032] nn.Sequential: [nn.Linear: 0.031271784824074 nn.Linear: 0.022507776363511]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.21981479227543 nn.Linear: 0.15860438346863 nn.Linear: 0.10199201852083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069455064833164 nn.Linear: 0.084857329726219] nn.Sequential: [nn.Linear: 0.068214416503906 nn.Linear: 0.06814631074667]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001219540768146 nn.Linear: 0.00073418691600172 nn.Linear: 0.00037578295502549 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016472175563819 nn.Linear: 0.0045963677215275] nn.Sequential: [nn.Linear: 8.3561458659876e-05 nn.Linear: 0.0011675638315884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011093458160758 nn.Linear: 0.012706406414509 nn.Linear: 0.0092257941141725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051899086683989 nn.Linear: 0.035069033503532] nn.Sequential: [nn.Linear: 0.0024173553101718 nn.Linear: 0.011319056153297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062560801759163 nn.Linear: 0.062328465314113 nn.Linear: 0.044262957383146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031324730467316 nn.Linear: 0.026367785090059] nn.Sequential: [nn.Linear: 0.03127195902097 nn.Linear: 0.022514470550075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22041617333889 nn.Linear: 0.15773805975914 nn.Linear: 0.10213070362806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.06965809315443 nn.Linear: 0.085735134780407] nn.Sequential: [nn.Linear: 0.068263605237007 nn.Linear: 0.067503780126572]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010367283781261 nn.Linear: 0.00052812492586599 nn.Linear: 0.00023929982280326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6296618055891e-05 nn.Linear: 0.0019538018924545] nn.Sequential: [nn.Linear: 7.0767835447321e-05 nn.Linear: 0.00099324981931771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007012533955276 nn.Linear: 0.010598662309349 nn.Linear: 0.0068851290270686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039889425970614 nn.Linear: 0.012382619082928] nn.Sequential: [nn.Linear: 0.0021607812959701 nn.Linear: 0.007791783194989]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062565559790643 nn.Linear: 0.062334000303477 nn.Linear: 0.044264936885543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031325178396063 nn.Linear: 0.026470125131667] nn.Sequential: [nn.Linear: 0.031272282242914 nn.Linear: 0.022543484173896]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22174282371998 nn.Linear: 0.15766194462776 nn.Linear: 0.10226569324732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069582052528858 nn.Linear: 0.085686817765236] nn.Sequential: [nn.Linear: 0.068197622895241 nn.Linear: 0.067501664161682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071893620628944 nn.Linear: 0.0003302519850848 nn.Linear: 0.00016759541300799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.518200594406e-05 nn.Linear: 0.0012114423428686] nn.Sequential: [nn.Linear: 4.7718786526156e-05 nn.Linear: 0.00054452310063856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049676741473377 nn.Linear: 0.0063291918486357 nn.Linear: 0.0061555607244372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0025802259333432 nn.Linear: 0.0078801028430462] nn.Sequential: [nn.Linear: 0.001766310306266 nn.Linear: 0.0053577516227961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062570144538264 nn.Linear: 0.062338448622399 nn.Linear: 0.044266566929788 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03132564239291 nn.Linear: 0.026575999802617] nn.Sequential: [nn.Linear: 0.03127247889225 nn.Linear: 0.022546986922375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22317616641521 nn.Linear: 0.15867204964161 nn.Linear: 0.10213518887758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069566629827023 nn.Linear: 0.086012944579124] nn.Sequential: [nn.Linear: 0.068143576383591 nn.Linear: 0.067741103470325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086574157972505 nn.Linear: 0.00036395485058293 nn.Linear: 0.00018022215001951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.4766538561038e-05 nn.Linear: 0.00098637603598439] nn.Sequential: [nn.Linear: 6.8582607552834e-05 nn.Linear: 0.0010807466455876]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046864552423358 nn.Linear: 0.0068652462214231 nn.Linear: 0.0042985179461539 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029002267401665 nn.Linear: 0.0058283694088459] nn.Sequential: [nn.Linear: 0.0025235076900572 nn.Linear: 0.0081433709710836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062568353568023 nn.Linear: 0.062340320908649 nn.Linear: 0.044268035640093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031325980019202 nn.Linear: 0.026652766628303] nn.Sequential: [nn.Linear: 0.031272801686384 nn.Linear: 0.022569744718657]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22408252954483 nn.Linear: 0.15914875268936 nn.Linear: 0.10172184556723 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069901287555695 nn.Linear: 0.08589892834425] nn.Sequential: [nn.Linear: 0.068212881684303 nn.Linear: 0.068231381475925]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012467090550784 nn.Linear: 0.00059096783670827 nn.Linear: 0.00030523706780986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.983693433685e-05 nn.Linear: 0.0017816172656779] nn.Sequential: [nn.Linear: 0.00014146599470871 nn.Linear: 0.0025165462141751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077345641329885 nn.Linear: 0.010711872018874 nn.Linear: 0.0067342640832067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039325105026364 nn.Linear: 0.010694560594857] nn.Sequential: [nn.Linear: 0.0050801369361579 nn.Linear: 0.021268367767334]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06256410888128 nn.Linear: 0.062343960914375 nn.Linear: 0.044269764725516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326413337899 nn.Linear: 0.026734948076186] nn.Sequential: [nn.Linear: 0.031272846373885 nn.Linear: 0.022587028796503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22582560777664 nn.Linear: 0.16002653539181 nn.Linear: 0.10187216848135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070005171000957 nn.Linear: 0.08694339543581] nn.Sequential: [nn.Linear: 0.068296238780022 nn.Linear: 0.068961203098297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012025458760428 nn.Linear: 0.0006044981977344 nn.Linear: 0.00034232424149699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011044659120185 nn.Linear: 0.0034726418851658] nn.Sequential: [nn.Linear: 0.0001309093580234 nn.Linear: 0.0020527141491767]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068374709226191 nn.Linear: 0.010847295634449 nn.Linear: 0.0062329755164683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033921834547073 nn.Linear: 0.024041717872024] nn.Sequential: [nn.Linear: 0.0051437197253108 nn.Linear: 0.019629223272204]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06256119039146 nn.Linear: 0.062347212972409 nn.Linear: 0.044270382717573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326504128287 nn.Linear: 0.026767735907896] nn.Sequential: [nn.Linear: 0.03127307361011 nn.Linear: 0.022609802912281]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22671748697758 nn.Linear: 0.16023850440979 nn.Linear: 0.10225501656532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070066623389721 nn.Linear: 0.087227433919907] nn.Sequential: [nn.Linear: 0.068372137844563 nn.Linear: 0.069151341915131]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001293471893732 nn.Linear: 0.00080867095104195 nn.Linear: 0.00044999332693093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018593138864615 nn.Linear: 0.0059225643074186] nn.Sequential: [nn.Linear: 0.00018270198373712 nn.Linear: 0.0030680116619263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097412085160613 nn.Linear: 0.013112293556333 nn.Linear: 0.0093330610543489 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064031486399472 nn.Linear: 0.033794239163399] nn.Sequential: [nn.Linear: 0.0069262152537704 nn.Linear: 0.025468921288848]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.17587951262295	TD error	0.024398230582476	Qmax	1	

Steps: 500000 (frames: 2000000), score: 1338.94, higheset score: 4352, epsilon: 0.05, lr: 0.0005, training time: 437s, training rate: 2285fps, testing time: 97s, testing rate: 5136fps,  num. ep.: 208,  num. rewards: 8553	
   2    8    4    2
   4   16   64    8
   8    4  512    2
   4    8   16    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06255945929882 nn.Linear: 0.062346639980487 nn.Linear: 0.044270151225329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03132641969263 nn.Linear: 0.026709348244957] nn.Sequential: [nn.Linear: 0.031273008706677 nn.Linear: 0.02259693376186]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22740508615971 nn.Linear: 0.16013842821121 nn.Linear: 0.10261254012585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070040337741375 nn.Linear: 0.086483992636204] nn.Sequential: [nn.Linear: 0.06840181350708 nn.Linear: 0.068813867866993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013876753529625 nn.Linear: 0.00058265863009889 nn.Linear: 0.00025229352261735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.2884986116946e-05 nn.Linear: 0.002152403245907] nn.Sequential: [nn.Linear: 8.1191884440011e-05 nn.Linear: 0.0012440265988883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01168507616967 nn.Linear: 0.0092366077005863 nn.Linear: 0.0095419371500611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046542566269636 nn.Linear: 0.017002569511533] nn.Sequential: [nn.Linear: 0.0021883279550821 nn.Linear: 0.010806891135871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062552036496441 nn.Linear: 0.062342357146899 nn.Linear: 0.044268850990345 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326435721921 nn.Linear: 0.026694551135563] nn.Sequential: [nn.Linear: 0.031272730603669 nn.Linear: 0.022567251544888]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22858276963234 nn.Linear: 0.16074141860008 nn.Linear: 0.10204462707043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070061646401882 nn.Linear: 0.086779840290546] nn.Sequential: [nn.Linear: 0.068357944488525 nn.Linear: 0.068148203194141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007734438458734 nn.Linear: 0.0005106746740098 nn.Linear: 0.0002692428562469 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012675547092652 nn.Linear: 0.0041939091821885] nn.Sequential: [nn.Linear: 7.6693737001847e-05 nn.Linear: 0.0013295152574701]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074640507809818 nn.Linear: 0.0096347127109766 nn.Linear: 0.0051596038974822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059397560544312 nn.Linear: 0.025418404489756] nn.Sequential: [nn.Linear: 0.0025827530771494 nn.Linear: 0.011917622759938]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062549272420741 nn.Linear: 0.062341490175096 nn.Linear: 0.044268943653966 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326645307368 nn.Linear: 0.026718051666478] nn.Sequential: [nn.Linear: 0.03127264392338 nn.Linear: 0.022568374455838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.22953128814697 nn.Linear: 0.16053484380245 nn.Linear: 0.10201033204794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069912292063236 nn.Linear: 0.087505109608173] nn.Sequential: [nn.Linear: 0.068266496062279 nn.Linear: 0.068044520914555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012222247183456 nn.Linear: 0.00068173923022316 nn.Linear: 0.00033890442887889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018829933841032 nn.Linear: 0.0066404818750133] nn.Sequential: [nn.Linear: 8.1642195183731e-05 nn.Linear: 0.0012711754791997]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010881288908422 nn.Linear: 0.010647747665644 nn.Linear: 0.0071351174265146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053009283728898 nn.Linear: 0.035415407270193] nn.Sequential: [nn.Linear: 0.0023384992964566 nn.Linear: 0.010442925617099]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062543968066734 nn.Linear: 0.062340289424474 nn.Linear: 0.044268898412066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326787474901 nn.Linear: 0.026722922679312] nn.Sequential: [nn.Linear: 0.03127253119145 nn.Linear: 0.022562079064152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23060522973537 nn.Linear: 0.16124722361565 nn.Linear: 0.10216665267944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069833919405937 nn.Linear: 0.087908744812012] nn.Sequential: [nn.Linear: 0.068268440663815 nn.Linear: 0.068089656531811]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013866373625609 nn.Linear: 0.0005997822376822 nn.Linear: 0.00027489770590282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011922683546039 nn.Linear: 0.0036251174865365] nn.Sequential: [nn.Linear: 7.357360346254e-05 nn.Linear: 0.00094429832979133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010901634581387 nn.Linear: 0.010310284793377 nn.Linear: 0.0064250468276441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063279550522566 nn.Linear: 0.022103926166892] nn.Sequential: [nn.Linear: 0.0023268859367818 nn.Linear: 0.0070482417941093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06254071487569 nn.Linear: 0.062342184896509 nn.Linear: 0.044269239193665 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031326872043296 nn.Linear: 0.026732485877034] nn.Sequential: [nn.Linear: 0.0312725530195 nn.Linear: 0.02256722180217]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23069009184837 nn.Linear: 0.15981069207191 nn.Linear: 0.1019764393568 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069841265678406 nn.Linear: 0.089282691478729] nn.Sequential: [nn.Linear: 0.068402707576752 nn.Linear: 0.068526349961758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017942152345437 nn.Linear: 0.0010410226823955 nn.Linear: 0.00055816519068689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028964951272449 nn.Linear: 0.010057822189489] nn.Sequential: [nn.Linear: 9.503634349954e-05 nn.Linear: 0.0014083846096899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012457242235541 nn.Linear: 0.019461484625936 nn.Linear: 0.01239516492933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097927823662758 nn.Linear: 0.064682237803936] nn.Sequential: [nn.Linear: 0.0027194041758776 nn.Linear: 0.0097666354849935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062534222353934 nn.Linear: 0.06234327800332 nn.Linear: 0.04426929049048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327062248532 nn.Linear: 0.026788695525397] nn.Sequential: [nn.Linear: 0.031272708714394 nn.Linear: 0.022577409926611]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23177091777325 nn.Linear: 0.16105386614799 nn.Linear: 0.10256814211607 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.069965109229088 nn.Linear: 0.089188247919083] nn.Sequential: [nn.Linear: 0.06856232136488 nn.Linear: 0.068131275475025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077486016483755 nn.Linear: 0.00046841348627908 nn.Linear: 0.0002255048003511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.3008003954943e-05 nn.Linear: 0.001850896558595] nn.Sequential: [nn.Linear: 8.211661753838e-05 nn.Linear: 0.0012711838975759]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049838093109429 nn.Linear: 0.010890469886363 nn.Linear: 0.009155984967947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0028177676722407 nn.Linear: 0.013051133602858] nn.Sequential: [nn.Linear: 0.0031910396646708 nn.Linear: 0.011511439457536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06253171669163 nn.Linear: 0.062345032331282 nn.Linear: 0.044269933246605 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327295322958 nn.Linear: 0.02683923493359] nn.Sequential: [nn.Linear: 0.031272838417694 nn.Linear: 0.022590374060135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23215086758137 nn.Linear: 0.16105274856091 nn.Linear: 0.10280203074217 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070067331194878 nn.Linear: 0.089897789061069] nn.Sequential: [nn.Linear: 0.068704225122929 nn.Linear: 0.068240351974964]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016577093593063 nn.Linear: 0.0009172848833142 nn.Linear: 0.0005315629163041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014559348621637 nn.Linear: 0.0027860000806904] nn.Sequential: [nn.Linear: 0.0002504073633144 nn.Linear: 0.0034696440976771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011613464914262 nn.Linear: 0.01798447035253 nn.Linear: 0.014280186966062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069171544164419 nn.Linear: 0.014308946207166] nn.Sequential: [nn.Linear: 0.010395701043308 nn.Linear: 0.039559260010719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062524874101475 nn.Linear: 0.062345904821152 nn.Linear: 0.044270357096438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327310852776 nn.Linear: 0.026858326915963] nn.Sequential: [nn.Linear: 0.031273041095211 nn.Linear: 0.022605642470871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23352958261967 nn.Linear: 0.16167743504047 nn.Linear: 0.10289706289768 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070094026625156 nn.Linear: 0.090051352977753] nn.Sequential: [nn.Linear: 0.068687818944454 nn.Linear: 0.068421058356762]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095037386032313 nn.Linear: 0.00040391879692335 nn.Linear: 0.00020127916569009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.6213607114682e-05 nn.Linear: 0.0016555990488738] nn.Sequential: [nn.Linear: 6.4205932950787e-05 nn.Linear: 0.00083147452769917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058813514187932 nn.Linear: 0.0088434815406799 nn.Linear: 0.0055413893423975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030188856180757 nn.Linear: 0.009910142980516] nn.Sequential: [nn.Linear: 0.0028222873806953 nn.Linear: 0.008381343446672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0625231070479 nn.Linear: 0.062346612838758 nn.Linear: 0.044271890911528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327606238816 nn.Linear: 0.026951453853727] nn.Sequential: [nn.Linear: 0.031273166120716 nn.Linear: 0.022620436071533]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2342699021101 nn.Linear: 0.1616407930851 nn.Linear: 0.10253632813692 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070211060345173 nn.Linear: 0.091221816837788] nn.Sequential: [nn.Linear: 0.068805940449238 nn.Linear: 0.068281263113022]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088182736192949 nn.Linear: 0.00048235229532554 nn.Linear: 0.00023573612861315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010370796415529 nn.Linear: 0.0034235451632822] nn.Sequential: [nn.Linear: 7.8650487962805e-05 nn.Linear: 0.0012695588960154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094554582610726 nn.Linear: 0.0092234704643488 nn.Linear: 0.0048040067777038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0032426395919174 nn.Linear: 0.021152392029762] nn.Sequential: [nn.Linear: 0.0027140348684043 nn.Linear: 0.010164682753384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062520656458869 nn.Linear: 0.062348684394918 nn.Linear: 0.044272130100664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327705028386 nn.Linear: 0.026980311999637] nn.Sequential: [nn.Linear: 0.031273295623685 nn.Linear: 0.022630800148455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2347342222929 nn.Linear: 0.16118024289608 nn.Linear: 0.10284425318241 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070109151303768 nn.Linear: 0.091413967311382] nn.Sequential: [nn.Linear: 0.068880073726177 nn.Linear: 0.068116515874863]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010582037020764 nn.Linear: 0.00061207304914256 nn.Linear: 0.00030148108434601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012467137189099 nn.Linear: 0.0035271813365438] nn.Sequential: [nn.Linear: 0.00011612551794745 nn.Linear: 0.0022893799634826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079503217712045 nn.Linear: 0.011883726343513 nn.Linear: 0.0069358577020466 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039552259258926 nn.Linear: 0.021570106968284] nn.Sequential: [nn.Linear: 0.0041826162487268 nn.Linear: 0.015863385051489]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062516614561297 nn.Linear: 0.062347695999665 nn.Linear: 0.0442730818354 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031327893604522 nn.Linear: 0.02699166626789] nn.Sequential: [nn.Linear: 0.031273476242614 nn.Linear: 0.022655369275373]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23513083159924 nn.Linear: 0.16182366013527 nn.Linear: 0.1030313372612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070181660354137 nn.Linear: 0.092666506767273] nn.Sequential: [nn.Linear: 0.068826168775558 nn.Linear: 0.069082662463188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013950373661983 nn.Linear: 0.00072147329467975 nn.Linear: 0.00038708861000588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000142688677114 nn.Linear: 0.004220322202567] nn.Sequential: [nn.Linear: 0.00012386011989318 nn.Linear: 0.0019346995872219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076286620460451 nn.Linear: 0.018564511090517 nn.Linear: 0.0087569542229176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006210271269083 nn.Linear: 0.026857368648052] nn.Sequential: [nn.Linear: 0.0039923395961523 nn.Linear: 0.01974318549037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062510464012379 nn.Linear: 0.062349504945483 nn.Linear: 0.044273928956353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031328263170455 nn.Linear: 0.027082941338165] nn.Sequential: [nn.Linear: 0.031273517598439 nn.Linear: 0.022665853281045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23606000840664 nn.Linear: 0.1613751500845 nn.Linear: 0.10334466397762 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070165015757084 nn.Linear: 0.093359090387821] nn.Sequential: [nn.Linear: 0.068979106843472 nn.Linear: 0.068400979042053]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00078421920366761 nn.Linear: 0.00048091332318046 nn.Linear: 0.00023721636241048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.9176879620082e-05 nn.Linear: 0.0015878067424093] nn.Sequential: [nn.Linear: 8.2184480893638e-05 nn.Linear: 0.0011639626249341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005730006378144 nn.Linear: 0.010223100893199 nn.Linear: 0.0083282571285963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0026280994061381 nn.Linear: 0.010690117254853] nn.Sequential: [nn.Linear: 0.0022767703048885 nn.Linear: 0.009901518933475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062511404123622 nn.Linear: 0.062351692332635 nn.Linear: 0.044274068901033 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031328447583082 nn.Linear: 0.027122454326786] nn.Sequential: [nn.Linear: 0.031273624623883 nn.Linear: 0.022671907932788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23698788881302 nn.Linear: 0.16251710057259 nn.Linear: 0.10374923050404 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070176385343075 nn.Linear: 0.093891724944115] nn.Sequential: [nn.Linear: 0.069000206887722 nn.Linear: 0.068423122167587]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096129319596766 nn.Linear: 0.00039789689795839 nn.Linear: 0.00019935183703869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.4471693681508e-05 nn.Linear: 0.0012759157153805] nn.Sequential: [nn.Linear: 6.5887007207277e-05 nn.Linear: 0.00076521777785066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056650042533875 nn.Linear: 0.009056962095201 nn.Linear: 0.0047512464225292 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0025544720701873 nn.Linear: 0.0078626964241266] nn.Sequential: [nn.Linear: 0.0018686157418415 nn.Linear: 0.0090160435065627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062509771183956 nn.Linear: 0.06235304406825 nn.Linear: 0.044275972961076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031328731575145 nn.Linear: 0.027198915176825] nn.Sequential: [nn.Linear: 0.031273856983566 nn.Linear: 0.022702185620044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23873484134674 nn.Linear: 0.16409856081009 nn.Linear: 0.10421033203602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070357479155064 nn.Linear: 0.094617500901222] nn.Sequential: [nn.Linear: 0.069088622927666 nn.Linear: 0.068731218576431]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010934930468871 nn.Linear: 0.00059012088855123 nn.Linear: 0.0003055445802269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013060439432488 nn.Linear: 0.0036325913111328] nn.Sequential: [nn.Linear: 0.0001077168766047 nn.Linear: 0.0017738786075425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090808598324656 nn.Linear: 0.013994025066495 nn.Linear: 0.0070291203446686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005339790135622 nn.Linear: 0.025456899777055] nn.Sequential: [nn.Linear: 0.0034786048345268 nn.Linear: 0.012130243703723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062506309258106 nn.Linear: 0.062355532973738 nn.Linear: 0.044276782543851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031329163438412 nn.Linear: 0.027281518483974] nn.Sequential: [nn.Linear: 0.03127399882598 nn.Linear: 0.022721074484207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.23937955498695 nn.Linear: 0.16368372738361 nn.Linear: 0.10491898655891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070283018052578 nn.Linear: 0.095985695719719] nn.Sequential: [nn.Linear: 0.069154188036919 nn.Linear: 0.068458206951618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092618118828994 nn.Linear: 0.00047793147478948 nn.Linear: 0.0002268826588296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.4955580596499e-05 nn.Linear: 0.0019463800956661] nn.Sequential: [nn.Linear: 6.2404650554925e-05 nn.Linear: 0.00081106989873127]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006692205555737 nn.Linear: 0.0077646439895034 nn.Linear: 0.0055260295048356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037379839923233 nn.Linear: 0.013074257411063] nn.Sequential: [nn.Linear: 0.002331541152671 nn.Linear: 0.0076724123209715]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062506366481814 nn.Linear: 0.06235914357499 nn.Linear: 0.044277580403141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031329426711373 nn.Linear: 0.02735295568872] nn.Sequential: [nn.Linear: 0.031274239240877 nn.Linear: 0.022745528848244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24036537110806 nn.Linear: 0.16538260877132 nn.Linear: 0.10472165048122 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070493280887604 nn.Linear: 0.097487702965736] nn.Sequential: [nn.Linear: 0.069179467856884 nn.Linear: 0.068829067051411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007885019438493 nn.Linear: 0.00043676877614783 nn.Linear: 0.000224904252198 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2010226712379e-05 nn.Linear: 0.0020678219204142] nn.Sequential: [nn.Linear: 6.9550416683837e-05 nn.Linear: 0.0012079791447272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064895558170974 nn.Linear: 0.0085655152797699 nn.Linear: 0.0061425636522472 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039858506061137 nn.Linear: 0.015610622242093] nn.Sequential: [nn.Linear: 0.0023765049409121 nn.Linear: 0.0083354776725173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062505301954976 nn.Linear: 0.062362502419973 nn.Linear: 0.044278958554621 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031329799951126 nn.Linear: 0.027424412073685] nn.Sequential: [nn.Linear: 0.031274339169424 nn.Linear: 0.022756338800557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24103556573391 nn.Linear: 0.16505038738251 nn.Linear: 0.10490682721138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070608668029308 nn.Linear: 0.098804883658886] nn.Sequential: [nn.Linear: 0.069214887917042 nn.Linear: 0.068575352430344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017655530280529 nn.Linear: 0.00090490131194455 nn.Linear: 0.00044654479924303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022690371393654 nn.Linear: 0.006389465129029] nn.Sequential: [nn.Linear: 0.00017699602182052 nn.Linear: 0.0030139032143476]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014265111647546 nn.Linear: 0.021074907854199 nn.Linear: 0.022594872862101 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010810636915267 nn.Linear: 0.043831262737513] nn.Sequential: [nn.Linear: 0.0082063376903534 nn.Linear: 0.037801865488291]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062498957076151 nn.Linear: 0.062363376796071 nn.Linear: 0.044279680810681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330083304683 nn.Linear: 0.027489178364391] nn.Sequential: [nn.Linear: 0.031274533613397 nn.Linear: 0.022781005922503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24238933622837 nn.Linear: 0.16521200537682 nn.Linear: 0.10502098500729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070695899426937 nn.Linear: 0.098556570708752] nn.Sequential: [nn.Linear: 0.069293797016144 nn.Linear: 0.068897604942322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088899701466014 nn.Linear: 0.00055155021901707 nn.Linear: 0.00029664796105123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014375927459629 nn.Linear: 0.0047296493835304] nn.Sequential: [nn.Linear: 9.4169295918388e-05 nn.Linear: 0.0018115363463053]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064712190069258 nn.Linear: 0.013656372204423 nn.Linear: 0.0058427178300917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044364002533257 nn.Linear: 0.028836645185947] nn.Sequential: [nn.Linear: 0.003397373482585 nn.Linear: 0.013258525170386]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06249530439187 nn.Linear: 0.062364106383003 nn.Linear: 0.04428034186357 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330181965153 nn.Linear: 0.02749663201088] nn.Sequential: [nn.Linear: 0.031274818587119 nn.Linear: 0.022811993631635]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24334068596363 nn.Linear: 0.16632027924061 nn.Linear: 0.10535238683224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070789106190205 nn.Linear: 0.098106510937214] nn.Sequential: [nn.Linear: 0.069349750876427 nn.Linear: 0.069488830864429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013609163309084 nn.Linear: 0.00055481891280082 nn.Linear: 0.00027217581299573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001131648827796 nn.Linear: 0.0033655589549255] nn.Sequential: [nn.Linear: 9.5899816052722e-05 nn.Linear: 0.0014646273055684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094514070078731 nn.Linear: 0.011701789684594 nn.Linear: 0.0078643541783094 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043317833915353 nn.Linear: 0.025940058752894] nn.Sequential: [nn.Linear: 0.0031875898130238 nn.Linear: 0.014619527384639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062495567565673 nn.Linear: 0.062368218873535 nn.Linear: 0.04428211353596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330494189122 nn.Linear: 0.027575521549736] nn.Sequential: [nn.Linear: 0.031275230055429 nn.Linear: 0.022841591451439]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24414347112179 nn.Linear: 0.16751958429813 nn.Linear: 0.10531350970268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070784516632557 nn.Linear: 0.099606364965439] nn.Sequential: [nn.Linear: 0.069307923316956 nn.Linear: 0.069559246301651]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025056957986572 nn.Linear: 0.0013655403791428 nn.Linear: 0.00064786524000442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033585003112794 nn.Linear: 0.011187312998252] nn.Sequential: [nn.Linear: 0.00017372868192146 nn.Linear: 0.0028660920654513]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.031177952885628 nn.Linear: 0.036084696650505 nn.Linear: 0.015790769830346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010874768719077 nn.Linear: 0.064581662416458] nn.Sequential: [nn.Linear: 0.0064905527979136 nn.Linear: 0.029299113899469]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062495083038558 nn.Linear: 0.062370074523888 nn.Linear: 0.044282648803242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330632266942 nn.Linear: 0.027622780404247] nn.Sequential: [nn.Linear: 0.03127546445747 nn.Linear: 0.022853056145343]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24522368609905 nn.Linear: 0.16776117682457 nn.Linear: 0.10557695478201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.070937745273113 nn.Linear: 0.10060986876488] nn.Sequential: [nn.Linear: 0.069423541426659 nn.Linear: 0.069592274725437]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093532760394717 nn.Linear: 0.00051891293305566 nn.Linear: 0.0002618670917393 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.2807624092324e-05 nn.Linear: 0.0012626622017056] nn.Sequential: [nn.Linear: 0.00010096155720912 nn.Linear: 0.001656855641862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059406254440546 nn.Linear: 0.0074126245453954 nn.Linear: 0.006902813911438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031277819070965 nn.Linear: 0.0084691299125552] nn.Sequential: [nn.Linear: 0.0030297462362796 nn.Linear: 0.011667593382299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062485850442185 nn.Linear: 0.062371971718174 nn.Linear: 0.044283464393693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330855992634 nn.Linear: 0.02768825059627] nn.Sequential: [nn.Linear: 0.031275774226752 nn.Linear: 0.02288834128075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24591034650803 nn.Linear: 0.1679585725069 nn.Linear: 0.10599485039711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071064986288548 nn.Linear: 0.10061482340097] nn.Sequential: [nn.Linear: 0.069544605910778 nn.Linear: 0.069987721741199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011028488345561 nn.Linear: 0.00064351222567859 nn.Linear: 0.00035868610584151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017680346946976 nn.Linear: 0.0051099877301275] nn.Sequential: [nn.Linear: 5.981527471171e-05 nn.Linear: 0.0006630441162683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079843960702419 nn.Linear: 0.013191798701882 nn.Linear: 0.0077416654676199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050783692859113 nn.Linear: 0.032861206680536] nn.Sequential: [nn.Linear: 0.0014927580486983 nn.Linear: 0.0047435653395951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062486843727721 nn.Linear: 0.062374408237847 nn.Linear: 0.044284359290859 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031330944514641 nn.Linear: 0.027720935434047] nn.Sequential: [nn.Linear: 0.031276116945553 nn.Linear: 0.022915878675265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24761037528515 nn.Linear: 0.16908611357212 nn.Linear: 0.10581686347723 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071228042244911 nn.Linear: 0.1006468385458] nn.Sequential: [nn.Linear: 0.069683104753494 nn.Linear: 0.070414528250694]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011258766939716 nn.Linear: 0.00064716472223809 nn.Linear: 0.00032077671855226 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012036056997455 nn.Linear: 0.0034348025747972] nn.Sequential: [nn.Linear: 0.00012998080117405 nn.Linear: 0.002018238797029]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084746293723583 nn.Linear: 0.012173966504633 nn.Linear: 0.0081126196309924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042472723871469 nn.Linear: 0.019484005868435] nn.Sequential: [nn.Linear: 0.0046478388831019 nn.Linear: 0.023109089583158]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062482838201199 nn.Linear: 0.062379318610593 nn.Linear: 0.044286521019644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031331344943717 nn.Linear: 0.027845135803126] nn.Sequential: [nn.Linear: 0.031276405368561 nn.Linear: 0.022951388213784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.24952772259712 nn.Linear: 0.1694121658802 nn.Linear: 0.10587801039219 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071281798183918 nn.Linear: 0.10158090293407] nn.Sequential: [nn.Linear: 0.069771654903889 nn.Linear: 0.07053978741169]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013115320748859 nn.Linear: 0.00059644507403758 nn.Linear: 0.00030703901417238 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.2360791818322e-05 nn.Linear: 0.0015495308478315] nn.Sequential: [nn.Linear: 0.00010822106358124 nn.Linear: 0.0016327493401223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091637540608644 nn.Linear: 0.012480171397328 nn.Linear: 0.0080297337844968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037792730145156 nn.Linear: 0.011210106313229] nn.Sequential: [nn.Linear: 0.0035515776835382 nn.Linear: 0.011953780427575]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062481030647141 nn.Linear: 0.062381737771184 nn.Linear: 0.044287651818458 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031331767129906 nn.Linear: 0.027993244854692] nn.Sequential: [nn.Linear: 0.031276613196064 nn.Linear: 0.022970336623529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2502788901329 nn.Linear: 0.16928207874298 nn.Linear: 0.10639864951372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07162743806839 nn.Linear: 0.10290060937405] nn.Sequential: [nn.Linear: 0.069825239479542 nn.Linear: 0.07067483663559]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015754809128027 nn.Linear: 0.00078411098766379 nn.Linear: 0.00038413220035181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018450419516565 nn.Linear: 0.0051436733845927] nn.Sequential: [nn.Linear: 0.00012939076251809 nn.Linear: 0.0018717720752666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012249642051756 nn.Linear: 0.01487769279629 nn.Linear: 0.0088421301916242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062179556116462 nn.Linear: 0.030301915481687] nn.Sequential: [nn.Linear: 0.0044314204715192 nn.Linear: 0.018408017233014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.15088008844852	TD error	0.024332745358348	Qmax	1	

Steps: 750000 (frames: 3000000), score: 1527.69, higheset score: 4476, epsilon: 0.05, lr: 0.0005, training time: 484s, training rate: 2064fps, testing time: 89s, testing rate: 5590fps,  num. ep.: 267,  num. rewards: 11964	
   2    8    2    4
   4   16   32    8
   8   32    2   64
   2    4  512    8
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062483432673331 nn.Linear: 0.06238825037827 nn.Linear: 0.044289915699897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031332246343573 nn.Linear: 0.028089326746354] nn.Sequential: [nn.Linear: 0.031276962933763 nn.Linear: 0.022998515802117]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25173571705818 nn.Linear: 0.16923047602177 nn.Linear: 0.10694643110037 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071733273565769 nn.Linear: 0.10344987362623] nn.Sequential: [nn.Linear: 0.069876402616501 nn.Linear: 0.070802733302116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002200031560646 nn.Linear: 0.0010912377756405 nn.Linear: 0.00047234224042056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011587841619716 nn.Linear: 0.0020046142408986] nn.Sequential: [nn.Linear: 0.0001993162401476 nn.Linear: 0.002990661472341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018773069605231 nn.Linear: 0.018722951412201 nn.Linear: 0.0096255876123905 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054468014277518 nn.Linear: 0.014555409550667] nn.Sequential: [nn.Linear: 0.005705323535949 nn.Linear: 0.03154082596302]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06247911192335 nn.Linear: 0.06239158327922 nn.Linear: 0.04429096333582 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031332590898027 nn.Linear: 0.028172774174461] nn.Sequential: [nn.Linear: 0.031277067243959 nn.Linear: 0.023017696114698]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25287574529648 nn.Linear: 0.17106558382511 nn.Linear: 0.1070616543293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071681447327137 nn.Linear: 0.10439565032721] nn.Sequential: [nn.Linear: 0.069867379963398 nn.Linear: 0.071003422141075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094987582005207 nn.Linear: 0.0005196047527053 nn.Linear: 0.00023914410873356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.6187339835228e-05 nn.Linear: 0.0022505670789883] nn.Sequential: [nn.Linear: 6.3840289206304e-05 nn.Linear: 0.00066832224435801]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058341501280665 nn.Linear: 0.0086681889370084 nn.Linear: 0.0051218923181295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047247218899429 nn.Linear: 0.013266026973724] nn.Sequential: [nn.Linear: 0.0019201213726774 nn.Linear: 0.0045813480392098]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062472171849668 nn.Linear: 0.062393574420822 nn.Linear: 0.04429158695232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031333068939758 nn.Linear: 0.028308316906561] nn.Sequential: [nn.Linear: 0.031277320293211 nn.Linear: 0.023048910722948]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25439882278442 nn.Linear: 0.1707811653614 nn.Linear: 0.10714149475098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071688279509544 nn.Linear: 0.10394966602325] nn.Sequential: [nn.Linear: 0.069914154708385 nn.Linear: 0.071283161640167]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023944313834419 nn.Linear: 0.0010679782288902 nn.Linear: 0.00050205108066476 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016581580680372 nn.Linear: 0.0032614810341445] nn.Sequential: [nn.Linear: 0.00014617829509858 nn.Linear: 0.0024159249074061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018557902425528 nn.Linear: 0.02402781881392 nn.Linear: 0.012121679261327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070770215243101 nn.Linear: 0.029335064813495] nn.Sequential: [nn.Linear: 0.0051486543379724 nn.Linear: 0.026287933811545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062476439060129 nn.Linear: 0.062396139254752 nn.Linear: 0.044293032056499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031333465735274 nn.Linear: 0.028388144589357] nn.Sequential: [nn.Linear: 0.031277662518939 nn.Linear: 0.023071442940413]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2557744383812 nn.Linear: 0.17130289971828 nn.Linear: 0.10714025050402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071593157947063 nn.Linear: 0.10499337315559] nn.Sequential: [nn.Linear: 0.069956175982952 nn.Linear: 0.071049273014069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00084067361319075 nn.Linear: 0.00057611779087975 nn.Linear: 0.00029644862890846 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.9964879393707e-05 nn.Linear: 0.00099532687853326] nn.Sequential: [nn.Linear: 0.00014477030014953 nn.Linear: 0.0022632816951806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005597498267889 nn.Linear: 0.0089485561475158 nn.Linear: 0.0072471713647246 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035955552011728 nn.Linear: 0.0057503525167704] nn.Sequential: [nn.Linear: 0.005340083502233 nn.Linear: 0.025812963023782]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062470960881448 nn.Linear: 0.062401214038827 nn.Linear: 0.044294245386297 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031333923191056 nn.Linear: 0.028493825768546] nn.Sequential: [nn.Linear: 0.031277975579289 nn.Linear: 0.023102973903583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25701847672462 nn.Linear: 0.17128537595272 nn.Linear: 0.10718667507172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071498408913612 nn.Linear: 0.10546187311411] nn.Sequential: [nn.Linear: 0.069995172321796 nn.Linear: 0.071060329675674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014766985750375 nn.Linear: 0.00071685395306532 nn.Linear: 0.00035589057214986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012901138337779 nn.Linear: 0.0031316555208118] nn.Sequential: [nn.Linear: 0.000112160767915 nn.Linear: 0.0017038051112818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086974427103996 nn.Linear: 0.017074592411518 nn.Linear: 0.0074296002276242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046614455059171 nn.Linear: 0.018127603456378] nn.Sequential: [nn.Linear: 0.004396942909807 nn.Linear: 0.015316835604608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062469641479726 nn.Linear: 0.062405153109853 nn.Linear: 0.044296078473039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031334059140333 nn.Linear: 0.028545326824396] nn.Sequential: [nn.Linear: 0.031278299669801 nn.Linear: 0.02313225117403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25843426585197 nn.Linear: 0.17196907103062 nn.Linear: 0.10738384723663 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071770399808884 nn.Linear: 0.10706140100956] nn.Sequential: [nn.Linear: 0.070101916790009 nn.Linear: 0.071751527488232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00056843496619057 nn.Linear: 0.00029430268632336 nn.Linear: 0.00016746842893711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.7942318337147e-05 nn.Linear: 0.001381689319089] nn.Sequential: [nn.Linear: 5.2165621873039e-05 nn.Linear: 0.00064211930668882]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052133705466986 nn.Linear: 0.0058324439451098 nn.Linear: 0.0042289909906685 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0032070521265268 nn.Linear: 0.010657794773579] nn.Sequential: [nn.Linear: 0.001382464542985 nn.Linear: 0.0047482908703387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062465548729804 nn.Linear: 0.062408796816181 nn.Linear: 0.044297546147008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03133454786478 nn.Linear: 0.028650793547659] nn.Sequential: [nn.Linear: 0.031278534751212 nn.Linear: 0.023162825217522]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.25925087928772 nn.Linear: 0.17185571789742 nn.Linear: 0.10786288231611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071841947734356 nn.Linear: 0.10752219706774] nn.Sequential: [nn.Linear: 0.070111207664013 nn.Linear: 0.071780517697334]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012612239445392 nn.Linear: 0.00062990528872559 nn.Linear: 0.00031872523491703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001220266658125 nn.Linear: 0.0029883658617558] nn.Sequential: [nn.Linear: 0.0001095296811772 nn.Linear: 0.0013966563939597]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012218039482832 nn.Linear: 0.010908896103501 nn.Linear: 0.0052086915820837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048188040964305 nn.Linear: 0.017335020005703] nn.Sequential: [nn.Linear: 0.0039571607485414 nn.Linear: 0.013615002855659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062462880687606 nn.Linear: 0.062411332772118 nn.Linear: 0.044298461089862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031334674531647 nn.Linear: 0.028717895845475] nn.Sequential: [nn.Linear: 0.031278868251799 nn.Linear: 0.023194788918123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26053589582443 nn.Linear: 0.17294010519981 nn.Linear: 0.10864976793528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.072084583342075 nn.Linear: 0.10871592909098] nn.Sequential: [nn.Linear: 0.070258185267448 nn.Linear: 0.072114154696465]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016487254277778 nn.Linear: 0.00073161031004293 nn.Linear: 0.00036406985966534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013835165045139 nn.Linear: 0.0033977161176122] nn.Sequential: [nn.Linear: 9.7404112657077e-05 nn.Linear: 0.0010446620435618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014187397435308 nn.Linear: 0.020092880353332 nn.Linear: 0.012185296043754 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049552638083696 nn.Linear: 0.026213055476546] nn.Sequential: [nn.Linear: 0.002915354212746 nn.Linear: 0.0093463230878115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062460412195111 nn.Linear: 0.062413436483211 nn.Linear: 0.044298868130453 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031335219841812 nn.Linear: 0.028882664596964] nn.Sequential: [nn.Linear: 0.03127896926055 nn.Linear: 0.023210709629971]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2622038424015 nn.Linear: 0.17253471910954 nn.Linear: 0.10789205133915 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071912340819836 nn.Linear: 0.1088675558567] nn.Sequential: [nn.Linear: 0.070276223123074 nn.Linear: 0.072622373700142]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019943593158959 nn.Linear: 0.0010376671820089 nn.Linear: 0.00050664950035877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017069453346872 nn.Linear: 0.0032548811272293] nn.Sequential: [nn.Linear: 0.00015507864597722 nn.Linear: 0.0026259689038215]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013668629340827 nn.Linear: 0.020993236452341 nn.Linear: 0.010584554634988 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056264628656209 nn.Linear: 0.023025095462799] nn.Sequential: [nn.Linear: 0.0047472408041358 nn.Linear: 0.026193784549832]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06245525968149 nn.Linear: 0.062415700818086 nn.Linear: 0.044301350517722 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031335644750967 nn.Linear: 0.028958511055485] nn.Sequential: [nn.Linear: 0.031279389775684 nn.Linear: 0.023245248815517]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26442340016365 nn.Linear: 0.17378194630146 nn.Linear: 0.10883352905512 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.072065338492393 nn.Linear: 0.10962173342705] nn.Sequential: [nn.Linear: 0.070270642638206 nn.Linear: 0.073265574872494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00046207394938926 nn.Linear: 0.00027463031370007 nn.Linear: 0.00014533079904275 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.1059814766827e-05 nn.Linear: 0.0010540178560943] nn.Sequential: [nn.Linear: 5.9487688448318e-05 nn.Linear: 0.00087139555086498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0034879439044744 nn.Linear: 0.0046549993567169 nn.Linear: 0.0034746669698507 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0019108281703666 nn.Linear: 0.0071219578385353] nn.Sequential: [nn.Linear: 0.0021243584342301 nn.Linear: 0.0083510186523199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06245131142518 nn.Linear: 0.062421626819595 nn.Linear: 0.044302833629528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031336211980488 nn.Linear: 0.029075517881221] nn.Sequential: [nn.Linear: 0.03127959406631 nn.Linear: 0.023266459187331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26522183418274 nn.Linear: 0.17462562024593 nn.Linear: 0.10876460373402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07248368114233 nn.Linear: 0.11064120382071] nn.Sequential: [nn.Linear: 0.070389322936535 nn.Linear: 0.073175199329853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016734951706469 nn.Linear: 0.0010023388610864 nn.Linear: 0.00048158410432058 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019447049468439 nn.Linear: 0.0044537590525536] nn.Sequential: [nn.Linear: 0.00017462377370884 nn.Linear: 0.0026415035615012]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011400513350964 nn.Linear: 0.022947400808334 nn.Linear: 0.0097742546349764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087214773520827 nn.Linear: 0.029432876035571] nn.Sequential: [nn.Linear: 0.0060723409987986 nn.Linear: 0.02818888425827]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062445233359158 nn.Linear: 0.062423939630085 nn.Linear: 0.044303662618781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031336492381281 nn.Linear: 0.029165575563241] nn.Sequential: [nn.Linear: 0.031279845669007 nn.Linear: 0.023299100203739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26631394028664 nn.Linear: 0.17558056116104 nn.Linear: 0.10918512940407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.072801426053047 nn.Linear: 0.11233284324408] nn.Sequential: [nn.Linear: 0.070357009768486 nn.Linear: 0.074151888489723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017028213890865 nn.Linear: 0.00088783594697127 nn.Linear: 0.00045560471278197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020470486125293 nn.Linear: 0.006329823851642] nn.Sequential: [nn.Linear: 0.00015684974309858 nn.Linear: 0.0023859877766764]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011278798803687 nn.Linear: 0.031087279319763 nn.Linear: 0.016773365437984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074745616875589 nn.Linear: 0.044574879109859] nn.Sequential: [nn.Linear: 0.003942874725908 nn.Linear: 0.022456020116806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062447349664871 nn.Linear: 0.062429286260783 nn.Linear: 0.044305423424071 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031336816233817 nn.Linear: 0.029252913205816] nn.Sequential: [nn.Linear: 0.031280411042814 nn.Linear: 0.023331226483603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26718819141388 nn.Linear: 0.17559315264225 nn.Linear: 0.10912264883518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.073049806058407 nn.Linear: 0.11267375946045] nn.Sequential: [nn.Linear: 0.070414356887341 nn.Linear: 0.074607267975807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016432746205448 nn.Linear: 0.00094597060051011 nn.Linear: 0.00047216150818589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001780601242808 nn.Linear: 0.0044687735355345] nn.Sequential: [nn.Linear: 9.8407778148229e-05 nn.Linear: 0.0012715643972219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013202333822846 nn.Linear: 0.022195152938366 nn.Linear: 0.0089120334014297 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006859197281301 nn.Linear: 0.031274061650038] nn.Sequential: [nn.Linear: 0.0040652486495674 nn.Linear: 0.014975847676396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062445817231088 nn.Linear: 0.062433830346264 nn.Linear: 0.044307264267588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031337337817975 nn.Linear: 0.029398589136435] nn.Sequential: [nn.Linear: 0.031280908599327 nn.Linear: 0.023372161697591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.26883128285408 nn.Linear: 0.17632852494717 nn.Linear: 0.10951611399651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.073183409869671 nn.Linear: 0.1145376265049] nn.Sequential: [nn.Linear: 0.070485897362232 nn.Linear: 0.075100056827068]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011494734066563 nn.Linear: 0.00060208843339336 nn.Linear: 0.00029700554266372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8437503102062e-05 nn.Linear: 0.0017774430623367] nn.Sequential: [nn.Linear: 0.00011713471868418 nn.Linear: 0.001600534493995]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010052230209112 nn.Linear: 0.010207243263721 nn.Linear: 0.007941528223455 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004600883461535 nn.Linear: 0.011073703877628] nn.Sequential: [nn.Linear: 0.0034010531380773 nn.Linear: 0.013023858889937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062442994707292 nn.Linear: 0.06243692281723 nn.Linear: 0.044308831395827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031337717374497 nn.Linear: 0.029524987627827] nn.Sequential: [nn.Linear: 0.031281238676809 nn.Linear: 0.023402590688217]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27010813355446 nn.Linear: 0.17675703763962 nn.Linear: 0.10914389044046 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.073293291032314 nn.Linear: 0.11517253518105] nn.Sequential: [nn.Linear: 0.070512615144253 nn.Linear: 0.075343899428844]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083196459707672 nn.Linear: 0.00051500420070685 nn.Linear: 0.00025883168208208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011052420572273 nn.Linear: 0.0029148205492769] nn.Sequential: [nn.Linear: 9.327023883186e-05 nn.Linear: 0.0013309775513808]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071382438763976 nn.Linear: 0.0086925122886896 nn.Linear: 0.0056696673855186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029324940405786 nn.Linear: 0.018443509936333] nn.Sequential: [nn.Linear: 0.0025368570350111 nn.Linear: 0.01253960095346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062440332622524 nn.Linear: 0.062440176412114 nn.Linear: 0.044310206320806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031338189562305 nn.Linear: 0.029640351723607] nn.Sequential: [nn.Linear: 0.031281531087371 nn.Linear: 0.023433534511127]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27098816633224 nn.Linear: 0.17633885145187 nn.Linear: 0.10948472470045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.073573522269726 nn.Linear: 0.11685060709715] nn.Sequential: [nn.Linear: 0.070504389703274 nn.Linear: 0.075236529111862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016059282058217 nn.Linear: 0.0008558955784679 nn.Linear: 0.00040444510340163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017138938805178 nn.Linear: 0.0038941631457521] nn.Sequential: [nn.Linear: 0.00010775893829585 nn.Linear: 0.0011531424854371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010128041729331 nn.Linear: 0.01551294978708 nn.Linear: 0.0082419496029615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075105926953256 nn.Linear: 0.024513069540262] nn.Sequential: [nn.Linear: 0.0030260263010859 nn.Linear: 0.0093028526753187]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062432619274494 nn.Linear: 0.062442655527485 nn.Linear: 0.044311656705249 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031338649657998 nn.Linear: 0.029735458246243] nn.Sequential: [nn.Linear: 0.031281716424423 nn.Linear: 0.023456936574862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27291288971901 nn.Linear: 0.17761471867561 nn.Linear: 0.10935660451651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.073681332170963 nn.Linear: 0.11730789393187] nn.Sequential: [nn.Linear: 0.070514388382435 nn.Linear: 0.075209125876427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017376495095349 nn.Linear: 0.0010185868564497 nn.Linear: 0.00053136668939066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002431184052001 nn.Linear: 0.0063713650214274] nn.Sequential: [nn.Linear: 0.00012645418511263 nn.Linear: 0.0016018311327259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013619424775243 nn.Linear: 0.02282646484673 nn.Linear: 0.012046036310494 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079596964642406 nn.Linear: 0.040687739849091] nn.Sequential: [nn.Linear: 0.0047142906114459 nn.Linear: 0.016584450379014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062424475149617 nn.Linear: 0.062444789968212 nn.Linear: 0.044312128991745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031338752370679 nn.Linear: 0.029752519450184] nn.Sequential: [nn.Linear: 0.031282069192408 nn.Linear: 0.023488101117557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27465641498566 nn.Linear: 0.17831969261169 nn.Linear: 0.10989933460951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.074139282107353 nn.Linear: 0.1175260618329] nn.Sequential: [nn.Linear: 0.070531509816647 nn.Linear: 0.075818099081516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002007027375228 nn.Linear: 0.0011949415162187 nn.Linear: 0.0006465674367498 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027908648031218 nn.Linear: 0.0077993762879334] nn.Sequential: [nn.Linear: 0.00013775878768552 nn.Linear: 0.0020621588485425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013398330658674 nn.Linear: 0.031512096524239 nn.Linear: 0.012940913438797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008491663262248 nn.Linear: 0.044978585094213] nn.Sequential: [nn.Linear: 0.0041910363361239 nn.Linear: 0.019470043480396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062420710651462 nn.Linear: 0.06244686526728 nn.Linear: 0.044313359034321 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031339137321163 nn.Linear: 0.029849762196989] nn.Sequential: [nn.Linear: 0.031282311201581 nn.Linear: 0.023531074027788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27598389983177 nn.Linear: 0.17840698361397 nn.Linear: 0.10978213697672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07455063611269 nn.Linear: 0.11785125732422] nn.Sequential: [nn.Linear: 0.070528529584408 nn.Linear: 0.076584592461586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001479252390232 nn.Linear: 0.00084090990858203 nn.Linear: 0.00041063078226123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019928522290712 nn.Linear: 0.0052089100353856] nn.Sequential: [nn.Linear: 0.00014229165814001 nn.Linear: 0.0022348676929028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013468729332089 nn.Linear: 0.015027425251901 nn.Linear: 0.010098547674716 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061329151503742 nn.Linear: 0.031490169465542] nn.Sequential: [nn.Linear: 0.004841367714107 nn.Linear: 0.017847873270512]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062416023769901 nn.Linear: 0.062450326947248 nn.Linear: 0.044315110193038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031339883728158 nn.Linear: 0.029993127057665] nn.Sequential: [nn.Linear: 0.031282521979408 nn.Linear: 0.02354312801281]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27747112512589 nn.Linear: 0.17918832600117 nn.Linear: 0.10976911336184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.074949249625206 nn.Linear: 0.11956340074539] nn.Sequential: [nn.Linear: 0.070586271584034 nn.Linear: 0.076402328908443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018689427407328 nn.Linear: 0.0010774268003309 nn.Linear: 0.00057918800438626 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028238128069963 nn.Linear: 0.0079252539397114] nn.Sequential: [nn.Linear: 0.00012294083096547 nn.Linear: 0.0016267553285678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015558023005724 nn.Linear: 0.021758271381259 nn.Linear: 0.019149508327246 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076390840113163 nn.Linear: 0.04366697371006] nn.Sequential: [nn.Linear: 0.0039823856204748 nn.Linear: 0.012442611157894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062406589605855 nn.Linear: 0.062448357348397 nn.Linear: 0.044314642263227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340126105442 nn.Linear: 0.030054844387053] nn.Sequential: [nn.Linear: 0.031282230238462 nn.Linear: 0.023530175903556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27937540411949 nn.Linear: 0.18102131783962 nn.Linear: 0.10959607362747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.075290180742741 nn.Linear: 0.12006238847971] nn.Sequential: [nn.Linear: 0.070556990802288 nn.Linear: 0.076729714870453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019554815622807 nn.Linear: 0.00094872581984237 nn.Linear: 0.00040544280813148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011741924861794 nn.Linear: 0.0020246377284501] nn.Sequential: [nn.Linear: 0.0001287198914524 nn.Linear: 0.0017592317759153]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015717746689916 nn.Linear: 0.017160719260573 nn.Linear: 0.010682298801839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068476474843919 nn.Linear: 0.011296523734927] nn.Sequential: [nn.Linear: 0.003760278923437 nn.Linear: 0.015230141580105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062400569989064 nn.Linear: 0.062449445424392 nn.Linear: 0.044314623805425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340413446336 nn.Linear: 0.030126289233735] nn.Sequential: [nn.Linear: 0.031282139475784 nn.Linear: 0.023532490041973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.27983203530312 nn.Linear: 0.18181593716145 nn.Linear: 0.10992025583982 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07519605755806 nn.Linear: 0.12072947621346] nn.Sequential: [nn.Linear: 0.070582762360573 nn.Linear: 0.077516295015812]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010235352681549 nn.Linear: 0.00052901565603482 nn.Linear: 0.00020773382359491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.3224237417161e-05 nn.Linear: 0.00094424948618432] nn.Sequential: [nn.Linear: 6.7080578171311e-05 nn.Linear: 0.0008797535970422]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007448794785887 nn.Linear: 0.010907709598541 nn.Linear: 0.0062904828228056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0027839539106935 nn.Linear: 0.0060298764146864] nn.Sequential: [nn.Linear: 0.0019163365941495 nn.Linear: 0.0080790007486939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062390574829896 nn.Linear: 0.062448893340192 nn.Linear: 0.044314661086532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340430858822 nn.Linear: 0.030102036157558] nn.Sequential: [nn.Linear: 0.031282319907573 nn.Linear: 0.023546833862794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28037965297699 nn.Linear: 0.18236736953259 nn.Linear: 0.10967914015055 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.075266927480698 nn.Linear: 0.12143524736166] nn.Sequential: [nn.Linear: 0.070661015808582 nn.Linear: 0.078153066337109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020313675090953 nn.Linear: 0.001124086181536 nn.Linear: 0.00048955193805398 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022521376865884 nn.Linear: 0.0061914619920409] nn.Sequential: [nn.Linear: 9.1346190160159e-05 nn.Linear: 0.0011050959279034]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012416766025126 nn.Linear: 0.023293908685446 nn.Linear: 0.011584271676838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074948337860405 nn.Linear: 0.038846481591463] nn.Sequential: [nn.Linear: 0.0027033346705139 nn.Linear: 0.011298016645014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062380802439199 nn.Linear: 0.062449849930925 nn.Linear: 0.044314713957555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340479966933 nn.Linear: 0.030090963489215] nn.Sequential: [nn.Linear: 0.031282433848095 nn.Linear: 0.023564376606673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28093782067299 nn.Linear: 0.18276198208332 nn.Linear: 0.10978983342648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07567036151886 nn.Linear: 0.12144330143929] nn.Sequential: [nn.Linear: 0.070688813924789 nn.Linear: 0.078917451202869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013969527406254 nn.Linear: 0.00062368348767614 nn.Linear: 0.00033941849106169 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010515850932652 nn.Linear: 0.0021152774101124] nn.Sequential: [nn.Linear: 0.00014137609250148 nn.Linear: 0.0021336554901048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010744974017143 nn.Linear: 0.013346202671528 nn.Linear: 0.0057431580498815 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045882631093264 nn.Linear: 0.013606265187263] nn.Sequential: [nn.Linear: 0.003898945171386 nn.Linear: 0.023593401536345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062374202888885 nn.Linear: 0.062451020323479 nn.Linear: 0.044315337376171 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340675231349 nn.Linear: 0.030141001415643] nn.Sequential: [nn.Linear: 0.031282623453832 nn.Linear: 0.023580360876133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28203493356705 nn.Linear: 0.18317143619061 nn.Linear: 0.1097526922822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.075630359351635 nn.Linear: 0.12139578908682] nn.Sequential: [nn.Linear: 0.070674143731594 nn.Linear: 0.07925958186388]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018438352806342 nn.Linear: 0.00087904996561338 nn.Linear: 0.00040905302026951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014869025578864 nn.Linear: 0.0028845859668341] nn.Sequential: [nn.Linear: 0.00010030299955253 nn.Linear: 0.0011851545047519]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018154323101044 nn.Linear: 0.016212929040194 nn.Linear: 0.013799639418721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0080734677612782 nn.Linear: 0.020364001393318] nn.Sequential: [nn.Linear: 0.0038949730806053 nn.Linear: 0.010375305078924]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.12750106297433	TD error	0.020705751866102	Qmax	1	

Steps: 1000000 (frames: 4000000), score: 1673.91, higheset score: 6124, epsilon: 0.05, lr: 0.0005, training time: 524s, training rate: 1906fps, testing time: 89s, testing rate: 5582fps,  num. ep.: 251,  num. rewards: 12092	
   4    8   16    4
 128   64  128    2
   8    4   16  512
   2    8   64    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062368751280851 nn.Linear: 0.062450403085944 nn.Linear: 0.044315613618726 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031340770631386 nn.Linear: 0.030175851376683] nn.Sequential: [nn.Linear: 0.031282666262445 nn.Linear: 0.02359736980402]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28400844335556 nn.Linear: 0.18335831165314 nn.Linear: 0.10984189808369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076004430651665 nn.Linear: 0.12109041959047] nn.Sequential: [nn.Linear: 0.07072538882494 nn.Linear: 0.079601816833019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012352956832771 nn.Linear: 0.00084654696273123 nn.Linear: 0.00047958541647868 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024295789067448 nn.Linear: 0.0067597350314662] nn.Sequential: [nn.Linear: 9.3289057671521e-05 nn.Linear: 0.001111033781747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090867485851049 nn.Linear: 0.01563860103488 nn.Linear: 0.01214206404984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073550697416067 nn.Linear: 0.037181094288826] nn.Sequential: [nn.Linear: 0.0023801934439689 nn.Linear: 0.010650277137756]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062359127774481 nn.Linear: 0.062452619740652 nn.Linear: 0.044316487337984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03134104110476 nn.Linear: 0.030212648426243] nn.Sequential: [nn.Linear: 0.031282933261996 nn.Linear: 0.023620353723315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28493842482567 nn.Linear: 0.18291214108467 nn.Linear: 0.11014376580715 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076180383563042 nn.Linear: 0.12155655771494] nn.Sequential: [nn.Linear: 0.070903442800045 nn.Linear: 0.07991686463356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023709692092984 nn.Linear: 0.0013132251411202 nn.Linear: 0.0005724232486416 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021395655917685 nn.Linear: 0.0057041688082773] nn.Sequential: [nn.Linear: 0.00017086714862914 nn.Linear: 0.002292502512739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019646961241961 nn.Linear: 0.034520383924246 nn.Linear: 0.018439246341586 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010148327797651 nn.Linear: 0.037425938993692] nn.Sequential: [nn.Linear: 0.0070492392405868 nn.Linear: 0.030543748289347]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062352670089349 nn.Linear: 0.062453770872011 nn.Linear: 0.044317392361361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031341356957297 nn.Linear: 0.030278987252629] nn.Sequential: [nn.Linear: 0.031283119136035 nn.Linear: 0.023639238194317]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28598755598068 nn.Linear: 0.18300011754036 nn.Linear: 0.11012586206198 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076087437570095 nn.Linear: 0.12288025021553] nn.Sequential: [nn.Linear: 0.070816814899445 nn.Linear: 0.080415844917297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076433711990558 nn.Linear: 0.00042836598745527 nn.Linear: 0.00024153761205435 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.1110608282532e-05 nn.Linear: 0.0021047841127855] nn.Sequential: [nn.Linear: 9.703430565155e-05 nn.Linear: 0.0013349448311975]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097785955294967 nn.Linear: 0.0077714831568301 nn.Linear: 0.0041031576693058 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0028732498176396 nn.Linear: 0.015202470123768] nn.Sequential: [nn.Linear: 0.0025893221609294 nn.Linear: 0.014791765250266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062347391707528 nn.Linear: 0.062456824458978 nn.Linear: 0.044318027120307 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031341665064663 nn.Linear: 0.030331664633451] nn.Sequential: [nn.Linear: 0.031283411604243 nn.Linear: 0.02365821916724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28730818629265 nn.Linear: 0.18319721519947 nn.Linear: 0.11029341816902 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076150417327881 nn.Linear: 0.1231042817235] nn.Sequential: [nn.Linear: 0.070860616862774 nn.Linear: 0.081028550863266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019664350095993 nn.Linear: 0.0010319154594121 nn.Linear: 0.00051096242162802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021415625174502 nn.Linear: 0.0056135098460164] nn.Sequential: [nn.Linear: 0.00012452902361208 nn.Linear: 0.0015300434832283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019281541928649 nn.Linear: 0.028150763362646 nn.Linear: 0.012636619620025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010865357704461 nn.Linear: 0.036332972347736] nn.Sequential: [nn.Linear: 0.0047736470587552 nn.Linear: 0.013425705954432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062338870621256 nn.Linear: 0.06245600094494 nn.Linear: 0.044318212591649 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031341725554624 nn.Linear: 0.030343309100093] nn.Sequential: [nn.Linear: 0.031283512642244 nn.Linear: 0.023673852240285]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28766846656799 nn.Linear: 0.18335267901421 nn.Linear: 0.11002346128225 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076234057545662 nn.Linear: 0.12266736477613] nn.Sequential: [nn.Linear: 0.070905700325966 nn.Linear: 0.081541664898396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098420848092544 nn.Linear: 0.0004723247661744 nn.Linear: 0.00019891599483924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1703521692117e-05 nn.Linear: 0.001054955293169] nn.Sequential: [nn.Linear: 5.6177369500396e-05 nn.Linear: 0.00051709872932818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008460184559226 nn.Linear: 0.0089630195870996 nn.Linear: 0.0043897903524339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0028676330111921 nn.Linear: 0.0068123247474432] nn.Sequential: [nn.Linear: 0.001695572398603 nn.Linear: 0.0044052540324628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062333820730942 nn.Linear: 0.062457536207014 nn.Linear: 0.044318923280362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031341964042864 nn.Linear: 0.03040362544103] nn.Sequential: [nn.Linear: 0.031283688585058 nn.Linear: 0.023696511729967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28843623399734 nn.Linear: 0.18459537625313 nn.Linear: 0.11091878265142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076354473829269 nn.Linear: 0.1228986531496] nn.Sequential: [nn.Linear: 0.070999898016453 nn.Linear: 0.082076959311962]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092338347055543 nn.Linear: 0.00043320310164141 nn.Linear: 0.00022609944285961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.0289916651633e-05 nn.Linear: 0.0012652601985486] nn.Sequential: [nn.Linear: 8.692007752995e-05 nn.Linear: 0.0010159703975774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068051484413445 nn.Linear: 0.0071225860156119 nn.Linear: 0.0048975199460983 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045205350033939 nn.Linear: 0.0092603657394648] nn.Sequential: [nn.Linear: 0.0027501448057592 nn.Linear: 0.0096738934516907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062324139017846 nn.Linear: 0.062461053035259 nn.Linear: 0.044319613579008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031342035014411 nn.Linear: 0.030412341085988] nn.Sequential: [nn.Linear: 0.031283866462836 nn.Linear: 0.023710782013502]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.28991129994392 nn.Linear: 0.18470564484596 nn.Linear: 0.11155359447002 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076199062168598 nn.Linear: 0.12302413582802] nn.Sequential: [nn.Linear: 0.071043580770493 nn.Linear: 0.082623705267906]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094266273631427 nn.Linear: 0.00048355840688465 nn.Linear: 0.00027582373943116 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6915051299233e-05 nn.Linear: 0.001968614124233] nn.Sequential: [nn.Linear: 0.00010717261575061 nn.Linear: 0.0013820406475722]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062132370658219 nn.Linear: 0.0080843335017562 nn.Linear: 0.0052188131958246 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030875543598086 nn.Linear: 0.011803882196546] nn.Sequential: [nn.Linear: 0.003473588032648 nn.Linear: 0.012729240581393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062321451727842 nn.Linear: 0.062464067506171 nn.Linear: 0.044321123859717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031342483859864 nn.Linear: 0.030506574793549] nn.Sequential: [nn.Linear: 0.031284084491185 nn.Linear: 0.023725345320026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29048472642899 nn.Linear: 0.18471087515354 nn.Linear: 0.11178404837847 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0765390843153 nn.Linear: 0.12352436035872] nn.Sequential: [nn.Linear: 0.071094408631325 nn.Linear: 0.082896552979946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016210595228773 nn.Linear: 0.00080710849144035 nn.Linear: 0.00036678592215577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016231722988092 nn.Linear: 0.0036982734606498] nn.Sequential: [nn.Linear: 8.8796524015302e-05 nn.Linear: 0.001221192609371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0113639337942 nn.Linear: 0.023844186216593 nn.Linear: 0.011365838348866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073714810423553 nn.Linear: 0.022330386564136] nn.Sequential: [nn.Linear: 0.0025062824133784 nn.Linear: 0.01631785556674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062309666281 nn.Linear: 0.06246375246146 nn.Linear: 0.044321205045658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031342740698954 nn.Linear: 0.030588529422602] nn.Sequential: [nn.Linear: 0.031284102913145 nn.Linear: 0.023737662605295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29152747988701 nn.Linear: 0.1860316991806 nn.Linear: 0.11199206858873 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076563775539398 nn.Linear: 0.12410948425531] nn.Sequential: [nn.Linear: 0.071023248136044 nn.Linear: 0.083589233458042]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002528711925218 nn.Linear: 0.0011436777982707 nn.Linear: 0.00049218167971156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017626334344768 nn.Linear: 0.0036928884038354] nn.Sequential: [nn.Linear: 0.00012747565494164 nn.Linear: 0.0016158251320435]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023011721670628 nn.Linear: 0.021624637767673 nn.Linear: 0.016881985589862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099791968241334 nn.Linear: 0.026007803156972] nn.Sequential: [nn.Linear: 0.0041213608346879 nn.Linear: 0.020965302363038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062304541615068 nn.Linear: 0.062468135139854 nn.Linear: 0.044323287949776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031343109697106 nn.Linear: 0.030671021181973] nn.Sequential: [nn.Linear: 0.031284430871821 nn.Linear: 0.023755171515108]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29322358965874 nn.Linear: 0.18630516529083 nn.Linear: 0.11183131486177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076769463717937 nn.Linear: 0.1241959631443] nn.Sequential: [nn.Linear: 0.071107923984528 nn.Linear: 0.083762541413307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017542030924684 nn.Linear: 0.00083159089732475 nn.Linear: 0.00040261579645346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019308732376019 nn.Linear: 0.0050355697077633] nn.Sequential: [nn.Linear: 5.3523126043702e-05 nn.Linear: 0.00058624540063268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012352364137769 nn.Linear: 0.022603992372751 nn.Linear: 0.0090344222262502 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056299064308405 nn.Linear: 0.030054623261094] nn.Sequential: [nn.Linear: 0.0012510379310697 nn.Linear: 0.0043890038505197]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06229820403212 nn.Linear: 0.062473398652583 nn.Linear: 0.044325501679035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031344063118736 nn.Linear: 0.030910337864768] nn.Sequential: [nn.Linear: 0.031284361353403 nn.Linear: 0.023765999923976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29421609640121 nn.Linear: 0.18737182021141 nn.Linear: 0.11189912259579 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077019549906254 nn.Linear: 0.12681236863136] nn.Sequential: [nn.Linear: 0.071145251393318 nn.Linear: 0.084216706454754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082350781543706 nn.Linear: 0.00048833632493294 nn.Linear: 0.00023209136834395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.6022373025641e-05 nn.Linear: 0.0015225995348984] nn.Sequential: [nn.Linear: 7.2996394230883e-05 nn.Linear: 0.00095719197198761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072511173784733 nn.Linear: 0.010183126665652 nn.Linear: 0.0041903294622898 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003336891066283 nn.Linear: 0.008235203102231] nn.Sequential: [nn.Linear: 0.0023775715380907 nn.Linear: 0.0092116864398122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062292025432914 nn.Linear: 0.062474228195796 nn.Linear: 0.044325716918179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031344380566466 nn.Linear: 0.030956837524826] nn.Sequential: [nn.Linear: 0.031284501895537 nn.Linear: 0.023784451434605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29549944400787 nn.Linear: 0.18622848391533 nn.Linear: 0.11186992377043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076982520520687 nn.Linear: 0.12712503969669] nn.Sequential: [nn.Linear: 0.071282505989075 nn.Linear: 0.08461781591177]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086490668238203 nn.Linear: 0.00044919231374178 nn.Linear: 0.0001970810155914 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.3427465314083e-05 nn.Linear: 0.0018356318258781] nn.Sequential: [nn.Linear: 4.4665484905027e-05 nn.Linear: 0.00066366915157461]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053427158854902 nn.Linear: 0.0094905644655228 nn.Linear: 0.0045289974659681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033640919718891 nn.Linear: 0.011741842143238] nn.Sequential: [nn.Linear: 0.0013774776598439 nn.Linear: 0.0056073367595673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062282353688312 nn.Linear: 0.06247403644679 nn.Linear: 0.04432641299766 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031344424005433 nn.Linear: 0.030931622254286] nn.Sequential: [nn.Linear: 0.031284788340762 nn.Linear: 0.02381282522531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.2960512638092 nn.Linear: 0.18729040026665 nn.Linear: 0.11180885136127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.076956152915955 nn.Linear: 0.12686800956726] nn.Sequential: [nn.Linear: 0.071294851601124 nn.Linear: 0.085375614464283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076879063577587 nn.Linear: 0.0004384354577939 nn.Linear: 0.00023733586750997 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5990134536516e-05 nn.Linear: 0.0018944701506025] nn.Sequential: [nn.Linear: 7.6546866206345e-05 nn.Linear: 0.00089489032263421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070769339799881 nn.Linear: 0.0079679796472192 nn.Linear: 0.0078437738120556 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030232118442655 nn.Linear: 0.011549537070096] nn.Sequential: [nn.Linear: 0.0020504966378212 nn.Linear: 0.0073207188397646]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062284839766821 nn.Linear: 0.062477938012031 nn.Linear: 0.044328366130317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031344927514497 nn.Linear: 0.031016404931659] nn.Sequential: [nn.Linear: 0.031285135285589 nn.Linear: 0.023844170779971]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29716947674751 nn.Linear: 0.18806694447994 nn.Linear: 0.11188002675772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077420175075531 nn.Linear: 0.12675166130066] nn.Sequential: [nn.Linear: 0.071374706923962 nn.Linear: 0.086019672453403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012010196635646 nn.Linear: 0.00068420976844778 nn.Linear: 0.00037642044365326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016341714240149 nn.Linear: 0.0040776436106416] nn.Sequential: [nn.Linear: 0.00010104705078673 nn.Linear: 0.0012632477400509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010300589725375 nn.Linear: 0.013041635043919 nn.Linear: 0.0086311306804419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049184416420758 nn.Linear: 0.020926982164383] nn.Sequential: [nn.Linear: 0.0027927597984672 nn.Linear: 0.0092158960178494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062276201852051 nn.Linear: 0.062478599525517 nn.Linear: 0.044328117868772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345244596688 nn.Linear: 0.031065289744561] nn.Sequential: [nn.Linear: 0.031285279452246 nn.Linear: 0.023861129360861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29801514744759 nn.Linear: 0.1879440844059 nn.Linear: 0.11243317276239 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077694967389107 nn.Linear: 0.12765757739544] nn.Sequential: [nn.Linear: 0.071491792798042 nn.Linear: 0.086553245782852]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012227681469937 nn.Linear: 0.00061468675159397 nn.Linear: 0.00026645053532742 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8883727646219e-05 nn.Linear: 0.0023736785519673] nn.Sequential: [nn.Linear: 9.2100828658113e-05 nn.Linear: 0.0011514165682341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011649624444544 nn.Linear: 0.0088449204340577 nn.Linear: 0.0045387428253889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040529468096793 nn.Linear: 0.011974265798926] nn.Sequential: [nn.Linear: 0.0034521482884884 nn.Linear: 0.012439482845366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06227017765419 nn.Linear: 0.062479498220723 nn.Linear: 0.04432925547294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345249995277 nn.Linear: 0.031069046295263] nn.Sequential: [nn.Linear: 0.031285543999018 nn.Linear: 0.023878056133723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.29941663146019 nn.Linear: 0.1886402964592 nn.Linear: 0.11249279975891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077847048640251 nn.Linear: 0.12777714431286] nn.Sequential: [nn.Linear: 0.071528948843479 nn.Linear: 0.086972787976265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012496485532892 nn.Linear: 0.00059849699001224 nn.Linear: 0.00031890281210519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2381879438973e-05 nn.Linear: 0.0016755428932495] nn.Sequential: [nn.Linear: 0.00013980900104467 nn.Linear: 0.0023339708546573]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086849341169 nn.Linear: 0.011315324343741 nn.Linear: 0.0059929294511676 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0036792969331145 nn.Linear: 0.010395835153759] nn.Sequential: [nn.Linear: 0.0042813643813133 nn.Linear: 0.023915747180581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062261018175869 nn.Linear: 0.06247866243051 nn.Linear: 0.044329394508377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345095054746 nn.Linear: 0.031051691619325] nn.Sequential: [nn.Linear: 0.031285726330561 nn.Linear: 0.023892847662236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30019107460976 nn.Linear: 0.18836045265198 nn.Linear: 0.11283662170172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078016236424446 nn.Linear: 0.12778720259666] nn.Sequential: [nn.Linear: 0.071582056581974 nn.Linear: 0.087183453142643]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00063552344686563 nn.Linear: 0.00035806567520681 nn.Linear: 0.00020382428753427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.0855528521236e-05 nn.Linear: 0.0012009196902796] nn.Sequential: [nn.Linear: 8.3586657728935e-05 nn.Linear: 0.0011991256078162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043246578425169 nn.Linear: 0.0068575972691178 nn.Linear: 0.0050907540135086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042990958318114 nn.Linear: 0.0094748372212052] nn.Sequential: [nn.Linear: 0.00288055697456 nn.Linear: 0.014323418028653]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062251770490481 nn.Linear: 0.062478489975543 nn.Linear: 0.044329017433586 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345269184298 nn.Linear: 0.031066725006141] nn.Sequential: [nn.Linear: 0.031285637742759 nn.Linear: 0.023892227110334]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30009445548058 nn.Linear: 0.1889106631279 nn.Linear: 0.11284227669239 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077801078557968 nn.Linear: 0.12887655198574] nn.Sequential: [nn.Linear: 0.071693509817123 nn.Linear: 0.087489172816277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011582277388221 nn.Linear: 0.00076212289370827 nn.Linear: 0.00036733258440271 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018244934570107 nn.Linear: 0.0045488717620004] nn.Sequential: [nn.Linear: 0.00010706160242369 nn.Linear: 0.0014752062696868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086078336462379 nn.Linear: 0.012607817538083 nn.Linear: 0.0074253384955227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005056684371084 nn.Linear: 0.026263419538736] nn.Sequential: [nn.Linear: 0.0033820737153292 nn.Linear: 0.014418203383684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240863330997 nn.Linear: 0.062477190300579 nn.Linear: 0.044328144410112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345309346089 nn.Linear: 0.031035312444423] nn.Sequential: [nn.Linear: 0.031285508386881 nn.Linear: 0.023893476207439]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30048561096191 nn.Linear: 0.18867616355419 nn.Linear: 0.11327211558819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.077850930392742 nn.Linear: 0.12916453182697] nn.Sequential: [nn.Linear: 0.071678601205349 nn.Linear: 0.087580218911171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00058659061580615 nn.Linear: 0.00032398728048782 nn.Linear: 0.00018040803690442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.8763100518488e-05 nn.Linear: 0.0014126474638538] nn.Sequential: [nn.Linear: 5.9034182220107e-05 nn.Linear: 0.00064913785720584]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052732578478754 nn.Linear: 0.0052753258496523 nn.Linear: 0.0037571780849248 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030638717580587 nn.Linear: 0.008492162451148] nn.Sequential: [nn.Linear: 0.0016254237852991 nn.Linear: 0.0061211097054183]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062234785852745 nn.Linear: 0.062477914272274 nn.Linear: 0.044327869053031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345324755666 nn.Linear: 0.031022035044884] nn.Sequential: [nn.Linear: 0.031285547952085 nn.Linear: 0.023899541336815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30098843574524 nn.Linear: 0.18850591778755 nn.Linear: 0.11264676600695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078111499547958 nn.Linear: 0.12856791913509] nn.Sequential: [nn.Linear: 0.07178520411253 nn.Linear: 0.087751276791096]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082943289056007 nn.Linear: 0.00048072273267794 nn.Linear: 0.00022703580365324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.094949051159e-05 nn.Linear: 0.0021589826732671] nn.Sequential: [nn.Linear: 5.8155648850028e-05 nn.Linear: 0.00067180068515307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005922042299062 nn.Linear: 0.0078558381646872 nn.Linear: 0.0066611063666642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034698667004704 nn.Linear: 0.013871543109417] nn.Sequential: [nn.Linear: 0.0017185917822644 nn.Linear: 0.0054141893051565]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062227984075741 nn.Linear: 0.06247732713067 nn.Linear: 0.044328056431009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345354162693 nn.Linear: 0.031026343885969] nn.Sequential: [nn.Linear: 0.031285492067111 nn.Linear: 0.023904133676716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30115780234337 nn.Linear: 0.18922597169876 nn.Linear: 0.11287214607 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078345149755478 nn.Linear: 0.12845157086849] nn.Sequential: [nn.Linear: 0.071854248642921 nn.Linear: 0.088267885148525]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014414040639101 nn.Linear: 0.00079505742161915 nn.Linear: 0.00039730720427559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001094652340796 nn.Linear: 0.0018301719292671] nn.Sequential: [nn.Linear: 0.00014472346771163 nn.Linear: 0.0017159393931779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011733089573681 nn.Linear: 0.011533277109265 nn.Linear: 0.0082595469430089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048304107040167 nn.Linear: 0.010419961996377] nn.Sequential: [nn.Linear: 0.0048147202469409 nn.Linear: 0.013514677062631]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062223427696391 nn.Linear: 0.062476964824171 nn.Linear: 0.044328025447312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345449864935 nn.Linear: 0.031057143588241] nn.Sequential: [nn.Linear: 0.031285546974804 nn.Linear: 0.02391088765871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30136930942535 nn.Linear: 0.18853314220905 nn.Linear: 0.11270359158516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078037112951279 nn.Linear: 0.12809684872627] nn.Sequential: [nn.Linear: 0.071988582611084 nn.Linear: 0.088481493294239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0008868605720101 nn.Linear: 0.00048108094638702 nn.Linear: 0.00025796072428969 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5091366059622e-05 nn.Linear: 0.0016998671584869] nn.Sequential: [nn.Linear: 7.2130846136734e-05 nn.Linear: 0.00089006301072483]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056973700411618 nn.Linear: 0.0089059034362435 nn.Linear: 0.0054746912792325 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040765176527202 nn.Linear: 0.01121277268976] nn.Sequential: [nn.Linear: 0.0023578023537993 nn.Linear: 0.0099271796643734]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06221435624891 nn.Linear: 0.062475022690839 nn.Linear: 0.044327358568622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345585421839 nn.Linear: 0.031072399545536] nn.Sequential: [nn.Linear: 0.031285630994435 nn.Linear: 0.023920208123308]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30161428451538 nn.Linear: 0.1881610006094 nn.Linear: 0.11339170485735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078099079430103 nn.Linear: 0.12880070507526] nn.Sequential: [nn.Linear: 0.071903206408024 nn.Linear: 0.088954463601112]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012167492487053 nn.Linear: 0.0006889878078845 nn.Linear: 0.0003858800641033 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018060181844227 nn.Linear: 0.0044479638201869] nn.Sequential: [nn.Linear: 7.6289928208153e-05 nn.Linear: 0.00094071285766603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098953489214182 nn.Linear: 0.011884937994182 nn.Linear: 0.0068128751590848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074010859243572 nn.Linear: 0.029250256717205] nn.Sequential: [nn.Linear: 0.0022382407914847 nn.Linear: 0.0089443763718009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062209198584198 nn.Linear: 0.062476385433078 nn.Linear: 0.044327669838544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345760296989 nn.Linear: 0.031112170437268] nn.Sequential: [nn.Linear: 0.031285768506086 nn.Linear: 0.023937813159947]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30231204628944 nn.Linear: 0.18858914077282 nn.Linear: 0.1137266382575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078052788972855 nn.Linear: 0.12841418385506] nn.Sequential: [nn.Linear: 0.071987971663475 nn.Linear: 0.089043118059635]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069426018935134 nn.Linear: 0.00038219404358972 nn.Linear: 0.00022366913499975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.6510299335387e-05 nn.Linear: 0.0016092209081966] nn.Sequential: [nn.Linear: 7.7741030949833e-05 nn.Linear: 0.0010117403164182]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058472687378526 nn.Linear: 0.0050411988049746 nn.Linear: 0.003790489397943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0022186690475792 nn.Linear: 0.012007094919682] nn.Sequential: [nn.Linear: 0.0022794262040406 nn.Linear: 0.0075983791612089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062205311959456 nn.Linear: 0.062476753397561 nn.Linear: 0.044328177927287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031345920124092 nn.Linear: 0.031144266865226] nn.Sequential: [nn.Linear: 0.031285794069675 nn.Linear: 0.023940964767601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30336371064186 nn.Linear: 0.18947103619576 nn.Linear: 0.11419586092234 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078191183507442 nn.Linear: 0.12814420461655] nn.Sequential: [nn.Linear: 0.07190765440464 nn.Linear: 0.089457549154758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009798791679822 nn.Linear: 0.0005526109642249 nn.Linear: 0.00034040686321675 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010472875532239 nn.Linear: 0.001812093000813] nn.Sequential: [nn.Linear: 0.00014684294770959 nn.Linear: 0.0021466349428361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081380670890212 nn.Linear: 0.01514651812613 nn.Linear: 0.0059284982271492 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004248823504895 nn.Linear: 0.015008958987892] nn.Sequential: [nn.Linear: 0.0045955651439726 nn.Linear: 0.017287721857429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.12290512763709	TD error	0.018527985349298	Qmax	1	

Steps: 1250000 (frames: 5000000), score: 1860.25, higheset score: 6196, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1814fps, testing time: 89s, testing rate: 5577fps,  num. ep.: 252,  num. rewards: 13365	
   4    2   32    4
   2   32   64  256
   4    2    8  512
   2    4    2   16
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062201239022282 nn.Linear: 0.062477931413833 nn.Linear: 0.04432916380303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346002074938 nn.Linear: 0.031149695916774] nn.Sequential: [nn.Linear: 0.031286022722726 nn.Linear: 0.023955323473588]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30423232913017 nn.Linear: 0.1890797317028 nn.Linear: 0.11424478888512 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078316830098629 nn.Linear: 0.12807603180408] nn.Sequential: [nn.Linear: 0.071975365281105 nn.Linear: 0.089776314795017]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.000898973466323 nn.Linear: 0.00061672898475906 nn.Linear: 0.00032468083874677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016200654822071 nn.Linear: 0.0044283298187719] nn.Sequential: [nn.Linear: 7.7949734754707e-05 nn.Linear: 0.0011657336001154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077859233133495 nn.Linear: 0.0096955839544535 nn.Linear: 0.0098386146128178 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046205813996494 nn.Linear: 0.023751430213451] nn.Sequential: [nn.Linear: 0.002383770653978 nn.Linear: 0.012298142537475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062191442897316 nn.Linear: 0.062477450093383 nn.Linear: 0.044329360428898 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346113126359 nn.Linear: 0.031156022604819] nn.Sequential: [nn.Linear: 0.031286160310957 nn.Linear: 0.023968231229779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30449342727661 nn.Linear: 0.18941393494606 nn.Linear: 0.11443237960339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078327968716621 nn.Linear: 0.12798295915127] nn.Sequential: [nn.Linear: 0.072040885686874 nn.Linear: 0.089964359998703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00060505061951807 nn.Linear: 0.00031970264370011 nn.Linear: 0.00016251020762125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 4.4535590598949e-05 nn.Linear: 0.0006855220926405] nn.Sequential: [nn.Linear: 6.7567847613346e-05 nn.Linear: 0.00093788979298787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004884144756943 nn.Linear: 0.0046369447372854 nn.Linear: 0.0034241524990648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0017345498781651 nn.Linear: 0.005765846464783] nn.Sequential: [nn.Linear: 0.0021627657115459 nn.Linear: 0.0070176576264203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062181496064115 nn.Linear: 0.06248089261492 nn.Linear: 0.044330212057962 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346320909827 nn.Linear: 0.031185231384654] nn.Sequential: [nn.Linear: 0.031286314786821 nn.Linear: 0.023991170126157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30497795343399 nn.Linear: 0.1885120421648 nn.Linear: 0.11488953232765 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078337050974369 nn.Linear: 0.12876135110855] nn.Sequential: [nn.Linear: 0.072014763951302 nn.Linear: 0.090218655765057]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00058614760763531 nn.Linear: 0.0003401966687108 nn.Linear: 0.00017050274523943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1365189577109e-05 nn.Linear: 0.00096693273455051] nn.Sequential: [nn.Linear: 5.2502706713453e-05 nn.Linear: 0.00075655191304813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0050538005307317 nn.Linear: 0.0061634024605155 nn.Linear: 0.0039971945807338 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.002545066177845 nn.Linear: 0.0057569034397602] nn.Sequential: [nn.Linear: 0.0020342604257166 nn.Linear: 0.0074888523668051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062179160181689 nn.Linear: 0.062480887131599 nn.Linear: 0.044330397379774 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346492480916 nn.Linear: 0.031225499392065] nn.Sequential: [nn.Linear: 0.031286167501793 nn.Linear: 0.02398752373097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30540439486504 nn.Linear: 0.18852171301842 nn.Linear: 0.11472116410732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078729763627052 nn.Linear: 0.12904396653175] nn.Sequential: [nn.Linear: 0.072031565010548 nn.Linear: 0.090690083801746]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013191874437396 nn.Linear: 0.00068643580027194 nn.Linear: 0.00024242299352405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0769392495375e-05 nn.Linear: 0.0018343170959496] nn.Sequential: [nn.Linear: 7.4949100221817e-05 nn.Linear: 0.0010248587310569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010719116777182 nn.Linear: 0.010425385087729 nn.Linear: 0.0064593381248415 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045017506927252 nn.Linear: 0.012853175401688] nn.Sequential: [nn.Linear: 0.0022159940563142 nn.Linear: 0.0095813469961286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062176126773966 nn.Linear: 0.062483256433464 nn.Linear: 0.044331212327879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346698751849 nn.Linear: 0.031288473052683] nn.Sequential: [nn.Linear: 0.031286320871225 nn.Linear: 0.024000961568851]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3058814406395 nn.Linear: 0.1883479654789 nn.Linear: 0.11525658518076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078543908894062 nn.Linear: 0.1290806978941] nn.Sequential: [nn.Linear: 0.072069346904755 nn.Linear: 0.091404557228088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009546023054279 nn.Linear: 0.00049093888183921 nn.Linear: 0.0002356121430831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.3877869430887e-05 nn.Linear: 0.0013013394414574] nn.Sequential: [nn.Linear: 8.2161090142728e-05 nn.Linear: 0.0009814616014044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083111226558685 nn.Linear: 0.0084696104750037 nn.Linear: 0.0049901534803212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031022189650685 nn.Linear: 0.0076723955571651] nn.Sequential: [nn.Linear: 0.0031470595858991 nn.Linear: 0.0067574800923467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062171500991829 nn.Linear: 0.062483854003129 nn.Linear: 0.044332086772639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346587953083 nn.Linear: 0.031255061992177] nn.Sequential: [nn.Linear: 0.031286651182754 nn.Linear: 0.024022715380404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30659556388855 nn.Linear: 0.18794284760952 nn.Linear: 0.1150336265564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078868292272091 nn.Linear: 0.12878845632076] nn.Sequential: [nn.Linear: 0.07216028124094 nn.Linear: 0.091547898948193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091176577669064 nn.Linear: 0.00049747265355995 nn.Linear: 0.000269043688979 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001008084916456 nn.Linear: 0.0023616963193715] nn.Sequential: [nn.Linear: 0.00010269406114203 nn.Linear: 0.0015905922829917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074661066755652 nn.Linear: 0.0086801555007696 nn.Linear: 0.0061405380256474 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043358434922993 nn.Linear: 0.014347368851304] nn.Sequential: [nn.Linear: 0.0034427039790899 nn.Linear: 0.015439323149621]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062162524704462 nn.Linear: 0.062484287288942 nn.Linear: 0.04433245363414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346640332132 nn.Linear: 0.031300064036484] nn.Sequential: [nn.Linear: 0.031286787555743 nn.Linear: 0.024038123667689]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30785688757896 nn.Linear: 0.18869557976723 nn.Linear: 0.11498025804758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078889787197113 nn.Linear: 0.12887717783451] nn.Sequential: [nn.Linear: 0.072120971977711 nn.Linear: 0.091810196638107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077354665708709 nn.Linear: 0.00039600381268758 nn.Linear: 0.00022207473302262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.1431691630497e-05 nn.Linear: 0.0014175697194912] nn.Sequential: [nn.Linear: 9.4828663624606e-05 nn.Linear: 0.0012614178022306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059988149441779 nn.Linear: 0.0065887649543583 nn.Linear: 0.0041104769334197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0028670858591795 nn.Linear: 0.0089007448405027] nn.Sequential: [nn.Linear: 0.0027928594499826 nn.Linear: 0.014404265210032]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062162189918547 nn.Linear: 0.062485470131878 nn.Linear: 0.044333381737578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03134684650988 nn.Linear: 0.031341477019566] nn.Sequential: [nn.Linear: 0.031286938589029 nn.Linear: 0.024055425558258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.30892160534859 nn.Linear: 0.189308360219 nn.Linear: 0.11521214991808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079003259539604 nn.Linear: 0.12941189110279] nn.Sequential: [nn.Linear: 0.072077736258507 nn.Linear: 0.09208482503891]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013300183081421 nn.Linear: 0.00077508000146405 nn.Linear: 0.00045743955213623 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021116785719945 nn.Linear: 0.005145755581448] nn.Sequential: [nn.Linear: 0.00014379483735251 nn.Linear: 0.002077227015787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089424643665552 nn.Linear: 0.01508351508528 nn.Linear: 0.0094135804101825 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091350460425019 nn.Linear: 0.031168317422271] nn.Sequential: [nn.Linear: 0.0060152811929584 nn.Linear: 0.017741836607456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06216037182184 nn.Linear: 0.062489862120097 nn.Linear: 0.044334401878896 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031346991217561 nn.Linear: 0.031384990144026] nn.Sequential: [nn.Linear: 0.031287181097273 nn.Linear: 0.024069368708286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3092400431633 nn.Linear: 0.18872848153114 nn.Linear: 0.11488472670317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.07906374335289 nn.Linear: 0.13017436861992] nn.Sequential: [nn.Linear: 0.072136722505093 nn.Linear: 0.09261192381382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094341140840765 nn.Linear: 0.00053835804771241 nn.Linear: 0.00028156423773332 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010280310462585 nn.Linear: 0.002175249490677] nn.Sequential: [nn.Linear: 9.9539475983663e-05 nn.Linear: 0.0012937772701994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067255361936986 nn.Linear: 0.0095210708677769 nn.Linear: 0.0052868537604809 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042402725666761 nn.Linear: 0.013421128503978] nn.Sequential: [nn.Linear: 0.0025423720944673 nn.Linear: 0.014432592317462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062156129509252 nn.Linear: 0.062491744872553 nn.Linear: 0.04433515930952 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031347599549318 nn.Linear: 0.031524720082146] nn.Sequential: [nn.Linear: 0.031286962296132 nn.Linear: 0.02407234166105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31000182032585 nn.Linear: 0.18896327912807 nn.Linear: 0.11508580297232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079190254211426 nn.Linear: 0.13121294975281] nn.Sequential: [nn.Linear: 0.072168134152889 nn.Linear: 0.092523507773876]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027431025582255 nn.Linear: 0.0012817483307502 nn.Linear: 0.00056671748788342 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024384837961795 nn.Linear: 0.0054156476347174] nn.Sequential: [nn.Linear: 8.0490931513948e-05 nn.Linear: 0.00089655437022898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019289055839181 nn.Linear: 0.026337085291743 nn.Linear: 0.016970546916127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091804480180144 nn.Linear: 0.036393295973539] nn.Sequential: [nn.Linear: 0.0051635606214404 nn.Linear: 0.0069014001637697]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062154896706705 nn.Linear: 0.062492331927156 nn.Linear: 0.044335445876424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031347733900017 nn.Linear: 0.031566818978931] nn.Sequential: [nn.Linear: 0.031286824798552 nn.Linear: 0.024085926810326]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31056323647499 nn.Linear: 0.18901109695435 nn.Linear: 0.11542169004679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079630695283413 nn.Linear: 0.13143730163574] nn.Sequential: [nn.Linear: 0.0721295773983 nn.Linear: 0.092835232615471]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028465605936375 nn.Linear: 0.0015077206912277 nn.Linear: 0.00074083110369122 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025068657704257 nn.Linear: 0.0048623380372188] nn.Sequential: [nn.Linear: 0.00024318331246623 nn.Linear: 0.0037367359626019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024132927879691 nn.Linear: 0.030696049332619 nn.Linear: 0.021869963034987 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013910632580519 nn.Linear: 0.038845125585794] nn.Sequential: [nn.Linear: 0.0091479513794184 nn.Linear: 0.04380089789629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062148062880183 nn.Linear: 0.062492980184854 nn.Linear: 0.044335686576691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031347611363871 nn.Linear: 0.031539043590129] nn.Sequential: [nn.Linear: 0.031287229148567 nn.Linear: 0.024108471142915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31099551916122 nn.Linear: 0.18970811367035 nn.Linear: 0.11534886807203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079383291304111 nn.Linear: 0.1311976313591] nn.Sequential: [nn.Linear: 0.072195872664452 nn.Linear: 0.093618795275688]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082282672840412 nn.Linear: 0.00042231817237699 nn.Linear: 0.00019767699493323 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.9975515768049e-05 nn.Linear: 0.00094421085677432] nn.Sequential: [nn.Linear: 6.5939543956882e-05 nn.Linear: 0.00080250963920969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069519937969744 nn.Linear: 0.0080794170498848 nn.Linear: 0.0053654001094401 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031024895142764 nn.Linear: 0.0063902582041919] nn.Sequential: [nn.Linear: 0.0017264327034354 nn.Linear: 0.0079001523554325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062147085100157 nn.Linear: 0.062495522829292 nn.Linear: 0.044336992581002 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031347623821347 nn.Linear: 0.031535783798276] nn.Sequential: [nn.Linear: 0.031287626231752 nn.Linear: 0.024128608113004]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31161305308342 nn.Linear: 0.18966798484325 nn.Linear: 0.11517798900604 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079070821404457 nn.Linear: 0.13104455173016] nn.Sequential: [nn.Linear: 0.072155460715294 nn.Linear: 0.093900978565216]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017087978060324 nn.Linear: 0.00072206811337239 nn.Linear: 0.00027461081756694 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.2730043643662e-05 nn.Linear: 0.0013177111621507] nn.Sequential: [nn.Linear: 9.4780142256324e-05 nn.Linear: 0.0011603228540366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01438214816153 nn.Linear: 0.012484041042626 nn.Linear: 0.0094510894268751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042739645577967 nn.Linear: 0.0087681114673615] nn.Sequential: [nn.Linear: 0.0037014789413661 nn.Linear: 0.013397973962128]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062139341917574 nn.Linear: 0.062495897947183 nn.Linear: 0.044337313142323 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031347940326394 nn.Linear: 0.031608034304952] nn.Sequential: [nn.Linear: 0.031287644624544 nn.Linear: 0.024143113678889]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31257200241089 nn.Linear: 0.19000260531902 nn.Linear: 0.11546902358532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079164654016495 nn.Linear: 0.13198059797287] nn.Sequential: [nn.Linear: 0.072180710732937 nn.Linear: 0.09407664090395]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019174131184657 nn.Linear: 0.0010699683902459 nn.Linear: 0.0005846452520724 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022732187974856 nn.Linear: 0.0049344218418132] nn.Sequential: [nn.Linear: 0.0002112856316738 nn.Linear: 0.0027573307050604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012469566427171 nn.Linear: 0.015491288155317 nn.Linear: 0.011559912934899 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077782380394638 nn.Linear: 0.031519059091806] nn.Sequential: [nn.Linear: 0.007097524125129 nn.Linear: 0.031766168773174]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062135862149007 nn.Linear: 0.062498325423039 nn.Linear: 0.044337972018541 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0313481194638 nn.Linear: 0.031616025530411] nn.Sequential: [nn.Linear: 0.031287829596737 nn.Linear: 0.024156070316939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3129910826683 nn.Linear: 0.19042514264584 nn.Linear: 0.11560545861721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079108729958534 nn.Linear: 0.1318496465683] nn.Sequential: [nn.Linear: 0.072153590619564 nn.Linear: 0.094220846891403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011431234603118 nn.Linear: 0.00062412007529487 nn.Linear: 0.00028866359631251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.3263608107607e-05 nn.Linear: 0.0020159808374896] nn.Sequential: [nn.Linear: 9.729763056909e-05 nn.Linear: 0.0013334151486738]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010809342376888 nn.Linear: 0.012710547074676 nn.Linear: 0.0071980291977525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039517311379313 nn.Linear: 0.012285941280425] nn.Sequential: [nn.Linear: 0.0027643125504255 nn.Linear: 0.0094167878851295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062128174881497 nn.Linear: 0.062496615659608 nn.Linear: 0.044338400395408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031348161275273 nn.Linear: 0.031627967550548] nn.Sequential: [nn.Linear: 0.031287988604594 nn.Linear: 0.024167637781915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31356194615364 nn.Linear: 0.19085571169853 nn.Linear: 0.11584048718214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079129561781883 nn.Linear: 0.13250251114368] nn.Sequential: [nn.Linear: 0.072335183620453 nn.Linear: 0.094572357833385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00075289493007144 nn.Linear: 0.0003450479193879 nn.Linear: 0.00016605618159056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1840528344453e-05 nn.Linear: 0.0009720936015476] nn.Sequential: [nn.Linear: 4.3252772724593e-05 nn.Linear: 0.00041045828775291]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072355722077191 nn.Linear: 0.0059739798307419 nn.Linear: 0.0033897475805134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0024440272245556 nn.Linear: 0.0084956847131252] nn.Sequential: [nn.Linear: 0.0017740036128089 nn.Linear: 0.0048652463592589]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062130022152309 nn.Linear: 0.062500739740574 nn.Linear: 0.044339926167684 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031348550277155 nn.Linear: 0.031688786666891] nn.Sequential: [nn.Linear: 0.0312881950809 nn.Linear: 0.024191630275378]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31429180502892 nn.Linear: 0.19045494496822 nn.Linear: 0.11565801501274 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078960247337818 nn.Linear: 0.13277150690556] nn.Sequential: [nn.Linear: 0.072415411472321 nn.Linear: 0.095311559736729]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00051956079606502 nn.Linear: 0.00034297947795654 nn.Linear: 0.00019428406733807 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1647424474462e-05 nn.Linear: 0.00098708406648929] nn.Sequential: [nn.Linear: 7.724695582106e-05 nn.Linear: 0.0011593618585542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0042065745219588 nn.Linear: 0.0048605897463858 nn.Linear: 0.0055118794552982 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0024861481506377 nn.Linear: 0.0058967494405806] nn.Sequential: [nn.Linear: 0.0021001165732741 nn.Linear: 0.012661757878959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062132414713573 nn.Linear: 0.062504575847808 nn.Linear: 0.04434147146776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031348920253533 nn.Linear: 0.031770614858658] nn.Sequential: [nn.Linear: 0.031288425950184 nn.Linear: 0.024209582698065]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31472870707512 nn.Linear: 0.19071184098721 nn.Linear: 0.11596056818962 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078886196017265 nn.Linear: 0.13334350287914] nn.Sequential: [nn.Linear: 0.072584256529808 nn.Linear: 0.095883317291737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012071239562321 nn.Linear: 0.00064943558744988 nn.Linear: 0.00037454900415193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011985705671329 nn.Linear: 0.002293947761446] nn.Sequential: [nn.Linear: 0.00016717193026026 nn.Linear: 0.0024401681943666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013324950821698 nn.Linear: 0.011959187686443 nn.Linear: 0.0059289229102433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063593829981983 nn.Linear: 0.014906129799783] nn.Sequential: [nn.Linear: 0.0058165732771158 nn.Linear: 0.028832718729973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062129625386273 nn.Linear: 0.062507696568585 nn.Linear: 0.04434293984443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03134922896841 nn.Linear: 0.031815066236703] nn.Sequential: [nn.Linear: 0.031288709091761 nn.Linear: 0.024233324026465]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31531172990799 nn.Linear: 0.19138818979263 nn.Linear: 0.11645083129406 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078881196677685 nn.Linear: 0.13358601927757] nn.Sequential: [nn.Linear: 0.072717241942883 nn.Linear: 0.096574895083904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007467943849445 nn.Linear: 0.00040714311382364 nn.Linear: 0.00019565100096471 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.3315482734446e-05 nn.Linear: 0.001281298725706] nn.Sequential: [nn.Linear: 5.5210786591279e-05 nn.Linear: 0.0006192053594307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005469209048897 nn.Linear: 0.0085493456572294 nn.Linear: 0.0039004520513117 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033417528029531 nn.Linear: 0.0087696565315127] nn.Sequential: [nn.Linear: 0.0014329428086057 nn.Linear: 0.0039593386463821]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062128272539397 nn.Linear: 0.062510821330125 nn.Linear: 0.044343442235446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031349488967607 nn.Linear: 0.031880673755836] nn.Sequential: [nn.Linear: 0.031288859438878 nn.Linear: 0.024251158612159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3161945939064 nn.Linear: 0.19052952528 nn.Linear: 0.11606042832136 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.078664675354958 nn.Linear: 0.13408207893372] nn.Sequential: [nn.Linear: 0.072800971567631 nn.Linear: 0.096744574606419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021826789994085 nn.Linear: 0.0012549025423857 nn.Linear: 0.00070281291290052 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023445346782594 nn.Linear: 0.0039211693023602] nn.Sequential: [nn.Linear: 0.00024740622184736 nn.Linear: 0.003084626424003]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01606810092926 nn.Linear: 0.020507961511612 nn.Linear: 0.019960639998317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082276174798608 nn.Linear: 0.028736393898726] nn.Sequential: [nn.Linear: 0.007185329683125 nn.Linear: 0.034951511770487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062129854693192 nn.Linear: 0.06251167991794 nn.Linear: 0.044344336594737 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031349673158451 nn.Linear: 0.031913197161089] nn.Sequential: [nn.Linear: 0.031288845474417 nn.Linear: 0.024258852764638]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31662020087242 nn.Linear: 0.19069372117519 nn.Linear: 0.11605405062437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079031080007553 nn.Linear: 0.13422641158104] nn.Sequential: [nn.Linear: 0.072959162294865 nn.Linear: 0.096494399011135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015355998171014 nn.Linear: 0.00085244917853918 nn.Linear: 0.00041915607132889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017762724432982 nn.Linear: 0.0043002954462313] nn.Sequential: [nn.Linear: 7.6174588814656e-05 nn.Linear: 0.00096494070494961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010689313523471 nn.Linear: 0.017084771767259 nn.Linear: 0.0069880289956927 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062357177957892 nn.Linear: 0.025324834510684] nn.Sequential: [nn.Linear: 0.0026171377394348 nn.Linear: 0.0085122557356954]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062126815995294 nn.Linear: 0.062515337471515 nn.Linear: 0.044345394605249 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031349868989645 nn.Linear: 0.031986499577329] nn.Sequential: [nn.Linear: 0.031289042731398 nn.Linear: 0.024277946584959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31724217534065 nn.Linear: 0.19123266637325 nn.Linear: 0.11624544858932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079447984695435 nn.Linear: 0.13374283909798] nn.Sequential: [nn.Linear: 0.072969041764736 nn.Linear: 0.096436396241188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017960542534174 nn.Linear: 0.00082462262712307 nn.Linear: 0.00035876573007138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011355956189616 nn.Linear: 0.0021738501336239] nn.Sequential: [nn.Linear: 9.8578832266328e-05 nn.Linear: 0.0011438428182325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013885959982872 nn.Linear: 0.019570773467422 nn.Linear: 0.0084862075746059 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049250097945333 nn.Linear: 0.012555400840938] nn.Sequential: [nn.Linear: 0.0030585385393351 nn.Linear: 0.011345090344548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062122718052967 nn.Linear: 0.062518807821336 nn.Linear: 0.044346786194596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031350246236521 nn.Linear: 0.032055809882934] nn.Sequential: [nn.Linear: 0.031289208057097 nn.Linear: 0.024298775727214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31800162792206 nn.Linear: 0.19112509489059 nn.Linear: 0.11689557135105 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079593889415264 nn.Linear: 0.1347680836916] nn.Sequential: [nn.Linear: 0.072889305651188 nn.Linear: 0.096955135464668]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00136721285287 nn.Linear: 0.00072586871418011 nn.Linear: 0.0003379473515543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010970964539367 nn.Linear: 0.0017269694339901] nn.Sequential: [nn.Linear: 0.00011905866227841 nn.Linear: 0.0014534729547703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013029132969677 nn.Linear: 0.010739873163402 nn.Linear: 0.0081225801259279 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044472045265138 nn.Linear: 0.010143267922103] nn.Sequential: [nn.Linear: 0.0051416251808405 nn.Linear: 0.011690925806761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062119568233268 nn.Linear: 0.062521187583639 nn.Linear: 0.044347603476966 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03135040043327 nn.Linear: 0.032116591118097] nn.Sequential: [nn.Linear: 0.031289426147573 nn.Linear: 0.024318843429659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31781905889511 nn.Linear: 0.19178386032581 nn.Linear: 0.11664194613695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079404301941395 nn.Linear: 0.13454142212868] nn.Sequential: [nn.Linear: 0.072946809232235 nn.Linear: 0.097208797931671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.000957598532703 nn.Linear: 0.00050102912854062 nn.Linear: 0.00025434697974876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0076403542641e-05 nn.Linear: 0.0011994871889597] nn.Sequential: [nn.Linear: 7.7565604057522e-05 nn.Linear: 0.00087363344272579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071048201061785 nn.Linear: 0.0087888333946466 nn.Linear: 0.0068109179846942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042013204656541 nn.Linear: 0.0073775108903646] nn.Sequential: [nn.Linear: 0.0017134267836809 nn.Linear: 0.0069888844154775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062121715869688 nn.Linear: 0.062522912844059 nn.Linear: 0.044348737851872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031350457270219 nn.Linear: 0.03213149928672] nn.Sequential: [nn.Linear: 0.031289766057685 nn.Linear: 0.02434401809106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31793767213821 nn.Linear: 0.19180382788181 nn.Linear: 0.11637873202562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0794338285923 nn.Linear: 0.13451091945171] nn.Sequential: [nn.Linear: 0.07305958122015 nn.Linear: 0.097447909414768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00058404694657886 nn.Linear: 0.00029912142099945 nn.Linear: 0.00015177729168455 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.0079327763297e-05 nn.Linear: 0.00083917181301996] nn.Sequential: [nn.Linear: 5.1067897712411e-05 nn.Linear: 0.00069075063417556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067217573523521 nn.Linear: 0.0057100467383862 nn.Linear: 0.0037445735652 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0021446063183248 nn.Linear: 0.0049969721585512] nn.Sequential: [nn.Linear: 0.0013244398869574 nn.Linear: 0.0056438436731696]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.11502592334151	TD error	0.019687946934253	Qmax	1	

Steps: 1500000 (frames: 6000000), score: 1859.49, higheset score: 5664, epsilon: 0.05, lr: 0.0005, training time: 582s, training rate: 1718fps, testing time: 96s, testing rate: 5181fps,  num. ep.: 316,  num. rewards: 15653	
   2    4   32   64
   8   16  128  512
   2   32   64    2
   4    8   32    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062122445990348 nn.Linear: 0.062525878283062 nn.Linear: 0.044349854607922 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031350865969463 nn.Linear: 0.032189414926847] nn.Sequential: [nn.Linear: 0.031289992001615 nn.Linear: 0.024361939197496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31827348470688 nn.Linear: 0.19213818013668 nn.Linear: 0.11646103858948 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079899184405804 nn.Linear: 0.13458938896656] nn.Sequential: [nn.Linear: 0.073070615530014 nn.Linear: 0.097640596330166]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015126630931344 nn.Linear: 0.00098607814170324 nn.Linear: 0.00047014045812292 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012755657527624 nn.Linear: 0.0026926522271991] nn.Sequential: [nn.Linear: 0.00016689038863463 nn.Linear: 0.0020315349857802]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012120355851948 nn.Linear: 0.016298737376928 nn.Linear: 0.0096119521185756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055907969363034 nn.Linear: 0.01648179627955] nn.Sequential: [nn.Linear: 0.005636349786073 nn.Linear: 0.020354462787509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062123580918413 nn.Linear: 0.062527312754882 nn.Linear: 0.044351153267108 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031351234101593 nn.Linear: 0.032264763135231] nn.Sequential: [nn.Linear: 0.031290051778132 nn.Linear: 0.024382316335306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.31891712546349 nn.Linear: 0.19295485317707 nn.Linear: 0.11669899523258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0797338783741 nn.Linear: 0.13458314538002] nn.Sequential: [nn.Linear: 0.073284186422825 nn.Linear: 0.098027817904949]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001645921751938 nn.Linear: 0.0008081042296454 nn.Linear: 0.00034640833353254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000117633147923 nn.Linear: 0.0018867386738781] nn.Sequential: [nn.Linear: 0.00010209056318931 nn.Linear: 0.0012154373817823]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016409449279308 nn.Linear: 0.01844060048461 nn.Linear: 0.0091534629464149 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052767214365304 nn.Linear: 0.013475910760462] nn.Sequential: [nn.Linear: 0.002966979984194 nn.Linear: 0.010680001229048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06211970001349 nn.Linear: 0.0625297726196 nn.Linear: 0.044352102251071 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031351491473755 nn.Linear: 0.032298924982342] nn.Sequential: [nn.Linear: 0.031290229422723 nn.Linear: 0.024396278747524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32000496983528 nn.Linear: 0.19297349452972 nn.Linear: 0.11698193848133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080037750303745 nn.Linear: 0.13520373404026] nn.Sequential: [nn.Linear: 0.073460698127747 nn.Linear: 0.098612785339355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019726259208403 nn.Linear: 0.00091466969535359 nn.Linear: 0.00040438028645436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012221887373091 nn.Linear: 0.0021477071964489] nn.Sequential: [nn.Linear: 0.00014491188120623 nn.Linear: 0.0020535697395536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012986964546144 nn.Linear: 0.018381532281637 nn.Linear: 0.012200691737235 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061669889837503 nn.Linear: 0.013965616002679] nn.Sequential: [nn.Linear: 0.0055164117366076 nn.Linear: 0.025497552007437]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062115271945832 nn.Linear: 0.062530635175095 nn.Linear: 0.044352654561558 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031351443591928 nn.Linear: 0.032276826804036] nn.Sequential: [nn.Linear: 0.031290620079409 nn.Linear: 0.024420605418512]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32025769352913 nn.Linear: 0.19288408756256 nn.Linear: 0.11688132584095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.079841174185276 nn.Linear: 0.13484632968903] nn.Sequential: [nn.Linear: 0.073667898774147 nn.Linear: 0.099217854440212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014317211857989 nn.Linear: 0.00065690842877394 nn.Linear: 0.00035400516631661 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013913182635644 nn.Linear: 0.0026979433961205] nn.Sequential: [nn.Linear: 0.00011506480326169 nn.Linear: 0.0015149466033222]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01273478101939 nn.Linear: 0.012012144550681 nn.Linear: 0.0084019377827644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00586794083938 nn.Linear: 0.019112283363938] nn.Sequential: [nn.Linear: 0.0033961520530283 nn.Linear: 0.015666646882892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062115934429637 nn.Linear: 0.062532527615687 nn.Linear: 0.044353779545413 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03135137980771 nn.Linear: 0.03227085444027] nn.Sequential: [nn.Linear: 0.031291064075732 nn.Linear: 0.024455639592361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3202488720417 nn.Linear: 0.19202336668968 nn.Linear: 0.1167183816433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080050259828568 nn.Linear: 0.13515688478947] nn.Sequential: [nn.Linear: 0.07368142157793 nn.Linear: 0.099567823112011]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010665945655417 nn.Linear: 0.00060723596855351 nn.Linear: 0.0003154684513025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001220325755848 nn.Linear: 0.0021908867454778] nn.Sequential: [nn.Linear: 9.1403952385747e-05 nn.Linear: 0.001138739607365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012002122588456 nn.Linear: 0.010947106406093 nn.Linear: 0.0057747629471123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051300623454154 nn.Linear: 0.012298651970923] nn.Sequential: [nn.Linear: 0.0025073697324842 nn.Linear: 0.010584698989987]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06211768958611 nn.Linear: 0.062535641290911 nn.Linear: 0.044354965479054 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031351646379735 nn.Linear: 0.032276561882583] nn.Sequential: [nn.Linear: 0.031291310216136 nn.Linear: 0.024475727213069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32104581594467 nn.Linear: 0.19209976494312 nn.Linear: 0.11608707904816 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080353975296021 nn.Linear: 0.13574157655239] nn.Sequential: [nn.Linear: 0.073910482227802 nn.Linear: 0.099598757922649]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001141836010393 nn.Linear: 0.00054239624759832 nn.Linear: 0.00027861170017542 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011797986678559 nn.Linear: 0.0023364145327429] nn.Sequential: [nn.Linear: 5.481521704523e-05 nn.Linear: 0.00067924378395902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091761127114296 nn.Linear: 0.011969952844083 nn.Linear: 0.005725922062993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049782278947532 nn.Linear: 0.014418649487197] nn.Sequential: [nn.Linear: 0.001660538255237 nn.Linear: 0.008104951120913]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062112772445823 nn.Linear: 0.062537330417973 nn.Linear: 0.044355765784786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031351889121807 nn.Linear: 0.032352149429641] nn.Sequential: [nn.Linear: 0.031291401675072 nn.Linear: 0.024493658350846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32148057222366 nn.Linear: 0.1916583776474 nn.Linear: 0.11617384850979 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080289788544178 nn.Linear: 0.13641242682934] nn.Sequential: [nn.Linear: 0.073862679302692 nn.Linear: 0.099946245551109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016948199796596 nn.Linear: 0.00079198907617651 nn.Linear: 0.00038012734365715 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013665359343005 nn.Linear: 0.0026168951541443] nn.Sequential: [nn.Linear: 0.00011280281503943 nn.Linear: 0.0014474614278366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011361566372216 nn.Linear: 0.014753428287804 nn.Linear: 0.0069319973699749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053387633524835 nn.Linear: 0.021700037643313] nn.Sequential: [nn.Linear: 0.0031678986269981 nn.Linear: 0.0092969071120024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062115739605041 nn.Linear: 0.062542606760197 nn.Linear: 0.044357016839293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352088396807 nn.Linear: 0.032350080352842] nn.Sequential: [nn.Linear: 0.031291785023924 nn.Linear: 0.024517000918429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32160028815269 nn.Linear: 0.1918740272522 nn.Linear: 0.11639012396336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080516807734966 nn.Linear: 0.13663394749165] nn.Sequential: [nn.Linear: 0.074075646698475 nn.Linear: 0.10013911873102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011292034073483 nn.Linear: 0.00076555751966571 nn.Linear: 0.00040104804877752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020492916165995 nn.Linear: 0.0053477478853977] nn.Sequential: [nn.Linear: 0.00011950110799246 nn.Linear: 0.0018054920661868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010834271088243 nn.Linear: 0.014923760667443 nn.Linear: 0.0072136567905545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074332994408906 nn.Linear: 0.028018768876791] nn.Sequential: [nn.Linear: 0.0028165276162326 nn.Linear: 0.016618089750409]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062113840678741 nn.Linear: 0.062543624439132 nn.Linear: 0.04435815579144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352285206843 nn.Linear: 0.032377599831477] nn.Sequential: [nn.Linear: 0.031291976366642 nn.Linear: 0.024539113615959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32216623425484 nn.Linear: 0.19226045906544 nn.Linear: 0.11618895828724 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080598495900631 nn.Linear: 0.13699010014534] nn.Sequential: [nn.Linear: 0.074000611901283 nn.Linear: 0.10066670924425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083118556541724 nn.Linear: 0.00059091268743094 nn.Linear: 0.00029335587890449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011033410485014 nn.Linear: 0.0024978871734458] nn.Sequential: [nn.Linear: 7.4587476289388e-05 nn.Linear: 0.00097941427022574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079771680757403 nn.Linear: 0.010536963120103 nn.Linear: 0.0085835698992014 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051013906486332 nn.Linear: 0.015270937234163] nn.Sequential: [nn.Linear: 0.0034802772570401 nn.Linear: 0.011105465702713]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062110127533716 nn.Linear: 0.062547265167238 nn.Linear: 0.044359249381488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352553060817 nn.Linear: 0.032455868521751] nn.Sequential: [nn.Linear: 0.031292138936288 nn.Linear: 0.024565234989693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32296648621559 nn.Linear: 0.19190062582493 nn.Linear: 0.11682137101889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080636665225029 nn.Linear: 0.13764907419682] nn.Sequential: [nn.Linear: 0.074048906564713 nn.Linear: 0.10094063729048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015383413623788 nn.Linear: 0.0009383794409549 nn.Linear: 0.00050627359449199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017899730459513 nn.Linear: 0.002757845715994] nn.Sequential: [nn.Linear: 0.00018054925501548 nn.Linear: 0.0022365783606496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012005222961307 nn.Linear: 0.023026091977954 nn.Linear: 0.010542258620262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068121231161058 nn.Linear: 0.015015096403658] nn.Sequential: [nn.Linear: 0.005319275893271 nn.Linear: 0.024757416918874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062110448911362 nn.Linear: 0.062549690051661 nn.Linear: 0.044360340181833 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352709351641 nn.Linear: 0.032468190772605] nn.Sequential: [nn.Linear: 0.031292355542862 nn.Linear: 0.024583669421322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32246592640877 nn.Linear: 0.19162258505821 nn.Linear: 0.11704381555319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080689191818237 nn.Linear: 0.13774991035461] nn.Sequential: [nn.Linear: 0.074132658541203 nn.Linear: 0.10100496560335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013234625584868 nn.Linear: 0.00092918198248903 nn.Linear: 0.00040605511983791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016851590475053 nn.Linear: 0.003718277047584] nn.Sequential: [nn.Linear: 0.00010327931194776 nn.Linear: 0.0014083208638408]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014282279647887 nn.Linear: 0.01586894877255 nn.Linear: 0.010635438375175 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077256122604012 nn.Linear: 0.023218667134643] nn.Sequential: [nn.Linear: 0.0040414440445602 nn.Linear: 0.01470925938338]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062108040564055 nn.Linear: 0.062552992205694 nn.Linear: 0.044360726281905 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352577312276 nn.Linear: 0.032434889460347] nn.Sequential: [nn.Linear: 0.031292710516574 nn.Linear: 0.024610958097625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32285955548286 nn.Linear: 0.19149859249592 nn.Linear: 0.11692174524069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080433785915375 nn.Linear: 0.13806517422199] nn.Sequential: [nn.Linear: 0.07418904453516 nn.Linear: 0.10205073654652]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011515243307682 nn.Linear: 0.00060082620802901 nn.Linear: 0.0003843116699744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015572776835641 nn.Linear: 0.0028776740357137] nn.Sequential: [nn.Linear: 0.00010490028359149 nn.Linear: 0.0010484656842831]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099955881014466 nn.Linear: 0.0097763417288661 nn.Linear: 0.0081870052963495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069793872535229 nn.Linear: 0.016025753691792] nn.Sequential: [nn.Linear: 0.0030702967196703 nn.Linear: 0.010888966731727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062110492892203 nn.Linear: 0.062555893728973 nn.Linear: 0.044361790810165 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031352786825979 nn.Linear: 0.032473931613197] nn.Sequential: [nn.Linear: 0.031292859675125 nn.Linear: 0.024628548133219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32307341694832 nn.Linear: 0.19182361662388 nn.Linear: 0.11739660054445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080995090305805 nn.Linear: 0.13828435540199] nn.Sequential: [nn.Linear: 0.074222445487976 nn.Linear: 0.1021611765027]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092567728447235 nn.Linear: 0.00052557733661792 nn.Linear: 0.00026157766730593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.7210845004219e-05 nn.Linear: 0.0017895182373755] nn.Sequential: [nn.Linear: 8.2313363235078e-05 nn.Linear: 0.00098331875895781]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064683179371059 nn.Linear: 0.0069479499943554 nn.Linear: 0.0053322114981711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039688446559012 nn.Linear: 0.013168310746551] nn.Sequential: [nn.Linear: 0.0023308475501835 nn.Linear: 0.0095848301425576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062109052705999 nn.Linear: 0.062559645802889 nn.Linear: 0.044363263395065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031353217621504 nn.Linear: 0.032569637646759] nn.Sequential: [nn.Linear: 0.03129297489855 nn.Linear: 0.024646370073333]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32371345162392 nn.Linear: 0.191381290555 nn.Linear: 0.11735387146473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081040687859058 nn.Linear: 0.13893419504166] nn.Sequential: [nn.Linear: 0.074357159435749 nn.Linear: 0.10269775241613]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077711882493697 nn.Linear: 0.00043228984168247 nn.Linear: 0.00021870102717261 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.1170108085953e-05 nn.Linear: 0.0010129095231823] nn.Sequential: [nn.Linear: 9.4545484384373e-05 nn.Linear: 0.0012134717185354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076776286587119 nn.Linear: 0.008163652382791 nn.Linear: 0.0036969182547182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038587318267673 nn.Linear: 0.0061719543300569] nn.Sequential: [nn.Linear: 0.0035405566450208 nn.Linear: 0.013064778409898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062109194494798 nn.Linear: 0.062564674654992 nn.Linear: 0.044365100468043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031353619025457 nn.Linear: 0.032636291281506] nn.Sequential: [nn.Linear: 0.031293290897482 nn.Linear: 0.024672320647174]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32418301701546 nn.Linear: 0.19117884337902 nn.Linear: 0.11708299815655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081019878387451 nn.Linear: 0.13929548859596] nn.Sequential: [nn.Linear: 0.074520707130432 nn.Linear: 0.10300701111555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010678854593139 nn.Linear: 0.00060364929881611 nn.Linear: 0.00033649805287041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015628146280487 nn.Linear: 0.0034607044899211] nn.Sequential: [nn.Linear: 8.9955783927393e-05 nn.Linear: 0.0012092483700232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066001443192363 nn.Linear: 0.011951614171267 nn.Linear: 0.0076348069123924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047475574538112 nn.Linear: 0.021684862673283] nn.Sequential: [nn.Linear: 0.0021823074202985 nn.Linear: 0.011775131337345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062111806986566 nn.Linear: 0.062567902124055 nn.Linear: 0.044366392358259 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031353878167666 nn.Linear: 0.032708570480622] nn.Sequential: [nn.Linear: 0.031293596199005 nn.Linear: 0.024694291015406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32356467843056 nn.Linear: 0.19176542758942 nn.Linear: 0.11742948740721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0811677724123 nn.Linear: 0.13883720338345] nn.Sequential: [nn.Linear: 0.074547953903675 nn.Linear: 0.10352181643248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093917864367488 nn.Linear: 0.00065320877909791 nn.Linear: 0.00038348909062985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012373371372574 nn.Linear: 0.0020067380377515] nn.Sequential: [nn.Linear: 0.00014641420210201 nn.Linear: 0.0017753665706935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068605067208409 nn.Linear: 0.010527337901294 nn.Linear: 0.0072878557257354 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057612932287157 nn.Linear: 0.015953820198774] nn.Sequential: [nn.Linear: 0.0045096036046743 nn.Linear: 0.016625262796879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062113917178278 nn.Linear: 0.062571548068129 nn.Linear: 0.044367869401846 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031354084436021 nn.Linear: 0.032752913151938] nn.Sequential: [nn.Linear: 0.031293922812277 nn.Linear: 0.024727568918745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32378581166267 nn.Linear: 0.19163167476654 nn.Linear: 0.11776133626699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081197239458561 nn.Linear: 0.13905498385429] nn.Sequential: [nn.Linear: 0.07459806650877 nn.Linear: 0.10397081822157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097399379050656 nn.Linear: 0.00048757676023097 nn.Linear: 0.00024809814612214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010922995042646 nn.Linear: 0.0025394379068174] nn.Sequential: [nn.Linear: 3.9721950053486e-05 nn.Linear: 0.00039266723494823]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078839948400855 nn.Linear: 0.010522055439651 nn.Linear: 0.0048434245400131 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045554195530713 nn.Linear: 0.015672918409109] nn.Sequential: [nn.Linear: 0.0013554483884946 nn.Linear: 0.0037627655547112]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06211693776466 nn.Linear: 0.062576252379479 nn.Linear: 0.04436918310899 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031354391815563 nn.Linear: 0.032791110041757] nn.Sequential: [nn.Linear: 0.031294102947268 nn.Linear: 0.024740168971416]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32401221990585 nn.Linear: 0.19190236926079 nn.Linear: 0.11731673032045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081138983368874 nn.Linear: 0.13903583586216] nn.Sequential: [nn.Linear: 0.074656896293163 nn.Linear: 0.1038074940443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095404062627698 nn.Linear: 0.00057210869012106 nn.Linear: 0.00035033336738391 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013406952512987 nn.Linear: 0.002837073318859] nn.Sequential: [nn.Linear: 0.00012700833637689 nn.Linear: 0.0016192551381045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091128759086132 nn.Linear: 0.0075559564866126 nn.Linear: 0.0066879913210869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042919046245515 nn.Linear: 0.017292337492108] nn.Sequential: [nn.Linear: 0.0032642837613821 nn.Linear: 0.013662560842931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062115846034539 nn.Linear: 0.062581158566572 nn.Linear: 0.044370775893063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031354822325092 nn.Linear: 0.032883838649695] nn.Sequential: [nn.Linear: 0.03129423139918 nn.Linear: 0.02475784355102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32445272803307 nn.Linear: 0.19155995547771 nn.Linear: 0.11750677973032 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081131011247635 nn.Linear: 0.14002394676208] nn.Sequential: [nn.Linear: 0.074898324906826 nn.Linear: 0.10426008701324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013954035567263 nn.Linear: 0.00084207969881407 nn.Linear: 0.00042840839738798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020142697888577 nn.Linear: 0.0048413836486079] nn.Sequential: [nn.Linear: 0.00010374563364852 nn.Linear: 0.0013020246758429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01269893348217 nn.Linear: 0.020841730758548 nn.Linear: 0.012122374027967 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065605253912508 nn.Linear: 0.02687188051641] nn.Sequential: [nn.Linear: 0.002961321733892 nn.Linear: 0.012072437442839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062114692668468 nn.Linear: 0.062581828304762 nn.Linear: 0.044371415073241 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031355087041162 nn.Linear: 0.032954389261221] nn.Sequential: [nn.Linear: 0.031294282016143 nn.Linear: 0.024770577308069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32507020235062 nn.Linear: 0.19179163873196 nn.Linear: 0.11782624572515 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.080824442207813 nn.Linear: 0.14034667611122] nn.Sequential: [nn.Linear: 0.075007632374763 nn.Linear: 0.10477130115032]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089762782890537 nn.Linear: 0.00050912437674716 nn.Linear: 0.00025342163428778 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.9448637821576e-05 nn.Linear: 0.0016708570518127] nn.Sequential: [nn.Linear: 0.00010123004534936 nn.Linear: 0.0012784857479724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059889182448387 nn.Linear: 0.0079715363681316 nn.Linear: 0.0042588389478624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035811243578792 nn.Linear: 0.011136178858578] nn.Sequential: [nn.Linear: 0.0027820023242384 nn.Linear: 0.015627015382051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062122027816167 nn.Linear: 0.062586359998787 nn.Linear: 0.04437276285557 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031355354875921 nn.Linear: 0.033004912342051] nn.Sequential: [nn.Linear: 0.031294628926288 nn.Linear: 0.024793594724947]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3252726495266 nn.Linear: 0.19238391518593 nn.Linear: 0.11809764802456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08100438117981 nn.Linear: 0.14074845612049] nn.Sequential: [nn.Linear: 0.075345061719418 nn.Linear: 0.10463102906942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013782219200774 nn.Linear: 0.00074240178407306 nn.Linear: 0.00032029429068457 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011979410355643 nn.Linear: 0.0027825072726753] nn.Sequential: [nn.Linear: 6.0851240764976e-05 nn.Linear: 0.00068725332547826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014067620038986 nn.Linear: 0.019866559654474 nn.Linear: 0.0086909765377641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052820108830929 nn.Linear: 0.017906192690134] nn.Sequential: [nn.Linear: 0.0015262991655618 nn.Linear: 0.006001538131386]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062123303611434 nn.Linear: 0.062591812571847 nn.Linear: 0.044374051223217 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031355790331854 nn.Linear: 0.033095496184167] nn.Sequential: [nn.Linear: 0.031294963385354 nn.Linear: 0.024824128815286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32570052146912 nn.Linear: 0.19205136597157 nn.Linear: 0.11854224652052 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081386260688305 nn.Linear: 0.1408739387989] nn.Sequential: [nn.Linear: 0.075437411665916 nn.Linear: 0.10506523400545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00074541837439311 nn.Linear: 0.00038772049933914 nn.Linear: 0.00016461423445078 nn.ConcatTable: [nn.Sequential: [nn.Linear: 4.9088160911393e-05 nn.Linear: 0.00075509388658461] nn.Sequential: [nn.Linear: 4.2185199637816e-05 nn.Linear: 0.00046045707533447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071235210634768 nn.Linear: 0.0057807313278317 nn.Linear: 0.0040344540029764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0018794898642227 nn.Linear: 0.0056353216059506] nn.Sequential: [nn.Linear: 0.001761908410117 nn.Linear: 0.0041265841573477]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062124382365862 nn.Linear: 0.062596005292746 nn.Linear: 0.044375955916069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031356024379875 nn.Linear: 0.033140731675921] nn.Sequential: [nn.Linear: 0.031295111400202 nn.Linear: 0.024842062491837]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32561314105988 nn.Linear: 0.19251027703285 nn.Linear: 0.11782352626324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081444159150124 nn.Linear: 0.14072342216969] nn.Sequential: [nn.Linear: 0.075712442398071 nn.Linear: 0.10548143833876]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011387833224938 nn.Linear: 0.00073099124097196 nn.Linear: 0.00036620707397219 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014701556312135 nn.Linear: 0.0032390422030311] nn.Sequential: [nn.Linear: 6.2954318757529e-05 nn.Linear: 0.0007316851861346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091400090605021 nn.Linear: 0.016173986718059 nn.Linear: 0.0069091096520424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061106272041798 nn.Linear: 0.021336512640119] nn.Sequential: [nn.Linear: 0.0017101790290326 nn.Linear: 0.0053711305372417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06212677087861 nn.Linear: 0.062600471567138 nn.Linear: 0.044377115887873 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03135639710009 nn.Linear: 0.033187278874621] nn.Sequential: [nn.Linear: 0.031295202321107 nn.Linear: 0.024854024277426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32682704925537 nn.Linear: 0.19161236286163 nn.Linear: 0.11809258162975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081667624413967 nn.Linear: 0.14080181717873] nn.Sequential: [nn.Linear: 0.075579978525639 nn.Linear: 0.10606816411018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014664272034147 nn.Linear: 0.00077217171832786 nn.Linear: 0.0003927698495509 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013740328774005 nn.Linear: 0.0023465962449902] nn.Sequential: [nn.Linear: 0.00012170325036198 nn.Linear: 0.0015573338696159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092463390901685 nn.Linear: 0.013149250298738 nn.Linear: 0.0076077841222286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058249025605619 nn.Linear: 0.017513684928417] nn.Sequential: [nn.Linear: 0.0032984085846692 nn.Linear: 0.012722608633339]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062124876694589 nn.Linear: 0.062602273622915 nn.Linear: 0.044377443550465 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031356450924062 nn.Linear: 0.033212904741504] nn.Sequential: [nn.Linear: 0.031295442486605 nn.Linear: 0.024879353027683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32706636190414 nn.Linear: 0.1913828253746 nn.Linear: 0.11844113469124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081635102629662 nn.Linear: 0.14072205126286] nn.Sequential: [nn.Linear: 0.075661614537239 nn.Linear: 0.10594910383224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094477498071164 nn.Linear: 0.00051996192862643 nn.Linear: 0.0002469855904673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.0254634943184e-05 nn.Linear: 0.0015917435507733] nn.Sequential: [nn.Linear: 6.339396612388e-05 nn.Linear: 0.00069342065421663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065114530734718 nn.Linear: 0.0080553693696856 nn.Linear: 0.005132828373462 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054247383959591 nn.Linear: 0.011859486810863] nn.Sequential: [nn.Linear: 0.0019330650102347 nn.Linear: 0.0075105540454388]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10385385396332	TD error	0.020015364129096	Qmax	1	

Steps: 1750000 (frames: 7000000), score: 1986.78, higheset score: 6396, epsilon: 0.05, lr: 0.0005, training time: 610s, training rate: 1637fps, testing time: 95s, testing rate: 5234fps,  num. ep.: 316,  num. rewards: 17073	
   2    4    8   16
   8    2   64    4
   4   32  256  512
   2    4   64    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062125480926199 nn.Linear: 0.062605817592692 nn.Linear: 0.044378525743112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031356499517026 nn.Linear: 0.033206110920361] nn.Sequential: [nn.Linear: 0.031295693421286 nn.Linear: 0.024894553126207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32660394906998 nn.Linear: 0.19143389165401 nn.Linear: 0.11864808946848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081615909934044 nn.Linear: 0.14084731042385] nn.Sequential: [nn.Linear: 0.075739853084087 nn.Linear: 0.10629527270794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089227695337379 nn.Linear: 0.00055110633641588 nn.Linear: 0.00027918909376294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012445622638579 nn.Linear: 0.0027347624721616] nn.Sequential: [nn.Linear: 4.1740323072322e-05 nn.Linear: 0.00047636661636066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060208556242287 nn.Linear: 0.0088010029867291 nn.Linear: 0.004215610679239 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043335352092981 nn.Linear: 0.01598540134728] nn.Sequential: [nn.Linear: 0.0014524179277942 nn.Linear: 0.0047880047932267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062128839863345 nn.Linear: 0.062608627932884 nn.Linear: 0.044379815454633 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031356883165123 nn.Linear: 0.033229210786203] nn.Sequential: [nn.Linear: 0.031295945037589 nn.Linear: 0.024920730948629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32739046216011 nn.Linear: 0.19125878810883 nn.Linear: 0.11874661594629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08159576356411 nn.Linear: 0.14127826690674] nn.Sequential: [nn.Linear: 0.075958020985126 nn.Linear: 0.10667627304792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00087033618124731 nn.Linear: 0.0005368189604278 nn.Linear: 0.00026716636832968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011969431482523 nn.Linear: 0.0027434009454796] nn.Sequential: [nn.Linear: 7.487011177328e-05 nn.Linear: 0.0009691817747093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088140126317739 nn.Linear: 0.0084216995164752 nn.Linear: 0.0048346309922636 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039617926813662 nn.Linear: 0.015258086845279] nn.Sequential: [nn.Linear: 0.0019644435960799 nn.Linear: 0.0079407067969441]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062135711615451 nn.Linear: 0.062611752196063 nn.Linear: 0.044380334938871 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031357141536188 nn.Linear: 0.033279792902078] nn.Sequential: [nn.Linear: 0.031296146504659 nn.Linear: 0.02494709364663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32765805721283 nn.Linear: 0.19174037873745 nn.Linear: 0.11847046762705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081661306321621 nn.Linear: 0.1416627317667] nn.Sequential: [nn.Linear: 0.076070994138718 nn.Linear: 0.10715933889151]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00058239305544564 nn.Linear: 0.0003386238243118 nn.Linear: 0.00015222620709718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 4.7142740887376e-05 nn.Linear: 0.00081120064378212] nn.Sequential: [nn.Linear: 4.3066205075647e-05 nn.Linear: 0.00058721445438033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053028143011034 nn.Linear: 0.0056715793907642 nn.Linear: 0.0031729126349092 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0019352759700269 nn.Linear: 0.0056912554427981] nn.Sequential: [nn.Linear: 0.0012175092706457 nn.Linear: 0.0070885941386223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062139048340265 nn.Linear: 0.062615878432146 nn.Linear: 0.044381374111148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03135749939711 nn.Linear: 0.033367582861956] nn.Sequential: [nn.Linear: 0.031296389361934 nn.Linear: 0.024974944949154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3282416164875 nn.Linear: 0.19141156971455 nn.Linear: 0.11849286407232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081631474196911 nn.Linear: 0.1420074403286] nn.Sequential: [nn.Linear: 0.076061084866524 nn.Linear: 0.10746134072542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014536532200807 nn.Linear: 0.00086538788687661 nn.Linear: 0.00040624801138281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014969467901636 nn.Linear: 0.002255003626123] nn.Sequential: [nn.Linear: 0.00010332122712879 nn.Linear: 0.0011923976457295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018349112942815 nn.Linear: 0.011408791877329 nn.Linear: 0.0072276825085282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057781110517681 nn.Linear: 0.014843507669866] nn.Sequential: [nn.Linear: 0.0033930509816855 nn.Linear: 0.012182079255581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062139116968864 nn.Linear: 0.062619165392273 nn.Linear: 0.044382781106377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031357576726563 nn.Linear: 0.033347877682615] nn.Sequential: [nn.Linear: 0.031296801738852 nn.Linear: 0.025002325457599]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32861173152924 nn.Linear: 0.19157907366753 nn.Linear: 0.11846636235714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081787869334221 nn.Linear: 0.14177158474922] nn.Sequential: [nn.Linear: 0.076193928718567 nn.Linear: 0.10792808234692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00063779347192994 nn.Linear: 0.0003794634806958 nn.Linear: 0.00021992356172624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.279264941106e-05 nn.Linear: 0.0013869754283013] nn.Sequential: [nn.Linear: 8.6963582263485e-05 nn.Linear: 0.00097929901801675]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046301567927003 nn.Linear: 0.0067130895331502 nn.Linear: 0.0061107948422432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029467600397766 nn.Linear: 0.0083760404959321] nn.Sequential: [nn.Linear: 0.0029565293807536 nn.Linear: 0.0073473048396409]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062138085212283 nn.Linear: 0.062621651441821 nn.Linear: 0.044384083870228 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031357754479571 nn.Linear: 0.033388053098179] nn.Sequential: [nn.Linear: 0.031296943991258 nn.Linear: 0.025017996681076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32927161455154 nn.Linear: 0.1916366070509 nn.Linear: 0.11843714863062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082062110304832 nn.Linear: 0.14159549772739] nn.Sequential: [nn.Linear: 0.07613879442215 nn.Linear: 0.10856162011623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014210695359961 nn.Linear: 0.00084821096354599 nn.Linear: 0.00037966956824674 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013870832608441 nn.Linear: 0.002139351886658] nn.Sequential: [nn.Linear: 0.00010206004214764 nn.Linear: 0.0012610286925012]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087731461971998 nn.Linear: 0.014124114066362 nn.Linear: 0.009482772089541 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097866570577025 nn.Linear: 0.020965253934264] nn.Sequential: [nn.Linear: 0.0030189985409379 nn.Linear: 0.013143714517355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062138052977319 nn.Linear: 0.062623283597726 nn.Linear: 0.044385008706793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031357749813549 nn.Linear: 0.033391900034417] nn.Sequential: [nn.Linear: 0.031297323362488 nn.Linear: 0.025040216173686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32926112413406 nn.Linear: 0.19168150424957 nn.Linear: 0.11828403919935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082186333835125 nn.Linear: 0.14202561974525] nn.Sequential: [nn.Linear: 0.076327443122864 nn.Linear: 0.10845154523849]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00073875937034562 nn.Linear: 0.00039339705938685 nn.Linear: 0.00018099811215563 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.5078335352604e-05 nn.Linear: 0.0012764422590252] nn.Sequential: [nn.Linear: 5.2083813354462e-05 nn.Linear: 0.00062143093441068]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074342978186905 nn.Linear: 0.005289698485285 nn.Linear: 0.0038325374480337 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037818502169102 nn.Linear: 0.0099961226806045] nn.Sequential: [nn.Linear: 0.001923791365698 nn.Linear: 0.0062118568457663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06214314021802 nn.Linear: 0.062627733780555 nn.Linear: 0.044386595068689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031358169432388 nn.Linear: 0.033486477885504] nn.Sequential: [nn.Linear: 0.031297426026674 nn.Linear: 0.025063014714023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.32970455288887 nn.Linear: 0.19190590083599 nn.Linear: 0.11830962449312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082261383533478 nn.Linear: 0.14259549975395] nn.Sequential: [nn.Linear: 0.076403558254242 nn.Linear: 0.10847122222185]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0032495760068703 nn.Linear: 0.0017198595257791 nn.Linear: 0.00083473610878201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00035411426469263 nn.Linear: 0.0080420514031861] nn.Sequential: [nn.Linear: 0.0001704589869051 nn.Linear: 0.0021553791670798]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.030355060473084 nn.Linear: 0.048852734267712 nn.Linear: 0.019730681553483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013199796900153 nn.Linear: 0.052358657121658] nn.Sequential: [nn.Linear: 0.0070608761161566 nn.Linear: 0.0302031096071]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062139596268438 nn.Linear: 0.062627665731807 nn.Linear: 0.044387102061493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031358223010944 nn.Linear: 0.033499855691673] nn.Sequential: [nn.Linear: 0.031297616912744 nn.Linear: 0.025078742063073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33041030168533 nn.Linear: 0.19149166345596 nn.Linear: 0.11835619062185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082296676933765 nn.Linear: 0.14308519661427] nn.Sequential: [nn.Linear: 0.076423265039921 nn.Linear: 0.10913191735744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098529330481608 nn.Linear: 0.00049769295216492 nn.Linear: 0.00020956541259538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1102103567819e-05 nn.Linear: 0.000912580801855] nn.Sequential: [nn.Linear: 7.5828072504134e-05 nn.Linear: 0.00093855019297675]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079514812678099 nn.Linear: 0.009859586134553 nn.Linear: 0.0048168171197176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0024235327728093 nn.Linear: 0.0062138680368662] nn.Sequential: [nn.Linear: 0.0017955785151571 nn.Linear: 0.0081161102280021]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062138175385529 nn.Linear: 0.062632056675476 nn.Linear: 0.04438861556172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031358288768691 nn.Linear: 0.033539711351864] nn.Sequential: [nn.Linear: 0.031297930457047 nn.Linear: 0.025108732968088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33082520961761 nn.Linear: 0.19118638336658 nn.Linear: 0.11812838166952 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082297995686531 nn.Linear: 0.14309331774712] nn.Sequential: [nn.Linear: 0.0764185115695 nn.Linear: 0.10948376357555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001509416654014 nn.Linear: 0.0010841406754152 nn.Linear: 0.00059233136539694 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028490407446453 nn.Linear: 0.0066911162545891] nn.Sequential: [nn.Linear: 0.00011629185815473 nn.Linear: 0.0014872898429143]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089363325387239 nn.Linear: 0.019792763516307 nn.Linear: 0.014187419787049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086605483666062 nn.Linear: 0.037757758051157] nn.Sequential: [nn.Linear: 0.0030565292108804 nn.Linear: 0.015217259526253]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062140014148661 nn.Linear: 0.062634760775338 nn.Linear: 0.044389999935761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031358732981233 nn.Linear: 0.033582415712964] nn.Sequential: [nn.Linear: 0.031298006033312 nn.Linear: 0.025122052342243]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33128878474236 nn.Linear: 0.19217371940613 nn.Linear: 0.11828915774822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082589626312256 nn.Linear: 0.14310298860073] nn.Sequential: [nn.Linear: 0.076681680977345 nn.Linear: 0.10925690829754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019066035192325 nn.Linear: 0.0010391381222504 nn.Linear: 0.0006130557654732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024587980366062 nn.Linear: 0.0041062616810685] nn.Sequential: [nn.Linear: 0.00022101286131884 nn.Linear: 0.0030135423492976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01716860756278 nn.Linear: 0.022529453039169 nn.Linear: 0.011391379870474 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010721095837653 nn.Linear: 0.030560564249754] nn.Sequential: [nn.Linear: 0.008629840798676 nn.Linear: 0.037072028964758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062145528952524 nn.Linear: 0.062638321727046 nn.Linear: 0.044391571876068 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031358885113803 nn.Linear: 0.033611024604118] nn.Sequential: [nn.Linear: 0.031298210542664 nn.Linear: 0.025138127820488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33091878890991 nn.Linear: 0.19254936277866 nn.Linear: 0.11792851239443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082381084561348 nn.Linear: 0.14317072927952] nn.Sequential: [nn.Linear: 0.076710350811481 nn.Linear: 0.10989509522915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083119657744088 nn.Linear: 0.00048893011198948 nn.Linear: 0.0002505596859119 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.9166617140996e-05 nn.Linear: 0.0016263976534819] nn.Sequential: [nn.Linear: 6.3597909419868e-05 nn.Linear: 0.00061320648551752]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066017019562423 nn.Linear: 0.0066113779321313 nn.Linear: 0.0044577191583812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034717873204499 nn.Linear: 0.0094280876219273] nn.Sequential: [nn.Linear: 0.0015632327413186 nn.Linear: 0.0048304586671293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	1880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062144396720269 nn.Linear: 0.062643091583467 nn.Linear: 0.044393144988073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031359295025278 nn.Linear: 0.033676941611162] nn.Sequential: [nn.Linear: 0.03129847245092 nn.Linear: 0.0251633633667]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33224460482597 nn.Linear: 0.19224536418915 nn.Linear: 0.11816968768835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082642294466496 nn.Linear: 0.14355660974979] nn.Sequential: [nn.Linear: 0.076600633561611 nn.Linear: 0.11034950613976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011313993662988 nn.Linear: 0.00070832040353459 nn.Linear: 0.00040165364984624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013838473042527 nn.Linear: 0.0029469956074694] nn.Sequential: [nn.Linear: 0.00011491352616238 nn.Linear: 0.0015505790181361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083343693986535 nn.Linear: 0.013782887719572 nn.Linear: 0.006970226764679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066824089735746 nn.Linear: 0.016721965745091] nn.Sequential: [nn.Linear: 0.0033562972676009 nn.Linear: 0.013740487396717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062151212136869 nn.Linear: 0.062647063098289 nn.Linear: 0.044394126425445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031359449668837 nn.Linear: 0.033705132838918] nn.Sequential: [nn.Linear: 0.031298759716327 nn.Linear: 0.025185867939911]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33245038986206 nn.Linear: 0.19216945767403 nn.Linear: 0.11806704849005 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082550905644894 nn.Linear: 0.14403811097145] nn.Sequential: [nn.Linear: 0.076732084155083 nn.Linear: 0.11078812927008]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018463968006833 nn.Linear: 0.0012143186071665 nn.Linear: 0.00060816858278523 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024144334945514 nn.Linear: 0.0048622492167034] nn.Sequential: [nn.Linear: 0.00012669018631624 nn.Linear: 0.0016627556275294]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014267931692302 nn.Linear: 0.021587813273072 nn.Linear: 0.016006033867598 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011068671010435 nn.Linear: 0.028696728870273] nn.Sequential: [nn.Linear: 0.0032591065391898 nn.Linear: 0.015675896778703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062149578163073 nn.Linear: 0.062648034953301 nn.Linear: 0.04439421404459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031359815622537 nn.Linear: 0.033770661396318] nn.Sequential: [nn.Linear: 0.031298750640413 nn.Linear: 0.025201407393562]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3321767449379 nn.Linear: 0.19244216382504 nn.Linear: 0.11818538606167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082310773432255 nn.Linear: 0.1444718837738] nn.Sequential: [nn.Linear: 0.076719783246517 nn.Linear: 0.11143928021193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00066935941469521 nn.Linear: 0.00032368782699565 nn.Linear: 0.00014922797667816 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.2946017625033e-05 nn.Linear: 0.00078837956401956] nn.Sequential: [nn.Linear: 3.3480424759383e-05 nn.Linear: 0.00029681056412433]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051196571439505 nn.Linear: 0.0062081669457257 nn.Linear: 0.0033092582598329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0023581674322486 nn.Linear: 0.0050854124128819] nn.Sequential: [nn.Linear: 0.00094491522759199 nn.Linear: 0.0026057306677103]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062152652188743 nn.Linear: 0.062651208975437 nn.Linear: 0.044394938867801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031359781874507 nn.Linear: 0.033754318923457] nn.Sequential: [nn.Linear: 0.031299033069245 nn.Linear: 0.025231744728164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33248615264893 nn.Linear: 0.19261085987091 nn.Linear: 0.11842050403357 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082295373082161 nn.Linear: 0.14407214522362] nn.Sequential: [nn.Linear: 0.076790392398834 nn.Linear: 0.1113388389349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015416421029286 nn.Linear: 0.00085958889929319 nn.Linear: 0.00039750856328326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012439724733967 nn.Linear: 0.0020323505466011] nn.Sequential: [nn.Linear: 0.0001041624485069 nn.Linear: 0.0012901938410885]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01501330267638 nn.Linear: 0.013448518700898 nn.Linear: 0.0091125685721636 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0067286635749042 nn.Linear: 0.013194168917835] nn.Sequential: [nn.Linear: 0.0038945323321968 nn.Linear: 0.01335431728512]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062157245285787 nn.Linear: 0.062653039982895 nn.Linear: 0.044396014420671 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031359895408046 nn.Linear: 0.033785076255242] nn.Sequential: [nn.Linear: 0.031299411757649 nn.Linear: 0.025249200639721]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33274403214455 nn.Linear: 0.19245457649231 nn.Linear: 0.11804161965847 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082323081791401 nn.Linear: 0.14410048723221] nn.Sequential: [nn.Linear: 0.077021807432175 nn.Linear: 0.11141218990088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017075147441405 nn.Linear: 0.00075989067540852 nn.Linear: 0.00033395231733359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010522454321565 nn.Linear: 0.0017115767115241] nn.Sequential: [nn.Linear: 9.8533362656325e-05 nn.Linear: 0.0011789654489256]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016718402504921 nn.Linear: 0.018951678648591 nn.Linear: 0.0083873849362135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046171164140105 nn.Linear: 0.011890354566276] nn.Sequential: [nn.Linear: 0.0044106272980571 nn.Linear: 0.013245720416307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062156089007838 nn.Linear: 0.06265561027565 nn.Linear: 0.044397007266842 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03136047246553 nn.Linear: 0.033904724282564] nn.Sequential: [nn.Linear: 0.031299431606395 nn.Linear: 0.025258517500816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33276864886284 nn.Linear: 0.1926683485508 nn.Linear: 0.11811316013336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08267455548048 nn.Linear: 0.14451774954796] nn.Sequential: [nn.Linear: 0.076862685382366 nn.Linear: 0.11149459332228]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097017717726006 nn.Linear: 0.00055144080316183 nn.Linear: 0.00024420541207891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.6742624498145e-05 nn.Linear: 0.0012999829367064] nn.Sequential: [nn.Linear: 6.899705044071e-05 nn.Linear: 0.00096649375565191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085335085168481 nn.Linear: 0.0087250750511885 nn.Linear: 0.0055829281918705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043930849060416 nn.Linear: 0.010880348272622] nn.Sequential: [nn.Linear: 0.0016772480448708 nn.Linear: 0.0073505127802491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0621594652326 nn.Linear: 0.062660240902459 nn.Linear: 0.044398985861506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031360606655632 nn.Linear: 0.033896897498607] nn.Sequential: [nn.Linear: 0.031299844304135 nn.Linear: 0.025280682947523]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33308112621307 nn.Linear: 0.19304820895195 nn.Linear: 0.1178225427866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082625053822994 nn.Linear: 0.14471869170666] nn.Sequential: [nn.Linear: 0.076800182461739 nn.Linear: 0.11221553385258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017259367517312 nn.Linear: 0.00097838612983849 nn.Linear: 0.0005171808406109 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020184687078015 nn.Linear: 0.0039048388053962] nn.Sequential: [nn.Linear: 0.00013929403481832 nn.Linear: 0.0015498180767536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012506528757513 nn.Linear: 0.013413441367447 nn.Linear: 0.012789067812264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085251228883862 nn.Linear: 0.025772992521524] nn.Sequential: [nn.Linear: 0.004413643386215 nn.Linear: 0.016305312514305]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062159725197446 nn.Linear: 0.062665171550874 nn.Linear: 0.044400683840753 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031360791213079 nn.Linear: 0.033942333722621] nn.Sequential: [nn.Linear: 0.031300106814831 nn.Linear: 0.025305107971612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33324977755547 nn.Linear: 0.19250480830669 nn.Linear: 0.11760634928942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082753174006939 nn.Linear: 0.14459449052811] nn.Sequential: [nn.Linear: 0.077040247619152 nn.Linear: 0.11263278126717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013394951815254 nn.Linear: 0.00081859098071525 nn.Linear: 0.0004341334826657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015947114477023 nn.Linear: 0.0026797337774072] nn.Sequential: [nn.Linear: 0.00011350643448434 nn.Linear: 0.0012101399943308]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083069894462824 nn.Linear: 0.01364222727716 nn.Linear: 0.0086722346022725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056756781414151 nn.Linear: 0.015343344770372] nn.Sequential: [nn.Linear: 0.0039190389215946 nn.Linear: 0.013235068880022]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062160486103599 nn.Linear: 0.062666795072272 nn.Linear: 0.044401202141548 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031361030861071 nn.Linear: 0.033972795486115] nn.Sequential: [nn.Linear: 0.031300210863007 nn.Linear: 0.025321989320974]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33349132537842 nn.Linear: 0.19244173169136 nn.Linear: 0.11751829087734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082806266844273 nn.Linear: 0.14451861381531] nn.Sequential: [nn.Linear: 0.077125929296017 nn.Linear: 0.11295879632235]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00055109972217697 nn.Linear: 0.00031594441710827 nn.Linear: 0.00019171905624973 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.5254768645225e-05 nn.Linear: 0.0010120812341621] nn.Sequential: [nn.Linear: 7.066016440894e-05 nn.Linear: 0.00083053241059655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054326858371496 nn.Linear: 0.0049638822674751 nn.Linear: 0.0032676756381989 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0024078006390482 nn.Linear: 0.0076939314603806] nn.Sequential: [nn.Linear: 0.0020598906558007 nn.Linear: 0.0081299319863319]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062169532749547 nn.Linear: 0.062672515136527 nn.Linear: 0.044403204321515 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031361181783942 nn.Linear: 0.0339679152728] nn.Sequential: [nn.Linear: 0.031300600472538 nn.Linear: 0.025342709901174]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33316242694855 nn.Linear: 0.19286017119884 nn.Linear: 0.11746843159199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.082796148955822 nn.Linear: 0.14491622149944] nn.Sequential: [nn.Linear: 0.077273607254028 nn.Linear: 0.11318250745535]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010206450401661 nn.Linear: 0.00051797146050978 nn.Linear: 0.00020960784760585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.0148985594255e-05 nn.Linear: 0.0010255922017661] nn.Sequential: [nn.Linear: 6.9696210681545e-05 nn.Linear: 0.00084783026419526]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008300855755806 nn.Linear: 0.0065789823420346 nn.Linear: 0.0055703748948872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035890452563763 nn.Linear: 0.0061300285160542] nn.Sequential: [nn.Linear: 0.0021459176205099 nn.Linear: 0.0084019061177969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062171087246343 nn.Linear: 0.062674736645406 nn.Linear: 0.044404469921923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031361400235151 nn.Linear: 0.033973989755737] nn.Sequential: [nn.Linear: 0.031300711067039 nn.Linear: 0.025345645803037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33315676450729 nn.Linear: 0.1925882101059 nn.Linear: 0.11732961982489 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083061866462231 nn.Linear: 0.14489118754864] nn.Sequential: [nn.Linear: 0.077254846692085 nn.Linear: 0.11338555812836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022028459350924 nn.Linear: 0.001241424863738 nn.Linear: 0.00059644164292072 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021613861806044 nn.Linear: 0.0043253856341104] nn.Sequential: [nn.Linear: 0.00020160936960335 nn.Linear: 0.0024197860493618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018628023564816 nn.Linear: 0.026666032150388 nn.Linear: 0.020049510523677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087572308257222 nn.Linear: 0.027859365567565] nn.Sequential: [nn.Linear: 0.0074701514095068 nn.Linear: 0.021832443773746]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	1990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062172059280366 nn.Linear: 0.062677374290899 nn.Linear: 0.044405238921297 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031361705841024 nn.Linear: 0.034004443271115] nn.Sequential: [nn.Linear: 0.031300743923221 nn.Linear: 0.025355989151391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33370986580849 nn.Linear: 0.19304870069027 nn.Linear: 0.11736964434385 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083360306918621 nn.Linear: 0.14550615847111] nn.Sequential: [nn.Linear: 0.077434822916985 nn.Linear: 0.11335664242506]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013169842918087 nn.Linear: 0.00081617549110123 nn.Linear: 0.00041299654554236 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017391603728757 nn.Linear: 0.0039147319604333] nn.Sequential: [nn.Linear: 0.00014111066923101 nn.Linear: 0.0018807860723287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092857219278812 nn.Linear: 0.01151357870549 nn.Linear: 0.0073761446401477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066441996023059 nn.Linear: 0.020864447578788] nn.Sequential: [nn.Linear: 0.0039006203878671 nn.Linear: 0.013915200717747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062179563376978 nn.Linear: 0.06268043829377 nn.Linear: 0.044406240316878 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031362030752232 nn.Linear: 0.034046119099912] nn.Sequential: [nn.Linear: 0.03130099103251 nn.Linear: 0.02537216055342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33412316441536 nn.Linear: 0.192637398839 nn.Linear: 0.11726541817188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0832244977355 nn.Linear: 0.14603681862354] nn.Sequential: [nn.Linear: 0.077393658459187 nn.Linear: 0.11317735910416]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012520156837807 nn.Linear: 0.00091017573944852 nn.Linear: 0.00042312748991358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015018760038033 nn.Linear: 0.0026008901910779] nn.Sequential: [nn.Linear: 0.00010678500543036 nn.Linear: 0.0010755410195146]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009607664309442 nn.Linear: 0.015266476199031 nn.Linear: 0.0096910297870636 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065319109708071 nn.Linear: 0.01842000707984] nn.Sequential: [nn.Linear: 0.0038343593478203 nn.Linear: 0.0092677706852555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10533709198236	TD error	0.020628989286721	Qmax	1	

Steps: 2000000 (frames: 8000000), score: 1978.84, higheset score: 6156, epsilon: 0.05, lr: 0.0005, training time: 585s, training rate: 1709fps, testing time: 90s, testing rate: 5536fps,  num. ep.: 287,  num. rewards: 15283	
   2    4   16    4
   8   16  256    8
   4   32   64  512
   2    4    8    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062177435394508 nn.Linear: 0.062681024969839 nn.Linear: 0.044406398530851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03136195897792 nn.Linear: 0.034057602768058] nn.Sequential: [nn.Linear: 0.031301072239324 nn.Linear: 0.025385012026847]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33374720811844 nn.Linear: 0.19182941317558 nn.Linear: 0.1177394837141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083251513540745 nn.Linear: 0.14629153907299] nn.Sequential: [nn.Linear: 0.077464364469051 nn.Linear: 0.1134866476059]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0005415367795855 nn.Linear: 0.00032704051645783 nn.Linear: 0.00017425237917481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.6996091897061e-05 nn.Linear: 0.0014881295120652] nn.Sequential: [nn.Linear: 6.6888533225292e-05 nn.Linear: 0.00091407599978475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0040004914626479 nn.Linear: 0.0056264838203788 nn.Linear: 0.0037028782535344 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0021383494604379 nn.Linear: 0.0078027774579823] nn.Sequential: [nn.Linear: 0.0020303523633629 nn.Linear: 0.010534873232245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062175052902547 nn.Linear: 0.062684692820237 nn.Linear: 0.044408124302084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03136229023969 nn.Linear: 0.034132323006418] nn.Sequential: [nn.Linear: 0.03130123975464 nn.Linear: 0.025403366988213]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33426308631897 nn.Linear: 0.19214168190956 nn.Linear: 0.11769089102745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083484373986721 nn.Linear: 0.1462017595768] nn.Sequential: [nn.Linear: 0.077712550759315 nn.Linear: 0.11385050415993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00055519782695354 nn.Linear: 0.00033941879820178 nn.Linear: 0.00019296321141149 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.1679156118831e-05 nn.Linear: 0.00078571523454819] nn.Sequential: [nn.Linear: 7.4378023703802e-05 nn.Linear: 0.00092334877338555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0050386479124427 nn.Linear: 0.0056783696636558 nn.Linear: 0.0035386797972023 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035101489629596 nn.Linear: 0.0050137471407652] nn.Sequential: [nn.Linear: 0.0023008997086436 nn.Linear: 0.0096129411831498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062168768495488 nn.Linear: 0.062684261102597 nn.Linear: 0.04440773361439 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031362481334687 nn.Linear: 0.03415555489812] nn.Sequential: [nn.Linear: 0.031301262179238 nn.Linear: 0.025412129349667]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33514159917831 nn.Linear: 0.19260074198246 nn.Linear: 0.11773674935102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08357672393322 nn.Linear: 0.14693734049797] nn.Sequential: [nn.Linear: 0.07777313888073 nn.Linear: 0.11401625722647]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012046525616104 nn.Linear: 0.00073992515004482 nn.Linear: 0.00036165125393695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014165750592767 nn.Linear: 0.0029048380639123] nn.Sequential: [nn.Linear: 9.5205555622239e-05 nn.Linear: 0.0011703608743118]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010906526818871 nn.Linear: 0.013276196084917 nn.Linear: 0.0065076062455773 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053305760957301 nn.Linear: 0.017600974068046] nn.Sequential: [nn.Linear: 0.0030074107926339 nn.Linear: 0.0077372579835355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062167774003365 nn.Linear: 0.062687469471661 nn.Linear: 0.044408573929624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031362532363162 nn.Linear: 0.034162611753434] nn.Sequential: [nn.Linear: 0.031301393738659 nn.Linear: 0.025422277830672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33494144678116 nn.Linear: 0.19279961287975 nn.Linear: 0.11753059178591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083685331046581 nn.Linear: 0.14693136513233] nn.Sequential: [nn.Linear: 0.077836580574512 nn.Linear: 0.11427771300077]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012608037708646 nn.Linear: 0.00070874897832183 nn.Linear: 0.00033894317318084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014326498887409 nn.Linear: 0.002631710620796] nn.Sequential: [nn.Linear: 7.5243514500133e-05 nn.Linear: 0.00074490562922589]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010024463757873 nn.Linear: 0.012514848262072 nn.Linear: 0.0073801097460091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052512302063406 nn.Linear: 0.020294889807701] nn.Sequential: [nn.Linear: 0.0032198545522988 nn.Linear: 0.0064105847850442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062173772797152 nn.Linear: 0.062693513412167 nn.Linear: 0.044410935018876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031362685032132 nn.Linear: 0.034182599397241] nn.Sequential: [nn.Linear: 0.031301942036197 nn.Linear: 0.025457174647325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33483240008354 nn.Linear: 0.192906036973 nn.Linear: 0.11750862747431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.083797864615917 nn.Linear: 0.14696498215199] nn.Sequential: [nn.Linear: 0.077811539173126 nn.Linear: 0.11441998183727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019372399415878 nn.Linear: 0.0011047314448457 nn.Linear: 0.00050934980884125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020468286693223 nn.Linear: 0.0040960236945327] nn.Sequential: [nn.Linear: 0.00010417231044735 nn.Linear: 0.0011533395747089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013578824698925 nn.Linear: 0.026909222826362 nn.Linear: 0.0099925892427564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093626035377383 nn.Linear: 0.024886671453714] nn.Sequential: [nn.Linear: 0.0035943782422692 nn.Linear: 0.010461289435625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062180771545581 nn.Linear: 0.062698347381709 nn.Linear: 0.044412832265194 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031363024963301 nn.Linear: 0.034284508058647] nn.Sequential: [nn.Linear: 0.031302158829685 nn.Linear: 0.025477735615134]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33496797084808 nn.Linear: 0.19298833608627 nn.Linear: 0.11733164638281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084046706557274 nn.Linear: 0.14683279395103] nn.Sequential: [nn.Linear: 0.077831983566284 nn.Linear: 0.11470417678356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011789928647043 nn.Linear: 0.00067187018643965 nn.Linear: 0.0003428120067465 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014873367324238 nn.Linear: 0.0026581248947323] nn.Sequential: [nn.Linear: 7.2247020776538e-05 nn.Linear: 0.00081129208994318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068155224435031 nn.Linear: 0.012766909785569 nn.Linear: 0.0058495374396443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052402652800083 nn.Linear: 0.020270494744182] nn.Sequential: [nn.Linear: 0.0024825769942254 nn.Linear: 0.0061470353975892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062185320349697 nn.Linear: 0.062701021036648 nn.Linear: 0.0444137757446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031363223667925 nn.Linear: 0.034297995494413] nn.Sequential: [nn.Linear: 0.031302374094014 nn.Linear: 0.025492928336494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33586287498474 nn.Linear: 0.19304865598679 nn.Linear: 0.11751585453749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08448151499033 nn.Linear: 0.14657850563526] nn.Sequential: [nn.Linear: 0.078045517206192 nn.Linear: 0.11471429467201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094458571493048 nn.Linear: 0.00060031504630776 nn.Linear: 0.00036488120509431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016827013101534 nn.Linear: 0.0039967375996603] nn.Sequential: [nn.Linear: 0.00014951757987579 nn.Linear: 0.0019050046525079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076739392243326 nn.Linear: 0.0086375419050455 nn.Linear: 0.0068145398981869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055612241849303 nn.Linear: 0.02327380888164] nn.Sequential: [nn.Linear: 0.0040368023328483 nn.Linear: 0.014156673103571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062189944091282 nn.Linear: 0.062703744240876 nn.Linear: 0.0444144434766 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031363099800375 nn.Linear: 0.034286015397186] nn.Sequential: [nn.Linear: 0.031302792460759 nn.Linear: 0.025515684909593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33550238609314 nn.Linear: 0.19275476038456 nn.Linear: 0.11762961745262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084452539682388 nn.Linear: 0.14635448157787] nn.Sequential: [nn.Linear: 0.077979572117329 nn.Linear: 0.11536268889904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019991225795933 nn.Linear: 0.0009630085936942 nn.Linear: 0.00035060936941009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.307308714811e-05 nn.Linear: 0.0015940088345019] nn.Sequential: [nn.Linear: 9.9383268646164e-05 nn.Linear: 0.0010337895313822]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017555782571435 nn.Linear: 0.016240365803242 nn.Linear: 0.0078989351168275 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040327291935682 nn.Linear: 0.010866942815483] nn.Sequential: [nn.Linear: 0.0029840290080756 nn.Linear: 0.010164089500904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062194786103857 nn.Linear: 0.062707592994887 nn.Linear: 0.044415351457096 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0313634151259 nn.Linear: 0.034338657815866] nn.Sequential: [nn.Linear: 0.031302870846641 nn.Linear: 0.025525361957418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33552214503288 nn.Linear: 0.19296304881573 nn.Linear: 0.11788252741098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084738381206989 nn.Linear: 0.14704540371895] nn.Sequential: [nn.Linear: 0.078064434230328 nn.Linear: 0.11540222167969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001082563305109 nn.Linear: 0.00064200634437171 nn.Linear: 0.00034227190645592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014974900384572 nn.Linear: 0.002942909018616] nn.Sequential: [nn.Linear: 8.4839189831065e-05 nn.Linear: 0.001011668850586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098293330520391 nn.Linear: 0.011059170588851 nn.Linear: 0.0064922608435154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044323322363198 nn.Linear: 0.016888327896595] nn.Sequential: [nn.Linear: 0.0021749420557171 nn.Linear: 0.0092818001285195]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062197056011622 nn.Linear: 0.062711340250225 nn.Linear: 0.044416418724181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031363757376911 nn.Linear: 0.03438134248114] nn.Sequential: [nn.Linear: 0.031303163010954 nn.Linear: 0.025544425449656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33615338802338 nn.Linear: 0.19232758879662 nn.Linear: 0.11774586141109 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084674298763275 nn.Linear: 0.14716291427612] nn.Sequential: [nn.Linear: 0.078183457255363 nn.Linear: 0.11553288251162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001729047583877 nn.Linear: 0.00094555715619769 nn.Linear: 0.00049217750192438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019698399188906 nn.Linear: 0.0037442828994161] nn.Sequential: [nn.Linear: 0.00013944064441693 nn.Linear: 0.001897026374209]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012553743086755 nn.Linear: 0.016297984868288 nn.Linear: 0.011914074420929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085453856736422 nn.Linear: 0.023013995960355] nn.Sequential: [nn.Linear: 0.0042992397211492 nn.Linear: 0.020871894434094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06219416742485 nn.Linear: 0.062714285383179 nn.Linear: 0.044417697496015 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364267991027 nn.Linear: 0.034449849444901] nn.Sequential: [nn.Linear: 0.03130306934738 nn.Linear: 0.025558015416489]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33613726496696 nn.Linear: 0.19282211363316 nn.Linear: 0.11764931678772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084696277976036 nn.Linear: 0.14765663444996] nn.Sequential: [nn.Linear: 0.078093111515045 nn.Linear: 0.11562968790531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014538926697167 nn.Linear: 0.00075383607079287 nn.Linear: 0.00038390725375644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012533919887494 nn.Linear: 0.0019159280932159] nn.Sequential: [nn.Linear: 0.00010707360333063 nn.Linear: 0.0013340235760496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011593031696975 nn.Linear: 0.011279358528554 nn.Linear: 0.0093951281160116 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048711630515754 nn.Linear: 0.01154070161283] nn.Sequential: [nn.Linear: 0.0032529339659959 nn.Linear: 0.0093121230602264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062194368753258 nn.Linear: 0.062716540159285 nn.Linear: 0.044418680072462 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364275749297 nn.Linear: 0.03444247369589] nn.Sequential: [nn.Linear: 0.031303304472953 nn.Linear: 0.025578038919946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33612537384033 nn.Linear: 0.19248166680336 nn.Linear: 0.11705477535725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085012458264828 nn.Linear: 0.14745457470417] nn.Sequential: [nn.Linear: 0.078300267457962 nn.Linear: 0.1161143258214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077226625983338 nn.Linear: 0.00043960789375152 nn.Linear: 0.00023124210610423 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.6479384459456e-05 nn.Linear: 0.0011310518064007] nn.Sequential: [nn.Linear: 8.7265163149212e-05 nn.Linear: 0.001092066704218]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067365616559982 nn.Linear: 0.0061315838247538 nn.Linear: 0.0037561173085123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029968672897667 nn.Linear: 0.006321759428829] nn.Sequential: [nn.Linear: 0.0024812782648951 nn.Linear: 0.0082414206117392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062196742310815 nn.Linear: 0.062719952721553 nn.Linear: 0.044419904775084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364294061877 nn.Linear: 0.034456311376829] nn.Sequential: [nn.Linear: 0.031303697542236 nn.Linear: 0.025609261667151]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33662554621696 nn.Linear: 0.19227364659309 nn.Linear: 0.11708441376686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085064880549908 nn.Linear: 0.14687252044678] nn.Sequential: [nn.Linear: 0.078132674098015 nn.Linear: 0.11625432223082]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001493213318848 nn.Linear: 0.0010462330847891 nn.Linear: 0.00051338684287605 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021940970876126 nn.Linear: 0.0044641778964671] nn.Sequential: [nn.Linear: 8.3184543587251e-05 nn.Linear: 0.00070975057387888]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010599219240248 nn.Linear: 0.017971977591515 nn.Linear: 0.011261135339737 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084287961944938 nn.Linear: 0.024610763415694] nn.Sequential: [nn.Linear: 0.002987811807543 nn.Linear: 0.0061037000268698]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062202555490455 nn.Linear: 0.062723221415815 nn.Linear: 0.044420621915213 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364297872919 nn.Linear: 0.034430270853477] nn.Sequential: [nn.Linear: 0.03130413405202 nn.Linear: 0.025630819011385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33612927794456 nn.Linear: 0.19188790023327 nn.Linear: 0.11755589395761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.084686852991581 nn.Linear: 0.14670723676682] nn.Sequential: [nn.Linear: 0.07814797013998 nn.Linear: 0.11653903126717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018537508377292 nn.Linear: 0.00091782951720315 nn.Linear: 0.00035085906750031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011132804611623 nn.Linear: 0.0018561989586164] nn.Sequential: [nn.Linear: 9.6952511916753e-05 nn.Linear: 0.0011490705092261]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013864372856915 nn.Linear: 0.014225314371288 nn.Linear: 0.0082965129986405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053078937344253 nn.Linear: 0.013617695309222] nn.Sequential: [nn.Linear: 0.0026152823120356 nn.Linear: 0.010180213488638]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062205624235428 nn.Linear: 0.062724255272123 nn.Linear: 0.044422201598721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364674294493 nn.Linear: 0.034501831510056] nn.Sequential: [nn.Linear: 0.031304173280194 nn.Linear: 0.025649714658853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33713454008102 nn.Linear: 0.19135914742947 nn.Linear: 0.11723589152098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085178814828396 nn.Linear: 0.14750736951828] nn.Sequential: [nn.Linear: 0.078071467578411 nn.Linear: 0.11729611456394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001479335474815 nn.Linear: 0.0010388520253869 nn.Linear: 0.00048921636052626 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018301077518879 nn.Linear: 0.0037184338365028] nn.Sequential: [nn.Linear: 9.7051762767311e-05 nn.Linear: 0.0011247469307972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013027815148234 nn.Linear: 0.02148811891675 nn.Linear: 0.010656001977623 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066634342074394 nn.Linear: 0.021642591804266] nn.Sequential: [nn.Linear: 0.0028066183440387 nn.Linear: 0.0079545825719833]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062207742311914 nn.Linear: 0.06272830072898 nn.Linear: 0.044423873040943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031364893233059 nn.Linear: 0.034532299999569] nn.Sequential: [nn.Linear: 0.03130452902549 nn.Linear: 0.025670207661455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33724811673164 nn.Linear: 0.19134193658829 nn.Linear: 0.11722841113806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08508312702179 nn.Linear: 0.14721128344536] nn.Sequential: [nn.Linear: 0.078276284039021 nn.Linear: 0.11753579229116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013936022804426 nn.Linear: 0.00089060570946029 nn.Linear: 0.00048024092638014 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023392338479217 nn.Linear: 0.0051101737278489] nn.Sequential: [nn.Linear: 0.00011342259519474 nn.Linear: 0.0015275512333113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075256177224219 nn.Linear: 0.01458893623203 nn.Linear: 0.0070152441039681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007730002515018 nn.Linear: 0.028695100918412] nn.Sequential: [nn.Linear: 0.0027634070720524 nn.Linear: 0.010574406012893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062214436619122 nn.Linear: 0.062733207201263 nn.Linear: 0.044425739713429 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031365139656194 nn.Linear: 0.034581515339028] nn.Sequential: [nn.Linear: 0.031304971526485 nn.Linear: 0.025710193027345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33739748597145 nn.Linear: 0.19203452765942 nn.Linear: 0.1174059510231 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085426270961761 nn.Linear: 0.14702191948891] nn.Sequential: [nn.Linear: 0.078313373029232 nn.Linear: 0.1185314655304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015813935331423 nn.Linear: 0.001084880786916 nn.Linear: 0.00050247615726863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021156140161026 nn.Linear: 0.004233070996587] nn.Sequential: [nn.Linear: 0.00013814369845599 nn.Linear: 0.001489914558763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01037360727787 nn.Linear: 0.02240701392293 nn.Linear: 0.012243881821632 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011419357731938 nn.Linear: 0.031214214861393] nn.Sequential: [nn.Linear: 0.0044467998668551 nn.Linear: 0.017409766092896]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062222591443363 nn.Linear: 0.062740775772071 nn.Linear: 0.04442801449447 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031365409783431 nn.Linear: 0.034623194006258] nn.Sequential: [nn.Linear: 0.031305387183316 nn.Linear: 0.025735673695786]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33762064576149 nn.Linear: 0.19191001355648 nn.Linear: 0.11746233701706 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085156850516796 nn.Linear: 0.147136926651] nn.Sequential: [nn.Linear: 0.078393816947937 nn.Linear: 0.11922599375248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014672912080353 nn.Linear: 0.00080901938124763 nn.Linear: 0.00040496418490794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015081088588401 nn.Linear: 0.0026014484066155] nn.Sequential: [nn.Linear: 0.00011457415013258 nn.Linear: 0.0012957176838835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010967902839184 nn.Linear: 0.014221946708858 nn.Linear: 0.0078849727287889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066936248913407 nn.Linear: 0.019385054707527] nn.Sequential: [nn.Linear: 0.0039766696281731 nn.Linear: 0.013008362613618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062227207628381 nn.Linear: 0.062746453057581 nn.Linear: 0.04443000151697 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031365871892407 nn.Linear: 0.03472247004467] nn.Sequential: [nn.Linear: 0.031305542966671 nn.Linear: 0.025756208792175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33742493391037 nn.Linear: 0.19227541983128 nn.Linear: 0.1178344860673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085260413587093 nn.Linear: 0.14721596240997] nn.Sequential: [nn.Linear: 0.078288540244102 nn.Linear: 0.11949215084314]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012913489580554 nn.Linear: 0.00064730194387142 nn.Linear: 0.00025848896454628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5511835906316e-05 nn.Linear: 0.0017349260537782] nn.Sequential: [nn.Linear: 6.4167744241554e-05 nn.Linear: 0.00066085244534731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092633422464132 nn.Linear: 0.0089852381497622 nn.Linear: 0.0065208990126848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044974600896239 nn.Linear: 0.011208730749786] nn.Sequential: [nn.Linear: 0.002138843992725 nn.Linear: 0.0043080085888505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062230438108384 nn.Linear: 0.06275153648288 nn.Linear: 0.044431138545779 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031366150335133 nn.Linear: 0.034769974195967] nn.Sequential: [nn.Linear: 0.031305721132203 nn.Linear: 0.025779535030365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3378621339798 nn.Linear: 0.19213306903839 nn.Linear: 0.11807091534138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085312314331532 nn.Linear: 0.14676873385906] nn.Sequential: [nn.Linear: 0.078289821743965 nn.Linear: 0.1198588386178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010982889284043 nn.Linear: 0.00069853294680728 nn.Linear: 0.00037939191476254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013380692790971 nn.Linear: 0.0025999624811978] nn.Sequential: [nn.Linear: 0.00010567044221275 nn.Linear: 0.0012898293796101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084622772410512 nn.Linear: 0.015420347452164 nn.Linear: 0.0069881700910628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057248873636127 nn.Linear: 0.017878975719213] nn.Sequential: [nn.Linear: 0.0044130990281701 nn.Linear: 0.016532311215997]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062231475991462 nn.Linear: 0.062753431586838 nn.Linear: 0.044431771378248 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031366367170976 nn.Linear: 0.034817484521753] nn.Sequential: [nn.Linear: 0.031305739200235 nn.Linear: 0.025791053284159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33844146132469 nn.Linear: 0.1922052949667 nn.Linear: 0.11778756976128 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085548266768456 nn.Linear: 0.14659637212753] nn.Sequential: [nn.Linear: 0.078365981578827 nn.Linear: 0.1204315200448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00084496585035386 nn.Linear: 0.00045370576785304 nn.Linear: 0.00022401601746957 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.0822087877988e-05 nn.Linear: 0.00090048113917396] nn.Sequential: [nn.Linear: 6.2430687590605e-05 nn.Linear: 0.00074241536536425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085440464317799 nn.Linear: 0.006575888954103 nn.Linear: 0.004256758838892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030963057652116 nn.Linear: 0.0060165892355144] nn.Sequential: [nn.Linear: 0.0021585284266621 nn.Linear: 0.0081272264942527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240459827192 nn.Linear: 0.062757673712264 nn.Linear: 0.044433563248411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031366325485346 nn.Linear: 0.034795533977388] nn.Sequential: [nn.Linear: 0.031306287483549 nn.Linear: 0.025822028776386]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33868825435638 nn.Linear: 0.19189934432507 nn.Linear: 0.11828979104757 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085737586021423 nn.Linear: 0.14650931954384] nn.Sequential: [nn.Linear: 0.078396521508694 nn.Linear: 0.12104392796755]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011266709849549 nn.Linear: 0.0005875157839086 nn.Linear: 0.00027295165557251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4893382399998e-05 nn.Linear: 0.001416860580417] nn.Sequential: [nn.Linear: 9.0472876193603e-05 nn.Linear: 0.0011235330752164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011704489588737 nn.Linear: 0.013914963230491 nn.Linear: 0.0066506178118289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073051052168012 nn.Linear: 0.010557984001935] nn.Sequential: [nn.Linear: 0.0031215820927173 nn.Linear: 0.0087962979450822]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242941014572 nn.Linear: 0.062760179464354 nn.Linear: 0.044434572886281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031366664315232 nn.Linear: 0.034874120360456] nn.Sequential: [nn.Linear: 0.031306345684073 nn.Linear: 0.025832675950345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33940863609314 nn.Linear: 0.1920452862978 nn.Linear: 0.11817015707493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085823722183704 nn.Linear: 0.14645698666573] nn.Sequential: [nn.Linear: 0.078288897871971 nn.Linear: 0.12131094932556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012012850036588 nn.Linear: 0.00063655703964251 nn.Linear: 0.00026582254138307 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.1851630131852e-05 nn.Linear: 0.0015473538839321] nn.Sequential: [nn.Linear: 6.7323524599403e-05 nn.Linear: 0.00074953627056542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077270278707147 nn.Linear: 0.0092695532366633 nn.Linear: 0.0046908506192267 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045737195760012 nn.Linear: 0.010754318907857] nn.Sequential: [nn.Linear: 0.0022275187075138 nn.Linear: 0.0066412319429219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062246061796687 nn.Linear: 0.062764044083304 nn.Linear: 0.044435365299627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031366922042634 nn.Linear: 0.034912641775144] nn.Sequential: [nn.Linear: 0.031306547553229 nn.Linear: 0.025856270747351]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33976668119431 nn.Linear: 0.19208733737469 nn.Linear: 0.11787740141153 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086039833724499 nn.Linear: 0.1466516405344] nn.Sequential: [nn.Linear: 0.078324109315872 nn.Linear: 0.1209262534976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017064411611107 nn.Linear: 0.0010099710582396 nn.Linear: 0.0005085436206247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020874684908169 nn.Linear: 0.003881113961528] nn.Sequential: [nn.Linear: 0.00016673843296145 nn.Linear: 0.0021324356165541]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012601970694959 nn.Linear: 0.018840556964278 nn.Linear: 0.017788339406252 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091511430218816 nn.Linear: 0.03020891174674] nn.Sequential: [nn.Linear: 0.0056808665394783 nn.Linear: 0.023020565509796]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062243801438707 nn.Linear: 0.062764841910118 nn.Linear: 0.044435300848957 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03136705970933 nn.Linear: 0.034951915588593] nn.Sequential: [nn.Linear: 0.031306651588452 nn.Linear: 0.025868888820564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33957329392433 nn.Linear: 0.19159276783466 nn.Linear: 0.11783972382545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085968181490898 nn.Linear: 0.14708741009235] nn.Sequential: [nn.Linear: 0.078353926539421 nn.Linear: 0.12146657705307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024427252675563 nn.Linear: 0.0011943107645344 nn.Linear: 0.00053752375304978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015279543862211 nn.Linear: 0.0025473768370262] nn.Sequential: [nn.Linear: 0.00018206348858843 nn.Linear: 0.002339973212342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019298082217574 nn.Linear: 0.023953333497047 nn.Linear: 0.014134467579424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083258133381605 nn.Linear: 0.019845258444548] nn.Sequential: [nn.Linear: 0.0082851806655526 nn.Linear: 0.027820697054267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.1014503313154	TD error	0.021714286267757	Qmax	1	

Steps: 2250000 (frames: 9000000), score: 1806.92, higheset score: 5496, epsilon: 0.05, lr: 0.0005, training time: 595s, training rate: 1678fps, testing time: 96s, testing rate: 5169fps,  num. ep.: 312,  num. rewards: 15519	
   2    8    4    2
   8   32    8    4
   4  512  128   32
   2   64    2   64
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062245985140571 nn.Linear: 0.06276992041189 nn.Linear: 0.044436439145251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367247181002 nn.Linear: 0.034952434258514] nn.Sequential: [nn.Linear: 0.031306954078822 nn.Linear: 0.025876999799257]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34045627713203 nn.Linear: 0.19216315448284 nn.Linear: 0.117865704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.085970170795918 nn.Linear: 0.14675422012806] nn.Sequential: [nn.Linear: 0.078412137925625 nn.Linear: 0.12161923199892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015267793382517 nn.Linear: 0.00096757700495337 nn.Linear: 0.00052166606602416 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020707243801963 nn.Linear: 0.0044489661216989] nn.Sequential: [nn.Linear: 0.00013022476919939 nn.Linear: 0.0013224156941997]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011165350675583 nn.Linear: 0.016975061967969 nn.Linear: 0.015554774552584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085697425529361 nn.Linear: 0.027856392785907] nn.Sequential: [nn.Linear: 0.0036659657489508 nn.Linear: 0.010163341648877]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062245141791112 nn.Linear: 0.062773386110356 nn.Linear: 0.044437409793843 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367603279723 nn.Linear: 0.035027745153798] nn.Sequential: [nn.Linear: 0.03130692314536 nn.Linear: 0.025892833966361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34012019634247 nn.Linear: 0.19220985472202 nn.Linear: 0.11793659627438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086206287145615 nn.Linear: 0.14700846374035] nn.Sequential: [nn.Linear: 0.078305795788765 nn.Linear: 0.12175035476685]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015604119461307 nn.Linear: 0.00096098421163462 nn.Linear: 0.00050138571624985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001976001615922 nn.Linear: 0.0033051905730352] nn.Sequential: [nn.Linear: 0.00012809762780388 nn.Linear: 0.0018198741712322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014561950229108 nn.Linear: 0.018506335094571 nn.Linear: 0.010033149272203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065091056749225 nn.Linear: 0.018607636913657] nn.Sequential: [nn.Linear: 0.0038312107790262 nn.Linear: 0.016782475635409]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242376375872 nn.Linear: 0.062777574683856 nn.Linear: 0.044437935584664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367600299807 nn.Linear: 0.035031392829069] nn.Sequential: [nn.Linear: 0.031307265247421 nn.Linear: 0.025916100261638]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.33991488814354 nn.Linear: 0.19212356209755 nn.Linear: 0.11791582405567 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086596347391605 nn.Linear: 0.14705792069435] nn.Sequential: [nn.Linear: 0.078344598412514 nn.Linear: 0.12247195094824]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0037215959122166 nn.Linear: 0.0023134478860186 nn.Linear: 0.0009021797018227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023743489260122 nn.Linear: 0.0039119688704696] nn.Sequential: [nn.Linear: 0.00026333092744397 nn.Linear: 0.0034196881037405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022333193570375 nn.Linear: 0.027542550116777 nn.Linear: 0.020639833062887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012612908147275 nn.Linear: 0.029264802113175] nn.Sequential: [nn.Linear: 0.011083241552114 nn.Linear: 0.034432467073202]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062251009037923 nn.Linear: 0.062781058332584 nn.Linear: 0.044439819786359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367687424899 nn.Linear: 0.035028548946912] nn.Sequential: [nn.Linear: 0.031307693696615 nn.Linear: 0.025939531581054]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34031069278717 nn.Linear: 0.1917849779129 nn.Linear: 0.11834645271301 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08684565871954 nn.Linear: 0.14710946381092] nn.Sequential: [nn.Linear: 0.078674592077732 nn.Linear: 0.12300699949265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061524675133909 nn.Linear: 0.00037540907325034 nn.Linear: 0.00018486125300749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.6629608483314e-05 nn.Linear: 0.00111082457946] nn.Sequential: [nn.Linear: 4.8510960267272e-05 nn.Linear: 0.00050786432504313]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048455623909831 nn.Linear: 0.0044822520576417 nn.Linear: 0.0041327350772917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003394678235054 nn.Linear: 0.0079483864828944] nn.Sequential: [nn.Linear: 0.0019188206642866 nn.Linear: 0.0044248425401747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062246755877149 nn.Linear: 0.062781485414128 nn.Linear: 0.044439316238012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367631021703 nn.Linear: 0.035014382331383] nn.Sequential: [nn.Linear: 0.031307593002875 nn.Linear: 0.025940794416343]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34084969758987 nn.Linear: 0.19172267615795 nn.Linear: 0.11796229332685 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086530759930611 nn.Linear: 0.14751324057579] nn.Sequential: [nn.Linear: 0.07877192646265 nn.Linear: 0.1228009685874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011395494085815 nn.Linear: 0.00061786596587282 nn.Linear: 0.00029335969425115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.7609177604056e-05 nn.Linear: 0.0012621705964955] nn.Sequential: [nn.Linear: 9.662621191478e-05 nn.Linear: 0.00098462358507194]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083209471777081 nn.Linear: 0.0091957710683346 nn.Linear: 0.0047541977837682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055647320114076 nn.Linear: 0.0081627136096358] nn.Sequential: [nn.Linear: 0.0027264517266303 nn.Linear: 0.0086792474612594]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062248668379004 nn.Linear: 0.062782851930574 nn.Linear: 0.044439262361298 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367481549805 nn.Linear: 0.034988980111805] nn.Sequential: [nn.Linear: 0.031307716239918 nn.Linear: 0.025950605065088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34024488925934 nn.Linear: 0.19158016145229 nn.Linear: 0.11782140284777 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086671508848667 nn.Linear: 0.14746059477329] nn.Sequential: [nn.Linear: 0.079034239053726 nn.Linear: 0.12266603857279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011355940828502 nn.Linear: 0.00069343284356778 nn.Linear: 0.00037881494158207 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017270462890455 nn.Linear: 0.0036491949434355] nn.Sequential: [nn.Linear: 9.2020797100359e-05 nn.Linear: 0.001167579933987]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095134954899549 nn.Linear: 0.014580931514502 nn.Linear: 0.0091216182336211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0080824522301555 nn.Linear: 0.019436415284872] nn.Sequential: [nn.Linear: 0.0029192063957453 nn.Linear: 0.0088962092995644]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062245626968321 nn.Linear: 0.062783238040286 nn.Linear: 0.044439384034945 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367589544211 nn.Linear: 0.034985826405276] nn.Sequential: [nn.Linear: 0.031307634927444 nn.Linear: 0.025951009002491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3404498398304 nn.Linear: 0.19057002663612 nn.Linear: 0.11782050132751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086737856268883 nn.Linear: 0.14738060534] nn.Sequential: [nn.Linear: 0.079003028571606 nn.Linear: 0.12283941358328]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017670482930507 nn.Linear: 0.001010903524329 nn.Linear: 0.00052059613480868 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002208244142625 nn.Linear: 0.0039037019160979] nn.Sequential: [nn.Linear: 0.00015273613656863 nn.Linear: 0.0018482265834668]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015727706253529 nn.Linear: 0.016527831554413 nn.Linear: 0.012884373776615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007904808036983 nn.Linear: 0.023563014343381] nn.Sequential: [nn.Linear: 0.0050816396251321 nn.Linear: 0.013699786737561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062238420884331 nn.Linear: 0.062783089256886 nn.Linear: 0.044439538813208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367729137221 nn.Linear: 0.034948287962678] nn.Sequential: [nn.Linear: 0.031307628023474 nn.Linear: 0.025954683734312]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34056705236435 nn.Linear: 0.19053849577904 nn.Linear: 0.11775720119476 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086771763861179 nn.Linear: 0.14729502797127] nn.Sequential: [nn.Linear: 0.079076766967773 nn.Linear: 0.12283428013325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011605901936108 nn.Linear: 0.00069991175327753 nn.Linear: 0.00037359837953939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015313529931355 nn.Linear: 0.0032587235919594] nn.Sequential: [nn.Linear: 8.2412430384387e-05 nn.Linear: 0.0010006645420207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012483654543757 nn.Linear: 0.013086223043501 nn.Linear: 0.0090042473748326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072441608645022 nn.Linear: 0.017960254102945] nn.Sequential: [nn.Linear: 0.0029608972836286 nn.Linear: 0.0076052621006966]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062234677383072 nn.Linear: 0.062782680163903 nn.Linear: 0.044439241193737 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367813634148 nn.Linear: 0.034953504283681] nn.Sequential: [nn.Linear: 0.03130759805461 nn.Linear: 0.025961979882472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34043776988983 nn.Linear: 0.1910001039505 nn.Linear: 0.11777453124523 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086810037493706 nn.Linear: 0.14762163162231] nn.Sequential: [nn.Linear: 0.079157285392284 nn.Linear: 0.12279583513737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007740411938335 nn.Linear: 0.00053212000234865 nn.Linear: 0.00025775408341725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010247450674099 nn.Linear: 0.0021964934208466] nn.Sequential: [nn.Linear: 8.9509939033823e-05 nn.Linear: 0.0012347230365461]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051802396774292 nn.Linear: 0.0068087982945144 nn.Linear: 0.0046383854933083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035913337487727 nn.Linear: 0.012216737493873] nn.Sequential: [nn.Linear: 0.0024739312939346 nn.Linear: 0.010712226852775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062236576624187 nn.Linear: 0.062787093929735 nn.Linear: 0.044440548145531 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367928617379 nn.Linear: 0.034974620526498] nn.Sequential: [nn.Linear: 0.031307869264371 nn.Linear: 0.025977168828751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34061220288277 nn.Linear: 0.19105887413025 nn.Linear: 0.11756115406752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086852721869946 nn.Linear: 0.14774438738823] nn.Sequential: [nn.Linear: 0.079126507043839 nn.Linear: 0.12315555661917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014612145787158 nn.Linear: 0.00090542278051971 nn.Linear: 0.00043493655862613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019114543210655 nn.Linear: 0.0035845485090349] nn.Sequential: [nn.Linear: 0.0001166658689137 nn.Linear: 0.0013916185205547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015123434364796 nn.Linear: 0.020930165424943 nn.Linear: 0.012252422049642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010318733751774 nn.Linear: 0.024614457041025] nn.Sequential: [nn.Linear: 0.0053746663033962 nn.Linear: 0.014969363808632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062232655495174 nn.Linear: 0.062787236664408 nn.Linear: 0.04444078600976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368018627533 nn.Linear: 0.034984433783563] nn.Sequential: [nn.Linear: 0.031307854245447 nn.Linear: 0.025983231979598]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34036284685135 nn.Linear: 0.19168458878994 nn.Linear: 0.11775498837233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086792454123497 nn.Linear: 0.14768531918526] nn.Sequential: [nn.Linear: 0.079144939780235 nn.Linear: 0.1234235316515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009675027161394 nn.Linear: 0.0006260975166701 nn.Linear: 0.00032969154215079 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014942796791915 nn.Linear: 0.003017311203086] nn.Sequential: [nn.Linear: 6.9780154713864e-05 nn.Linear: 0.00066012329717448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066117006354034 nn.Linear: 0.010943663306534 nn.Linear: 0.0057809669524431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051814061589539 nn.Linear: 0.017478335648775] nn.Sequential: [nn.Linear: 0.0018872118089348 nn.Linear: 0.0056540071964264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062233594543703 nn.Linear: 0.062789917380125 nn.Linear: 0.044441867817201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368007884535 nn.Linear: 0.034997540544623] nn.Sequential: [nn.Linear: 0.031308177975607 nn.Linear: 0.026010239739574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34036359190941 nn.Linear: 0.1910018324852 nn.Linear: 0.11813937872648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086921386420727 nn.Linear: 0.14777503907681] nn.Sequential: [nn.Linear: 0.078958049416542 nn.Linear: 0.12444581091404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016104883738744 nn.Linear: 0.00090962274296363 nn.Linear: 0.0004402104570015 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015789215830962 nn.Linear: 0.0025576337595938] nn.Sequential: [nn.Linear: 0.00012758709635921 nn.Linear: 0.0013447943444208]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01125973649323 nn.Linear: 0.016083953902125 nn.Linear: 0.009991068392992 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081447921693325 nn.Linear: 0.02576288767159] nn.Sequential: [nn.Linear: 0.002980561228469 nn.Linear: 0.011537318117917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062230213604481 nn.Linear: 0.062791462767615 nn.Linear: 0.044441674730504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031367890426636 nn.Linear: 0.034969942058098] nn.Sequential: [nn.Linear: 0.031308342844803 nn.Linear: 0.026017779763482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3406857252121 nn.Linear: 0.19114597141743 nn.Linear: 0.11810664087534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086789891123772 nn.Linear: 0.14745870232582] nn.Sequential: [nn.Linear: 0.07921788841486 nn.Linear: 0.12465804815292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013965861137041 nn.Linear: 0.00085968404132896 nn.Linear: 0.00049576759457572 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023617717144255 nn.Linear: 0.0051294985596653] nn.Sequential: [nn.Linear: 0.00015164064409541 nn.Linear: 0.0020831360681113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008566184900701 nn.Linear: 0.016441971063614 nn.Linear: 0.011787061579525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063289613462985 nn.Linear: 0.02604822255671] nn.Sequential: [nn.Linear: 0.0057696583680809 nn.Linear: 0.022527933120728]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062230445592897 nn.Linear: 0.062794181290127 nn.Linear: 0.044443397621916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368042406256 nn.Linear: 0.034979945773181] nn.Sequential: [nn.Linear: 0.031308596912703 nn.Linear: 0.026031974660222]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34083133935928 nn.Linear: 0.19104805588722 nn.Linear: 0.11800039559603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086662657558918 nn.Linear: 0.1473064571619] nn.Sequential: [nn.Linear: 0.079447597265244 nn.Linear: 0.12521483004093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010676051265757 nn.Linear: 0.00064139590096595 nn.Linear: 0.00029961739336348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012483595897339 nn.Linear: 0.0024798128618388] nn.Sequential: [nn.Linear: 5.4575187825995e-05 nn.Linear: 0.00054790363218303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010177662596107 nn.Linear: 0.014484753832221 nn.Linear: 0.008530842140317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070729916915298 nn.Linear: 0.016326097771525] nn.Sequential: [nn.Linear: 0.0013678985415027 nn.Linear: 0.0040216827765107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062229279336878 nn.Linear: 0.062795213357732 nn.Linear: 0.044443308130919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03136829341772 nn.Linear: 0.035018997893761] nn.Sequential: [nn.Linear: 0.031308566047391 nn.Linear: 0.026050239449841]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34116610884666 nn.Linear: 0.19079427421093 nn.Linear: 0.11793396621943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086603462696075 nn.Linear: 0.14754155278206] nn.Sequential: [nn.Linear: 0.079230763018131 nn.Linear: 0.12521307170391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00070826563694084 nn.Linear: 0.00044171183878896 nn.Linear: 0.00022023671888858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6854122853589e-05 nn.Linear: 0.0019522435854826] nn.Sequential: [nn.Linear: 5.984945382048e-05 nn.Linear: 0.00064722896581414]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070655113086104 nn.Linear: 0.0058279070071876 nn.Linear: 0.0065192175097764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038767580408603 nn.Linear: 0.011380712501705] nn.Sequential: [nn.Linear: 0.0017919804668054 nn.Linear: 0.0054587917402387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062225704944181 nn.Linear: 0.062797956473923 nn.Linear: 0.044444208580279 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368265143836 nn.Linear: 0.035029222727729] nn.Sequential: [nn.Linear: 0.031308794970215 nn.Linear: 0.026057263303387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34107440710068 nn.Linear: 0.19124671816826 nn.Linear: 0.1183300241828 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086721330881119 nn.Linear: 0.14762333035469] nn.Sequential: [nn.Linear: 0.079391911625862 nn.Linear: 0.12548437714577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00065128125405688 nn.Linear: 0.00038557348108032 nn.Linear: 0.00020182997675867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.0255351194674e-05 nn.Linear: 0.0007857573143486] nn.Sequential: [nn.Linear: 8.8945249059241e-05 nn.Linear: 0.0010173639191296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0050686369650066 nn.Linear: 0.006605003029108 nn.Linear: 0.0041585289873183 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035773585550487 nn.Linear: 0.0050632948987186] nn.Sequential: [nn.Linear: 0.0028952108696103 nn.Linear: 0.010939227417111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062231359794344 nn.Linear: 0.062801815776336 nn.Linear: 0.044444515832369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368433512791 nn.Linear: 0.035066702768695] nn.Sequential: [nn.Linear: 0.031308815728125 nn.Linear: 0.026066710789209]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34157681465149 nn.Linear: 0.19107891619205 nn.Linear: 0.11843144893646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08657456189394 nn.Linear: 0.14784272015095] nn.Sequential: [nn.Linear: 0.079380042850971 nn.Linear: 0.12520654499531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016430042863514 nn.Linear: 0.00093481623605272 nn.Linear: 0.00047992252524467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017115605690974 nn.Linear: 0.0028074613115461] nn.Sequential: [nn.Linear: 0.0001599498692234 nn.Linear: 0.0017518691288327]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012621220201254 nn.Linear: 0.016410276293755 nn.Linear: 0.010966312140226 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011234377510846 nn.Linear: 0.021242745220661] nn.Sequential: [nn.Linear: 0.0056236633099616 nn.Linear: 0.016639607027173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062234060214865 nn.Linear: 0.062803090513193 nn.Linear: 0.044445275724449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368539916663 nn.Linear: 0.035096213200632] nn.Sequential: [nn.Linear: 0.031308999148842 nn.Linear: 0.026079044990396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34198996424675 nn.Linear: 0.19130715727806 nn.Linear: 0.1182793751359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08646697551012 nn.Linear: 0.14787764847279] nn.Sequential: [nn.Linear: 0.07932660728693 nn.Linear: 0.12561085820198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088065538787788 nn.Linear: 0.00052369432634314 nn.Linear: 0.00026668437408039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012157863772342 nn.Linear: 0.002438363290547] nn.Sequential: [nn.Linear: 6.8001267871065e-05 nn.Linear: 0.00065773868258714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068667577579618 nn.Linear: 0.0087125515565276 nn.Linear: 0.0043523297645152 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043842908926308 nn.Linear: 0.015143821947277] nn.Sequential: [nn.Linear: 0.0016596976201981 nn.Linear: 0.0063046691939235]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06223489430632 nn.Linear: 0.06280414219429 nn.Linear: 0.0444458792843 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368745070279 nn.Linear: 0.035102382734152] nn.Sequential: [nn.Linear: 0.031309213654156 nn.Linear: 0.026090173410608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34219887852669 nn.Linear: 0.1917902380228 nn.Linear: 0.11846045404673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086865171790123 nn.Linear: 0.14787046611309] nn.Sequential: [nn.Linear: 0.07948761433363 nn.Linear: 0.12615931034088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013210429521339 nn.Linear: 0.00075529617328683 nn.Linear: 0.00039439620751819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017409451710544 nn.Linear: 0.0037228690297806] nn.Sequential: [nn.Linear: 0.00010554731267282 nn.Linear: 0.0012857136849478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01287329941988 nn.Linear: 0.014503727667034 nn.Linear: 0.0069766966626048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053444039076567 nn.Linear: 0.020898235961795] nn.Sequential: [nn.Linear: 0.0031888743396848 nn.Linear: 0.013773819431663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062234298201026 nn.Linear: 0.062807837778154 nn.Linear: 0.044446869008954 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031368956651892 nn.Linear: 0.03515585229507] nn.Sequential: [nn.Linear: 0.031309399485805 nn.Linear: 0.02610700859964]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34226411581039 nn.Linear: 0.1910053640604 nn.Linear: 0.11864196509123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087041959166527 nn.Linear: 0.14827705919743] nn.Sequential: [nn.Linear: 0.079329743981361 nn.Linear: 0.12638093531132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011731105244174 nn.Linear: 0.0008072054410898 nn.Linear: 0.00044303675977823 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018327892183034 nn.Linear: 0.0033959604557692] nn.Sequential: [nn.Linear: 0.0001573999381589 nn.Linear: 0.0020490006077824]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008035046979785 nn.Linear: 0.018947249278426 nn.Linear: 0.01305019762367 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011666030623019 nn.Linear: 0.030504642054439] nn.Sequential: [nn.Linear: 0.0056573082692921 nn.Linear: 0.022962670773268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062238132325429 nn.Linear: 0.062811309206318 nn.Linear: 0.044447957574467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369274598322 nn.Linear: 0.035179356284866] nn.Sequential: [nn.Linear: 0.031309469641713 nn.Linear: 0.02612442135751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34176409244537 nn.Linear: 0.19054612517357 nn.Linear: 0.11853058636189 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086876235902309 nn.Linear: 0.14857585728168] nn.Sequential: [nn.Linear: 0.079382427036762 nn.Linear: 0.12621891498566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013679631669448 nn.Linear: 0.00085554402381812 nn.Linear: 0.00044895718429627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015666904250798 nn.Linear: 0.0024679864880826] nn.Sequential: [nn.Linear: 0.00013078713701077 nn.Linear: 0.0013382963992324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012076795101166 nn.Linear: 0.011667082086205 nn.Linear: 0.0088468240574002 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061923847533762 nn.Linear: 0.015369297005236] nn.Sequential: [nn.Linear: 0.0038248719647527 nn.Linear: 0.012419198639691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240708908819 nn.Linear: 0.062815267356366 nn.Linear: 0.044449381092654 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369428045021 nn.Linear: 0.035200499458888] nn.Sequential: [nn.Linear: 0.031309763059712 nn.Linear: 0.026154225151644]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34177976846695 nn.Linear: 0.19001352787018 nn.Linear: 0.11849889159203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087027795612812 nn.Linear: 0.14823536574841] nn.Sequential: [nn.Linear: 0.079336777329445 nn.Linear: 0.12701012194157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018542742488304 nn.Linear: 0.0010632685600699 nn.Linear: 0.00042972439161345 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016259645262019 nn.Linear: 0.0034909289547942] nn.Sequential: [nn.Linear: 0.00012275507858446 nn.Linear: 0.0014142764071939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01537427585572 nn.Linear: 0.020904680714011 nn.Linear: 0.0099830217659473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074123004451394 nn.Linear: 0.022660912945867] nn.Sequential: [nn.Linear: 0.0032797148451209 nn.Linear: 0.013927242718637]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062239091364292 nn.Linear: 0.062817658159087 nn.Linear: 0.044449929217578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369669153454 nn.Linear: 0.035248115911472] nn.Sequential: [nn.Linear: 0.031309848081327 nn.Linear: 0.026165363729381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34234440326691 nn.Linear: 0.19063261151314 nn.Linear: 0.11839816719294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087327808141708 nn.Linear: 0.14842694997787] nn.Sequential: [nn.Linear: 0.079468250274658 nn.Linear: 0.12727004289627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00070165336108912 nn.Linear: 0.00046267733336551 nn.Linear: 0.00022423864710326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.9285931005952e-05 nn.Linear: 0.0016469043655579] nn.Sequential: [nn.Linear: 6.7205195460788e-05 nn.Linear: 0.00072841186540182]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069944080896676 nn.Linear: 0.0066749430261552 nn.Linear: 0.0072964685969055 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045755878090858 nn.Linear: 0.010462639853358] nn.Sequential: [nn.Linear: 0.0024740837980062 nn.Linear: 0.0071829366497695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062239895382363 nn.Linear: 0.06282057118644 nn.Linear: 0.044450289758994 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369517707229 nn.Linear: 0.035252914539853] nn.Sequential: [nn.Linear: 0.0313100608019 nn.Linear: 0.026173512712456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.342170804739 nn.Linear: 0.19083552062511 nn.Linear: 0.11830914020538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086891353130341 nn.Linear: 0.14846882224083] nn.Sequential: [nn.Linear: 0.079808324575424 nn.Linear: 0.1272829324007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001051151767533 nn.Linear: 0.00066770304574756 nn.Linear: 0.0003461859437269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012063807954159 nn.Linear: 0.0017037298540883] nn.Sequential: [nn.Linear: 9.7756766370045e-05 nn.Linear: 0.0011148054502818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074564944952726 nn.Linear: 0.009878933429718 nn.Linear: 0.008033400401473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088581498712301 nn.Linear: 0.012774266302586] nn.Sequential: [nn.Linear: 0.0032013824675232 nn.Linear: 0.012703772634268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062245771151776 nn.Linear: 0.062823868455757 nn.Linear: 0.044451606721112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369756554602 nn.Linear: 0.035273326584054] nn.Sequential: [nn.Linear: 0.031310243516256 nn.Linear: 0.026183618546009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34229063987732 nn.Linear: 0.19070534408092 nn.Linear: 0.11852314323187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087184347212315 nn.Linear: 0.14838138222694] nn.Sequential: [nn.Linear: 0.079810120165348 nn.Linear: 0.12767757475376]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013245075698967 nn.Linear: 0.00078198309501368 nn.Linear: 0.00039730115438551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017490310356111 nn.Linear: 0.003279075064841] nn.Sequential: [nn.Linear: 0.00010745054226363 nn.Linear: 0.0012498338342546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010398340411484 nn.Linear: 0.010976142250001 nn.Linear: 0.007088900078088 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061755222268403 nn.Linear: 0.020390596240759] nn.Sequential: [nn.Linear: 0.0048595233820379 nn.Linear: 0.01114253513515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10038142099977	TD error	0.019765262093395	Qmax	1	

Steps: 2500000 (frames: 10000000), score: 1858.18, higheset score: 6308, epsilon: 0.05, lr: 0.0005, training time: 574s, training rate: 1740fps, testing time: 91s, testing rate: 5479fps,  num. ep.: 440,  num. rewards: 20636	
   4    2   16    4
   2    8   32    8
  16   32   64  256
   2    4  512    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240964289396 nn.Linear: 0.062826067835337 nn.Linear: 0.044452437999571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031369839429318 nn.Linear: 0.03528548743958] nn.Sequential: [nn.Linear: 0.031310323809118 nn.Linear: 0.026197442273098]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34265571832657 nn.Linear: 0.19003500044346 nn.Linear: 0.1184106990695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.086956828832626 nn.Linear: 0.14868095517159] nn.Sequential: [nn.Linear: 0.079828761518002 nn.Linear: 0.12788613140583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013307262732011 nn.Linear: 0.00086668250352136 nn.Linear: 0.00045619750246341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018660532831081 nn.Linear: 0.0032305055464876] nn.Sequential: [nn.Linear: 0.00011887652491458 nn.Linear: 0.0015560219145823]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084312949329615 nn.Linear: 0.011269426904619 nn.Linear: 0.010598300024867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084568858146667 nn.Linear: 0.024242792278528] nn.Sequential: [nn.Linear: 0.0037382084410638 nn.Linear: 0.014550232328475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240114352711 nn.Linear: 0.062829191198609 nn.Linear: 0.044452961922591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031370039241388 nn.Linear: 0.035336556282591] nn.Sequential: [nn.Linear: 0.031310559175923 nn.Linear: 0.026217847942665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34334275126457 nn.Linear: 0.18974517285824 nn.Linear: 0.1188976764679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087264716625214 nn.Linear: 0.14863736927509] nn.Sequential: [nn.Linear: 0.079892188310623 nn.Linear: 0.12828415632248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00062904921515081 nn.Linear: 0.0004284554186513 nn.Linear: 0.00026298538161404 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.9002964886889e-05 nn.Linear: 0.0018269972009564] nn.Sequential: [nn.Linear: 0.00010061296796197 nn.Linear: 0.0012147962433189]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0047042798250914 nn.Linear: 0.0075678052380681 nn.Linear: 0.0065091014839709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035668008495122 nn.Linear: 0.015297998674214] nn.Sequential: [nn.Linear: 0.0026918149087578 nn.Linear: 0.013137950561941]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242970909738 nn.Linear: 0.062830826367358 nn.Linear: 0.044454010190844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031370093730777 nn.Linear: 0.03532425524304] nn.Sequential: [nn.Linear: 0.031310838955155 nn.Linear: 0.026236664678845]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3434699177742 nn.Linear: 0.19000767171383 nn.Linear: 0.11878824234009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08730398863554 nn.Linear: 0.14855799078941] nn.Sequential: [nn.Linear: 0.080138832330704 nn.Linear: 0.12818105518818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015689205177228 nn.Linear: 0.00097323493065711 nn.Linear: 0.00052932183321467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020763182381912 nn.Linear: 0.0040226149322713] nn.Sequential: [nn.Linear: 0.00016851488712231 nn.Linear: 0.0022638123189096]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010121006518602 nn.Linear: 0.017088547348976 nn.Linear: 0.0099489232525229 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007179859559983 nn.Linear: 0.023490520194173] nn.Sequential: [nn.Linear: 0.0051982728764415 nn.Linear: 0.024528201669455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240709437134 nn.Linear: 0.062831440929121 nn.Linear: 0.044454523621774 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031370158768474 nn.Linear: 0.035343382895491] nn.Sequential: [nn.Linear: 0.031310984468393 nn.Linear: 0.026248906713669]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34357267618179 nn.Linear: 0.19040702283382 nn.Linear: 0.11847111582756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087262585759163 nn.Linear: 0.14873811602592] nn.Sequential: [nn.Linear: 0.080222636461258 nn.Linear: 0.12863527238369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010338527639733 nn.Linear: 0.00050485537689667 nn.Linear: 0.00021250044033961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.4912731566254e-05 nn.Linear: 0.0013441033167747] nn.Sequential: [nn.Linear: 6.5160853121867e-05 nn.Linear: 0.00072264169592196]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00755829596892 nn.Linear: 0.0069035380147398 nn.Linear: 0.0045989383943379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0026460799854249 nn.Linear: 0.0081753823906183] nn.Sequential: [nn.Linear: 0.0017793229781091 nn.Linear: 0.0065951473079622]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242662949199 nn.Linear: 0.062834494617874 nn.Linear: 0.044455833387679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031370467679746 nn.Linear: 0.035391270559188] nn.Sequential: [nn.Linear: 0.031311092352552 nn.Linear: 0.02626564632145]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34381490945816 nn.Linear: 0.19020448625088 nn.Linear: 0.11893754452467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087063103914261 nn.Linear: 0.14920134842396] nn.Sequential: [nn.Linear: 0.08007238060236 nn.Linear: 0.12881769239902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011726555947798 nn.Linear: 0.00075534064746234 nn.Linear: 0.00038691246320632 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001411516285758 nn.Linear: 0.0027367185181044] nn.Sequential: [nn.Linear: 0.00012490460796826 nn.Linear: 0.001313132267492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011417942121625 nn.Linear: 0.012366049923003 nn.Linear: 0.008969065733254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065599833615124 nn.Linear: 0.016723126173019] nn.Sequential: [nn.Linear: 0.0035101526882499 nn.Linear: 0.012222143821418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242394075679 nn.Linear: 0.062839163497723 nn.Linear: 0.044457220619939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03137065775912 nn.Linear: 0.035415402277806] nn.Sequential: [nn.Linear: 0.031311378271684 nn.Linear: 0.026284637062224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34422960877419 nn.Linear: 0.18989662826061 nn.Linear: 0.11916545778513 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087016060948372 nn.Linear: 0.14901472628117] nn.Sequential: [nn.Linear: 0.080111466348171 nn.Linear: 0.12937630712986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080099673358793 nn.Linear: 0.00050483380168845 nn.Linear: 0.00029504280152477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.6526907851289e-05 nn.Linear: 0.0014859490193998] nn.Sequential: [nn.Linear: 0.00013842808492061 nn.Linear: 0.0014801038254375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063632437959313 nn.Linear: 0.0088797435164452 nn.Linear: 0.0079436162486672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005783427041024 nn.Linear: 0.0091539854183793] nn.Sequential: [nn.Linear: 0.0054780747741461 nn.Linear: 0.014822015538812]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242341021028 nn.Linear: 0.062844318524661 nn.Linear: 0.044458331059265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371096120395 nn.Linear: 0.03548182324154] nn.Sequential: [nn.Linear: 0.03131134136475 nn.Linear: 0.026288841268194]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34541249275208 nn.Linear: 0.19004790484905 nn.Linear: 0.11941573768854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087269872426987 nn.Linear: 0.14899934828281] nn.Sequential: [nn.Linear: 0.080201834440231 nn.Linear: 0.12926781177521]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085061254747725 nn.Linear: 0.00048278205607726 nn.Linear: 0.00030533792211614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014334048294038 nn.Linear: 0.0025219784828109] nn.Sequential: [nn.Linear: 9.1146476293333e-05 nn.Linear: 0.00095508068834777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006327616982162 nn.Linear: 0.0084909200668335 nn.Linear: 0.0049620545469224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059772641398013 nn.Linear: 0.01673143170774] nn.Sequential: [nn.Linear: 0.0027075505349785 nn.Linear: 0.0087149851024151]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062242478209722 nn.Linear: 0.062845369313074 nn.Linear: 0.044458624515628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371350625199 nn.Linear: 0.035513905287839] nn.Sequential: [nn.Linear: 0.031311562985056 nn.Linear: 0.026313675681915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34565132856369 nn.Linear: 0.19055466353893 nn.Linear: 0.1190460473299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0872687920928 nn.Linear: 0.14938886463642] nn.Sequential: [nn.Linear: 0.080147407948971 nn.Linear: 0.12966887652874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012904876708706 nn.Linear: 0.00074051718326121 nn.Linear: 0.00036414365897181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014937663587293 nn.Linear: 0.0023717468797964] nn.Sequential: [nn.Linear: 8.4560027083088e-05 nn.Linear: 0.00083607366295803]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095233013853431 nn.Linear: 0.011233075521886 nn.Linear: 0.0070659657940269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085068019106984 nn.Linear: 0.014118692837656] nn.Sequential: [nn.Linear: 0.0019102529622614 nn.Linear: 0.0071032494306564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062240240834185 nn.Linear: 0.062846267728165 nn.Linear: 0.044459329204641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371372423475 nn.Linear: 0.035530820262537] nn.Sequential: [nn.Linear: 0.031311722910419 nn.Linear: 0.026332843315305]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34539812803268 nn.Linear: 0.19019143283367 nn.Linear: 0.11912637203932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087511368095875 nn.Linear: 0.14957238733768] nn.Sequential: [nn.Linear: 0.080078445374966 nn.Linear: 0.13042666018009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010763334225319 nn.Linear: 0.00063814274692551 nn.Linear: 0.00035433848841583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001499973862357 nn.Linear: 0.0024161649382326] nn.Sequential: [nn.Linear: 8.7868062213289e-05 nn.Linear: 0.00087927806949595]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081947464495897 nn.Linear: 0.013767180033028 nn.Linear: 0.0069241439923644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007372023537755 nn.Linear: 0.016440704464912] nn.Sequential: [nn.Linear: 0.0026517761871219 nn.Linear: 0.0091932155191898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06223908891663 nn.Linear: 0.062848626567294 nn.Linear: 0.044460462161164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371711744576 nn.Linear: 0.035580942845996] nn.Sequential: [nn.Linear: 0.031311769648819 nn.Linear: 0.026336136341367]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34535083174706 nn.Linear: 0.18978388607502 nn.Linear: 0.11931579560041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087668396532536 nn.Linear: 0.15009698271751] nn.Sequential: [nn.Linear: 0.080146439373493 nn.Linear: 0.13033764064312]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00059111434624295 nn.Linear: 0.00031499918134581 nn.Linear: 0.00016868603108361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.879409005684e-05 nn.Linear: 0.00083936582354682] nn.Sequential: [nn.Linear: 4.4992118095565e-05 nn.Linear: 0.00039899776301504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0042377370409667 nn.Linear: 0.0047581093385816 nn.Linear: 0.0031439065933228 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0026678703725338 nn.Linear: 0.0063190460205078] nn.Sequential: [nn.Linear: 0.0012515583075583 nn.Linear: 0.0039610741659999]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062244306872745 nn.Linear: 0.062853001975798 nn.Linear: 0.044461361514324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371859120435 nn.Linear: 0.035594201753526] nn.Sequential: [nn.Linear: 0.031312194171753 nn.Linear: 0.026365054881069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34612482786179 nn.Linear: 0.19048702716827 nn.Linear: 0.11936287581921 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087464705109596 nn.Linear: 0.15065436065197] nn.Sequential: [nn.Linear: 0.080350436270237 nn.Linear: 0.1305965334177]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00068018176071615 nn.Linear: 0.00045537351078212 nn.Linear: 0.00022701214400441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.7316787190059e-05 nn.Linear: 0.0011450819107821] nn.Sequential: [nn.Linear: 5.9097731841427e-05 nn.Linear: 0.00062719246424728]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048784124664962 nn.Linear: 0.0079726399853826 nn.Linear: 0.0049322322010994 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034021425526589 nn.Linear: 0.0069638169370592] nn.Sequential: [nn.Linear: 0.0016583369579166 nn.Linear: 0.0061497227288783]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062247313754053 nn.Linear: 0.062855496106118 nn.Linear: 0.044462196297519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031371981951564 nn.Linear: 0.035594830950174] nn.Sequential: [nn.Linear: 0.031312389610073 nn.Linear: 0.026378489088163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34695583581924 nn.Linear: 0.19019412994385 nn.Linear: 0.1193333119154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087546423077583 nn.Linear: 0.15082314610481] nn.Sequential: [nn.Linear: 0.080293253064156 nn.Linear: 0.1306719481945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00052633841375873 nn.Linear: 0.00038514124714045 nn.Linear: 0.00023654490427036 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010789118951795 nn.Linear: 0.0022746735232223] nn.Sequential: [nn.Linear: 7.5388282070765e-05 nn.Linear: 0.00092244384459682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046148197725415 nn.Linear: 0.0055563584901392 nn.Linear: 0.0050031221471727 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031779611017555 nn.Linear: 0.012066601775587] nn.Sequential: [nn.Linear: 0.0017308574169874 nn.Linear: 0.0095011061057448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062247950751658 nn.Linear: 0.062858110580019 nn.Linear: 0.044463840758598 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372062644586 nn.Linear: 0.035617093122028] nn.Sequential: [nn.Linear: 0.031312716550383 nn.Linear: 0.026398462519147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34692296385765 nn.Linear: 0.18947987258434 nn.Linear: 0.11919868737459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087460674345493 nn.Linear: 0.15094931423664] nn.Sequential: [nn.Linear: 0.080218374729156 nn.Linear: 0.13140615820885]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011102080716342 nn.Linear: 0.00080464971884616 nn.Linear: 0.00040443976751227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018998216568291 nn.Linear: 0.003890984314009] nn.Sequential: [nn.Linear: 9.4993211196072e-05 nn.Linear: 0.0011717494472868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071225469000638 nn.Linear: 0.012297082692385 nn.Linear: 0.0061688208952546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070628058165312 nn.Linear: 0.022762384265661] nn.Sequential: [nn.Linear: 0.0034867289941758 nn.Linear: 0.011239601299167]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062243066563143 nn.Linear: 0.06285909792788 nn.Linear: 0.044463546636289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372236144134 nn.Linear: 0.035623990927753] nn.Sequential: [nn.Linear: 0.031312771111665 nn.Linear: 0.026397424725931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34665635228157 nn.Linear: 0.18970333039761 nn.Linear: 0.1190527677536 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087130159139633 nn.Linear: 0.15208029747009] nn.Sequential: [nn.Linear: 0.080424182116985 nn.Linear: 0.13143095374107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012894659591448 nn.Linear: 0.00083373466054671 nn.Linear: 0.00041616803807935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011821014797785 nn.Linear: 0.0015485002974382] nn.Sequential: [nn.Linear: 0.00013990157410071 nn.Linear: 0.0014015187779544]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011864216998219 nn.Linear: 0.014409605413675 nn.Linear: 0.0099298590794206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077256700024009 nn.Linear: 0.011151402257383] nn.Sequential: [nn.Linear: 0.0046635111793876 nn.Linear: 0.014399505220354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062243223962741 nn.Linear: 0.062861366450712 nn.Linear: 0.044464489655953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372620918163 nn.Linear: 0.035707669054517] nn.Sequential: [nn.Linear: 0.031312818466286 nn.Linear: 0.026412099980258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34739571809769 nn.Linear: 0.19011273980141 nn.Linear: 0.11927474290133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087398670613766 nn.Linear: 0.15249893069267] nn.Sequential: [nn.Linear: 0.080469943583012 nn.Linear: 0.13154916465282]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010128723929434 nn.Linear: 0.00062538277428233 nn.Linear: 0.00029859003153276 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2245647258568e-05 nn.Linear: 0.0013232295191868] nn.Sequential: [nn.Linear: 8.62538744067e-05 nn.Linear: 0.00080229105551874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008278745226562 nn.Linear: 0.012474108487368 nn.Linear: 0.0056833894923329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040349960327148 nn.Linear: 0.0073080523870885] nn.Sequential: [nn.Linear: 0.0030508204363286 nn.Linear: 0.0073127974756062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06224718385209 nn.Linear: 0.062863570072065 nn.Linear: 0.044465331071163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372634830963 nn.Linear: 0.035710943174038] nn.Sequential: [nn.Linear: 0.0313130250547 nn.Linear: 0.026428739565542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34677863121033 nn.Linear: 0.19044078886509 nn.Linear: 0.11924030631781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087784603238106 nn.Linear: 0.15256993472576] nn.Sequential: [nn.Linear: 0.080520316958427 nn.Linear: 0.13186505436897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016582704886288 nn.Linear: 0.0010962949664788 nn.Linear: 0.00051378346095169 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019930147499285 nn.Linear: 0.0034718491755572] nn.Sequential: [nn.Linear: 0.00015464290168421 nn.Linear: 0.0016201356475315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015798090025783 nn.Linear: 0.016576897352934 nn.Linear: 0.011187268421054 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093753030523658 nn.Linear: 0.026387922465801] nn.Sequential: [nn.Linear: 0.0042704329825938 nn.Linear: 0.016179112717509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062251953176588 nn.Linear: 0.062866301997725 nn.Linear: 0.044466808428562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372841087929 nn.Linear: 0.035750860570165] nn.Sequential: [nn.Linear: 0.031313334187299 nn.Linear: 0.026453611656562]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34722691774368 nn.Linear: 0.19027590751648 nn.Linear: 0.11913972347975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.087636508047581 nn.Linear: 0.15274481475353] nn.Sequential: [nn.Linear: 0.080624654889107 nn.Linear: 0.13216857612133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022323820322084 nn.Linear: 0.0013247372815707 nn.Linear: 0.00065013702265747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002303676526657 nn.Linear: 0.0038326581401834] nn.Sequential: [nn.Linear: 0.00019935648196344 nn.Linear: 0.0026708839668922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022364910691977 nn.Linear: 0.017645539715886 nn.Linear: 0.019031208008528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010995477437973 nn.Linear: 0.030948041006923] nn.Sequential: [nn.Linear: 0.0061854175291955 nn.Linear: 0.03163368627429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062250976646021 nn.Linear: 0.062870758744256 nn.Linear: 0.044468359674614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372824823788 nn.Linear: 0.035739100913418] nn.Sequential: [nn.Linear: 0.031313722431504 nn.Linear: 0.026472219467527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.348035633564 nn.Linear: 0.19005064666271 nn.Linear: 0.11908148229122 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088062353432178 nn.Linear: 0.15237441658974] nn.Sequential: [nn.Linear: 0.080820582807064 nn.Linear: 0.13245905935764]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00084606941230977 nn.Linear: 0.00055357044861721 nn.Linear: 0.00031334300213629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2593462324486e-05 nn.Linear: 0.0011609080017791] nn.Sequential: [nn.Linear: 0.00011286687311689 nn.Linear: 0.0012729558639846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005752460565418 nn.Linear: 0.0090950829908252 nn.Linear: 0.0065454742871225 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051231714896858 nn.Linear: 0.0078647704795003] nn.Sequential: [nn.Linear: 0.0035199117846787 nn.Linear: 0.013149108737707]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062251127074134 nn.Linear: 0.062871410678201 nn.Linear: 0.044468950785277 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031372893129199 nn.Linear: 0.035760115721615] nn.Sequential: [nn.Linear: 0.031313722241637 nn.Linear: 0.026482483680658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34794786572456 nn.Linear: 0.18951228260994 nn.Linear: 0.11944559216499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0880396515131 nn.Linear: 0.15214629471302] nn.Sequential: [nn.Linear: 0.080690115690231 nn.Linear: 0.13288441300392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013074603944734 nn.Linear: 0.00084816558353176 nn.Linear: 0.00045330245458188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016011312415137 nn.Linear: 0.0025080825247104] nn.Sequential: [nn.Linear: 0.00015616663045042 nn.Linear: 0.0019436323896813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010547789745033 nn.Linear: 0.0089794937521219 nn.Linear: 0.010476376861334 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076100383885205 nn.Linear: 0.014782456681132] nn.Sequential: [nn.Linear: 0.0047771143727005 nn.Linear: 0.017876345664263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062250101778323 nn.Linear: 0.062873537020116 nn.Linear: 0.044469998250931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031373139601917 nn.Linear: 0.035788564143306] nn.Sequential: [nn.Linear: 0.031313870979775 nn.Linear: 0.026504644838939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34847837686539 nn.Linear: 0.18930958211422 nn.Linear: 0.1192512139678 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088346444070339 nn.Linear: 0.15222606062889] nn.Sequential: [nn.Linear: 0.0807104408741 nn.Linear: 0.13409040868282]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011229478914899 nn.Linear: 0.00067870420914529 nn.Linear: 0.00035251025003415 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014204631667932 nn.Linear: 0.0021373066991224] nn.Sequential: [nn.Linear: 8.4130300704689e-05 nn.Linear: 0.00082597989820557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072517381049693 nn.Linear: 0.011489252559841 nn.Linear: 0.0080129019916058 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068096145987511 nn.Linear: 0.014808787032962] nn.Sequential: [nn.Linear: 0.002594978781417 nn.Linear: 0.0074707181192935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062249166632865 nn.Linear: 0.062876553745753 nn.Linear: 0.044470742835986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031373430794296 nn.Linear: 0.035834665029512] nn.Sequential: [nn.Linear: 0.031313878371843 nn.Linear: 0.026522514895043]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34856784343719 nn.Linear: 0.18992525339127 nn.Linear: 0.11955543607473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088473275303841 nn.Linear: 0.152597874403] nn.Sequential: [nn.Linear: 0.080728456377983 nn.Linear: 0.13467760384083]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076789926114071 nn.Linear: 0.0004510530734567 nn.Linear: 0.00024208794342552 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8744783854489e-05 nn.Linear: 0.0013514842636193] nn.Sequential: [nn.Linear: 9.2399460543365e-05 nn.Linear: 0.0012451295866444]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073851025663316 nn.Linear: 0.010837897658348 nn.Linear: 0.0070899049751461 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052270465530455 nn.Linear: 0.01144424173981] nn.Sequential: [nn.Linear: 0.00332689168863 nn.Linear: 0.012240235693753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06224990511557 nn.Linear: 0.062879460375455 nn.Linear: 0.044472130170431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031373676471136 nn.Linear: 0.035861763142293] nn.Sequential: [nn.Linear: 0.031314061401819 nn.Linear: 0.026530717949438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34885397553444 nn.Linear: 0.19019649922848 nn.Linear: 0.11956685036421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088227413594723 nn.Linear: 0.1529113650322] nn.Sequential: [nn.Linear: 0.080667823553085 nn.Linear: 0.13458789885044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086742477699797 nn.Linear: 0.00055378719402228 nn.Linear: 0.00030420769321767 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013194926590872 nn.Linear: 0.0024428744275569] nn.Sequential: [nn.Linear: 8.9190134817064e-05 nn.Linear: 0.00095529033826933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060024801641703 nn.Linear: 0.0076481350697577 nn.Linear: 0.0058616581372917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044941203668714 nn.Linear: 0.013788104988635] nn.Sequential: [nn.Linear: 0.0026038666255772 nn.Linear: 0.0082517843693495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062252708088679 nn.Linear: 0.062884685532967 nn.Linear: 0.044473182827145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03137394115361 nn.Linear: 0.035884776676085] nn.Sequential: [nn.Linear: 0.031314392007446 nn.Linear: 0.02654710456836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34925240278244 nn.Linear: 0.18955284357071 nn.Linear: 0.11980111896992 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088708087801933 nn.Linear: 0.1524538397789] nn.Sequential: [nn.Linear: 0.080692760646343 nn.Linear: 0.13460578024387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00052491934925031 nn.Linear: 0.00035091895870149 nn.Linear: 0.00018625627677056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.8387684705672e-05 nn.Linear: 0.0011784614558136] nn.Sequential: [nn.Linear: 6.7647145196617e-05 nn.Linear: 0.00077588803403309]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0037851477973163 nn.Linear: 0.004825359210372 nn.Linear: 0.004182358738035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0032596874516457 nn.Linear: 0.0091587174683809] nn.Sequential: [nn.Linear: 0.0024282683152705 nn.Linear: 0.0078958226367831]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062254027726516 nn.Linear: 0.06288787003775 nn.Linear: 0.044474844629794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031374411707514 nn.Linear: 0.035990182796468] nn.Sequential: [nn.Linear: 0.031314389081324 nn.Linear: 0.026547974648869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34953516721725 nn.Linear: 0.18984568119049 nn.Linear: 0.1200712621212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088974878191948 nn.Linear: 0.15238353610039] nn.Sequential: [nn.Linear: 0.080604188144207 nn.Linear: 0.13435132801533]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001298796093156 nn.Linear: 0.00089791744387966 nn.Linear: 0.00046405867718031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014919911004628 nn.Linear: 0.0021811583197465] nn.Sequential: [nn.Linear: 0.00016914050785395 nn.Linear: 0.0017572617446526]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089531159028411 nn.Linear: 0.013461108319461 nn.Linear: 0.0082621267065406 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063720312900841 nn.Linear: 0.01146246585995] nn.Sequential: [nn.Linear: 0.006104547996074 nn.Linear: 0.020929507911205]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062250921409428 nn.Linear: 0.062888420922892 nn.Linear: 0.044475207268614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031374575042487 nn.Linear: 0.0360376405593] nn.Sequential: [nn.Linear: 0.031314447114689 nn.Linear: 0.026567202187612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34956860542297 nn.Linear: 0.18968875706196 nn.Linear: 0.11998909711838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088970579206944 nn.Linear: 0.15249861776829] nn.Sequential: [nn.Linear: 0.080398119986057 nn.Linear: 0.13447773456573]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011033074356599 nn.Linear: 0.00062530027996801 nn.Linear: 0.00040996676359418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015562494291497 nn.Linear: 0.0024171431245534] nn.Sequential: [nn.Linear: 0.00014238848456474 nn.Linear: 0.001586885240921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070661809295416 nn.Linear: 0.011847965419292 nn.Linear: 0.0089757675305009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075948401354253 nn.Linear: 0.016249436885118] nn.Sequential: [nn.Linear: 0.0046020727604628 nn.Linear: 0.017851373180747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10217625589669	TD error	0.020537622321397	Qmax	1	

Steps: 2750000 (frames: 11000000), score: 2013.28, higheset score: 6956, epsilon: 0.05, lr: 0.0005, training time: 560s, training rate: 1783fps, testing time: 90s, testing rate: 5551fps,  num. ep.: 282,  num. rewards: 16413	
   4   16    4    2
   2    4   16   32
   8   16   64  256
   4  128  512    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062256843892805 nn.Linear: 0.06289459850839 nn.Linear: 0.044476443588482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031374750741536 nn.Linear: 0.036069805278999] nn.Sequential: [nn.Linear: 0.03131472890148 nn.Linear: 0.026582590486697]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3498267531395 nn.Linear: 0.18951873481274 nn.Linear: 0.11999426037073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089192755520344 nn.Linear: 0.15245245397091] nn.Sequential: [nn.Linear: 0.080578379333019 nn.Linear: 0.13464833796024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0008405724923975 nn.Linear: 0.00046527807411844 nn.Linear: 0.00023861204119702 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4891213582965e-05 nn.Linear: 0.0017175662381939] nn.Sequential: [nn.Linear: 5.6065352684227e-05 nn.Linear: 0.00058339007584875]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057777222245932 nn.Linear: 0.0068188300356269 nn.Linear: 0.0046913446858525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047493218444288 nn.Linear: 0.011951187625527] nn.Sequential: [nn.Linear: 0.0016195334028453 nn.Linear: 0.0054204850457609]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062257103892146 nn.Linear: 0.062896076155743 nn.Linear: 0.04447694586627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031374768358784 nn.Linear: 0.036073814749926] nn.Sequential: [nn.Linear: 0.031314750954469 nn.Linear: 0.026591844673893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34981760382652 nn.Linear: 0.18931441009045 nn.Linear: 0.12021673470736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089005194604397 nn.Linear: 0.15206786990166] nn.Sequential: [nn.Linear: 0.080772012472153 nn.Linear: 0.13474069535732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089582935486104 nn.Linear: 0.00056140671101217 nn.Linear: 0.00025275980187099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8603495741268e-05 nn.Linear: 0.0014690501046196] nn.Sequential: [nn.Linear: 9.3607170884682e-05 nn.Linear: 0.0012076366391053]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058018625713885 nn.Linear: 0.0085467807948589 nn.Linear: 0.0051167076453567 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043235891498625 nn.Linear: 0.0092869028449059] nn.Sequential: [nn.Linear: 0.0025483577046543 nn.Linear: 0.011799974367023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06225993383474 nn.Linear: 0.062901471946574 nn.Linear: 0.044478608745379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031375088367282 nn.Linear: 0.036101822254224] nn.Sequential: [nn.Linear: 0.031315053472448 nn.Linear: 0.026612088184001]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35017424821854 nn.Linear: 0.1895205527544 nn.Linear: 0.11998084932566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088712185621262 nn.Linear: 0.1523439437151] nn.Sequential: [nn.Linear: 0.080626130104065 nn.Linear: 0.1349423378706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00070063378820343 nn.Linear: 0.00046699349780584 nn.Linear: 0.00026453904738576 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.058949270946e-05 nn.Linear: 0.0018975050632704] nn.Sequential: [nn.Linear: 0.00010726794362015 nn.Linear: 0.0012856296443065]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062793409451842 nn.Linear: 0.0077622127719223 nn.Linear: 0.005161929409951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003702265676111 nn.Linear: 0.0093845380470157] nn.Sequential: [nn.Linear: 0.0040308241732419 nn.Linear: 0.0096822893247008]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06225458739198 nn.Linear: 0.062904225968384 nn.Linear: 0.044478963533922 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031375311958217 nn.Linear: 0.036137708261279] nn.Sequential: [nn.Linear: 0.031315059400652 nn.Linear: 0.026620438736972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34933888912201 nn.Linear: 0.18936210870743 nn.Linear: 0.11995306611061 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088775753974915 nn.Linear: 0.15311473608017] nn.Sequential: [nn.Linear: 0.080563448369503 nn.Linear: 0.13537676632404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069342303463569 nn.Linear: 0.00046496369344198 nn.Linear: 0.00024319688601422 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.1334418184604e-05 nn.Linear: 0.0016394278795124] nn.Sequential: [nn.Linear: 7.5492556034239e-05 nn.Linear: 0.00074739058665841]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058041280135512 nn.Linear: 0.0071466895751655 nn.Linear: 0.0057146842591465 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049893539398909 nn.Linear: 0.0090853562578559] nn.Sequential: [nn.Linear: 0.0020295255817473 nn.Linear: 0.007246870547533]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062260605010483 nn.Linear: 0.062906018222623 nn.Linear: 0.044481124629046 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031375576758888 nn.Linear: 0.036174150003063] nn.Sequential: [nn.Linear: 0.031315157172651 nn.Linear: 0.026640398787296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.34963050484657 nn.Linear: 0.18959400057793 nn.Linear: 0.11968571692705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088744327425957 nn.Linear: 0.15310350060463] nn.Sequential: [nn.Linear: 0.080384343862534 nn.Linear: 0.1350415199995]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010734435004019 nn.Linear: 0.00057149542954078 nn.Linear: 0.00029044643596826 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.4709158002652e-05 nn.Linear: 0.001112880072049] nn.Sequential: [nn.Linear: 8.5714765831684e-05 nn.Linear: 0.00082585151562344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091267814859748 nn.Linear: 0.0098504414781928 nn.Linear: 0.0053462493233383 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057086446322501 nn.Linear: 0.0087563740089536] nn.Sequential: [nn.Linear: 0.0022471901029348 nn.Linear: 0.0081769144162536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062263886928558 nn.Linear: 0.062911025731493 nn.Linear: 0.044483248539629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031375792605612 nn.Linear: 0.036205439169095] nn.Sequential: [nn.Linear: 0.031315459360836 nn.Linear: 0.026652094813838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35018128156662 nn.Linear: 0.18888552486897 nn.Linear: 0.11990017443895 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08894719928503 nn.Linear: 0.15320231020451] nn.Sequential: [nn.Linear: 0.080489367246628 nn.Linear: 0.13523803651333]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020988252430474 nn.Linear: 0.0013854677055496 nn.Linear: 0.00079533507705224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026866723913989 nn.Linear: 0.0047019489117065] nn.Sequential: [nn.Linear: 0.00026712066261419 nn.Linear: 0.003457459323989]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01321273483336 nn.Linear: 0.023114020004869 nn.Linear: 0.015790386125445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014548229984939 nn.Linear: 0.035527437925339] nn.Sequential: [nn.Linear: 0.0098952641710639 nn.Linear: 0.039133943617344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062265426320883 nn.Linear: 0.062914011507278 nn.Linear: 0.044484341445701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031376112923908 nn.Linear: 0.03625805370865] nn.Sequential: [nn.Linear: 0.031315632192845 nn.Linear: 0.026668451622976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35010957717896 nn.Linear: 0.18908041715622 nn.Linear: 0.1196127384901 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.088727131485939 nn.Linear: 0.15373232960701] nn.Sequential: [nn.Linear: 0.080694034695625 nn.Linear: 0.13595789670944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094268853982116 nn.Linear: 0.0006185630618133 nn.Linear: 0.00032062881602327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012035933175159 nn.Linear: 0.0018308928805829] nn.Sequential: [nn.Linear: 0.00010134191608616 nn.Linear: 0.0011991792357583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067673996090889 nn.Linear: 0.012186513282359 nn.Linear: 0.0071587688289583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073729739524424 nn.Linear: 0.011417045257986] nn.Sequential: [nn.Linear: 0.0041636154055595 nn.Linear: 0.013945485465229]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062267303143835 nn.Linear: 0.062916049296752 nn.Linear: 0.04448529175539 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031376411174166 nn.Linear: 0.036327739316732] nn.Sequential: [nn.Linear: 0.031315787052164 nn.Linear: 0.026691600974861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35017612576485 nn.Linear: 0.18933269381523 nn.Linear: 0.11974640935659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089027896523476 nn.Linear: 0.15428452193737] nn.Sequential: [nn.Linear: 0.08074127882719 nn.Linear: 0.13619668781757]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011389021481878 nn.Linear: 0.00084167803611287 nn.Linear: 0.00051559641969381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026828780698363 nn.Linear: 0.0057369041542192] nn.Sequential: [nn.Linear: 0.00013778137107724 nn.Linear: 0.0016195562571821]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095097534358501 nn.Linear: 0.01659550704062 nn.Linear: 0.009517447091639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068540377542377 nn.Linear: 0.030488470569253] nn.Sequential: [nn.Linear: 0.0027674166485667 nn.Linear: 0.01521934568882]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062266628313594 nn.Linear: 0.062920375136839 nn.Linear: 0.044486350780879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031376613830616 nn.Linear: 0.036351988492896] nn.Sequential: [nn.Linear: 0.031316110223636 nn.Linear: 0.026709372251346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35074791312218 nn.Linear: 0.18939465284348 nn.Linear: 0.11935759335756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089447014033794 nn.Linear: 0.1545320302248] nn.Sequential: [nn.Linear: 0.080747053027153 nn.Linear: 0.13690547645092]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025275797123032 nn.Linear: 0.0019155295181997 nn.Linear: 0.00095535788897022 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00044487361774733 nn.Linear: 0.0092296455699537] nn.Sequential: [nn.Linear: 0.00020250259501845 nn.Linear: 0.0022813225264297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027069007977843 nn.Linear: 0.025048403069377 nn.Linear: 0.022390104830265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017378125339746 nn.Linear: 0.051011711359024] nn.Sequential: [nn.Linear: 0.0067246910184622 nn.Linear: 0.018079895526171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062272237474263 nn.Linear: 0.06292324620401 nn.Linear: 0.044487987013649 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031376986107207 nn.Linear: 0.036429311148453] nn.Sequential: [nn.Linear: 0.031316300249727 nn.Linear: 0.026722022063029]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35060867667198 nn.Linear: 0.18961784243584 nn.Linear: 0.11951440572739 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089472621679306 nn.Linear: 0.15464754402637] nn.Sequential: [nn.Linear: 0.080807760357857 nn.Linear: 0.13711722195148]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00075983153265721 nn.Linear: 0.00054579155081976 nn.Linear: 0.00030933383446837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.2373893769566e-05 nn.Linear: 0.00094206314116096] nn.Sequential: [nn.Linear: 0.00014193411028621 nn.Linear: 0.0015672970504665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063890838064253 nn.Linear: 0.009741235524416 nn.Linear: 0.0057977647520602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033033343497664 nn.Linear: 0.0060841832309961] nn.Sequential: [nn.Linear: 0.0039879041723907 nn.Linear: 0.015058767050505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062276709465525 nn.Linear: 0.062926744709417 nn.Linear: 0.044488496303546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031377213569099 nn.Linear: 0.036470528117007] nn.Sequential: [nn.Linear: 0.03131629922692 nn.Linear: 0.026728697374658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35054108500481 nn.Linear: 0.18937148153782 nn.Linear: 0.11944803595543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089492231607437 nn.Linear: 0.15523542463779] nn.Sequential: [nn.Linear: 0.080817855894566 nn.Linear: 0.13684150576591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017606843213257 nn.Linear: 0.00087976122087332 nn.Linear: 0.00043956801241095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014414865101797 nn.Linear: 0.0024239839225031] nn.Sequential: [nn.Linear: 0.00014437971246467 nn.Linear: 0.0017261421356678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011467660777271 nn.Linear: 0.01388225145638 nn.Linear: 0.010440917685628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063929464668036 nn.Linear: 0.014767350628972] nn.Sequential: [nn.Linear: 0.0039942967705429 nn.Linear: 0.017305977642536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062273827264947 nn.Linear: 0.062931712372164 nn.Linear: 0.044489927744963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031377381837631 nn.Linear: 0.036481901213989] nn.Sequential: [nn.Linear: 0.031316665619014 nn.Linear: 0.026740539738244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35078603029251 nn.Linear: 0.18903337419033 nn.Linear: 0.11975910514593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089533381164074 nn.Linear: 0.15558780729771] nn.Sequential: [nn.Linear: 0.081088647246361 nn.Linear: 0.13699553906918]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009786668397706 nn.Linear: 0.00060407225753923 nn.Linear: 0.00036785454331466 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015730887382174 nn.Linear: 0.0032007762202324] nn.Sequential: [nn.Linear: 0.00010931881111503 nn.Linear: 0.0012575888071212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077416771091521 nn.Linear: 0.0082497205585241 nn.Linear: 0.0069817816838622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057712313719094 nn.Linear: 0.019015990197659] nn.Sequential: [nn.Linear: 0.0030732597224414 nn.Linear: 0.0080218650400639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	2880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062275411052065 nn.Linear: 0.062935826697014 nn.Linear: 0.044491148002075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031377825319425 nn.Linear: 0.036586204785333] nn.Sequential: [nn.Linear: 0.031316860724658 nn.Linear: 0.026756850089493]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35171985626221 nn.Linear: 0.18972244858742 nn.Linear: 0.11998888105154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089465700089931 nn.Linear: 0.15644936263561] nn.Sequential: [nn.Linear: 0.081059813499451 nn.Linear: 0.1371802687645]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016863953314724 nn.Linear: 0.0010533514681888 nn.Linear: 0.0005398157681251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022778079814032 nn.Linear: 0.0042729150990128] nn.Sequential: [nn.Linear: 0.00014670498322594 nn.Linear: 0.0015827767041797]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082681328058243 nn.Linear: 0.013685057871044 nn.Linear: 0.011280904524028 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088279563933611 nn.Linear: 0.028239542618394] nn.Sequential: [nn.Linear: 0.0046391813084483 nn.Linear: 0.017784584313631]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062271967640156 nn.Linear: 0.062940431814896 nn.Linear: 0.044492531299515 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031377906526396 nn.Linear: 0.036575709846957] nn.Sequential: [nn.Linear: 0.031317018108713 nn.Linear: 0.026764968145769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35208877921104 nn.Linear: 0.18890486657619 nn.Linear: 0.11979424953461 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.08939415961504 nn.Linear: 0.15663804113865] nn.Sequential: [nn.Linear: 0.080974973738194 nn.Linear: 0.13711799681187]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019043766305475 nn.Linear: 0.0011594293523753 nn.Linear: 0.00057554154484301 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025115017496707 nn.Linear: 0.0051314386956918] nn.Sequential: [nn.Linear: 0.00015067212637651 nn.Linear: 0.0019246322251502]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024043278768659 nn.Linear: 0.025266971439123 nn.Linear: 0.015987059101462 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012352291494608 nn.Linear: 0.032945837825537] nn.Sequential: [nn.Linear: 0.0071344040334225 nn.Linear: 0.024865947663784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062272730898684 nn.Linear: 0.062941619725033 nn.Linear: 0.044492850236075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031378255224853 nn.Linear: 0.03664209927669] nn.Sequential: [nn.Linear: 0.031317105193208 nn.Linear: 0.026786221019851]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35255336761475 nn.Linear: 0.18965566158295 nn.Linear: 0.12017649412155 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089517675340176 nn.Linear: 0.1564494073391] nn.Sequential: [nn.Linear: 0.080892659723759 nn.Linear: 0.13723184168339]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00087704002243851 nn.Linear: 0.00065013228769827 nn.Linear: 0.00033879538221849 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013888019946208 nn.Linear: 0.002760182191121] nn.Sequential: [nn.Linear: 8.2144124330357e-05 nn.Linear: 0.00079334893481036]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058766617439687 nn.Linear: 0.011795772239566 nn.Linear: 0.0054178521968424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047468789853156 nn.Linear: 0.015833109617233] nn.Sequential: [nn.Linear: 0.002818456152454 nn.Linear: 0.0076539623551071]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062275670507635 nn.Linear: 0.062943816400157 nn.Linear: 0.044494114569537 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031378190725182 nn.Linear: 0.036633704979103] nn.Sequential: [nn.Linear: 0.031317541740138 nn.Linear: 0.026793418007223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35331478714943 nn.Linear: 0.18930009007454 nn.Linear: 0.1197924092412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089422486722469 nn.Linear: 0.15612091124058] nn.Sequential: [nn.Linear: 0.081081077456474 nn.Linear: 0.13707354664803]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020931280760947 nn.Linear: 0.0012309526485175 nn.Linear: 0.00055204216430095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020712561250472 nn.Linear: 0.0030422875841034] nn.Sequential: [nn.Linear: 0.00019019348581675 nn.Linear: 0.0018794652072647]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019149642437696 nn.Linear: 0.019268527626991 nn.Linear: 0.012495502829552 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012476939707994 nn.Linear: 0.021586373448372] nn.Sequential: [nn.Linear: 0.0075839539058506 nn.Linear: 0.019292311742902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062275897493773 nn.Linear: 0.062947670980342 nn.Linear: 0.044495329796412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031378468593858 nn.Linear: 0.036687802706808] nn.Sequential: [nn.Linear: 0.031317643671255 nn.Linear: 0.026809149952046]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35352271795273 nn.Linear: 0.18837305903435 nn.Linear: 0.12011142075062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089719370007515 nn.Linear: 0.15662851929665] nn.Sequential: [nn.Linear: 0.081053607165813 nn.Linear: 0.13713385164738]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092381699409954 nn.Linear: 0.00065823761797424 nn.Linear: 0.00031763376491356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012537939163258 nn.Linear: 0.0020832886389677] nn.Sequential: [nn.Linear: 6.910807392433e-05 nn.Linear: 0.00058970127853101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006352317519486 nn.Linear: 0.0091734612360597 nn.Linear: 0.0070773074403405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00829510204494 nn.Linear: 0.013930212706327] nn.Sequential: [nn.Linear: 0.0028894050046802 nn.Linear: 0.0055390479974449]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062275311330334 nn.Linear: 0.062947822854159 nn.Linear: 0.0444960064129 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031378855411479 nn.Linear: 0.036741494472299] nn.Sequential: [nn.Linear: 0.031317702369605 nn.Linear: 0.026826588837002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35394394397736 nn.Linear: 0.18880224227905 nn.Linear: 0.120261952281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089595437049866 nn.Linear: 0.1568069010973] nn.Sequential: [nn.Linear: 0.081054344773293 nn.Linear: 0.13786092400551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088727346817002 nn.Linear: 0.0005366972452992 nn.Linear: 0.00029720173848176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011285975298876 nn.Linear: 0.0018268417864467] nn.Sequential: [nn.Linear: 0.00010885651901102 nn.Linear: 0.0011870270989899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007436650339514 nn.Linear: 0.0095252860337496 nn.Linear: 0.0053630680777133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056250048801303 nn.Linear: 0.012364177033305] nn.Sequential: [nn.Linear: 0.0032241221051663 nn.Linear: 0.015320685692132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062270575878801 nn.Linear: 0.062950912298994 nn.Linear: 0.044496812642016 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031378988674561 nn.Linear: 0.036763084365276] nn.Sequential: [nn.Linear: 0.031317864112494 nn.Linear: 0.026840071579277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35440021753311 nn.Linear: 0.18954040110111 nn.Linear: 0.12029999494553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089632347226143 nn.Linear: 0.15693648159504] nn.Sequential: [nn.Linear: 0.081056453287601 nn.Linear: 0.1380784958601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015265007711288 nn.Linear: 0.0011025477831886 nn.Linear: 0.00054880124843583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022468313264294 nn.Linear: 0.0042823557575564] nn.Sequential: [nn.Linear: 0.0001625337582351 nn.Linear: 0.0018001338396719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010747428052127 nn.Linear: 0.014918675646186 nn.Linear: 0.014538820832968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014184230938554 nn.Linear: 0.02732521109283] nn.Sequential: [nn.Linear: 0.009165033698082 nn.Linear: 0.024719590321183]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062271926415089 nn.Linear: 0.062955613753147 nn.Linear: 0.044498690826182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03137917141483 nn.Linear: 0.036778948701397] nn.Sequential: [nn.Linear: 0.031318123510274 nn.Linear: 0.02685080719371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35469624400139 nn.Linear: 0.18928813934326 nn.Linear: 0.11992205679417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089674808084965 nn.Linear: 0.15728183090687] nn.Sequential: [nn.Linear: 0.081088900566101 nn.Linear: 0.13801831007004]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092331465823083 nn.Linear: 0.00056894639542361 nn.Linear: 0.0002851870490125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010001669765651 nn.Linear: 0.0013806920087808] nn.Sequential: [nn.Linear: 8.6105173736579e-05 nn.Linear: 0.00077117495613885]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062440098263323 nn.Linear: 0.0067979828454554 nn.Linear: 0.0059336377307773 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040362309664488 nn.Linear: 0.007784640416503] nn.Sequential: [nn.Linear: 0.0031205122359097 nn.Linear: 0.00651242909953]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062275413533322 nn.Linear: 0.062961267210876 nn.Linear: 0.044500685917658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031379484242155 nn.Linear: 0.036825618598471] nn.Sequential: [nn.Linear: 0.031318459644567 nn.Linear: 0.026872130919358]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35506975650787 nn.Linear: 0.18857216835022 nn.Linear: 0.1201037093997 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089690402150154 nn.Linear: 0.15718285739422] nn.Sequential: [nn.Linear: 0.081053681671619 nn.Linear: 0.13801616430283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069812736908959 nn.Linear: 0.00043030513344058 nn.Linear: 0.00022488876200812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.5316068094833e-05 nn.Linear: 0.0010020640545135] nn.Sequential: [nn.Linear: 6.6397753008302e-05 nn.Linear: 0.00073661044585141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073315245099366 nn.Linear: 0.009040430188179 nn.Linear: 0.0047313529066741 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040653706528246 nn.Linear: 0.0067210216075182] nn.Sequential: [nn.Linear: 0.0021963196340948 nn.Linear: 0.0082794232293963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062276131124992 nn.Linear: 0.062963454441452 nn.Linear: 0.044502447935593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031379918437266 nn.Linear: 0.036890885046546] nn.Sequential: [nn.Linear: 0.031318847813458 nn.Linear: 0.026904540257867]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35563537478447 nn.Linear: 0.18870778381824 nn.Linear: 0.11996208131313 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089522562921047 nn.Linear: 0.15672646462917] nn.Sequential: [nn.Linear: 0.081049904227257 nn.Linear: 0.138438180089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015640169103842 nn.Linear: 0.00092279418602348 nn.Linear: 0.00046976573029591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017335117553512 nn.Linear: 0.0025431958757522] nn.Sequential: [nn.Linear: 0.00016100180367913 nn.Linear: 0.0016740582108332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012604377232492 nn.Linear: 0.013849724084139 nn.Linear: 0.010075721889734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052717220969498 nn.Linear: 0.0160016361624] nn.Sequential: [nn.Linear: 0.0039565665647388 nn.Linear: 0.013451801612973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062283251196406 nn.Linear: 0.062969791401255 nn.Linear: 0.044504044928683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031380104221127 nn.Linear: 0.036905230055993] nn.Sequential: [nn.Linear: 0.031319053612962 nn.Linear: 0.026912781682271]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35612267255783 nn.Linear: 0.18888413906097 nn.Linear: 0.12001071870327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089291855692863 nn.Linear: 0.15754237771034] nn.Sequential: [nn.Linear: 0.081124894320965 nn.Linear: 0.1386952996254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001253864556743 nn.Linear: 0.00077371695456168 nn.Linear: 0.00038246940660823 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013783049061069 nn.Linear: 0.0026036615289965] nn.Sequential: [nn.Linear: 0.00010250334753558 nn.Linear: 0.0010195360623839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089774243533611 nn.Linear: 0.015279141254723 nn.Linear: 0.0086156213656068 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059097167104483 nn.Linear: 0.014848358929157] nn.Sequential: [nn.Linear: 0.0025057229213417 nn.Linear: 0.0076585575006902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	2990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062282553063553 nn.Linear: 0.062973539214492 nn.Linear: 0.044505798380029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031380441962103 nn.Linear: 0.036949391240867] nn.Sequential: [nn.Linear: 0.031319259901159 nn.Linear: 0.026939467327454]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35627460479736 nn.Linear: 0.18853731453419 nn.Linear: 0.12030097842216 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089607939124107 nn.Linear: 0.1577884554863] nn.Sequential: [nn.Linear: 0.081182964146137 nn.Linear: 0.13922622799873]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015468858217961 nn.Linear: 0.0010677802788105 nn.Linear: 0.00053915690100296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024343081734392 nn.Linear: 0.0048136597189992] nn.Sequential: [nn.Linear: 0.00010961374081245 nn.Linear: 0.00097414852581409]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011121460236609 nn.Linear: 0.017063276842237 nn.Linear: 0.012351050972939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012214119546115 nn.Linear: 0.026996726170182] nn.Sequential: [nn.Linear: 0.0038302331231534 nn.Linear: 0.0090518807992339]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062284976149096 nn.Linear: 0.062977128838279 nn.Linear: 0.044506582630194 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03138054920257 nn.Linear: 0.036977841936562] nn.Sequential: [nn.Linear: 0.031319657682158 nn.Linear: 0.026966772288826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35658115148544 nn.Linear: 0.18914301693439 nn.Linear: 0.12027858942747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089805610477924 nn.Linear: 0.15806156396866] nn.Sequential: [nn.Linear: 0.081154935061932 nn.Linear: 0.13925938308239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0005503635487778 nn.Linear: 0.0004048437483347 nn.Linear: 0.00022841605415712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010434044925231 nn.Linear: 0.0018266988415456] nn.Sequential: [nn.Linear: 8.7331609685609e-05 nn.Linear: 0.0011059576136292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.003991125151515 nn.Linear: 0.0052469316869974 nn.Linear: 0.0040783677250147 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0028509981930256 nn.Linear: 0.010937303304672] nn.Sequential: [nn.Linear: 0.0027314755134284 nn.Linear: 0.010513050481677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10511243332922	TD error	0.021146682500839	Qmax	1	

Steps: 3000000 (frames: 12000000), score: 1847.37, higheset score: 6152, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1812fps, testing time: 90s, testing rate: 5545fps,  num. ep.: 428,  num. rewards: 19855	
   2   16    8    2
   4   32   16    4
   8    2   32  256
  16   32    2  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062288373411533 nn.Linear: 0.062981450333055 nn.Linear: 0.044508117321705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031380640892649 nn.Linear: 0.036986031639287] nn.Sequential: [nn.Linear: 0.031320043419744 nn.Linear: 0.02699130627091]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35556054115295 nn.Linear: 0.18838502466679 nn.Linear: 0.12046083062887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089617595076561 nn.Linear: 0.15791802108288] nn.Sequential: [nn.Linear: 0.081250876188278 nn.Linear: 0.13955107331276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023624344071122 nn.Linear: 0.0013724491930358 nn.Linear: 0.00058511298849785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002958696395813 nn.Linear: 0.0052169461418456] nn.Sequential: [nn.Linear: 0.00019331550016748 nn.Linear: 0.0024161801956138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017465809360147 nn.Linear: 0.024742064997554 nn.Linear: 0.01871338672936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011055008508265 nn.Linear: 0.036190360784531] nn.Sequential: [nn.Linear: 0.0056930044665933 nn.Linear: 0.028097946196795]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062289998332424 nn.Linear: 0.062987100816623 nn.Linear: 0.044509211737373 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031381030305051 nn.Linear: 0.037061899797891] nn.Sequential: [nn.Linear: 0.031320143383275 nn.Linear: 0.027007852901022]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35654717683792 nn.Linear: 0.18884719908237 nn.Linear: 0.12028682976961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.089985206723213 nn.Linear: 0.15820541977882] nn.Sequential: [nn.Linear: 0.081146366894245 nn.Linear: 0.13986577093601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097398058759621 nn.Linear: 0.00050567490466469 nn.Linear: 0.00026283156806701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2745137287165e-05 nn.Linear: 0.0015719166255463] nn.Sequential: [nn.Linear: 0.00011669478022475 nn.Linear: 0.0015207902634692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073937582783401 nn.Linear: 0.0087830517441034 nn.Linear: 0.0065881395712495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048475186340511 nn.Linear: 0.01264507137239] nn.Sequential: [nn.Linear: 0.0033984780311584 nn.Linear: 0.015495836734772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062295421882361 nn.Linear: 0.062993396810451 nn.Linear: 0.044511147905861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031381391287351 nn.Linear: 0.037125395985925] nn.Sequential: [nn.Linear: 0.031320475206525 nn.Linear: 0.027023034466124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35758844017982 nn.Linear: 0.18953169882298 nn.Linear: 0.1206047013402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090119428932667 nn.Linear: 0.15813033282757] nn.Sequential: [nn.Linear: 0.081551656126976 nn.Linear: 0.14017552137375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011245090914314 nn.Linear: 0.00071966524543515 nn.Linear: 0.00037249399598207 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015842023954758 nn.Linear: 0.0024121759669589] nn.Sequential: [nn.Linear: 0.00010354980140573 nn.Linear: 0.0010108312463385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094020301476121 nn.Linear: 0.010253238491714 nn.Linear: 0.0085265394300222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053491815924644 nn.Linear: 0.014754937030375] nn.Sequential: [nn.Linear: 0.0027595167048275 nn.Linear: 0.011549233458936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062296367301431 nn.Linear: 0.062998150188084 nn.Linear: 0.044512834411203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031381796170312 nn.Linear: 0.037205689834565] nn.Sequential: [nn.Linear: 0.031320728791691 nn.Linear: 0.027055096039076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35759061574936 nn.Linear: 0.18912950158119 nn.Linear: 0.12037160247564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09001862257719 nn.Linear: 0.15821817517281] nn.Sequential: [nn.Linear: 0.081190280616283 nn.Linear: 0.1405261605978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0040401266757455 nn.Linear: 0.0019842141749163 nn.Linear: 0.00083873043795436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029252501452631 nn.Linear: 0.0048397533303364] nn.Sequential: [nn.Linear: 0.00018928129413896 nn.Linear: 0.0019848656818078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021718122065067 nn.Linear: 0.04194900393486 nn.Linear: 0.021832939237356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017211498692632 nn.Linear: 0.034530695527792] nn.Sequential: [nn.Linear: 0.0094223693013191 nn.Linear: 0.02220007032156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062296416622959 nn.Linear: 0.063002623375476 nn.Linear: 0.044513929372197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031382031279549 nn.Linear: 0.037255883270177] nn.Sequential: [nn.Linear: 0.031320714800607 nn.Linear: 0.02706075137337]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35687416791916 nn.Linear: 0.1894720941782 nn.Linear: 0.12009457498789 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090140640735626 nn.Linear: 0.15866996347904] nn.Sequential: [nn.Linear: 0.081222355365753 nn.Linear: 0.14061614871025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069217613454164 nn.Linear: 0.00040366051478305 nn.Linear: 0.00023051468463138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.5888863657275e-05 nn.Linear: 0.0013328291820711] nn.Sequential: [nn.Linear: 7.8410392290281e-05 nn.Linear: 0.00076682639499046]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054191607050598 nn.Linear: 0.0062826634384692 nn.Linear: 0.0047790012322366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047272448427975 nn.Linear: 0.0088896416127682] nn.Sequential: [nn.Linear: 0.0025990214198828 nn.Linear: 0.0088286390528083]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062299853938905 nn.Linear: 0.063006259972228 nn.Linear: 0.044515783695305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031382492289551 nn.Linear: 0.037289122582763] nn.Sequential: [nn.Linear: 0.031320858364296 nn.Linear: 0.027072289094173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35758954286575 nn.Linear: 0.18895646929741 nn.Linear: 0.12013450264931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090028062462807 nn.Linear: 0.15845170617104] nn.Sequential: [nn.Linear: 0.081507407128811 nn.Linear: 0.14118525385857]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00087250378730199 nn.Linear: 0.00050149580533551 nn.Linear: 0.00025204826682856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010438014937938 nn.Linear: 0.0018618189184929] nn.Sequential: [nn.Linear: 7.9761366875128e-05 nn.Linear: 0.0007952662124239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053549776785076 nn.Linear: 0.0068024792708457 nn.Linear: 0.0040173213928938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040847957134247 nn.Linear: 0.012440893799067] nn.Sequential: [nn.Linear: 0.0019622568506747 nn.Linear: 0.0054858736693859]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062299317184743 nn.Linear: 0.06300734639608 nn.Linear: 0.044516245694888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031382575885796 nn.Linear: 0.037289369652171] nn.Sequential: [nn.Linear: 0.031321026197379 nn.Linear: 0.027084897054073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35837098956108 nn.Linear: 0.1883819103241 nn.Linear: 0.12022049725056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090039327740669 nn.Linear: 0.15813264250755] nn.Sequential: [nn.Linear: 0.081519410014153 nn.Linear: 0.14100326597691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011310400580306 nn.Linear: 0.00068272654799243 nn.Linear: 0.00033949528714985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012610475068192 nn.Linear: 0.0018543415139654] nn.Sequential: [nn.Linear: 9.9597454747565e-05 nn.Linear: 0.0010565750359921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089186802506447 nn.Linear: 0.0096643939614296 nn.Linear: 0.0069200084544718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049108890816569 nn.Linear: 0.011018365621567] nn.Sequential: [nn.Linear: 0.0025638798251748 nn.Linear: 0.0099505642428994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062294472499676 nn.Linear: 0.063006484442084 nn.Linear: 0.044515541983589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031382422919211 nn.Linear: 0.037268395584761] nn.Sequential: [nn.Linear: 0.031321095286548 nn.Linear: 0.027094973516423]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35813257098198 nn.Linear: 0.18891623616219 nn.Linear: 0.11998251825571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090002551674843 nn.Linear: 0.15829338133335] nn.Sequential: [nn.Linear: 0.081640750169754 nn.Linear: 0.14144226908684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090445044473024 nn.Linear: 0.0005895570396579 nn.Linear: 0.00029849512340208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6680869181553e-05 nn.Linear: 0.0016620684769701] nn.Sequential: [nn.Linear: 0.00010326121241992 nn.Linear: 0.0010286257739695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00769830821082 nn.Linear: 0.0097566386684775 nn.Linear: 0.0050038299523294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038341744802892 nn.Linear: 0.00945960637182] nn.Sequential: [nn.Linear: 0.0028201069217175 nn.Linear: 0.010126029141247]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062298474080198 nn.Linear: 0.063011928352633 nn.Linear: 0.044517083648793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031382768122755 nn.Linear: 0.037292995171697] nn.Sequential: [nn.Linear: 0.031321420380671 nn.Linear: 0.027111721460283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35823899507523 nn.Linear: 0.18915192782879 nn.Linear: 0.11992172896862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090121120214462 nn.Linear: 0.1581571996212] nn.Sequential: [nn.Linear: 0.081687398254871 nn.Linear: 0.14139872789383]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098841667044627 nn.Linear: 0.00059128779509788 nn.Linear: 0.00029339033000073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8541297612494e-05 nn.Linear: 0.0015722661664572] nn.Sequential: [nn.Linear: 9.3119307982044e-05 nn.Linear: 0.0009751642897014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056348699145019 nn.Linear: 0.0091491024941206 nn.Linear: 0.0060394732281566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047577703371644 nn.Linear: 0.010913039557636] nn.Sequential: [nn.Linear: 0.0023755836300552 nn.Linear: 0.0084752701222897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062294532178284 nn.Linear: 0.063013629528104 nn.Linear: 0.044518273581134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031383140272663 nn.Linear: 0.037355484453201] nn.Sequential: [nn.Linear: 0.031321502750114 nn.Linear: 0.02712255973419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35805052518845 nn.Linear: 0.18901780247688 nn.Linear: 0.11994048207998 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090274691581726 nn.Linear: 0.15840068459511] nn.Sequential: [nn.Linear: 0.081530563533306 nn.Linear: 0.14161850512028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011755525328697 nn.Linear: 0.00087154964257507 nn.Linear: 0.00045376647431588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018020620558155 nn.Linear: 0.0036967453761789] nn.Sequential: [nn.Linear: 0.00014818608976063 nn.Linear: 0.0018448582834112]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010107981972396 nn.Linear: 0.016632489860058 nn.Linear: 0.010019010864198 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083970762789249 nn.Linear: 0.022682970389724] nn.Sequential: [nn.Linear: 0.0049491683021188 nn.Linear: 0.015292044728994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062299484951901 nn.Linear: 0.063020385046266 nn.Linear: 0.044520100685941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031383222233117 nn.Linear: 0.037365073926367] nn.Sequential: [nn.Linear: 0.031322001260998 nn.Linear: 0.027139762613176]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35851579904556 nn.Linear: 0.18888719379902 nn.Linear: 0.11979751288891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090317636728287 nn.Linear: 0.15833546221256] nn.Sequential: [nn.Linear: 0.08154135197401 nn.Linear: 0.14136345684528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010789815317553 nn.Linear: 0.00072984641527309 nn.Linear: 0.00038247679922278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013762320660828 nn.Linear: 0.002123326183026] nn.Sequential: [nn.Linear: 0.00012456714476806 nn.Linear: 0.0012584277313044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088774226605892 nn.Linear: 0.009511424228549 nn.Linear: 0.0066969124600291 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050138193182647 nn.Linear: 0.012755167670548] nn.Sequential: [nn.Linear: 0.0034716802183539 nn.Linear: 0.009697045199573]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062290630573536 nn.Linear: 0.063022469301299 nn.Linear: 0.044521254866662 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031383923248571 nn.Linear: 0.037495804048689] nn.Sequential: [nn.Linear: 0.031321912502935 nn.Linear: 0.027151234101558]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35911297798157 nn.Linear: 0.18920509517193 nn.Linear: 0.11988485604525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090682610869408 nn.Linear: 0.15876124799252] nn.Sequential: [nn.Linear: 0.081649407744408 nn.Linear: 0.14169204235077]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013567165070346 nn.Linear: 0.00082833781793671 nn.Linear: 0.00039989598856862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015182200079575 nn.Linear: 0.0028357685831081] nn.Sequential: [nn.Linear: 0.0001099514977064 nn.Linear: 0.0011487851852025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084175420925021 nn.Linear: 0.016268270090222 nn.Linear: 0.0086296694353223 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090929865837097 nn.Linear: 0.018270425498486] nn.Sequential: [nn.Linear: 0.0025544452946633 nn.Linear: 0.012896534986794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06229298582313 nn.Linear: 0.063025733605345 nn.Linear: 0.044522195868488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031384039637929 nn.Linear: 0.037483279099007] nn.Sequential: [nn.Linear: 0.031322068999425 nn.Linear: 0.027159813888993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35929021239281 nn.Linear: 0.1888383179903 nn.Linear: 0.1196501404047 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090749576687813 nn.Linear: 0.1586955934763] nn.Sequential: [nn.Linear: 0.081606179475784 nn.Linear: 0.14150170981884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016814444289653 nn.Linear: 0.0011112512873676 nn.Linear: 0.00055678571770123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020925583128998 nn.Linear: 0.0035060543906113] nn.Sequential: [nn.Linear: 0.0001946768949107 nn.Linear: 0.0019690002140588]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010238797403872 nn.Linear: 0.016726940870285 nn.Linear: 0.0091409524902701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010039228014648 nn.Linear: 0.024081273004413] nn.Sequential: [nn.Linear: 0.0060329106636345 nn.Linear: 0.019726505503058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062293907081116 nn.Linear: 0.063025756597141 nn.Linear: 0.044522449530177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031384151852604 nn.Linear: 0.037471695956413] nn.Sequential: [nn.Linear: 0.031322081008391 nn.Linear: 0.027157877093135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.35939356684685 nn.Linear: 0.18917794525623 nn.Linear: 0.11949844658375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090883232653141 nn.Linear: 0.15857003629208] nn.Sequential: [nn.Linear: 0.08179272711277 nn.Linear: 0.14147020876408]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013988184548545 nn.Linear: 0.00072344875713861 nn.Linear: 0.00040902012858852 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016832757075736 nn.Linear: 0.0033975984569135] nn.Sequential: [nn.Linear: 0.00014287789725666 nn.Linear: 0.0017979387601714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081668384373188 nn.Linear: 0.0096677206456661 nn.Linear: 0.0082834148779511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064160292968154 nn.Linear: 0.018650682643056] nn.Sequential: [nn.Linear: 0.0037641613744199 nn.Linear: 0.020133642479777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062297281442386 nn.Linear: 0.06303212132926 nn.Linear: 0.04452439256268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031384325828574 nn.Linear: 0.037502969369541] nn.Sequential: [nn.Linear: 0.031322396648909 nn.Linear: 0.027173932266905]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36024662852287 nn.Linear: 0.18903033435345 nn.Linear: 0.11968069523573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090732350945473 nn.Linear: 0.15878440439701] nn.Sequential: [nn.Linear: 0.081842064857483 nn.Linear: 0.14137224853039]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099244398495169 nn.Linear: 0.00064922174279732 nn.Linear: 0.00037565438464369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013857385529572 nn.Linear: 0.0020294892417178] nn.Sequential: [nn.Linear: 0.00010745236030033 nn.Linear: 0.00093683088192777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00843789242208 nn.Linear: 0.0098395049571991 nn.Linear: 0.0061564804054797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071205925196409 nn.Linear: 0.012373771518469] nn.Sequential: [nn.Linear: 0.0032200936693698 nn.Linear: 0.00890904199332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062292385720639 nn.Linear: 0.063033875696908 nn.Linear: 0.044524689541634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031384922431655 nn.Linear: 0.037615845438975] nn.Sequential: [nn.Linear: 0.031322142605338 nn.Linear: 0.027177588151677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36012229323387 nn.Linear: 0.18900820612907 nn.Linear: 0.11985299736261 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090935006737709 nn.Linear: 0.1591099947691] nn.Sequential: [nn.Linear: 0.081683233380318 nn.Linear: 0.14164084196091]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097266892535646 nn.Linear: 0.00061478829967069 nn.Linear: 0.0002891339586449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001152233032413 nn.Linear: 0.0016090345570985] nn.Sequential: [nn.Linear: 9.4287291245815e-05 nn.Linear: 0.00093205921489729]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078985560685396 nn.Linear: 0.0096383923664689 nn.Linear: 0.0052494988776743 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043248920701444 nn.Linear: 0.01106137316674] nn.Sequential: [nn.Linear: 0.0023069852031767 nn.Linear: 0.0070370100438595]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062299614423847 nn.Linear: 0.063039549736034 nn.Linear: 0.044526962839878 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031385199614129 nn.Linear: 0.037638830266843] nn.Sequential: [nn.Linear: 0.031322615964417 nn.Linear: 0.027212668694125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36023992300034 nn.Linear: 0.18886271119118 nn.Linear: 0.11985103040934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090783484280109 nn.Linear: 0.15920346975327] nn.Sequential: [nn.Linear: 0.081623397767544 nn.Linear: 0.14209449291229]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095808531468979 nn.Linear: 0.00063469177664625 nn.Linear: 0.00031255511318032 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4994478241597e-05 nn.Linear: 0.0012546752481946] nn.Sequential: [nn.Linear: 9.5648052249965e-05 nn.Linear: 0.00088264266584745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072792056016624 nn.Linear: 0.0077226837165654 nn.Linear: 0.0052057090215385 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0036150764208287 nn.Linear: 0.0070429043844342] nn.Sequential: [nn.Linear: 0.0024822051636875 nn.Linear: 0.0063080349937081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062300333701264 nn.Linear: 0.063043441741481 nn.Linear: 0.044527969648555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031385242370535 nn.Linear: 0.037675602850635] nn.Sequential: [nn.Linear: 0.031322679129413 nn.Linear: 0.027235140803434]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36048078536987 nn.Linear: 0.18906970322132 nn.Linear: 0.11975608766079 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091101095080376 nn.Linear: 0.15973220765591] nn.Sequential: [nn.Linear: 0.08158603310585 nn.Linear: 0.14274524152279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018627755248765 nn.Linear: 0.0010319619750088 nn.Linear: 0.00047123941046488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019900279018556 nn.Linear: 0.0033491168211823] nn.Sequential: [nn.Linear: 0.00012824410446471 nn.Linear: 0.0013140990839296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011778069660068 nn.Linear: 0.01496047526598 nn.Linear: 0.0094292452558875 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075964038260281 nn.Linear: 0.020849561318755] nn.Sequential: [nn.Linear: 0.0034386618062854 nn.Linear: 0.010018299333751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062303797763981 nn.Linear: 0.063047785260148 nn.Linear: 0.044529744749352 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031385519513798 nn.Linear: 0.03773247953135] nn.Sequential: [nn.Linear: 0.031323082924143 nn.Linear: 0.027253063039041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36124050617218 nn.Linear: 0.18910500407219 nn.Linear: 0.11956679075956 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090958423912525 nn.Linear: 0.16003347933292] nn.Sequential: [nn.Linear: 0.0817661434412 nn.Linear: 0.14279970526695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021648505578675 nn.Linear: 0.0013052512513204 nn.Linear: 0.0006061729937029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022542378498913 nn.Linear: 0.0039645076901684] nn.Sequential: [nn.Linear: 0.00015649459178914 nn.Linear: 0.0015789406856925]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014292826876044 nn.Linear: 0.016462698578835 nn.Linear: 0.014346769079566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069044209085405 nn.Linear: 0.022366801276803] nn.Sequential: [nn.Linear: 0.0043145986273885 nn.Linear: 0.013867478817701]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062307072274072 nn.Linear: 0.06305166658754 nn.Linear: 0.044530752983672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03138579419571 nn.Linear: 0.037759200865821] nn.Sequential: [nn.Linear: 0.031323211647268 nn.Linear: 0.02726357918883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36182168126106 nn.Linear: 0.18917821347713 nn.Linear: 0.11995631456375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091173253953457 nn.Linear: 0.15959820151329] nn.Sequential: [nn.Linear: 0.081844501197338 nn.Linear: 0.14264178276062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089193935526411 nn.Linear: 0.00055184053257106 nn.Linear: 0.00028216673549952 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011805513565893 nn.Linear: 0.0019718996768803] nn.Sequential: [nn.Linear: 0.0001065595793102 nn.Linear: 0.0011696106890252]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067634219303727 nn.Linear: 0.0087680919095874 nn.Linear: 0.0051635084673762 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042394050396979 nn.Linear: 0.015726273879409] nn.Sequential: [nn.Linear: 0.003147159004584 nn.Linear: 0.0071291881613433]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062300293273983 nn.Linear: 0.063051432832099 nn.Linear: 0.0445315892253 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031385881566132 nn.Linear: 0.037775580818582] nn.Sequential: [nn.Linear: 0.031323492748685 nn.Linear: 0.027284594671686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36222767829895 nn.Linear: 0.18924118578434 nn.Linear: 0.12000155448914 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.090909570455551 nn.Linear: 0.16020119190216] nn.Sequential: [nn.Linear: 0.08185900002718 nn.Linear: 0.14307829737663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017129990625096 nn.Linear: 0.00111086847787 nn.Linear: 0.00057096211168131 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002647664432887 nn.Linear: 0.0052084712700724] nn.Sequential: [nn.Linear: 0.00013758166123034 nn.Linear: 0.0016906690213945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087902210652828 nn.Linear: 0.01570332609117 nn.Linear: 0.011060517281294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010535699315369 nn.Linear: 0.030338909476995] nn.Sequential: [nn.Linear: 0.0047135734930634 nn.Linear: 0.013768603093922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062302782114542 nn.Linear: 0.063055413219474 nn.Linear: 0.04453232348247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031386180269491 nn.Linear: 0.037782653210201] nn.Sequential: [nn.Linear: 0.031323677356363 nn.Linear: 0.027298326643572]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36314684152603 nn.Linear: 0.18935035169125 nn.Linear: 0.12005440145731 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091245472431183 nn.Linear: 0.16023688018322] nn.Sequential: [nn.Linear: 0.081903591752052 nn.Linear: 0.14306904375553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099179404150626 nn.Linear: 0.00056985936790679 nn.Linear: 0.00028194070735078 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011975429856326 nn.Linear: 0.0021683013272415] nn.Sequential: [nn.Linear: 6.5807300724815e-05 nn.Linear: 0.00068129195267169]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058137821033597 nn.Linear: 0.010982901789248 nn.Linear: 0.0055711450986564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045336354523897 nn.Linear: 0.011541686020792] nn.Sequential: [nn.Linear: 0.0020010892767459 nn.Linear: 0.0054917801171541]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062303092861248 nn.Linear: 0.06305832932675 nn.Linear: 0.044533842149874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031386212563644 nn.Linear: 0.03777809952966] nn.Sequential: [nn.Linear: 0.031323960180927 nn.Linear: 0.027327003039254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36346885561943 nn.Linear: 0.18921148777008 nn.Linear: 0.12000852823257 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091008253395557 nn.Linear: 0.1601699590683] nn.Sequential: [nn.Linear: 0.081978142261505 nn.Linear: 0.14363640546799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010494842991517 nn.Linear: 0.00060539219410518 nn.Linear: 0.00029774044639017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010958382085764 nn.Linear: 0.0015776864111552] nn.Sequential: [nn.Linear: 9.3262233366872e-05 nn.Linear: 0.00083719447707922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008590062148869 nn.Linear: 0.0091134514659643 nn.Linear: 0.0066670477390289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004800122231245 nn.Linear: 0.011215387843549] nn.Sequential: [nn.Linear: 0.0023564640432596 nn.Linear: 0.008688922971487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062310745287703 nn.Linear: 0.063065570729141 nn.Linear: 0.044534959486495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031386346979051 nn.Linear: 0.03780504061994] nn.Sequential: [nn.Linear: 0.031324343685921 nn.Linear: 0.027351960330027]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36423879861832 nn.Linear: 0.18936204910278 nn.Linear: 0.12020768225193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091271802783012 nn.Linear: 0.1604822576046] nn.Sequential: [nn.Linear: 0.081886015832424 nn.Linear: 0.14430728554726]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.000797027050383 nn.Linear: 0.00060667208421124 nn.Linear: 0.00033769844013744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015408327175638 nn.Linear: 0.0028414747330752] nn.Sequential: [nn.Linear: 0.00011247216678766 nn.Linear: 0.0013795790113293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060215564444661 nn.Linear: 0.011228576302528 nn.Linear: 0.0060150106437504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061487513594329 nn.Linear: 0.015646880492568] nn.Sequential: [nn.Linear: 0.003247540211305 nn.Linear: 0.013072852045298]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062316788668338 nn.Linear: 0.063070099300735 nn.Linear: 0.044536757209784 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031386763860253 nn.Linear: 0.037869266003021] nn.Sequential: [nn.Linear: 0.031324439885352 nn.Linear: 0.027369910889206]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36493870615959 nn.Linear: 0.18948704004288 nn.Linear: 0.12049675732851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091254189610481 nn.Linear: 0.16098016500473] nn.Sequential: [nn.Linear: 0.08203786611557 nn.Linear: 0.14458206295967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071181758749531 nn.Linear: 0.00046226710186769 nn.Linear: 0.00028229244644824 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.1763240952824e-05 nn.Linear: 0.0013614881326037] nn.Sequential: [nn.Linear: 8.6455826414953e-05 nn.Linear: 0.00092288853720773]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059858723543584 nn.Linear: 0.0085049793124199 nn.Linear: 0.0060153580270708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042826840654016 nn.Linear: 0.0088028069585562] nn.Sequential: [nn.Linear: 0.0024197213351727 nn.Linear: 0.010020924732089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10506862130016	TD error	0.020408603552729	Qmax	1	

Steps: 3250000 (frames: 13000000), score: 2082.97, higheset score: 7496, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 89s, testing rate: 5567fps,  num. ep.: 325,  num. rewards: 18440	
   8    2   16    2
   2  256  512    4
  16    2    4  256
   4    8   16    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062318526395391 nn.Linear: 0.063073981900833 nn.Linear: 0.044538481856558 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031386907256503 nn.Linear: 0.037861363888201] nn.Sequential: [nn.Linear: 0.031324628562521 nn.Linear: 0.027370399206595]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36506745219231 nn.Linear: 0.1893452256918 nn.Linear: 0.12048743665218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09135240316391 nn.Linear: 0.16088749468327] nn.Sequential: [nn.Linear: 0.082265995442867 nn.Linear: 0.14450119435787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011322097354266 nn.Linear: 0.00074644539579135 nn.Linear: 0.00035541864116527 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015418254902166 nn.Linear: 0.0028652135498073] nn.Sequential: [nn.Linear: 8.4569990432225e-05 nn.Linear: 0.000735283028397]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010798238217831 nn.Linear: 0.011056105606258 nn.Linear: 0.009108304977417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053109740838408 nn.Linear: 0.019488103687763] nn.Sequential: [nn.Linear: 0.0023435221519321 nn.Linear: 0.0088507225736976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062313567796076 nn.Linear: 0.063074934309487 nn.Linear: 0.044539304987416 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03138702229899 nn.Linear: 0.037859997414566] nn.Sequential: [nn.Linear: 0.03132482523503 nn.Linear: 0.027389661664371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36471164226532 nn.Linear: 0.18876355886459 nn.Linear: 0.12088367342949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091307491064072 nn.Linear: 0.16049879789352] nn.Sequential: [nn.Linear: 0.082233399152756 nn.Linear: 0.14492399990559]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016145672897985 nn.Linear: 0.0011071680704094 nn.Linear: 0.00054180669127558 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020820935057097 nn.Linear: 0.0034029962625479] nn.Sequential: [nn.Linear: 0.00021446999697847 nn.Linear: 0.0027324958631539]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0176647529006 nn.Linear: 0.021908076480031 nn.Linear: 0.015226648189127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013105569407344 nn.Linear: 0.023136481642723] nn.Sequential: [nn.Linear: 0.0071756266988814 nn.Linear: 0.033439517021179]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062314798669733 nn.Linear: 0.063076869441648 nn.Linear: 0.04454099635818 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031387325338423 nn.Linear: 0.037945919146608] nn.Sequential: [nn.Linear: 0.031325103557823 nn.Linear: 0.027413586884411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36523815989494 nn.Linear: 0.18957528471947 nn.Linear: 0.12085212767124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091695658862591 nn.Linear: 0.16082334518433] nn.Sequential: [nn.Linear: 0.082130193710327 nn.Linear: 0.14538478851318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088636654496385 nn.Linear: 0.00059950079467012 nn.Linear: 0.00030679181904243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.1583110588343e-05 nn.Linear: 0.0011652887870777] nn.Sequential: [nn.Linear: 0.00012296907340498 nn.Linear: 0.0013564211284244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062399678863585 nn.Linear: 0.0080588990822434 nn.Linear: 0.0078941630199552 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040025035850704 nn.Linear: 0.0082329511642456] nn.Sequential: [nn.Linear: 0.0055288537405431 nn.Linear: 0.017307203263044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062318932904422 nn.Linear: 0.063084210966318 nn.Linear: 0.044542809436185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031387459036193 nn.Linear: 0.037955668460881] nn.Sequential: [nn.Linear: 0.031325489294549 nn.Linear: 0.027431545034384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36658385396004 nn.Linear: 0.19055558741093 nn.Linear: 0.12074314057827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091624476015568 nn.Linear: 0.16122698783875] nn.Sequential: [nn.Linear: 0.08230946958065 nn.Linear: 0.14521078765392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0005814925707511 nn.Linear: 0.00042231535574621 nn.Linear: 0.00024057586142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010118075178972 nn.Linear: 0.001731982900571] nn.Sequential: [nn.Linear: 5.8700263296429e-05 nn.Linear: 0.00059379164898911]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0036809800658375 nn.Linear: 0.0074975187890232 nn.Linear: 0.0041912435553968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034940738696605 nn.Linear: 0.0090335831046104] nn.Sequential: [nn.Linear: 0.0017753631109372 nn.Linear: 0.0051318667829037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06231987961607 nn.Linear: 0.063087593621517 nn.Linear: 0.044544186324682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031387882086399 nn.Linear: 0.038016961987466] nn.Sequential: [nn.Linear: 0.03132565365789 nn.Linear: 0.027456045928584]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36678245663643 nn.Linear: 0.18982714414597 nn.Linear: 0.1207357570529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09220477193594 nn.Linear: 0.16148264706135] nn.Sequential: [nn.Linear: 0.082331031560898 nn.Linear: 0.14554943144321]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011845260910201 nn.Linear: 0.00078110205774071 nn.Linear: 0.00042677251879482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017934535772432 nn.Linear: 0.0024726649826896] nn.Sequential: [nn.Linear: 0.00016303790962186 nn.Linear: 0.001635655219552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010002674534917 nn.Linear: 0.010069970972836 nn.Linear: 0.0093897022306919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066542336717248 nn.Linear: 0.01514345407486] nn.Sequential: [nn.Linear: 0.0048598530702293 nn.Linear: 0.016481207683682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062320687787857 nn.Linear: 0.063093173210443 nn.Linear: 0.044546047252145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388096098197 nn.Linear: 0.038048129141394] nn.Sequential: [nn.Linear: 0.031325922970138 nn.Linear: 0.027469719060743]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36726793646812 nn.Linear: 0.18964532017708 nn.Linear: 0.12090700864792 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092223182320595 nn.Linear: 0.16159579157829] nn.Sequential: [nn.Linear: 0.082447074353695 nn.Linear: 0.14564645290375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021644813678917 nn.Linear: 0.0012817707372978 nn.Linear: 0.00053508834613869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016428692671375 nn.Linear: 0.0022849113200734] nn.Sequential: [nn.Linear: 0.00014908519271421 nn.Linear: 0.0015158416860856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014150351285934 nn.Linear: 0.017419319599867 nn.Linear: 0.010717143304646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088804541155696 nn.Linear: 0.014644049108028] nn.Sequential: [nn.Linear: 0.0070034423843026 nn.Linear: 0.012339340522885]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062323990955122 nn.Linear: 0.063097734884385 nn.Linear: 0.04454826008744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388358182047 nn.Linear: 0.038111298977583] nn.Sequential: [nn.Linear: 0.031326369040778 nn.Linear: 0.02750097480067]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36718371510506 nn.Linear: 0.18959027528763 nn.Linear: 0.12131921201944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091843098402023 nn.Linear: 0.16199167072773] nn.Sequential: [nn.Linear: 0.082329571247101 nn.Linear: 0.14617091417313]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088927694465718 nn.Linear: 0.00049718954446425 nn.Linear: 0.00023050800092443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2440362159621e-05 nn.Linear: 0.0013564088872151] nn.Sequential: [nn.Linear: 6.6037570854159e-05 nn.Linear: 0.00065234266299273]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081874700263143 nn.Linear: 0.00817780662328 nn.Linear: 0.0041387560777366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057052010670304 nn.Linear: 0.0096970349550247] nn.Sequential: [nn.Linear: 0.0019231772748753 nn.Linear: 0.0073540392331779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062320212885847 nn.Linear: 0.063101936298968 nn.Linear: 0.044548660585105 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388634577165 nn.Linear: 0.038191627433406] nn.Sequential: [nn.Linear: 0.031326376539641 nn.Linear: 0.027511799603658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36749139428139 nn.Linear: 0.1890252828598 nn.Linear: 0.12124812602997 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091478578746319 nn.Linear: 0.1626014560461] nn.Sequential: [nn.Linear: 0.082549177110195 nn.Linear: 0.14616487920284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013201225514727 nn.Linear: 0.00073573242570815 nn.Linear: 0.00037667378032285 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015509228393525 nn.Linear: 0.0028865441850625] nn.Sequential: [nn.Linear: 9.9109367395627e-05 nn.Linear: 0.00084818307607241]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077773919329047 nn.Linear: 0.0094802407547832 nn.Linear: 0.0083874622359872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051648379303515 nn.Linear: 0.017253886908293] nn.Sequential: [nn.Linear: 0.0036883235443383 nn.Linear: 0.0074176881462336]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06232605914253 nn.Linear: 0.063106360713697 nn.Linear: 0.044550533137102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388623760306 nn.Linear: 0.038179682008419] nn.Sequential: [nn.Linear: 0.031326939855007 nn.Linear: 0.027537268152695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3675944507122 nn.Linear: 0.18924851715565 nn.Linear: 0.12135808169842 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091571904718876 nn.Linear: 0.16235145926476] nn.Sequential: [nn.Linear: 0.082844577729702 nn.Linear: 0.14646337926388]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023420430544334 nn.Linear: 0.0014981934888438 nn.Linear: 0.00067520309192006 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025619803281016 nn.Linear: 0.0047958339472838] nn.Sequential: [nn.Linear: 0.00022012983101242 nn.Linear: 0.0026131388724884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023828987032175 nn.Linear: 0.033048637211323 nn.Linear: 0.01761375926435 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012394952587783 nn.Linear: 0.032532446086407] nn.Sequential: [nn.Linear: 0.0068745766766369 nn.Linear: 0.031516436487436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062326266938274 nn.Linear: 0.063108992948014 nn.Linear: 0.044550815451254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388827650968 nn.Linear: 0.038231404614919] nn.Sequential: [nn.Linear: 0.031326896843522 nn.Linear: 0.027549008899717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36855319142342 nn.Linear: 0.18976375460625 nn.Linear: 0.12111658602953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091668352484703 nn.Linear: 0.16207359731197] nn.Sequential: [nn.Linear: 0.082714051008224 nn.Linear: 0.14625149965286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015639635434043 nn.Linear: 0.0011346983771662 nn.Linear: 0.00055584669741664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019242622626157 nn.Linear: 0.0036545471127267] nn.Sequential: [nn.Linear: 0.00015373217953638 nn.Linear: 0.0017646814037622]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015957383438945 nn.Linear: 0.020089751109481 nn.Linear: 0.014590797945857 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092276576906443 nn.Linear: 0.024589341133833] nn.Sequential: [nn.Linear: 0.0057281842455268 nn.Linear: 0.019930243492126]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062333641332404 nn.Linear: 0.063114230952315 nn.Linear: 0.044552603391036 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031388936383936 nn.Linear: 0.03824726388612] nn.Sequential: [nn.Linear: 0.031327221528325 nn.Linear: 0.02756221277585]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36894077062607 nn.Linear: 0.18964332342148 nn.Linear: 0.121018409729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091794900596142 nn.Linear: 0.16173860430717] nn.Sequential: [nn.Linear: 0.082736648619175 nn.Linear: 0.14605577290058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021020563315156 nn.Linear: 0.0012653802661029 nn.Linear: 0.00060620311777083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021597063638318 nn.Linear: 0.0042162816992273] nn.Sequential: [nn.Linear: 0.00016314823965809 nn.Linear: 0.0018653494348152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016572065651417 nn.Linear: 0.022050393745303 nn.Linear: 0.015870254486799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091198468580842 nn.Linear: 0.030030254274607] nn.Sequential: [nn.Linear: 0.0052564395591617 nn.Linear: 0.025007354095578]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062341867326302 nn.Linear: 0.063118341107802 nn.Linear: 0.044552978635054 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031389190636238 nn.Linear: 0.038285730753529] nn.Sequential: [nn.Linear: 0.031327290669479 nn.Linear: 0.027575906395911]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.36988750100136 nn.Linear: 0.18859021365643 nn.Linear: 0.12101173400879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091833539307117 nn.Linear: 0.16213946044445] nn.Sequential: [nn.Linear: 0.082680553197861 nn.Linear: 0.14646974205971]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001160344425916 nn.Linear: 0.00072387885843854 nn.Linear: 0.00039219367239264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013997263826705 nn.Linear: 0.0020086752031938] nn.Sequential: [nn.Linear: 0.00011489309955216 nn.Linear: 0.0011997032480013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074129910208285 nn.Linear: 0.010672828182578 nn.Linear: 0.0095049357041717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062417834997177 nn.Linear: 0.01218293607235] nn.Sequential: [nn.Linear: 0.0045202234759927 nn.Linear: 0.012443281710148]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062342399196963 nn.Linear: 0.063123752469578 nn.Linear: 0.044555039205436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031389437626148 nn.Linear: 0.038299941308978] nn.Sequential: [nn.Linear: 0.031327754707145 nn.Linear: 0.027614121173987]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37033405900002 nn.Linear: 0.18912637233734 nn.Linear: 0.12135951220989 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091911606490612 nn.Linear: 0.16229416429996] nn.Sequential: [nn.Linear: 0.082890175282955 nn.Linear: 0.1469489634037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012063520742672 nn.Linear: 0.00063984592975009 nn.Linear: 0.00033502055883326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010528365685239 nn.Linear: 0.0012921073524675] nn.Sequential: [nn.Linear: 9.2526471364408e-05 nn.Linear: 0.00094055024322963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079444628208876 nn.Linear: 0.0095786014571786 nn.Linear: 0.0063897725194693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060867066495121 nn.Linear: 0.0077237281948328] nn.Sequential: [nn.Linear: 0.0048526935279369 nn.Linear: 0.0092961704358459]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062340629551414 nn.Linear: 0.0631284354511 nn.Linear: 0.044555277981105 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031389544273887 nn.Linear: 0.038325990365436] nn.Sequential: [nn.Linear: 0.03132805914278 nn.Linear: 0.027634520738474]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37041673064232 nn.Linear: 0.18912795186043 nn.Linear: 0.12210401147604 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092064723372459 nn.Linear: 0.16286742687225] nn.Sequential: [nn.Linear: 0.082681730389595 nn.Linear: 0.14730958640575]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011863351485961 nn.Linear: 0.00074607351833722 nn.Linear: 0.00034259237187978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014422976709149 nn.Linear: 0.0027936487858666] nn.Sequential: [nn.Linear: 9.7287183790123e-05 nn.Linear: 0.00096834704031204]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099654970690608 nn.Linear: 0.0091652926057577 nn.Linear: 0.0065872380509973 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072401645593345 nn.Linear: 0.014660676009953] nn.Sequential: [nn.Linear: 0.0034029427915812 nn.Linear: 0.010824093595147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062338313871944 nn.Linear: 0.063131356609066 nn.Linear: 0.044557481324933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031389892842354 nn.Linear: 0.038392009977429] nn.Sequential: [nn.Linear: 0.031328373563852 nn.Linear: 0.027653064466499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37068194150925 nn.Linear: 0.18884725868702 nn.Linear: 0.12199610471725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092294409871101 nn.Linear: 0.16302008926868] nn.Sequential: [nn.Linear: 0.08261401206255 nn.Linear: 0.14756672084332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011282431867797 nn.Linear: 0.00082987792379628 nn.Linear: 0.00048159116970498 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023304484370307 nn.Linear: 0.0043546708969408] nn.Sequential: [nn.Linear: 0.00013393449377939 nn.Linear: 0.0013896527169417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097361374646425 nn.Linear: 0.01323280390352 nn.Linear: 0.0083839036524296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088424766436219 nn.Linear: 0.026231085881591] nn.Sequential: [nn.Linear: 0.0052455086261034 nn.Linear: 0.016499040648341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062339688745938 nn.Linear: 0.063136893867896 nn.Linear: 0.04455840138962 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031390300348196 nn.Linear: 0.038433649007935] nn.Sequential: [nn.Linear: 0.031328699214709 nn.Linear: 0.027681087157262]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37128484249115 nn.Linear: 0.18877717852592 nn.Linear: 0.12173207849264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092390090227127 nn.Linear: 0.16367401182652] nn.Sequential: [nn.Linear: 0.082505129277706 nn.Linear: 0.14769561588764]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015957509179157 nn.Linear: 0.00096719408491293 nn.Linear: 0.00043736157436425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011935362766178 nn.Linear: 0.0016038937642235] nn.Sequential: [nn.Linear: 0.00016133590728893 nn.Linear: 0.0018018041056305]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013055344112217 nn.Linear: 0.016777673736215 nn.Linear: 0.0089729158207774 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070473169907928 nn.Linear: 0.010967425070703] nn.Sequential: [nn.Linear: 0.0063389148563147 nn.Linear: 0.020283725112677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062344364824721 nn.Linear: 0.06314113068374 nn.Linear: 0.044560140824729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031390673235649 nn.Linear: 0.038490699868348] nn.Sequential: [nn.Linear: 0.031328919699764 nn.Linear: 0.027697184095448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37154519557953 nn.Linear: 0.18947124481201 nn.Linear: 0.12202943861485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092626743018627 nn.Linear: 0.16404139995575] nn.Sequential: [nn.Linear: 0.08254062384367 nn.Linear: 0.14798179268837]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094289226818783 nn.Linear: 0.00065510025169517 nn.Linear: 0.00036594831329337 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012887681896758 nn.Linear: 0.0017747652177197] nn.Sequential: [nn.Linear: 0.00013617088919882 nn.Linear: 0.001413491700335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066299415193498 nn.Linear: 0.012620435096323 nn.Linear: 0.007345830090344 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056776264682412 nn.Linear: 0.010931328870356] nn.Sequential: [nn.Linear: 0.0036892828065902 nn.Linear: 0.014460442587733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062338806884378 nn.Linear: 0.063141431512372 nn.Linear: 0.044561072718434 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031390657978679 nn.Linear: 0.038503626807753] nn.Sequential: [nn.Linear: 0.031329253962026 nn.Linear: 0.027721941846792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37252101302147 nn.Linear: 0.18910972774029 nn.Linear: 0.12197718769312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092240661382675 nn.Linear: 0.16470344364643] nn.Sequential: [nn.Linear: 0.082575440406799 nn.Linear: 0.14841943979263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061073615213338 nn.Linear: 0.00042373901091539 nn.Linear: 0.00023251149130453 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8359842086831e-05 nn.Linear: 0.0012624681188111] nn.Sequential: [nn.Linear: 9.0224409995788e-05 nn.Linear: 0.00082176085892299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00435423059389 nn.Linear: 0.0079877115786076 nn.Linear: 0.0050774961709976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0027815047651529 nn.Linear: 0.0092730931937695] nn.Sequential: [nn.Linear: 0.002957126358524 nn.Linear: 0.0092737292870879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062343625821899 nn.Linear: 0.063148707191126 nn.Linear: 0.044562936707692 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391004193037 nn.Linear: 0.038591143563508] nn.Sequential: [nn.Linear: 0.031329394928451 nn.Linear: 0.027729844546212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37230396270752 nn.Linear: 0.1892599016428 nn.Linear: 0.12195530533791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091851003468037 nn.Linear: 0.16566126048565] nn.Sequential: [nn.Linear: 0.082719951868057 nn.Linear: 0.14826828241348]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012774337309883 nn.Linear: 0.00081319671881261 nn.Linear: 0.0004083045465294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016386159457922 nn.Linear: 0.0030733660793222] nn.Sequential: [nn.Linear: 8.9602695055872e-05 nn.Linear: 0.00092284755112052]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079011144116521 nn.Linear: 0.014514799229801 nn.Linear: 0.0087663736194372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089796641841531 nn.Linear: 0.020726384595037] nn.Sequential: [nn.Linear: 0.0034258053638041 nn.Linear: 0.011749313212931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062352280933202 nn.Linear: 0.063155738442464 nn.Linear: 0.044565118844291 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391378832749 nn.Linear: 0.038627164297395] nn.Sequential: [nn.Linear: 0.031329755445273 nn.Linear: 0.027752447544184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37326315045357 nn.Linear: 0.18893454968929 nn.Linear: 0.12200979143381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091751046478748 nn.Linear: 0.1656678467989] nn.Sequential: [nn.Linear: 0.082963541150093 nn.Linear: 0.14839708805084]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016190170375011 nn.Linear: 0.0010763147416009 nn.Linear: 0.00049012938025928 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001960165958433 nn.Linear: 0.0038385552930573] nn.Sequential: [nn.Linear: 0.00013071750608893 nn.Linear: 0.001276807458665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014614732936025 nn.Linear: 0.016874168068171 nn.Linear: 0.010332957841456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070051071234047 nn.Linear: 0.022380076348782] nn.Sequential: [nn.Linear: 0.003945620264858 nn.Linear: 0.012362225912511]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062346990658693 nn.Linear: 0.063155876035376 nn.Linear: 0.044565656749035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391356355646 nn.Linear: 0.038613166347176] nn.Sequential: [nn.Linear: 0.031329910814886 nn.Linear: 0.027759256397381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37385922670364 nn.Linear: 0.18871192634106 nn.Linear: 0.12184233218431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09168317168951 nn.Linear: 0.16556423902512] nn.Sequential: [nn.Linear: 0.082870095968246 nn.Linear: 0.14872288703918]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00066634905869407 nn.Linear: 0.00041674304624812 nn.Linear: 0.00023805491476695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.9314705521661e-05 nn.Linear: 0.0017353974204808] nn.Sequential: [nn.Linear: 6.8772706844236e-05 nn.Linear: 0.00068221497852851]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052253296598792 nn.Linear: 0.005713973660022 nn.Linear: 0.0040652896277606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003633150132373 nn.Linear: 0.0097734611481428] nn.Sequential: [nn.Linear: 0.0015604323707521 nn.Linear: 0.0065023922361434]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062349101189767 nn.Linear: 0.063160379897155 nn.Linear: 0.044567264150681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391584771443 nn.Linear: 0.038620202429207] nn.Sequential: [nn.Linear: 0.031330195906692 nn.Linear: 0.027790138253394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37404537200928 nn.Linear: 0.18810850381851 nn.Linear: 0.12212842702866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091761782765388 nn.Linear: 0.16565401852131] nn.Sequential: [nn.Linear: 0.082841917872429 nn.Linear: 0.14873275160789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012125089186651 nn.Linear: 0.00074509898379723 nn.Linear: 0.0004060673564749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019261182987364 nn.Linear: 0.0035355580070764] nn.Sequential: [nn.Linear: 0.00012913187413983 nn.Linear: 0.0014317654595901]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010795065201819 nn.Linear: 0.012411005795002 nn.Linear: 0.0079779280349612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0078977551311255 nn.Linear: 0.021636778488755] nn.Sequential: [nn.Linear: 0.0038938459474593 nn.Linear: 0.013426481746137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062353497871838 nn.Linear: 0.063165142270058 nn.Linear: 0.044568932259596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391702818428 nn.Linear: 0.038644525254] nn.Sequential: [nn.Linear: 0.031330647541361 nn.Linear: 0.027809304798941]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37430414557457 nn.Linear: 0.18853631615639 nn.Linear: 0.12204376608133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091982901096344 nn.Linear: 0.16594311594963] nn.Sequential: [nn.Linear: 0.082661189138889 nn.Linear: 0.14916144311428]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013055894757139 nn.Linear: 0.00072000445617243 nn.Linear: 0.0003305414204887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010604989907541 nn.Linear: 0.0014206503361833] nn.Sequential: [nn.Linear: 0.0001336654571303 nn.Linear: 0.0016839463277527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010273455642164 nn.Linear: 0.011744960211217 nn.Linear: 0.006978846155107 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042257742024958 nn.Linear: 0.0089095598086715] nn.Sequential: [nn.Linear: 0.0031576473265886 nn.Linear: 0.016299342736602]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062356139231811 nn.Linear: 0.063167406316029 nn.Linear: 0.044569720321219 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031391973700285 nn.Linear: 0.03868448745277] nn.Sequential: [nn.Linear: 0.031330844760018 nn.Linear: 0.027821523987807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37533488869667 nn.Linear: 0.18898573517799 nn.Linear: 0.12234845012426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091691613197327 nn.Linear: 0.16626687347889] nn.Sequential: [nn.Linear: 0.082868233323097 nn.Linear: 0.1490912437439]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019986895120775 nn.Linear: 0.001040812327975 nn.Linear: 0.00061213094552805 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027268233932131 nn.Linear: 0.0046057009526503] nn.Sequential: [nn.Linear: 0.00020323691689165 nn.Linear: 0.0018203990427547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018117137253284 nn.Linear: 0.019726011902094 nn.Linear: 0.013207015581429 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010689942166209 nn.Linear: 0.030131828039885] nn.Sequential: [nn.Linear: 0.0059221563860774 nn.Linear: 0.015739379450679]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062356096671765 nn.Linear: 0.06317161072425 nn.Linear: 0.044571433976158 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031392480660873 nn.Linear: 0.038778664168944] nn.Sequential: [nn.Linear: 0.03133106952465 nn.Linear: 0.027844828157006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37609332799911 nn.Linear: 0.18901491165161 nn.Linear: 0.12215922027826 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091756977140903 nn.Linear: 0.16626995801926] nn.Sequential: [nn.Linear: 0.082757815718651 nn.Linear: 0.14986552298069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.004010786089257 nn.Linear: 0.0023035823532609 nn.Linear: 0.0010688586196111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00043045606703057 nn.Linear: 0.007538893033569] nn.Sequential: [nn.Linear: 0.00029841012490814 nn.Linear: 0.0035361715252883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.029934985563159 nn.Linear: 0.052276350557804 nn.Linear: 0.032945930957794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017396807670593 nn.Linear: 0.059706751257181] nn.Sequential: [nn.Linear: 0.0087989578023553 nn.Linear: 0.041722722351551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10586688255519	TD error	0.021715766385198	Qmax	1	

Steps: 3500000 (frames: 14000000), score: 1772.03, higheset score: 6404, epsilon: 0.05, lr: 0.0005, training time: 553s, training rate: 1807fps, testing time: 90s, testing rate: 5552fps,  num. ep.: 299,  num. rewards: 15120	
   4    2    4   16
   8    4   32    2
   4    8   64  512
   2   64  256    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062357817180609 nn.Linear: 0.063174849457318 nn.Linear: 0.044571725487501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031392508744582 nn.Linear: 0.038799504030408] nn.Sequential: [nn.Linear: 0.031331267434933 nn.Linear: 0.027854785768552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37591421604156 nn.Linear: 0.18875965476036 nn.Linear: 0.12211059033871 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091952368617058 nn.Linear: 0.16603042185307] nn.Sequential: [nn.Linear: 0.08292143791914 nn.Linear: 0.15007758140564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014384905178841 nn.Linear: 0.00084742295754979 nn.Linear: 0.00039524957043134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012520348228935 nn.Linear: 0.0017762428657833] nn.Sequential: [nn.Linear: 0.00011881190426049 nn.Linear: 0.0011200046505197]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010271243751049 nn.Linear: 0.0098393289372325 nn.Linear: 0.010783863253891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074846222996712 nn.Linear: 0.011497216299176] nn.Sequential: [nn.Linear: 0.004902336280793 nn.Linear: 0.012852932326496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062359676895158 nn.Linear: 0.063182995105595 nn.Linear: 0.044573239958188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031392510311865 nn.Linear: 0.038799228708399] nn.Sequential: [nn.Linear: 0.031331544522987 nn.Linear: 0.027878667731244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.3765771985054 nn.Linear: 0.18858951330185 nn.Linear: 0.1218269765377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091795079410076 nn.Linear: 0.16662377119064] nn.Sequential: [nn.Linear: 0.083053775131702 nn.Linear: 0.15030500292778]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015742316946432 nn.Linear: 0.00097569655424036 nn.Linear: 0.0004679285708392 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025218804543757 nn.Linear: 0.0050249707832828] nn.Sequential: [nn.Linear: 0.0001918600196555 nn.Linear: 0.0022443639824802]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014128962531686 nn.Linear: 0.022129781544209 nn.Linear: 0.021843399852514 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0113062588498 nn.Linear: 0.032699067145586] nn.Sequential: [nn.Linear: 0.0065640960820019 nn.Linear: 0.025858404114842]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062350519014506 nn.Linear: 0.063181857745051 nn.Linear: 0.044573785880177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031392756227305 nn.Linear: 0.038803992031433] nn.Sequential: [nn.Linear: 0.031331613390862 nn.Linear: 0.027900988755834]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37701973319054 nn.Linear: 0.18903997540474 nn.Linear: 0.12196576595306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.091932788491249 nn.Linear: 0.16637074947357] nn.Sequential: [nn.Linear: 0.082972086966038 nn.Linear: 0.1504513323307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00057891241090432 nn.Linear: 0.00048644031373749 nn.Linear: 0.00027408590729582 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.452876190323e-05 nn.Linear: 0.0013986967433868] nn.Sequential: [nn.Linear: 0.00011221145458135 nn.Linear: 0.0013064245434708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048325420357287 nn.Linear: 0.0063132070936263 nn.Linear: 0.0054236194118857 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004219870083034 nn.Linear: 0.0093385688960552] nn.Sequential: [nn.Linear: 0.0028258254751563 nn.Linear: 0.013960960321128]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062352509522936 nn.Linear: 0.063187635302775 nn.Linear: 0.044575491682418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031392884735264 nn.Linear: 0.03880575106939] nn.Sequential: [nn.Linear: 0.031332045689695 nn.Linear: 0.027924137418267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37755262851715 nn.Linear: 0.18934899568558 nn.Linear: 0.12208441644907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092122793197632 nn.Linear: 0.16637699306011] nn.Sequential: [nn.Linear: 0.083109378814697 nn.Linear: 0.15064731240273]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00068971234442539 nn.Linear: 0.00042366947486043 nn.Linear: 0.00022867668709859 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011225446389458 nn.Linear: 0.0021124227221225] nn.Sequential: [nn.Linear: 5.7384831691606e-05 nn.Linear: 0.00075665267600547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054672905243933 nn.Linear: 0.010415764525533 nn.Linear: 0.0064710341393948 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037943061906844 nn.Linear: 0.012608740478754] nn.Sequential: [nn.Linear: 0.0015133946435526 nn.Linear: 0.005100317299366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06236029530538 nn.Linear: 0.06319310440767 nn.Linear: 0.044577242218713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031393047946461 nn.Linear: 0.038825457777563] nn.Sequential: [nn.Linear: 0.031332297067412 nn.Linear: 0.027949636734894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37811186909676 nn.Linear: 0.18834121525288 nn.Linear: 0.1222777813673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092368468642235 nn.Linear: 0.16633042693138] nn.Sequential: [nn.Linear: 0.082869648933411 nn.Linear: 0.15094836056232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00064842854670901 nn.Linear: 0.00038642937766578 nn.Linear: 0.00022056338055535 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.8816864797117e-05 nn.Linear: 0.0010151767577562] nn.Sequential: [nn.Linear: 7.7813660879495e-05 nn.Linear: 0.00078600245334227]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069422256201506 nn.Linear: 0.0048390701413155 nn.Linear: 0.0037294009234756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.002791911130771 nn.Linear: 0.006455160677433] nn.Sequential: [nn.Linear: 0.0020595157984644 nn.Linear: 0.0061672227457166]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06236103620879 nn.Linear: 0.063196774244306 nn.Linear: 0.044578031144038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031393348525312 nn.Linear: 0.038873114861133] nn.Sequential: [nn.Linear: 0.031332431127777 nn.Linear: 0.027965233299533]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37833496928215 nn.Linear: 0.18942905962467 nn.Linear: 0.12266280502081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092304155230522 nn.Linear: 0.16603051126003] nn.Sequential: [nn.Linear: 0.082964904606342 nn.Linear: 0.15091648697853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012654369094821 nn.Linear: 0.0006902299278269 nn.Linear: 0.00034346574842147 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011747196324264 nn.Linear: 0.0013529146349125] nn.Sequential: [nn.Linear: 8.6047931905175e-05 nn.Linear: 0.00080507999035426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01049186475575 nn.Linear: 0.013270714320242 nn.Linear: 0.0083016790449619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052127949893475 nn.Linear: 0.011787006631494] nn.Sequential: [nn.Linear: 0.0032624416053295 nn.Linear: 0.0079080862924457]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062359947723674 nn.Linear: 0.063197649082624 nn.Linear: 0.044578870135444 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031393387677023 nn.Linear: 0.038892281700612] nn.Sequential: [nn.Linear: 0.031332748971387 nn.Linear: 0.027976165730165]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37865555286407 nn.Linear: 0.18961217999458 nn.Linear: 0.1227435991168 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092130698263645 nn.Linear: 0.16671389341354] nn.Sequential: [nn.Linear: 0.083070062100887 nn.Linear: 0.15130639076233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027456273971639 nn.Linear: 0.0015172812925719 nn.Linear: 0.00070139656990851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025694372930371 nn.Linear: 0.0044406842385273] nn.Sequential: [nn.Linear: 0.00018532722412938 nn.Linear: 0.0018746045135749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025576552376151 nn.Linear: 0.041829898953438 nn.Linear: 0.021631676703691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013131219893694 nn.Linear: 0.031246660277247] nn.Sequential: [nn.Linear: 0.006651567760855 nn.Linear: 0.01770394295454]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062366468350869 nn.Linear: 0.063205489605047 nn.Linear: 0.044581580669897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031393893701811 nn.Linear: 0.038949758320868] nn.Sequential: [nn.Linear: 0.031333229367039 nn.Linear: 0.028014570232048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37902769446373 nn.Linear: 0.18918584287167 nn.Linear: 0.12268759310246 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092107892036438 nn.Linear: 0.16762807965279] nn.Sequential: [nn.Linear: 0.083190895617008 nn.Linear: 0.15119977295399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014502105475759 nn.Linear: 0.00089190691808301 nn.Linear: 0.00040013632614991 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012921223311494 nn.Linear: 0.0017733980697099] nn.Sequential: [nn.Linear: 0.00012802324518153 nn.Linear: 0.0013853473025458]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088052302598953 nn.Linear: 0.014753450639546 nn.Linear: 0.010203159414232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062149493023753 nn.Linear: 0.011751890182495] nn.Sequential: [nn.Linear: 0.0042072981595993 nn.Linear: 0.016539679840207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062367846006971 nn.Linear: 0.063207212691995 nn.Linear: 0.044581834717328 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031394104397063 nn.Linear: 0.038982758532782] nn.Sequential: [nn.Linear: 0.031333312922177 nn.Linear: 0.028036240338565]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37948173284531 nn.Linear: 0.18931093811989 nn.Linear: 0.12327929586172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092162169516087 nn.Linear: 0.16742521524429] nn.Sequential: [nn.Linear: 0.0831678211689 nn.Linear: 0.15116237103939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010806670464187 nn.Linear: 0.00084134674183216 nn.Linear: 0.00042635651837214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017121985057473 nn.Linear: 0.0028706257903566] nn.Sequential: [nn.Linear: 0.00011771580929619 nn.Linear: 0.0011172123358984]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099604474380612 nn.Linear: 0.01225898321718 nn.Linear: 0.010653544217348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0080604953691363 nn.Linear: 0.017561523243785] nn.Sequential: [nn.Linear: 0.0037296230439097 nn.Linear: 0.015482003800571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062368349512704 nn.Linear: 0.063213750190462 nn.Linear: 0.044583559020261 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031394273502784 nn.Linear: 0.038980114998182] nn.Sequential: [nn.Linear: 0.031333818376546 nn.Linear: 0.028054570552346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37971472740173 nn.Linear: 0.18913891911507 nn.Linear: 0.12338520586491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092299938201904 nn.Linear: 0.16786733269691] nn.Sequential: [nn.Linear: 0.083383165299892 nn.Linear: 0.15152633190155]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086078892642633 nn.Linear: 0.00049823006591048 nn.Linear: 0.00021639313330326 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.3455320260217e-05 nn.Linear: 0.0015672630905691] nn.Sequential: [nn.Linear: 6.621086369088e-05 nn.Linear: 0.00070029596814606]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053178598172963 nn.Linear: 0.0080516021698713 nn.Linear: 0.0058105238713324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038799298927188 nn.Linear: 0.0088491104543209] nn.Sequential: [nn.Linear: 0.0020838871132582 nn.Linear: 0.0082180220633745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062369375576568 nn.Linear: 0.063218578566856 nn.Linear: 0.044584346292369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031394681744381 nn.Linear: 0.039031756986493] nn.Sequential: [nn.Linear: 0.031333923442655 nn.Linear: 0.02807064362721]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.37923192977905 nn.Linear: 0.18833181262016 nn.Linear: 0.12325274199247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092545591294765 nn.Linear: 0.16833288967609] nn.Sequential: [nn.Linear: 0.083457194268703 nn.Linear: 0.15145547688007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092269108808878 nn.Linear: 0.00058881654079474 nn.Linear: 0.0003649210039079 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016885068415179 nn.Linear: 0.0032107538004835] nn.Sequential: [nn.Linear: 0.00010928572013432 nn.Linear: 0.0011686852732493]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057272538542747 nn.Linear: 0.012455370277166 nn.Linear: 0.0065306276082993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052087754011154 nn.Linear: 0.020000690594316] nn.Sequential: [nn.Linear: 0.0033847792074084 nn.Linear: 0.014617011882365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062374034576143 nn.Linear: 0.063225047444262 nn.Linear: 0.044586288866213 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031395128321206 nn.Linear: 0.039112596259372] nn.Sequential: [nn.Linear: 0.031334327406557 nn.Linear: 0.028083003998045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38057574629784 nn.Linear: 0.1882536560297 nn.Linear: 0.12321005016565 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092552706599236 nn.Linear: 0.16883118450642] nn.Sequential: [nn.Linear: 0.083456814289093 nn.Linear: 0.15156282484531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014075771234759 nn.Linear: 0.00089743987024647 nn.Linear: 0.00041448591950916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015830092990208 nn.Linear: 0.0025777133883285] nn.Sequential: [nn.Linear: 0.00010337797761715 nn.Linear: 0.00098013739260122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010633094236255 nn.Linear: 0.013190777041018 nn.Linear: 0.0092999152839184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008793861605227 nn.Linear: 0.013369688764215] nn.Sequential: [nn.Linear: 0.0030728662386537 nn.Linear: 0.0082033704966307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062370260119669 nn.Linear: 0.063228649243964 nn.Linear: 0.044587477945038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031395273643725 nn.Linear: 0.039168375076486] nn.Sequential: [nn.Linear: 0.031334440368805 nn.Linear: 0.02811249805269]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38102781772614 nn.Linear: 0.18878796696663 nn.Linear: 0.12324574589729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09260430932045 nn.Linear: 0.1690217256546] nn.Sequential: [nn.Linear: 0.083538442850113 nn.Linear: 0.15213602781296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010985478995272 nn.Linear: 0.00068802792796445 nn.Linear: 0.00035302753002838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012818125406699 nn.Linear: 0.002046931545386] nn.Sequential: [nn.Linear: 0.0001109822993406 nn.Linear: 0.0011791942566921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072348807007074 nn.Linear: 0.01027206517756 nn.Linear: 0.0082366541028023 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070605203509331 nn.Linear: 0.012602920643985] nn.Sequential: [nn.Linear: 0.0041721910238266 nn.Linear: 0.011888097971678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062369405897892 nn.Linear: 0.063232223693845 nn.Linear: 0.04458877406045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031395334169975 nn.Linear: 0.039162068840881] nn.Sequential: [nn.Linear: 0.031334630185431 nn.Linear: 0.028122350321505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38154751062393 nn.Linear: 0.18873097002506 nn.Linear: 0.12342388927937 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092613585293293 nn.Linear: 0.1690014898777] nn.Sequential: [nn.Linear: 0.083599619567394 nn.Linear: 0.15215139091015]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025663052180718 nn.Linear: 0.0019924577942959 nn.Linear: 0.00099612394525359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0004446315555602 nn.Linear: 0.0084197600124507] nn.Sequential: [nn.Linear: 0.00029636042948606 nn.Linear: 0.0030370673254593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01954604499042 nn.Linear: 0.028203580528498 nn.Linear: 0.034074146300554 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022597758099437 nn.Linear: 0.051582328975201] nn.Sequential: [nn.Linear: 0.01850588992238 nn.Linear: 0.032510168850422]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062377382544816 nn.Linear: 0.063237934091643 nn.Linear: 0.04459071324695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031395502343338 nn.Linear: 0.039235932648694] nn.Sequential: [nn.Linear: 0.031335134923003 nn.Linear: 0.02815649954497]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38155034184456 nn.Linear: 0.18779996037483 nn.Linear: 0.12378300726414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092419341206551 nn.Linear: 0.16923049092293] nn.Sequential: [nn.Linear: 0.083619832992554 nn.Linear: 0.15255439281464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018337958530093 nn.Linear: 0.0012459532320738 nn.Linear: 0.00062133531604631 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025457618379067 nn.Linear: 0.004613676444384] nn.Sequential: [nn.Linear: 0.00018602727469874 nn.Linear: 0.0018910770940381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012980068102479 nn.Linear: 0.025171894580126 nn.Linear: 0.015061445534229 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010940864682198 nn.Linear: 0.030008777976036] nn.Sequential: [nn.Linear: 0.0051691960543394 nn.Linear: 0.013041878119111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062374411750604 nn.Linear: 0.06324008993098 nn.Linear: 0.044591059961743 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031395868656011 nn.Linear: 0.039253343866619] nn.Sequential: [nn.Linear: 0.031335125160829 nn.Linear: 0.028172757891415]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38261145353317 nn.Linear: 0.18870635330677 nn.Linear: 0.12389433383942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092272005975246 nn.Linear: 0.16934506595135] nn.Sequential: [nn.Linear: 0.08354439586401 nn.Linear: 0.15263409912586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097609552573376 nn.Linear: 0.00063594147128366 nn.Linear: 0.00033416096044629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014805600117623 nn.Linear: 0.0022649379037132] nn.Sequential: [nn.Linear: 9.2038488007265e-05 nn.Linear: 0.00071468951409824]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095225609838963 nn.Linear: 0.0099163455888629 nn.Linear: 0.0064923861064017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004776450805366 nn.Linear: 0.01324109826237] nn.Sequential: [nn.Linear: 0.0027708227280527 nn.Linear: 0.0067787310108542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062387883097738 nn.Linear: 0.063246518058681 nn.Linear: 0.044593643256025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031396256099897 nn.Linear: 0.039318779127711] nn.Sequential: [nn.Linear: 0.031335752949653 nn.Linear: 0.028217111395922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38230481743813 nn.Linear: 0.18923607468605 nn.Linear: 0.12389654666185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092510059475899 nn.Linear: 0.16975755989552] nn.Sequential: [nn.Linear: 0.083618767559528 nn.Linear: 0.15269002318382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019308646914583 nn.Linear: 0.0010781738837871 nn.Linear: 0.00050152539762985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017872230971583 nn.Linear: 0.0026329174922666] nn.Sequential: [nn.Linear: 0.00013129950277786 nn.Linear: 0.0012962825048669]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019775232300162 nn.Linear: 0.017781043425202 nn.Linear: 0.015587008558214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075715510174632 nn.Linear: 0.020288459956646] nn.Sequential: [nn.Linear: 0.0034059195313603 nn.Linear: 0.013291958719492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062387091561549 nn.Linear: 0.063249931050434 nn.Linear: 0.044595198592017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031396415194947 nn.Linear: 0.039337390966523] nn.Sequential: [nn.Linear: 0.031336105396483 nn.Linear: 0.028230239819456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38314840197563 nn.Linear: 0.18916834890842 nn.Linear: 0.12427388876677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092384979128838 nn.Linear: 0.16946344077587] nn.Sequential: [nn.Linear: 0.083783462643623 nn.Linear: 0.15279901027679]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016806345855794 nn.Linear: 0.0013474824560637 nn.Linear: 0.00062363523931358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017294558229826 nn.Linear: 0.0025502521451218] nn.Sequential: [nn.Linear: 0.00019725122560998 nn.Linear: 0.0019025915022238]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096052223816514 nn.Linear: 0.01834755949676 nn.Linear: 0.013512674719095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099712098017335 nn.Linear: 0.018988268449903] nn.Sequential: [nn.Linear: 0.0078046848066151 nn.Linear: 0.023550206795335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062382985084668 nn.Linear: 0.063253489781747 nn.Linear: 0.044596115907711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031396807065233 nn.Linear: 0.039388662468525] nn.Sequential: [nn.Linear: 0.031336146500167 nn.Linear: 0.028249098234545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38313353061676 nn.Linear: 0.18910218775272 nn.Linear: 0.12428551912308 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092879131436348 nn.Linear: 0.16978351771832] nn.Sequential: [nn.Linear: 0.083694443106651 nn.Linear: 0.1530259847641]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090944218160323 nn.Linear: 0.00069260455578666 nn.Linear: 0.00035996388850269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012183546441264 nn.Linear: 0.0017550433087282] nn.Sequential: [nn.Linear: 0.00014201243383465 nn.Linear: 0.0014586589873822]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0061409510672092 nn.Linear: 0.009185403585434 nn.Linear: 0.0064253527671099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006176155526191 nn.Linear: 0.010724388994277] nn.Sequential: [nn.Linear: 0.0048836967907846 nn.Linear: 0.019125586375594]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062382354099874 nn.Linear: 0.063255705438403 nn.Linear: 0.044596712557058 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03139681897305 nn.Linear: 0.039357700042558] nn.Sequential: [nn.Linear: 0.031336491253542 nn.Linear: 0.028272741303921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38396266102791 nn.Linear: 0.18965150415897 nn.Linear: 0.12417047470808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09271601587534 nn.Linear: 0.17007233202457] nn.Sequential: [nn.Linear: 0.083658501505852 nn.Linear: 0.15356561541557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00065618958480121 nn.Linear: 0.0004657006642347 nn.Linear: 0.00028445647148055 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5837390338713e-05 nn.Linear: 0.001388291950233] nn.Sequential: [nn.Linear: 0.00013697676130942 nn.Linear: 0.0016842987210877]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0044648097828031 nn.Linear: 0.006059932988137 nn.Linear: 0.0038453217130154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045302798971534 nn.Linear: 0.0097119808197021] nn.Sequential: [nn.Linear: 0.0041449726559222 nn.Linear: 0.016599543392658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062385588508494 nn.Linear: 0.063257639438403 nn.Linear: 0.044598369034135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031396973741769 nn.Linear: 0.039392077113746] nn.Sequential: [nn.Linear: 0.031336693390501 nn.Linear: 0.028285222268689]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38402092456818 nn.Linear: 0.18931831419468 nn.Linear: 0.12410038709641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092769049108028 nn.Linear: 0.17030982673168] nn.Sequential: [nn.Linear: 0.083683475852013 nn.Linear: 0.15354415774345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011301513707948 nn.Linear: 0.00081022838946937 nn.Linear: 0.00044864065267024 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019417270456022 nn.Linear: 0.0037392599145694] nn.Sequential: [nn.Linear: 0.00013983676761672 nn.Linear: 0.0014415559895115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071464371867478 nn.Linear: 0.010704787448049 nn.Linear: 0.0069125541485846 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073999282903969 nn.Linear: 0.023675566539168] nn.Sequential: [nn.Linear: 0.0044473605230451 nn.Linear: 0.015501925721765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06238505570063 nn.Linear: 0.063262815308587 nn.Linear: 0.044600225574481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03139728511198 nn.Linear: 0.039439088886866] nn.Sequential: [nn.Linear: 0.031337168860102 nn.Linear: 0.028310555507996]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38486123085022 nn.Linear: 0.18919005990028 nn.Linear: 0.1246051415801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092617236077785 nn.Linear: 0.17102625966072] nn.Sequential: [nn.Linear: 0.083836287260056 nn.Linear: 0.15379050374031]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025386585558989 nn.Linear: 0.0016831198841509 nn.Linear: 0.00081784771562951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033915789307558 nn.Linear: 0.0061713623838417] nn.Sequential: [nn.Linear: 0.00014355722806585 nn.Linear: 0.0013276434866442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019217725843191 nn.Linear: 0.039176978170872 nn.Linear: 0.017412813380361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020982990041375 nn.Linear: 0.04115304350853] nn.Sequential: [nn.Linear: 0.0060045635327697 nn.Linear: 0.014896472916007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062392536573228 nn.Linear: 0.063270664040947 nn.Linear: 0.044603111683425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031397745483125 nn.Linear: 0.039493442109801] nn.Sequential: [nn.Linear: 0.031337571152408 nn.Linear: 0.028345172614216]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38556733727455 nn.Linear: 0.19021616876125 nn.Linear: 0.12453313916922 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092472694814205 nn.Linear: 0.17122587561607] nn.Sequential: [nn.Linear: 0.083811961114407 nn.Linear: 0.15404132008553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085812905746818 nn.Linear: 0.00054000374784032 nn.Linear: 0.00027288935275188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.2215544311357e-05 nn.Linear: 0.0015810859419408] nn.Sequential: [nn.Linear: 9.4888597469088e-05 nn.Linear: 0.00083464976794781]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065273963846266 nn.Linear: 0.0085082231089473 nn.Linear: 0.004907576367259 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045829615555704 nn.Linear: 0.0089917611330748] nn.Sequential: [nn.Linear: 0.0022793274838477 nn.Linear: 0.0072670537047088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062392968715866 nn.Linear: 0.063273235639186 nn.Linear: 0.044603175387195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031397887468137 nn.Linear: 0.039526188203183] nn.Sequential: [nn.Linear: 0.031337723804464 nn.Linear: 0.028360392799582]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38565188646317 nn.Linear: 0.19032134115696 nn.Linear: 0.12407730519772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09296377748251 nn.Linear: 0.17101103067398] nn.Sequential: [nn.Linear: 0.083657138049603 nn.Linear: 0.15437735617161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013357105660947 nn.Linear: 0.00074017847467193 nn.Linear: 0.00037841328794917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014613981288102 nn.Linear: 0.0018260873714588] nn.Sequential: [nn.Linear: 0.00012465790035081 nn.Linear: 0.0012147067919361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013055987656116 nn.Linear: 0.01297721080482 nn.Linear: 0.0081942500546575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068808603100479 nn.Linear: 0.01502326503396] nn.Sequential: [nn.Linear: 0.0039058316033334 nn.Linear: 0.013069529086351]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062401467543498 nn.Linear: 0.063278100779387 nn.Linear: 0.044603899033581 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031398076427061 nn.Linear: 0.039533306698388] nn.Sequential: [nn.Linear: 0.031338121637878 nn.Linear: 0.028392364296979]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38618850708008 nn.Linear: 0.19087672233582 nn.Linear: 0.12412317097187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092895068228245 nn.Linear: 0.17073228955269] nn.Sequential: [nn.Linear: 0.083824142813683 nn.Linear: 0.15441001951694]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012501227182059 nn.Linear: 0.00077889126458586 nn.Linear: 0.00041930536662008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015728382586328 nn.Linear: 0.0023261849171675] nn.Sequential: [nn.Linear: 0.00013692522688833 nn.Linear: 0.0014744786462186]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010512337088585 nn.Linear: 0.012165438383818 nn.Linear: 0.008007968775928 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048156077973545 nn.Linear: 0.013785982504487] nn.Sequential: [nn.Linear: 0.0030106611084193 nn.Linear: 0.013565671630204]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10187867709994	TD error	0.021061065346003	Qmax	1	

Steps: 3750000 (frames: 15000000), score: 2054.16, higheset score: 6712, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1810fps, testing time: 89s, testing rate: 5580fps,  num. ep.: 315,  num. rewards: 18919	
   2    4    8    4
   8   16   64  128
   4    8  256  512
   2    4    8    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062401566290823 nn.Linear: 0.063284885045167 nn.Linear: 0.044606102574618 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031398203084498 nn.Linear: 0.039531959774763] nn.Sequential: [nn.Linear: 0.031338514270244 nn.Linear: 0.028408111969686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38703832030296 nn.Linear: 0.19025388360023 nn.Linear: 0.12452911585569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093065023422241 nn.Linear: 0.1711493730545] nn.Sequential: [nn.Linear: 0.083770647644997 nn.Linear: 0.15438172221184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090752594346247 nn.Linear: 0.00064721637075955 nn.Linear: 0.00032645203386081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001150882529248 nn.Linear: 0.0018808127807395] nn.Sequential: [nn.Linear: 0.00010924910604766 nn.Linear: 0.0011999555080338]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080939903855324 nn.Linear: 0.0078534074127674 nn.Linear: 0.0065155988559127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049825613386929 nn.Linear: 0.011019321158528] nn.Sequential: [nn.Linear: 0.0032837765756994 nn.Linear: 0.010020053014159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062410246752042 nn.Linear: 0.063289473220196 nn.Linear: 0.044608588485386 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031398497752069 nn.Linear: 0.039589584686553] nn.Sequential: [nn.Linear: 0.031338870107043 nn.Linear: 0.028422340971451]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38765940070152 nn.Linear: 0.1902811974287 nn.Linear: 0.12465085089207 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092873618006706 nn.Linear: 0.17196722328663] nn.Sequential: [nn.Linear: 0.083967752754688 nn.Linear: 0.15473416447639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015093708427613 nn.Linear: 0.00087964954081494 nn.Linear: 0.00038457899767253 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012586463385849 nn.Linear: 0.0017885668607502] nn.Sequential: [nn.Linear: 0.00011899619945238 nn.Linear: 0.001097256475093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009589166380465 nn.Linear: 0.015086606144905 nn.Linear: 0.0072029819712043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005617150105536 nn.Linear: 0.011917658150196] nn.Sequential: [nn.Linear: 0.0035768672823906 nn.Linear: 0.0079139685258269]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062411923319039 nn.Linear: 0.063295610360698 nn.Linear: 0.044609765700347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031398577879062 nn.Linear: 0.039605377793066] nn.Sequential: [nn.Linear: 0.031339263428155 nn.Linear: 0.028453374025712]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38800185918808 nn.Linear: 0.19026204943657 nn.Linear: 0.12453536689281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092902757227421 nn.Linear: 0.17208482325077] nn.Sequential: [nn.Linear: 0.084143534302711 nn.Linear: 0.15475721657276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012543785852368 nn.Linear: 0.00071723465515496 nn.Linear: 0.00039254561002856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013587357456878 nn.Linear: 0.0016849916197815] nn.Sequential: [nn.Linear: 0.00017138990214616 nn.Linear: 0.0020327853662349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075616608373821 nn.Linear: 0.0091956360265613 nn.Linear: 0.0075626545585692 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070223840884864 nn.Linear: 0.013675465248525] nn.Sequential: [nn.Linear: 0.0064469398930669 nn.Linear: 0.02344966866076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062413501778058 nn.Linear: 0.063298384713982 nn.Linear: 0.044611830560659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031398822279636 nn.Linear: 0.039659247442387] nn.Sequential: [nn.Linear: 0.031339564404111 nn.Linear: 0.028481205056504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38791325688362 nn.Linear: 0.19051706790924 nn.Linear: 0.12482172250748 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093088313937187 nn.Linear: 0.1718857139349] nn.Sequential: [nn.Linear: 0.084060028195381 nn.Linear: 0.15552164614201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030695329878123 nn.Linear: 0.0018626366129378 nn.Linear: 0.00066136474643421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019250584409349 nn.Linear: 0.0025809571379254] nn.Sequential: [nn.Linear: 0.00020701117270624 nn.Linear: 0.002400248366079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.026363043114543 nn.Linear: 0.032458763569593 nn.Linear: 0.017517106607556 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010469794273376 nn.Linear: 0.01953374966979] nn.Sequential: [nn.Linear: 0.0056094210594893 nn.Linear: 0.028304271399975]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062414684032618 nn.Linear: 0.063304719222012 nn.Linear: 0.044613314308732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031399245944017 nn.Linear: 0.039690214299114] nn.Sequential: [nn.Linear: 0.031339961436342 nn.Linear: 0.028496613514683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38922396302223 nn.Linear: 0.19061174988747 nn.Linear: 0.12492743134499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093609899282455 nn.Linear: 0.17305833101273] nn.Sequential: [nn.Linear: 0.084070526063442 nn.Linear: 0.15557503700256]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071284826435852 nn.Linear: 0.00049046836825326 nn.Linear: 0.00024725833826739 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.9441984307618e-05 nn.Linear: 0.0010280339611692] nn.Sequential: [nn.Linear: 0.00010936219420456 nn.Linear: 0.0012129139324398]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0042296331375837 nn.Linear: 0.0051700649783015 nn.Linear: 0.0049991984851658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003302485216409 nn.Linear: 0.0070585999637842] nn.Sequential: [nn.Linear: 0.0031790174543858 nn.Linear: 0.013173162937164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062418843645604 nn.Linear: 0.063309519383236 nn.Linear: 0.044615334328609 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03139949050429 nn.Linear: 0.039734484322594] nn.Sequential: [nn.Linear: 0.031340134159651 nn.Linear: 0.028509208727662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.38937211036682 nn.Linear: 0.19098387658596 nn.Linear: 0.12523086369038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093568630516529 nn.Linear: 0.17313447594643] nn.Sequential: [nn.Linear: 0.084272980690002 nn.Linear: 0.15549510717392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012597451282401 nn.Linear: 0.00085786113688618 nn.Linear: 0.00040982349603341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015742614788424 nn.Linear: 0.0027410550597473] nn.Sequential: [nn.Linear: 0.00011609004131152 nn.Linear: 0.001135761659479]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010561667382717 nn.Linear: 0.013534721918404 nn.Linear: 0.012625607661903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050702826119959 nn.Linear: 0.015727238729596] nn.Sequential: [nn.Linear: 0.0059550269506872 nn.Linear: 0.011606398038566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062424787243724 nn.Linear: 0.063314047671216 nn.Linear: 0.044616724253234 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031399720752655 nn.Linear: 0.039768397507089] nn.Sequential: [nn.Linear: 0.031340305016911 nn.Linear: 0.028516012632234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39027765393257 nn.Linear: 0.19160388410091 nn.Linear: 0.12551414966583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093515761196613 nn.Linear: 0.17335885763168] nn.Sequential: [nn.Linear: 0.084156930446625 nn.Linear: 0.15522365272045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011774887639444 nn.Linear: 0.0006331723505185 nn.Linear: 0.00029863817222862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010203118328445 nn.Linear: 0.0015666825575289] nn.Sequential: [nn.Linear: 0.00010631093547342 nn.Linear: 0.0012133679828451]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090885730460286 nn.Linear: 0.012250860221684 nn.Linear: 0.0058151693083346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005174620077014 nn.Linear: 0.01340414956212] nn.Sequential: [nn.Linear: 0.0037124054506421 nn.Linear: 0.011613978073001]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062431497136306 nn.Linear: 0.063320150503784 nn.Linear: 0.044618750588289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031399980084326 nn.Linear: 0.039816143153747] nn.Sequential: [nn.Linear: 0.031340778179271 nn.Linear: 0.02855053650932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39088177680969 nn.Linear: 0.19135814905167 nn.Linear: 0.12530797719955 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093449093401432 nn.Linear: 0.17390358448029] nn.Sequential: [nn.Linear: 0.084271423518658 nn.Linear: 0.15551054477692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010985355667952 nn.Linear: 0.00075101669038923 nn.Linear: 0.00040038991708282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015513773212669 nn.Linear: 0.0022435891098295] nn.Sequential: [nn.Linear: 0.00013963466761864 nn.Linear: 0.001444498801507]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076071531511843 nn.Linear: 0.011170974932611 nn.Linear: 0.0081999003887177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086691379547119 nn.Linear: 0.01554892770946] nn.Sequential: [nn.Linear: 0.0050022266805172 nn.Linear: 0.017617080360651]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062431103215436 nn.Linear: 0.063325864516545 nn.Linear: 0.044620770825114 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140041545247 nn.Linear: 0.039896187547718] nn.Sequential: [nn.Linear: 0.031341241634289 nn.Linear: 0.028588407169716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39108318090439 nn.Linear: 0.19053018093109 nn.Linear: 0.12548345327377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09356676787138 nn.Linear: 0.17485544085503] nn.Sequential: [nn.Linear: 0.084281027317047 nn.Linear: 0.15601305663586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097415197639181 nn.Linear: 0.00054907427090698 nn.Linear: 0.00029813215112658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012927413248489 nn.Linear: 0.0019361952002521] nn.Sequential: [nn.Linear: 0.0001044095453044 nn.Linear: 0.00092308182336212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00713697867468 nn.Linear: 0.0079531231895089 nn.Linear: 0.0060592941008508 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052296998910606 nn.Linear: 0.013646519742906] nn.Sequential: [nn.Linear: 0.0031388474162668 nn.Linear: 0.0090868957340717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062441535859154 nn.Linear: 0.063332383491993 nn.Linear: 0.044622395786374 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031400423547248 nn.Linear: 0.03992400298246] nn.Sequential: [nn.Linear: 0.031341547809005 nn.Linear: 0.02860051628342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39149558544159 nn.Linear: 0.19134968519211 nn.Linear: 0.12561729550362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093517065048218 nn.Linear: 0.17478929460049] nn.Sequential: [nn.Linear: 0.084575615823269 nn.Linear: 0.15636931359768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099984411064521 nn.Linear: 0.00063617204554421 nn.Linear: 0.00033962077139856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011807903794035 nn.Linear: 0.0014276392802203] nn.Sequential: [nn.Linear: 0.00011060706205836 nn.Linear: 0.0010250922918703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067290687002242 nn.Linear: 0.010110137984157 nn.Linear: 0.0057484898716211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054068388417363 nn.Linear: 0.0095636853948236] nn.Sequential: [nn.Linear: 0.0029100747779012 nn.Linear: 0.0085369013249874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062441993518537 nn.Linear: 0.063337534220687 nn.Linear: 0.044624546901916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140096937164 nn.Linear: 0.039985938483284] nn.Sequential: [nn.Linear: 0.031341769168997 nn.Linear: 0.028614515666604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39177483320236 nn.Linear: 0.19055306911469 nn.Linear: 0.12568247318268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093133136630058 nn.Linear: 0.17419141530991] nn.Sequential: [nn.Linear: 0.084393404424191 nn.Linear: 0.15662682056427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015247172513546 nn.Linear: 0.00094158233615695 nn.Linear: 0.0004621901553077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019860325197351 nn.Linear: 0.0034750926992819] nn.Sequential: [nn.Linear: 0.00012311472428948 nn.Linear: 0.0010350047323236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014419112354517 nn.Linear: 0.023406732827425 nn.Linear: 0.011515354737639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010270184837282 nn.Linear: 0.023226380348206] nn.Sequential: [nn.Linear: 0.0039307652041316 nn.Linear: 0.011962295509875]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062446676423895 nn.Linear: 0.063340708864213 nn.Linear: 0.044626061626848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031401118669069 nn.Linear: 0.040033003431631] nn.Sequential: [nn.Linear: 0.031342038384512 nn.Linear: 0.028636043516778]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39207345247269 nn.Linear: 0.19066597521305 nn.Linear: 0.12550641596317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09329329431057 nn.Linear: 0.17437937855721] nn.Sequential: [nn.Linear: 0.084521941840649 nn.Linear: 0.15654769539833]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023533218253095 nn.Linear: 0.0012858610347217 nn.Linear: 0.00058468888958083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002512418167207 nn.Linear: 0.004363795844252] nn.Sequential: [nn.Linear: 0.0001413865730969 nn.Linear: 0.0013437605339891]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014438213780522 nn.Linear: 0.022684305906296 nn.Linear: 0.015242708846927 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094911716878414 nn.Linear: 0.02943366765976] nn.Sequential: [nn.Linear: 0.0060089896433055 nn.Linear: 0.016187788918614]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	3880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062451063111445 nn.Linear: 0.063346699214115 nn.Linear: 0.044627152760656 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031401484313397 nn.Linear: 0.040086075697864] nn.Sequential: [nn.Linear: 0.031342258953176 nn.Linear: 0.028642948443914]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39272925257683 nn.Linear: 0.19196875393391 nn.Linear: 0.12573018670082 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093235671520233 nn.Linear: 0.17500539124012] nn.Sequential: [nn.Linear: 0.084605500102043 nn.Linear: 0.15654717385769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010103764416104 nn.Linear: 0.00071526429935091 nn.Linear: 0.00030557181445822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012037203100659 nn.Linear: 0.0017180092266943] nn.Sequential: [nn.Linear: 7.6544944530532e-05 nn.Linear: 0.00069135360634495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075257676653564 nn.Linear: 0.0092188669368625 nn.Linear: 0.0072213262319565 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005829531699419 nn.Linear: 0.011095836758614] nn.Sequential: [nn.Linear: 0.0036957270931453 nn.Linear: 0.0085885552689433]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062449979161326 nn.Linear: 0.063353128182887 nn.Linear: 0.044629422781872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031401733730384 nn.Linear: 0.040123079756597] nn.Sequential: [nn.Linear: 0.031342754767937 nn.Linear: 0.028690805687963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39326336979866 nn.Linear: 0.19179776310921 nn.Linear: 0.12562850117683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092962250113487 nn.Linear: 0.1754190325737] nn.Sequential: [nn.Linear: 0.084583304822445 nn.Linear: 0.15719875693321]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00068037321600629 nn.Linear: 0.00039922983753965 nn.Linear: 0.00020839086037467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.2245699361892e-05 nn.Linear: 0.0012615570334442] nn.Sequential: [nn.Linear: 8.2762656435646e-05 nn.Linear: 0.00092548168334908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069977398961782 nn.Linear: 0.0048448480665684 nn.Linear: 0.0036555591505021 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037255547940731 nn.Linear: 0.008500405587256] nn.Sequential: [nn.Linear: 0.0026679798029363 nn.Linear: 0.0088004600256681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062462314283425 nn.Linear: 0.063359387732721 nn.Linear: 0.044631494872046 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031402066649353 nn.Linear: 0.04015213157982] nn.Sequential: [nn.Linear: 0.031343288638964 nn.Linear: 0.028712557359172]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39353439211845 nn.Linear: 0.19165736436844 nn.Linear: 0.12574611604214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092846892774105 nn.Linear: 0.17620877921581] nn.Sequential: [nn.Linear: 0.08470331132412 nn.Linear: 0.1575054526329]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016137713435807 nn.Linear: 0.0010450800161211 nn.Linear: 0.0004718183947002 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019485285301445 nn.Linear: 0.0033896882874773] nn.Sequential: [nn.Linear: 0.00011189842518087 nn.Linear: 0.00096562644472389]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011242962442338 nn.Linear: 0.019219793379307 nn.Linear: 0.0096526732668281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065730344504118 nn.Linear: 0.015277128666639] nn.Sequential: [nn.Linear: 0.0047387001104653 nn.Linear: 0.0086560845375061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062458430415086 nn.Linear: 0.063366576205256 nn.Linear: 0.044634263058963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031402357342427 nn.Linear: 0.040200933485977] nn.Sequential: [nn.Linear: 0.031343578839965 nn.Linear: 0.02873388616488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39385229349136 nn.Linear: 0.19091202318668 nn.Linear: 0.12595748901367 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092458359897137 nn.Linear: 0.17650972306728] nn.Sequential: [nn.Linear: 0.084779858589172 nn.Linear: 0.157619997859]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010398156168921 nn.Linear: 0.00062723069367064 nn.Linear: 0.0003067506059165 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012187094512751 nn.Linear: 0.0020393547485134] nn.Sequential: [nn.Linear: 7.8182709533281e-05 nn.Linear: 0.0006621475877564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085203964263201 nn.Linear: 0.01082831248641 nn.Linear: 0.00543417269364 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052795270457864 nn.Linear: 0.01157717872411] nn.Sequential: [nn.Linear: 0.0031335579697043 nn.Linear: 0.0050467643886805]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062460580366914 nn.Linear: 0.063371854596651 nn.Linear: 0.044636592378759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031402687865786 nn.Linear: 0.040234707387924] nn.Sequential: [nn.Linear: 0.031343943702593 nn.Linear: 0.028759232468923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39446669816971 nn.Linear: 0.19138941168785 nn.Linear: 0.12580685317516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092177323997021 nn.Linear: 0.17654158174992] nn.Sequential: [nn.Linear: 0.084986843168736 nn.Linear: 0.15799978375435]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027562930431295 nn.Linear: 0.0015863860279728 nn.Linear: 0.00076902929925122 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029303294759758 nn.Linear: 0.0039734146669038] nn.Sequential: [nn.Linear: 0.00021992739739622 nn.Linear: 0.0022407537712495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020218897610903 nn.Linear: 0.033382028341293 nn.Linear: 0.02085642889142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016364408656955 nn.Linear: 0.031563226133585] nn.Sequential: [nn.Linear: 0.0077936602756381 nn.Linear: 0.033436439931393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062456921800887 nn.Linear: 0.063374943566149 nn.Linear: 0.044637562979377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031402790845594 nn.Linear: 0.040269439977175] nn.Sequential: [nn.Linear: 0.031343996577505 nn.Linear: 0.02877996742208]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39526796340942 nn.Linear: 0.19073973596096 nn.Linear: 0.12602445483208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092796504497528 nn.Linear: 0.17671029269695] nn.Sequential: [nn.Linear: 0.084856539964676 nn.Linear: 0.15796735882759]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00079235292102399 nn.Linear: 0.00048596447185995 nn.Linear: 0.00025832100503201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4691192449915e-05 nn.Linear: 0.0011846547846882] nn.Sequential: [nn.Linear: 8.9370301543446e-05 nn.Linear: 0.0010047142859462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074585839174688 nn.Linear: 0.0056767035275698 nn.Linear: 0.0053397426381707 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048563601449132 nn.Linear: 0.008728832937777] nn.Sequential: [nn.Linear: 0.002636230783537 nn.Linear: 0.010458120144904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062467496921732 nn.Linear: 0.063381724779677 nn.Linear: 0.044639404508203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031402898264657 nn.Linear: 0.04024853140325] nn.Sequential: [nn.Linear: 0.031344620184115 nn.Linear: 0.02880043421842]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39559477567673 nn.Linear: 0.1899298876524 nn.Linear: 0.12607103586197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093228802084923 nn.Linear: 0.17675973474979] nn.Sequential: [nn.Linear: 0.084897294640541 nn.Linear: 0.15826652944088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012096946893178 nn.Linear: 0.00073367479655795 nn.Linear: 0.00043345364276186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016986001459205 nn.Linear: 0.0027354459747629] nn.Sequential: [nn.Linear: 0.00020229245037645 nn.Linear: 0.0023582476302919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088271601125598 nn.Linear: 0.017200067639351 nn.Linear: 0.012384301051497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066458997316658 nn.Linear: 0.016589641571045] nn.Sequential: [nn.Linear: 0.0073590641841292 nn.Linear: 0.028717434033751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062471253527359 nn.Linear: 0.063386618717488 nn.Linear: 0.04464127951796 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031403368424808 nn.Linear: 0.040299796878642] nn.Sequential: [nn.Linear: 0.031344995445884 nn.Linear: 0.028818164692549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39615401625633 nn.Linear: 0.18988658487797 nn.Linear: 0.12586583197117 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.092959105968475 nn.Linear: 0.17675809562206] nn.Sequential: [nn.Linear: 0.08496205508709 nn.Linear: 0.15838553011417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010919199623624 nn.Linear: 0.00066036136649516 nn.Linear: 0.00034988313510912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014397706724199 nn.Linear: 0.0023628772808434] nn.Sequential: [nn.Linear: 9.5301043017672e-05 nn.Linear: 0.00091041166784157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0055785477161407 nn.Linear: 0.010587180033326 nn.Linear: 0.0059983339160681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060117063112557 nn.Linear: 0.017427505925298] nn.Sequential: [nn.Linear: 0.0036336497869343 nn.Linear: 0.0075776833109558]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062469906320453 nn.Linear: 0.063392389627551 nn.Linear: 0.044642951095028 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031403557989897 nn.Linear: 0.040344002298795] nn.Sequential: [nn.Linear: 0.031345239735853 nn.Linear: 0.028847071810453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39654940366745 nn.Linear: 0.19035375118256 nn.Linear: 0.12550283968449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093195088207722 nn.Linear: 0.17685279250145] nn.Sequential: [nn.Linear: 0.085037805140018 nn.Linear: 0.15869210660458]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00065034037158732 nn.Linear: 0.00047147528673199 nn.Linear: 0.00026677077900755 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010164247656789 nn.Linear: 0.0015408142127024] nn.Sequential: [nn.Linear: 9.9068483971801e-05 nn.Linear: 0.00096597114246878]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043979017063975 nn.Linear: 0.0064278724603355 nn.Linear: 0.0046649449504912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049683749675751 nn.Linear: 0.011278460733593] nn.Sequential: [nn.Linear: 0.0023647365160286 nn.Linear: 0.0093895541504025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062475758093409 nn.Linear: 0.063395155086356 nn.Linear: 0.044643438821694 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031403739953703 nn.Linear: 0.04035557902931] nn.Sequential: [nn.Linear: 0.031345561026414 nn.Linear: 0.028851839586152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39665320515633 nn.Linear: 0.19169141352177 nn.Linear: 0.12575432658195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093541756272316 nn.Linear: 0.17750257253647] nn.Sequential: [nn.Linear: 0.085101172327995 nn.Linear: 0.15862965583801]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023864125619327 nn.Linear: 0.0014069210465876 nn.Linear: 0.00061222761165876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002384530299272 nn.Linear: 0.0032228320693863] nn.Sequential: [nn.Linear: 0.00021483089422831 nn.Linear: 0.0023978532742591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016054563224316 nn.Linear: 0.027428910136223 nn.Linear: 0.024068549275398 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014139850623906 nn.Linear: 0.023617722094059] nn.Sequential: [nn.Linear: 0.0096459239721298 nn.Linear: 0.030911721289158]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062476476539755 nn.Linear: 0.063400267795311 nn.Linear: 0.044645685659907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031403802484237 nn.Linear: 0.040354852704738] nn.Sequential: [nn.Linear: 0.031346063292253 nn.Linear: 0.02888894729275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39720264077187 nn.Linear: 0.19096592068672 nn.Linear: 0.12557183206081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093541339039803 nn.Linear: 0.17742323875427] nn.Sequential: [nn.Linear: 0.085248872637749 nn.Linear: 0.15899421274662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012894055121504 nn.Linear: 0.00078158843918589 nn.Linear: 0.0004095912713328 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002094987668352 nn.Linear: 0.0037732667488155] nn.Sequential: [nn.Linear: 0.00013278958897025 nn.Linear: 0.001493037871952]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089231953024864 nn.Linear: 0.01281248871237 nn.Linear: 0.0069971033371985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060301679186523 nn.Linear: 0.020270153880119] nn.Sequential: [nn.Linear: 0.0034796283580363 nn.Linear: 0.015407925471663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	3990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062480220512341 nn.Linear: 0.063404928705594 nn.Linear: 0.044647033799491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031404076173297 nn.Linear: 0.040399992082641] nn.Sequential: [nn.Linear: 0.031346432753003 nn.Linear: 0.028918290319701]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39805248379707 nn.Linear: 0.19048650562763 nn.Linear: 0.12562622129917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093776889145374 nn.Linear: 0.17739042639732] nn.Sequential: [nn.Linear: 0.085079088807106 nn.Linear: 0.15910971164703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090358279987028 nn.Linear: 0.00061079587089177 nn.Linear: 0.00029890869702151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013940454371627 nn.Linear: 0.0025441793136673] nn.Sequential: [nn.Linear: 5.2183123512417e-05 nn.Linear: 0.00039341805073467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068634347990155 nn.Linear: 0.010125377215445 nn.Linear: 0.0072132982313633 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085321655496955 nn.Linear: 0.015744727104902] nn.Sequential: [nn.Linear: 0.0015951972454786 nn.Linear: 0.0032998658716679]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062484954118106 nn.Linear: 0.063410632082048 nn.Linear: 0.044648481937879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031404377313378 nn.Linear: 0.04042110716081] nn.Sequential: [nn.Linear: 0.031346666955506 nn.Linear: 0.028941848038841]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39781212806702 nn.Linear: 0.19062133133411 nn.Linear: 0.12565861642361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094167083501816 nn.Linear: 0.17715710401535] nn.Sequential: [nn.Linear: 0.084868185222149 nn.Linear: 0.15950231254101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015587997031771 nn.Linear: 0.00097907001696409 nn.Linear: 0.0003798829205708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014276345035506 nn.Linear: 0.002302460451362] nn.Sequential: [nn.Linear: 0.00013222834775452 nn.Linear: 0.0013769715118574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014833022840321 nn.Linear: 0.018123367801309 nn.Linear: 0.0068908394314349 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059219906106591 nn.Linear: 0.014845550060272] nn.Sequential: [nn.Linear: 0.0051945713348687 nn.Linear: 0.019055960699916]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.11453177631646	TD error	0.021083719536662	Qmax	1	

Steps: 4000000 (frames: 16000000), score: 1922.73, higheset score: 5708, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 90s, testing rate: 5544fps,  num. ep.: 401,  num. rewards: 19091	
   2    4    8    4
   4   16    2   32
   8  128   16    2
  16   32  128  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062485655082004 nn.Linear: 0.063414109891662 nn.Linear: 0.044648959778462 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031404687163058 nn.Linear: 0.040451448385852] nn.Sequential: [nn.Linear: 0.031346799429082 nn.Linear: 0.028961166620409]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39854604005814 nn.Linear: 0.1907085776329 nn.Linear: 0.12531141936779 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094347074627876 nn.Linear: 0.17710202932358] nn.Sequential: [nn.Linear: 0.084715455770493 nn.Linear: 0.15951749682426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024053987495655 nn.Linear: 0.0015892396931478 nn.Linear: 0.00061585980452752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022285587028854 nn.Linear: 0.0035252477555033] nn.Sequential: [nn.Linear: 0.00015639834569898 nn.Linear: 0.0014606549595233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014230255037546 nn.Linear: 0.023575300350785 nn.Linear: 0.01720904558897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011657610535622 nn.Linear: 0.034618694335222] nn.Sequential: [nn.Linear: 0.0047123241238296 nn.Linear: 0.014060038141906]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062485438127161 nn.Linear: 0.063420152949822 nn.Linear: 0.044651045052236 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031404875387226 nn.Linear: 0.040482962862029] nn.Sequential: [nn.Linear: 0.031347327658072 nn.Linear: 0.028992114060249]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39896550774574 nn.Linear: 0.19085946679115 nn.Linear: 0.12550161778927 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093924686312675 nn.Linear: 0.17770360410213] nn.Sequential: [nn.Linear: 0.08483711630106 nn.Linear: 0.159707441926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014253382013036 nn.Linear: 0.00088168654651109 nn.Linear: 0.00044591402066657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017500908532964 nn.Linear: 0.0024298416545363] nn.Sequential: [nn.Linear: 0.00017313664665703 nn.Linear: 0.0017922164567775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011096742004156 nn.Linear: 0.013977132737637 nn.Linear: 0.0092578306794167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057362597435713 nn.Linear: 0.013519691303372] nn.Sequential: [nn.Linear: 0.005242929328233 nn.Linear: 0.019640879705548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062488502816802 nn.Linear: 0.063423734332447 nn.Linear: 0.044652279033841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031405083006837 nn.Linear: 0.040528368983502] nn.Sequential: [nn.Linear: 0.031347688497657 nn.Linear: 0.02900609106723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39888066053391 nn.Linear: 0.19137427210808 nn.Linear: 0.12570402026176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094036102294922 nn.Linear: 0.17808346450329] nn.Sequential: [nn.Linear: 0.084906309843063 nn.Linear: 0.15981063246727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012525822350553 nn.Linear: 0.00083188762439247 nn.Linear: 0.00042975365894378 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015709773518006 nn.Linear: 0.0027778887048908] nn.Sequential: [nn.Linear: 0.00013563223741534 nn.Linear: 0.0015467304337385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016005547717214 nn.Linear: 0.017552673816681 nn.Linear: 0.015886100009084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011825832538307 nn.Linear: 0.017258252948523] nn.Sequential: [nn.Linear: 0.0074876016005874 nn.Linear: 0.014636431820691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062493521729882 nn.Linear: 0.063430251330937 nn.Linear: 0.044653895381142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140521681686 nn.Linear: 0.040549629279155] nn.Sequential: [nn.Linear: 0.031348091580818 nn.Linear: 0.029022643438809]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39927846193314 nn.Linear: 0.1919459104538 nn.Linear: 0.1259348243475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094236776232719 nn.Linear: 0.17832753062248] nn.Sequential: [nn.Linear: 0.084649235010147 nn.Linear: 0.15999585390091]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069044589381717 nn.Linear: 0.00047950778315216 nn.Linear: 0.00024591632607685 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010236160809318 nn.Linear: 0.0014940489756592] nn.Sequential: [nn.Linear: 8.0626358279264e-05 nn.Linear: 0.00068642760238338]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059915939345956 nn.Linear: 0.0067143561318517 nn.Linear: 0.0056596347130835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048553990200162 nn.Linear: 0.009234145283699] nn.Sequential: [nn.Linear: 0.0028946499805897 nn.Linear: 0.0063203242607415]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062497031240988 nn.Linear: 0.063431762639563 nn.Linear: 0.044655263533633 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031405476393809 nn.Linear: 0.040598101482132] nn.Sequential: [nn.Linear: 0.031348380600186 nn.Linear: 0.029047828961634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.39984712004662 nn.Linear: 0.19127902388573 nn.Linear: 0.1258819848299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094097718596458 nn.Linear: 0.17933964729309] nn.Sequential: [nn.Linear: 0.084708750247955 nn.Linear: 0.16044162213802]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013737639080034 nn.Linear: 0.0010155062312894 nn.Linear: 0.00048001554413491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018286534940744 nn.Linear: 0.0030680615609932] nn.Sequential: [nn.Linear: 0.00017223717341153 nn.Linear: 0.0020192426463019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089845079928637 nn.Linear: 0.014323142357171 nn.Linear: 0.0095891356468201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096357446163893 nn.Linear: 0.020641706883907] nn.Sequential: [nn.Linear: 0.0076930695213377 nn.Linear: 0.02203725092113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062503999610376 nn.Linear: 0.063441162281147 nn.Linear: 0.044658064275752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031405762344492 nn.Linear: 0.04065669058626] nn.Sequential: [nn.Linear: 0.031348955595305 nn.Linear: 0.029068319899957]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40030360221863 nn.Linear: 0.19167013466358 nn.Linear: 0.12592247128487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094104617834091 nn.Linear: 0.17956003546715] nn.Sequential: [nn.Linear: 0.084663949906826 nn.Linear: 0.16000850498676]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00068984037302466 nn.Linear: 0.00046098498786434 nn.Linear: 0.00023662730189867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0377740644719e-05 nn.Linear: 0.001026554839775] nn.Sequential: [nn.Linear: 6.3949828818234e-05 nn.Linear: 0.00044364044679219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052057397551835 nn.Linear: 0.0068374671973288 nn.Linear: 0.0046674027107656 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00381447118707 nn.Linear: 0.0068337107077241] nn.Sequential: [nn.Linear: 0.0019997614435852 nn.Linear: 0.0043464121408761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062511857087735 nn.Linear: 0.063446785978256 nn.Linear: 0.044659229041069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031406209261982 nn.Linear: 0.040729165314872] nn.Sequential: [nn.Linear: 0.031349110332308 nn.Linear: 0.029092680178426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40002781152725 nn.Linear: 0.19158364832401 nn.Linear: 0.12617760896683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094279080629349 nn.Linear: 0.18022602796555] nn.Sequential: [nn.Linear: 0.084764137864113 nn.Linear: 0.16042475402355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017858691145728 nn.Linear: 0.0009360460657086 nn.Linear: 0.00042184881286897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012159625830743 nn.Linear: 0.0013213964363583] nn.Sequential: [nn.Linear: 0.00015248276234494 nn.Linear: 0.001508638479495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013674041256309 nn.Linear: 0.013848032802343 nn.Linear: 0.0065988190472126 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061062281019986 nn.Linear: 0.010619915090501] nn.Sequential: [nn.Linear: 0.0041595245711505 nn.Linear: 0.02036334015429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062516651146246 nn.Linear: 0.063454462261629 nn.Linear: 0.044661372415128 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031406263697676 nn.Linear: 0.040751165609777] nn.Sequential: [nn.Linear: 0.031349660089063 nn.Linear: 0.029120623125231]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40193846821785 nn.Linear: 0.19287687540054 nn.Linear: 0.12614676356316 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094117037951946 nn.Linear: 0.18056993186474] nn.Sequential: [nn.Linear: 0.084968939423561 nn.Linear: 0.1601674258709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090744422358332 nn.Linear: 0.00067207612090316 nn.Linear: 0.00035265764909066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014943639477338 nn.Linear: 0.0025351842985744] nn.Sequential: [nn.Linear: 0.00013829527169949 nn.Linear: 0.0015015940266438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068259402178228 nn.Linear: 0.0085800085216761 nn.Linear: 0.0055820378474891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060054045170546 nn.Linear: 0.015794195234776] nn.Sequential: [nn.Linear: 0.0046840719878674 nn.Linear: 0.017229750752449]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062523274085498 nn.Linear: 0.063459035375932 nn.Linear: 0.044664179879505 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031406668045038 nn.Linear: 0.04081260123256] nn.Sequential: [nn.Linear: 0.031350077680367 nn.Linear: 0.029158334416257]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40164157748222 nn.Linear: 0.19256176054478 nn.Linear: 0.12623976171017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093961857259274 nn.Linear: 0.18040710687637] nn.Sequential: [nn.Linear: 0.084994524717331 nn.Linear: 0.16031555831432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001188830183535 nn.Linear: 0.00073606256094867 nn.Linear: 0.00037839172560146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017264460642782 nn.Linear: 0.0032720848860945] nn.Sequential: [nn.Linear: 0.00011618725619767 nn.Linear: 0.001071631697502]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076766521669924 nn.Linear: 0.012090125121176 nn.Linear: 0.0063797989860177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055584772489965 nn.Linear: 0.018419053405523] nn.Sequential: [nn.Linear: 0.0026679595466703 nn.Linear: 0.0069924700073898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062528186841761 nn.Linear: 0.063464094899176 nn.Linear: 0.044665312933744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031406924611514 nn.Linear: 0.040840364348924] nn.Sequential: [nn.Linear: 0.031350284805665 nn.Linear: 0.029178824694238]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40203365683556 nn.Linear: 0.19255943596363 nn.Linear: 0.12654328346252 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094070009887218 nn.Linear: 0.1800412684679] nn.Sequential: [nn.Linear: 0.084902130067348 nn.Linear: 0.16091291606426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015372964244239 nn.Linear: 0.00094491033709349 nn.Linear: 0.00040985921044418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014377115215571 nn.Linear: 0.0019388492738726] nn.Sequential: [nn.Linear: 0.00014294424073274 nn.Linear: 0.0013911399813495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013698531314731 nn.Linear: 0.013792879879475 nn.Linear: 0.0076252217404544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057479795068502 nn.Linear: 0.015843296423554] nn.Sequential: [nn.Linear: 0.0042187287472188 nn.Linear: 0.016670165583491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062535788155675 nn.Linear: 0.063470274848887 nn.Linear: 0.04466749568676 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031407087688678 nn.Linear: 0.040878786773229] nn.Sequential: [nn.Linear: 0.031350826058064 nn.Linear: 0.029208573694758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4023924767971 nn.Linear: 0.19208274781704 nn.Linear: 0.12691108882427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094137154519558 nn.Linear: 0.18061409890652] nn.Sequential: [nn.Linear: 0.084825217723846 nn.Linear: 0.16105146706104]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085059173837984 nn.Linear: 0.0005240391936112 nn.Linear: 0.00026001151732247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.4336184737393e-05 nn.Linear: 0.0011718023141356] nn.Sequential: [nn.Linear: 9.201129235241e-05 nn.Linear: 0.00078974634912995]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072939656674862 nn.Linear: 0.0056153242476285 nn.Linear: 0.0047954996116459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035399028565735 nn.Linear: 0.0076153953559697] nn.Sequential: [nn.Linear: 0.0034078599419445 nn.Linear: 0.0064800740219653]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062533385942438 nn.Linear: 0.063474694874275 nn.Linear: 0.044668916819354 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140741174736 nn.Linear: 0.040923163187156] nn.Sequential: [nn.Linear: 0.03135102997932 nn.Linear: 0.029234472322612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40331310033798 nn.Linear: 0.19263832271099 nn.Linear: 0.12664610147476 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09355303645134 nn.Linear: 0.18113431334496] nn.Sequential: [nn.Linear: 0.084951467812061 nn.Linear: 0.16121450066566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001138101491496 nn.Linear: 0.00066100188266722 nn.Linear: 0.00030290967721542 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011213675896229 nn.Linear: 0.001541714773147] nn.Sequential: [nn.Linear: 7.4240189009997e-05 nn.Linear: 0.00060538711224462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083568822592497 nn.Linear: 0.0092710079625249 nn.Linear: 0.0063503170385957 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046396977268159 nn.Linear: 0.010614930652082] nn.Sequential: [nn.Linear: 0.0023046063724905 nn.Linear: 0.0048419870436192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062536716724381 nn.Linear: 0.063482367634907 nn.Linear: 0.044671570883139 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031407953495736 nn.Linear: 0.040991910493113] nn.Sequential: [nn.Linear: 0.031351378004841 nn.Linear: 0.029246835586996]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40386894345284 nn.Linear: 0.19207505881786 nn.Linear: 0.12648069858551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09399701654911 nn.Linear: 0.18188355863094] nn.Sequential: [nn.Linear: 0.084961496293545 nn.Linear: 0.1613567918539]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001010124572576 nn.Linear: 0.00074739397585509 nn.Linear: 0.00037741754747615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017713760543585 nn.Linear: 0.0032652541542326] nn.Sequential: [nn.Linear: 0.00014958245317252 nn.Linear: 0.0016059492814111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082726199179888 nn.Linear: 0.011852615512908 nn.Linear: 0.01070265006274 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006167100276798 nn.Linear: 0.019432103261352] nn.Sequential: [nn.Linear: 0.0040646367706358 nn.Linear: 0.012371808290482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06253742428451 nn.Linear: 0.063484598890082 nn.Linear: 0.044673080836678 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140815689631 nn.Linear: 0.041034164174846] nn.Sequential: [nn.Linear: 0.031351857991985 nn.Linear: 0.02928233565875]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40485900640488 nn.Linear: 0.19170254468918 nn.Linear: 0.12663006782532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093739867210388 nn.Linear: 0.18232604861259] nn.Sequential: [nn.Linear: 0.084695748984814 nn.Linear: 0.16138719022274]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010291390284631 nn.Linear: 0.00065412160631033 nn.Linear: 0.00038016015484538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012094571865196 nn.Linear: 0.0016382772006898] nn.Sequential: [nn.Linear: 0.00016577802485059 nn.Linear: 0.0018352230247287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077398968860507 nn.Linear: 0.010422714985907 nn.Linear: 0.0087474044412374 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070466720499098 nn.Linear: 0.01222273055464] nn.Sequential: [nn.Linear: 0.0043294448405504 nn.Linear: 0.022242087870836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062536311264439 nn.Linear: 0.063491486413646 nn.Linear: 0.044673876457975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031408156451515 nn.Linear: 0.041021593347715] nn.Sequential: [nn.Linear: 0.031352055308312 nn.Linear: 0.029285491348982]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40580716729164 nn.Linear: 0.19156095385551 nn.Linear: 0.12680549919605 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093967720866203 nn.Linear: 0.18242052197456] nn.Sequential: [nn.Linear: 0.084689408540726 nn.Linear: 0.16149686276913]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013824742623982 nn.Linear: 0.00080376546662418 nn.Linear: 0.00038878914745919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014370929776188 nn.Linear: 0.0019343337522386] nn.Sequential: [nn.Linear: 0.000101275498231 nn.Linear: 0.00076629288187986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010278070345521 nn.Linear: 0.015937967225909 nn.Linear: 0.0081213526427746 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057018306106329 nn.Linear: 0.013871188275516] nn.Sequential: [nn.Linear: 0.0031625649426132 nn.Linear: 0.0072981771081686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06253679466074 nn.Linear: 0.063495626386314 nn.Linear: 0.044676191357245 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031408349199706 nn.Linear: 0.041056936834168] nn.Sequential: [nn.Linear: 0.031352460653202 nn.Linear: 0.029311451567259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40631681680679 nn.Linear: 0.19146022200584 nn.Linear: 0.12674526870251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094094164669514 nn.Linear: 0.18240973353386] nn.Sequential: [nn.Linear: 0.084918670356274 nn.Linear: 0.16195873916149]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069027465009148 nn.Linear: 0.00040193831031383 nn.Linear: 0.00019910164442859 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5220634725512e-05 nn.Linear: 0.0016269924683024] nn.Sequential: [nn.Linear: 7.3742967242939e-05 nn.Linear: 0.00072548930481737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0042942338623106 nn.Linear: 0.0064303884282708 nn.Linear: 0.0050286953337491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029387841932476 nn.Linear: 0.0082330266013741] nn.Sequential: [nn.Linear: 0.0018425628077239 nn.Linear: 0.0062621114775538]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062543813020296 nn.Linear: 0.063500323055666 nn.Linear: 0.04467715603212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03140860175474 nn.Linear: 0.041107220840546] nn.Sequential: [nn.Linear: 0.031352810763368 nn.Linear: 0.029334944962866]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40703710913658 nn.Linear: 0.19176457822323 nn.Linear: 0.12682332098484 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093356601893902 nn.Linear: 0.18269626796246] nn.Sequential: [nn.Linear: 0.084863543510437 nn.Linear: 0.16226418316364]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009488613587154 nn.Linear: 0.0006565869532851 nn.Linear: 0.00033361864562315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012777677283866 nn.Linear: 0.0018651792041818] nn.Sequential: [nn.Linear: 0.00012369693369435 nn.Linear: 0.0013148203232901]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077025471255183 nn.Linear: 0.0095399534329772 nn.Linear: 0.0062302402220666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051275086589158 nn.Linear: 0.014005020260811] nn.Sequential: [nn.Linear: 0.0029663513414562 nn.Linear: 0.014751027338207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062543437749236 nn.Linear: 0.063505553882924 nn.Linear: 0.04467844857442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031408786586694 nn.Linear: 0.041129630870291] nn.Sequential: [nn.Linear: 0.031353225985804 nn.Linear: 0.029354989471983]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40803435444832 nn.Linear: 0.19212409853935 nn.Linear: 0.12699855864048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093417942523956 nn.Linear: 0.18217180669308] nn.Sequential: [nn.Linear: 0.084956362843513 nn.Linear: 0.16267801821232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018011543151582 nn.Linear: 0.0011219179350533 nn.Linear: 0.00051143354194876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018925776201983 nn.Linear: 0.0029371494359376] nn.Sequential: [nn.Linear: 0.00017640006702791 nn.Linear: 0.0018291086673868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012609595432878 nn.Linear: 0.016808848828077 nn.Linear: 0.014508116059005 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072876871563494 nn.Linear: 0.017484119161963] nn.Sequential: [nn.Linear: 0.0068048764951527 nn.Linear: 0.021883133798838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062549252637154 nn.Linear: 0.063510768171582 nn.Linear: 0.044680582175976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031409184684145 nn.Linear: 0.041208673854669] nn.Sequential: [nn.Linear: 0.031353467613486 nn.Linear: 0.029383012208438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40775254368782 nn.Linear: 0.19295750558376 nn.Linear: 0.12700074911118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093227282166481 nn.Linear: 0.182956174016] nn.Sequential: [nn.Linear: 0.085058100521564 nn.Linear: 0.1627102047205]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013232950340466 nn.Linear: 0.0007593353335055 nn.Linear: 0.00037505453234211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012475207640223 nn.Linear: 0.0014499213675709] nn.Sequential: [nn.Linear: 0.00011511083763025 nn.Linear: 0.00099882752812736]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011371659114957 nn.Linear: 0.012158093042672 nn.Linear: 0.012680692598224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089088343083858 nn.Linear: 0.01275206822902] nn.Sequential: [nn.Linear: 0.0048613017424941 nn.Linear: 0.0097549166530371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062550885065597 nn.Linear: 0.063517229785981 nn.Linear: 0.04468245757196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031409351784226 nn.Linear: 0.041241752919575] nn.Sequential: [nn.Linear: 0.031353756810625 nn.Linear: 0.029400128054551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40830257534981 nn.Linear: 0.19370590150356 nn.Linear: 0.12720230221748 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093480497598648 nn.Linear: 0.18305434286594] nn.Sequential: [nn.Linear: 0.085227012634277 nn.Linear: 0.16275045275688]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020564165904858 nn.Linear: 0.0013036542875347 nn.Linear: 0.00058204551266031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020619582685671 nn.Linear: 0.0032279797428258] nn.Sequential: [nn.Linear: 0.00017500429664759 nn.Linear: 0.0017472570600858]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012494369409978 nn.Linear: 0.016429184004664 nn.Linear: 0.016817238181829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.009519780986011 nn.Linear: 0.018609397113323] nn.Sequential: [nn.Linear: 0.0047195847146213 nn.Linear: 0.018581507727504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062552275318797 nn.Linear: 0.063522542910485 nn.Linear: 0.044684107982497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031409537442328 nn.Linear: 0.041273888338793] nn.Sequential: [nn.Linear: 0.031354224466209 nn.Linear: 0.029422457280225]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40807968378067 nn.Linear: 0.19330196082592 nn.Linear: 0.12733341753483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093380205333233 nn.Linear: 0.18337540328503] nn.Sequential: [nn.Linear: 0.085135012865067 nn.Linear: 0.16258415579796]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012369085339628 nn.Linear: 0.00074487876096253 nn.Linear: 0.00034987552524853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013039422589687 nn.Linear: 0.0016559263712215] nn.Sequential: [nn.Linear: 0.00012111776111364 nn.Linear: 0.0011669620229963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080161727964878 nn.Linear: 0.010016796179116 nn.Linear: 0.0056102350354195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053829401731491 nn.Linear: 0.010599988512695] nn.Sequential: [nn.Linear: 0.0035998288076371 nn.Linear: 0.013779241591692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062553079714085 nn.Linear: 0.063525817416887 nn.Linear: 0.044684429092916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031410056621625 nn.Linear: 0.041352043391612] nn.Sequential: [nn.Linear: 0.031354454002803 nn.Linear: 0.029455997832316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40894368290901 nn.Linear: 0.19370833039284 nn.Linear: 0.1279443949461 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093389168381691 nn.Linear: 0.18409635126591] nn.Sequential: [nn.Linear: 0.08527747541666 nn.Linear: 0.16250042617321]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024389392561681 nn.Linear: 0.0014954402726135 nn.Linear: 0.00077810575096039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034264759816017 nn.Linear: 0.0056872133219297] nn.Sequential: [nn.Linear: 0.00025833426560888 nn.Linear: 0.0023699605523243]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018384598195553 nn.Linear: 0.027796622365713 nn.Linear: 0.022906066849828 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011599813587964 nn.Linear: 0.030868085101247] nn.Sequential: [nn.Linear: 0.0073035801760852 nn.Linear: 0.025619957596064]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062553048061036 nn.Linear: 0.063530613730414 nn.Linear: 0.044686777678442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031410126017202 nn.Linear: 0.041361730666424] nn.Sequential: [nn.Linear: 0.031354913845814 nn.Linear: 0.029463713306542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.40956053137779 nn.Linear: 0.19456353783607 nn.Linear: 0.12724381685257 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093353249132633 nn.Linear: 0.18461045622826] nn.Sequential: [nn.Linear: 0.085539363324642 nn.Linear: 0.16288107633591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098204737882251 nn.Linear: 0.00059487851581941 nn.Linear: 0.00033571236523559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017125335215305 nn.Linear: 0.003045082678498] nn.Sequential: [nn.Linear: 0.0001349820798976 nn.Linear: 0.0013245664137238]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066574863158166 nn.Linear: 0.010278053581715 nn.Linear: 0.0061362157575786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049934866838157 nn.Linear: 0.015426624566317] nn.Sequential: [nn.Linear: 0.0037874998524785 nn.Linear: 0.016286207363009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062555523026063 nn.Linear: 0.063536421112076 nn.Linear: 0.044687296614886 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031410455722413 nn.Linear: 0.041403572102439] nn.Sequential: [nn.Linear: 0.031355203726095 nn.Linear: 0.029492452638702]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41055101156235 nn.Linear: 0.19450365006924 nn.Linear: 0.12732404470444 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093253597617149 nn.Linear: 0.18487524986267] nn.Sequential: [nn.Linear: 0.085029616951942 nn.Linear: 0.16280682384968]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022840273761825 nn.Linear: 0.0017809009138912 nn.Linear: 0.0008760874434538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00040598113126521 nn.Linear: 0.0073875618308799] nn.Sequential: [nn.Linear: 0.00031792232689828 nn.Linear: 0.0033300020162455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025470655411482 nn.Linear: 0.033014386892319 nn.Linear: 0.022331384941936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020209891721606 nn.Linear: 0.043461542576551] nn.Sequential: [nn.Linear: 0.009292284026742 nn.Linear: 0.036604456603527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062554905501006 nn.Linear: 0.063541463186401 nn.Linear: 0.044688894595943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031410540180297 nn.Linear: 0.041429426597091] nn.Sequential: [nn.Linear: 0.031355586586006 nn.Linear: 0.029513263505686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41117072105408 nn.Linear: 0.19543533027172 nn.Linear: 0.12732110917568 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093146145343781 nn.Linear: 0.18483851850033] nn.Sequential: [nn.Linear: 0.085167624056339 nn.Linear: 0.16270685195923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0029676705283269 nn.Linear: 0.0016085625058769 nn.Linear: 0.00074372377175409 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032170213648566 nn.Linear: 0.0050332177983945] nn.Sequential: [nn.Linear: 0.00029696268563694 nn.Linear: 0.0033834170277624]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.03050690330565 nn.Linear: 0.040459044277668 nn.Linear: 0.030652116984129 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012661029584706 nn.Linear: 0.031515412032604] nn.Sequential: [nn.Linear: 0.010021715424955 nn.Linear: 0.041233357042074]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10785348239541	TD error	0.022224481955171	Qmax	1	

Steps: 4250000 (frames: 17000000), score: 1907.35, higheset score: 6256, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 89s, testing rate: 5585fps,  num. ep.: 259,  num. rewards: 14314	
   2    4    2    4
   4    2    8   32
   8   32  256    8
  16   64  512    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06256293458952 nn.Linear: 0.06354847628785 nn.Linear: 0.044691587783392 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031410983181452 nn.Linear: 0.041468872845286] nn.Sequential: [nn.Linear: 0.031356123084913 nn.Linear: 0.029541710567245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41146972775459 nn.Linear: 0.19480155408382 nn.Linear: 0.12757325172424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093058317899704 nn.Linear: 0.18499279022217] nn.Sequential: [nn.Linear: 0.085169397294521 nn.Linear: 0.16288383305073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010976549442011 nn.Linear: 0.00083652901819778 nn.Linear: 0.00045824170625829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014501777259436 nn.Linear: 0.0019777931673399] nn.Sequential: [nn.Linear: 0.00017154368223182 nn.Linear: 0.0015801486234567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085504576563835 nn.Linear: 0.01004686113447 nn.Linear: 0.0075442711822689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006320065818727 nn.Linear: 0.010475713759661] nn.Sequential: [nn.Linear: 0.0042883912101388 nn.Linear: 0.019238883629441]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06255862743864 nn.Linear: 0.063548882152985 nn.Linear: 0.044692490133424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031411118218302 nn.Linear: 0.041493885412621] nn.Sequential: [nn.Linear: 0.031356363986188 nn.Linear: 0.029555126256305]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41181626915932 nn.Linear: 0.1940893381834 nn.Linear: 0.1275456994772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093417286872864 nn.Linear: 0.18508280813694] nn.Sequential: [nn.Linear: 0.085204765200615 nn.Linear: 0.16263671219349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021624134904515 nn.Linear: 0.0012966329508069 nn.Linear: 0.00057284417047674 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015292339613622 nn.Linear: 0.0022149955650598] nn.Sequential: [nn.Linear: 0.00018129586244414 nn.Linear: 0.0019377812344515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018499277532101 nn.Linear: 0.025160344317555 nn.Linear: 0.012637788429856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00522221904248 nn.Linear: 0.01596001163125] nn.Sequential: [nn.Linear: 0.0052547110244632 nn.Linear: 0.02334189042449]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062569913361133 nn.Linear: 0.063559101970406 nn.Linear: 0.04469534344924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031411338342985 nn.Linear: 0.041523202543786] nn.Sequential: [nn.Linear: 0.031356860795476 nn.Linear: 0.029569349118023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41234329342842 nn.Linear: 0.19362144172192 nn.Linear: 0.1275432407856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09359235316515 nn.Linear: 0.18520291149616] nn.Sequential: [nn.Linear: 0.085432276129723 nn.Linear: 0.16250813007355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015695117256214 nn.Linear: 0.0010583220814316 nn.Linear: 0.00054623510976181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025759576573122 nn.Linear: 0.0042832650039912] nn.Sequential: [nn.Linear: 0.00016766706875758 nn.Linear: 0.0014526048538623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01412720605731 nn.Linear: 0.016636243090034 nn.Linear: 0.011910575442016 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086577907204628 nn.Linear: 0.028875287622213] nn.Sequential: [nn.Linear: 0.0050543211400509 nn.Linear: 0.012166855856776]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062572496772328 nn.Linear: 0.063563042016655 nn.Linear: 0.044697207603243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031411837794782 nn.Linear: 0.041601973773581] nn.Sequential: [nn.Linear: 0.031357203888158 nn.Linear: 0.029605832638514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41283077001572 nn.Linear: 0.19360609352589 nn.Linear: 0.12743961811066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09350248426199 nn.Linear: 0.18546876311302] nn.Sequential: [nn.Linear: 0.085050486028194 nn.Linear: 0.16261368989944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098425779269718 nn.Linear: 0.00057021504897605 nn.Linear: 0.0002751154501474 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013433010861179 nn.Linear: 0.00221022634631] nn.Sequential: [nn.Linear: 7.1541602483039e-05 nn.Linear: 0.00055725444563936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077542364597321 nn.Linear: 0.0071590612642467 nn.Linear: 0.00527716986835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049600088968873 nn.Linear: 0.011699083261192] nn.Sequential: [nn.Linear: 0.0029670258518308 nn.Linear: 0.0051972605288029]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581377646948 nn.Linear: 0.063570557833626 nn.Linear: 0.044699965920535 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031412381166088 nn.Linear: 0.041684802237143] nn.Sequential: [nn.Linear: 0.031357681521683 nn.Linear: 0.029637107727272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41307157278061 nn.Linear: 0.19432669878006 nn.Linear: 0.12782935798168 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094068564474583 nn.Linear: 0.1857158690691] nn.Sequential: [nn.Linear: 0.08499763160944 nn.Linear: 0.16271714866161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013694476658259 nn.Linear: 0.00086742911375434 nn.Linear: 0.0004819399604838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021532823579507 nn.Linear: 0.0039334737163874] nn.Sequential: [nn.Linear: 0.00016178272393446 nn.Linear: 0.0014780850779106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011623069643974 nn.Linear: 0.016268897801638 nn.Linear: 0.0084438119083643 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008073010481894 nn.Linear: 0.019689118489623] nn.Sequential: [nn.Linear: 0.0042065284214914 nn.Linear: 0.013418299145997]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584010259758 nn.Linear: 0.063574743741546 nn.Linear: 0.044701019245438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031412650562146 nn.Linear: 0.041722100200445] nn.Sequential: [nn.Linear: 0.031357967962153 nn.Linear: 0.029661214537755]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41306701302528 nn.Linear: 0.19423434138298 nn.Linear: 0.12801922857761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09429670125246 nn.Linear: 0.18564875423908] nn.Sequential: [nn.Linear: 0.084813311696053 nn.Linear: 0.16316169500351]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00064818362617983 nn.Linear: 0.0003997675519387 nn.Linear: 0.00021405949569544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.1116407324427e-05 nn.Linear: 0.00087802655733529] nn.Sequential: [nn.Linear: 6.9780505017081e-05 nn.Linear: 0.00054739384027144]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.003474889555946 nn.Linear: 0.0050382721237838 nn.Linear: 0.0044571105390787 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047955978661776 nn.Linear: 0.0045600417070091] nn.Sequential: [nn.Linear: 0.0015187580138445 nn.Linear: 0.0045177317224443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587722419572 nn.Linear: 0.063579543943852 nn.Linear: 0.044703541132247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031412853430766 nn.Linear: 0.041756393401243] nn.Sequential: [nn.Linear: 0.031358510473136 nn.Linear: 0.029699031208487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41432732343674 nn.Linear: 0.19518050551414 nn.Linear: 0.12783414125443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093655794858932 nn.Linear: 0.18683925271034] nn.Sequential: [nn.Linear: 0.084907658398151 nn.Linear: 0.16349172592163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00063740867814286 nn.Linear: 0.00045170198844499 nn.Linear: 0.0002617480470515 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010217391932777 nn.Linear: 0.0015236837421105] nn.Sequential: [nn.Linear: 9.4718825698402e-05 nn.Linear: 0.00089064737674763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0040856846608222 nn.Linear: 0.006025318056345 nn.Linear: 0.0054851425811648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046203504316509 nn.Linear: 0.0098265865817666] nn.Sequential: [nn.Linear: 0.0029939173255116 nn.Linear: 0.0065301023423672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587558519894 nn.Linear: 0.063584432500184 nn.Linear: 0.044704808569436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031413190628795 nn.Linear: 0.041784938359143] nn.Sequential: [nn.Linear: 0.031358694847693 nn.Linear: 0.029715685791284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41529563069344 nn.Linear: 0.19529205560684 nn.Linear: 0.12779057025909 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093816347420216 nn.Linear: 0.18671761453152] nn.Sequential: [nn.Linear: 0.084862366318703 nn.Linear: 0.16320216655731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091477971501661 nn.Linear: 0.00059681099854632 nn.Linear: 0.00032007076425732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011985182095431 nn.Linear: 0.0013992149789814] nn.Sequential: [nn.Linear: 0.00012417530402807 nn.Linear: 0.0012474085513013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079769371077418 nn.Linear: 0.010190959088504 nn.Linear: 0.0053895451128483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039710593409836 nn.Linear: 0.0073707881383598] nn.Sequential: [nn.Linear: 0.0027290133293718 nn.Linear: 0.012665340676904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584895180308 nn.Linear: 0.063588076108109 nn.Linear: 0.044705989336446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031413469710472 nn.Linear: 0.041810597138351] nn.Sequential: [nn.Linear: 0.031358944968934 nn.Linear: 0.02973931393695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41550540924072 nn.Linear: 0.19522626698017 nn.Linear: 0.12798094749451 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093740314245224 nn.Linear: 0.1869680583477] nn.Sequential: [nn.Linear: 0.085002355277538 nn.Linear: 0.16328789293766]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013650365545337 nn.Linear: 0.0009597950780478 nn.Linear: 0.00050505066510839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014099890130883 nn.Linear: 0.0020007815899161] nn.Sequential: [nn.Linear: 0.00024135286612721 nn.Linear: 0.0024180261942129]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011895196512341 nn.Linear: 0.015713037922978 nn.Linear: 0.0086378781124949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057802964001894 nn.Linear: 0.010422737337649] nn.Sequential: [nn.Linear: 0.006366434507072 nn.Linear: 0.027604423463345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062583327231371 nn.Linear: 0.063591201680746 nn.Linear: 0.044706781138585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031413506756524 nn.Linear: 0.041794142155688] nn.Sequential: [nn.Linear: 0.031359373902569 nn.Linear: 0.02975566025734]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41598296165466 nn.Linear: 0.19542752206326 nn.Linear: 0.12780460715294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093971975147724 nn.Linear: 0.1869450956583] nn.Sequential: [nn.Linear: 0.085219264030457 nn.Linear: 0.16352447867393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025388759985738 nn.Linear: 0.0019489827480878 nn.Linear: 0.00090132060323584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034127613201147 nn.Linear: 0.0055756930289423] nn.Sequential: [nn.Linear: 0.00031129967540408 nn.Linear: 0.0033869023618475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.033734515309334 nn.Linear: 0.04485946148634 nn.Linear: 0.029173301532865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013799210079014 nn.Linear: 0.035586044192314] nn.Sequential: [nn.Linear: 0.0088980896398425 nn.Linear: 0.037237077951431]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587491574023 nn.Linear: 0.063597276720815 nn.Linear: 0.044708045917359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031413660627104 nn.Linear: 0.041836091497601] nn.Sequential: [nn.Linear: 0.031359831216575 nn.Linear: 0.029784940574453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41647857427597 nn.Linear: 0.19588616490364 nn.Linear: 0.12822081148624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093903489410877 nn.Linear: 0.18742746114731] nn.Sequential: [nn.Linear: 0.085256278514862 nn.Linear: 0.16340373456478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097643089607293 nn.Linear: 0.00067368974804011 nn.Linear: 0.00035429356579615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012223640356081 nn.Linear: 0.001667883654782] nn.Sequential: [nn.Linear: 0.00013129868266123 nn.Linear: 0.0011471535543936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081768948584795 nn.Linear: 0.010078665800393 nn.Linear: 0.0067102247849107 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035141208209097 nn.Linear: 0.010403292253613] nn.Sequential: [nn.Linear: 0.0036666011437774 nn.Linear: 0.012519393116236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062593114092488 nn.Linear: 0.063605775262299 nn.Linear: 0.044711084265856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031413949990222 nn.Linear: 0.041847771759336] nn.Sequential: [nn.Linear: 0.031360403862005 nn.Linear: 0.029814522188924]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41603636741638 nn.Linear: 0.19602544605732 nn.Linear: 0.1279079169035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093617767095566 nn.Linear: 0.18766212463379] nn.Sequential: [nn.Linear: 0.085352800786495 nn.Linear: 0.16379235684872]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001259855317491 nn.Linear: 0.0007602257883708 nn.Linear: 0.00033435075495184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012789876588689 nn.Linear: 0.0020827942324672] nn.Sequential: [nn.Linear: 0.00012920076345219 nn.Linear: 0.0012076146602266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010591399855912 nn.Linear: 0.012772887013853 nn.Linear: 0.0095107508823276 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052090212702751 nn.Linear: 0.012110416777432] nn.Sequential: [nn.Linear: 0.00339315389283 nn.Linear: 0.01129505597055]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062600177046326 nn.Linear: 0.063612271475314 nn.Linear: 0.044712256892113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031414106282143 nn.Linear: 0.041877814074411] nn.Sequential: [nn.Linear: 0.031360754774921 nn.Linear: 0.029837212813341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41677099466324 nn.Linear: 0.19547317922115 nn.Linear: 0.12809051573277 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093581132590771 nn.Linear: 0.18763794004917] nn.Sequential: [nn.Linear: 0.085331991314888 nn.Linear: 0.16381876170635]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013951656157248 nn.Linear: 0.00093051071341418 nn.Linear: 0.0004856198182587 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015425586079535 nn.Linear: 0.0018780311674735] nn.Sequential: [nn.Linear: 0.00014356730178139 nn.Linear: 0.001405627788218]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092720622196794 nn.Linear: 0.012080137617886 nn.Linear: 0.0088312588632107 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074198008514941 nn.Linear: 0.010010713711381] nn.Sequential: [nn.Linear: 0.0044291201047599 nn.Linear: 0.015653122216463]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062602426344998 nn.Linear: 0.063618497773412 nn.Linear: 0.044714260640408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031414608764798 nn.Linear: 0.041939534432089] nn.Sequential: [nn.Linear: 0.031361159771819 nn.Linear: 0.029856937527652]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41719517111778 nn.Linear: 0.19521345198154 nn.Linear: 0.12867078185081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0934714153409 nn.Linear: 0.18796309828758] nn.Sequential: [nn.Linear: 0.085393026471138 nn.Linear: 0.16390588879585]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009259765371161 nn.Linear: 0.00051514482866094 nn.Linear: 0.00026282586862529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0020665665091e-05 nn.Linear: 0.00087602354757421] nn.Sequential: [nn.Linear: 9.0378453022328e-05 nn.Linear: 0.00066267919138515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063806786201894 nn.Linear: 0.0088920686393976 nn.Linear: 0.0044243913143873 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050766607746482 nn.Linear: 0.0070686279796064] nn.Sequential: [nn.Linear: 0.0029768648091704 nn.Linear: 0.0071006142534316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062607767646598 nn.Linear: 0.063626341327699 nn.Linear: 0.04471658808743 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031414795314663 nn.Linear: 0.041910860322872] nn.Sequential: [nn.Linear: 0.031361755759158 nn.Linear: 0.029889240832993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41784247756004 nn.Linear: 0.19537803530693 nn.Linear: 0.12892682850361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093863666057587 nn.Linear: 0.18825636804104] nn.Sequential: [nn.Linear: 0.085482127964497 nn.Linear: 0.16392682492733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001419544092511 nn.Linear: 0.0011377462667086 nn.Linear: 0.00053019507619232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017179007399643 nn.Linear: 0.0026669133804357] nn.Sequential: [nn.Linear: 0.00017465668980461 nn.Linear: 0.0016510866523326]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010790500789881 nn.Linear: 0.018587673082948 nn.Linear: 0.012530433014035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074116848409176 nn.Linear: 0.016383446753025] nn.Sequential: [nn.Linear: 0.0060677039436996 nn.Linear: 0.016512809321284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062604319176124 nn.Linear: 0.063627064453707 nn.Linear: 0.044717244140314 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031415165035128 nn.Linear: 0.041938673774467] nn.Sequential: [nn.Linear: 0.031361981083718 nn.Linear: 0.029906525412106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41789209842682 nn.Linear: 0.19540151953697 nn.Linear: 0.12886084616184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093664027750492 nn.Linear: 0.18900607526302] nn.Sequential: [nn.Linear: 0.085270382463932 nn.Linear: 0.16421949863434]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093100876246513 nn.Linear: 0.00070693402591366 nn.Linear: 0.00038066591937672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015073046577181 nn.Linear: 0.0021140524675507] nn.Sequential: [nn.Linear: 0.00011795934677698 nn.Linear: 0.0011242544467456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075915334746242 nn.Linear: 0.011915528215468 nn.Linear: 0.0087308678776026 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071551185101271 nn.Linear: 0.015801573172212] nn.Sequential: [nn.Linear: 0.004053654614836 nn.Linear: 0.014607110060751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062615596278995 nn.Linear: 0.063635412841691 nn.Linear: 0.044720179186399 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031415387539686 nn.Linear: 0.041987865856754] nn.Sequential: [nn.Linear: 0.031362697687909 nn.Linear: 0.029937836188505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41804298758507 nn.Linear: 0.19447608292103 nn.Linear: 0.12879188358784 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09337130188942 nn.Linear: 0.18923883140087] nn.Sequential: [nn.Linear: 0.085354059934616 nn.Linear: 0.164276227355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00075996264103831 nn.Linear: 0.00043783248629138 nn.Linear: 0.00021981337713284 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8656597125126e-05 nn.Linear: 0.0014153826434343] nn.Sequential: [nn.Linear: 7.418963621705e-05 nn.Linear: 0.00068454694171902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053457459434867 nn.Linear: 0.006053882651031 nn.Linear: 0.0040814313106239 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0037049523089081 nn.Linear: 0.0089822327718139] nn.Sequential: [nn.Linear: 0.0019719949923456 nn.Linear: 0.0076244077645242]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062614268784579 nn.Linear: 0.06363900929279 nn.Linear: 0.04472122466093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031415855313804 nn.Linear: 0.042073340922684] nn.Sequential: [nn.Linear: 0.031362615108707 nn.Linear: 0.029953452596163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41815268993378 nn.Linear: 0.19541196525097 nn.Linear: 0.12876631319523 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093435019254684 nn.Linear: 0.18959659337997] nn.Sequential: [nn.Linear: 0.085093140602112 nn.Linear: 0.16422697901726]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016501202295285 nn.Linear: 0.0011776246906082 nn.Linear: 0.00052879742967269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015431863105994 nn.Linear: 0.0019327718058526] nn.Sequential: [nn.Linear: 0.00018507871147231 nn.Linear: 0.0016674253456697]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011649907566607 nn.Linear: 0.015055014751852 nn.Linear: 0.011855335906148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007074557710439 nn.Linear: 0.013196107931435] nn.Sequential: [nn.Linear: 0.0063039530068636 nn.Linear: 0.016844598576427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062621700833834 nn.Linear: 0.063646487574651 nn.Linear: 0.044723332056881 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031416050935676 nn.Linear: 0.042107252861399] nn.Sequential: [nn.Linear: 0.031363117289516 nn.Linear: 0.029977121499041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.41796576976776 nn.Linear: 0.19546675682068 nn.Linear: 0.12858028709888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093494944274426 nn.Linear: 0.19024612009525] nn.Sequential: [nn.Linear: 0.085167273879051 nn.Linear: 0.16409510374069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027776491684025 nn.Linear: 0.0015657147955311 nn.Linear: 0.00075709718279101 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029425660235078 nn.Linear: 0.0045859985580405] nn.Sequential: [nn.Linear: 0.00015385640232272 nn.Linear: 0.0012330974121693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016025070101023 nn.Linear: 0.02554988488555 nn.Linear: 0.017756499350071 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012236349284649 nn.Linear: 0.036938272416592] nn.Sequential: [nn.Linear: 0.0047389105893672 nn.Linear: 0.010822298005223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062630077304776 nn.Linear: 0.063652292146958 nn.Linear: 0.04472531299183 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031416313499869 nn.Linear: 0.042172734170407] nn.Sequential: [nn.Linear: 0.031363291272701 nn.Linear: 0.029993064224074]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4182805120945 nn.Linear: 0.1961784362793 nn.Linear: 0.12882563471794 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093905359506607 nn.Linear: 0.18970274925232] nn.Sequential: [nn.Linear: 0.085202842950821 nn.Linear: 0.16404083371162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013849425855239 nn.Linear: 0.00092446205038371 nn.Linear: 0.00047826024327094 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015536704260775 nn.Linear: 0.0020227487981319] nn.Sequential: [nn.Linear: 0.00020561569467417 nn.Linear: 0.0020620587715672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011052655987442 nn.Linear: 0.01967503875494 nn.Linear: 0.010712042450905 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071429540403187 nn.Linear: 0.013593236915767] nn.Sequential: [nn.Linear: 0.0068383561447263 nn.Linear: 0.018483681604266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062625160071878 nn.Linear: 0.063654527554234 nn.Linear: 0.044726015402262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031416797911778 nn.Linear: 0.042216421997495] nn.Sequential: [nn.Linear: 0.031363670371431 nn.Linear: 0.030006688465417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4195930659771 nn.Linear: 0.19561663269997 nn.Linear: 0.12917603552341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093919008970261 nn.Linear: 0.18988457322121] nn.Sequential: [nn.Linear: 0.085254848003387 nn.Linear: 0.16380600631237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077235135267829 nn.Linear: 0.00044278762671188 nn.Linear: 0.00023342559463598 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.5816892777642e-05 nn.Linear: 0.0014978139915173] nn.Sequential: [nn.Linear: 8.4381568412224e-05 nn.Linear: 0.00067844974612767]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004721156321466 nn.Linear: 0.0064571537077427 nn.Linear: 0.0047790855169296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003202217631042 nn.Linear: 0.0083410125225782] nn.Sequential: [nn.Linear: 0.0029689830262214 nn.Linear: 0.0085776476189494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629975055242 nn.Linear: 0.063662212831776 nn.Linear: 0.044728870143962 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031417485943381 nn.Linear: 0.04234341782302] nn.Sequential: [nn.Linear: 0.031364102322074 nn.Linear: 0.030033252178765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42061811685562 nn.Linear: 0.19564414024353 nn.Linear: 0.12969501316547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093554317951202 nn.Linear: 0.19038319587708] nn.Sequential: [nn.Linear: 0.085236825048923 nn.Linear: 0.16379480063915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013515104277148 nn.Linear: 0.00079514469862508 nn.Linear: 0.00039090017021788 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001445018048402 nn.Linear: 0.0020516639957578] nn.Sequential: [nn.Linear: 9.2682761730277e-05 nn.Linear: 0.00075665016766385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098692430183291 nn.Linear: 0.012496222741902 nn.Linear: 0.0091250706464052 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051243994385004 nn.Linear: 0.01255953963846] nn.Sequential: [nn.Linear: 0.0022579389624298 nn.Linear: 0.0060144979506731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062635452101664 nn.Linear: 0.063666840371576 nn.Linear: 0.044731302185725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031417527909431 nn.Linear: 0.042374892674388] nn.Sequential: [nn.Linear: 0.031364202030677 nn.Linear: 0.030047775767441]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42046946287155 nn.Linear: 0.19598989188671 nn.Linear: 0.12916643917561 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093828432261944 nn.Linear: 0.19049572944641] nn.Sequential: [nn.Linear: 0.08548428863287 nn.Linear: 0.16398176550865]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017240984133088 nn.Linear: 0.00097656109625896 nn.Linear: 0.00044095547792206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014313798192084 nn.Linear: 0.0019491178415962] nn.Sequential: [nn.Linear: 0.00015576515503229 nn.Linear: 0.0013395028469304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015784315764904 nn.Linear: 0.017948338761926 nn.Linear: 0.0085575236007571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084698311984539 nn.Linear: 0.014730643481016] nn.Sequential: [nn.Linear: 0.0049159252084792 nn.Linear: 0.013008068315685]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062627469418006 nn.Linear: 0.063670325625112 nn.Linear: 0.044732560037209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031417785332648 nn.Linear: 0.042391854223283] nn.Sequential: [nn.Linear: 0.031364520456019 nn.Linear: 0.030062506502208]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42118769884109 nn.Linear: 0.19562005996704 nn.Linear: 0.12931206822395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093944154679775 nn.Linear: 0.19110254943371] nn.Sequential: [nn.Linear: 0.085542850196362 nn.Linear: 0.16431328654289]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016911041080227 nn.Linear: 0.001031378597403 nn.Linear: 0.00042651721372738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021490863024334 nn.Linear: 0.0038397459198038] nn.Sequential: [nn.Linear: 9.7397657267102e-05 nn.Linear: 0.00088365425867301]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015348916873336 nn.Linear: 0.020221943035722 nn.Linear: 0.014880287460983 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064066522754729 nn.Linear: 0.020301721990108] nn.Sequential: [nn.Linear: 0.0031020587775856 nn.Linear: 0.0092389555647969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637860064004 nn.Linear: 0.063678795991506 nn.Linear: 0.044735383503018 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031418268424439 nn.Linear: 0.042430410499591] nn.Sequential: [nn.Linear: 0.031365087344952 nn.Linear: 0.030110528459593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42151707410812 nn.Linear: 0.19645997881889 nn.Linear: 0.12940655648708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094103753566742 nn.Linear: 0.19152861833572] nn.Sequential: [nn.Linear: 0.085512794554234 nn.Linear: 0.16484743356705]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015451528128271 nn.Linear: 0.00099600368051875 nn.Linear: 0.00044589758955619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018245217515927 nn.Linear: 0.0028560726973725] nn.Sequential: [nn.Linear: 0.00011865670751644 nn.Linear: 0.0010336554421704]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012398539111018 nn.Linear: 0.017641322687268 nn.Linear: 0.0093598952516913 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075551522895694 nn.Linear: 0.020934177562594] nn.Sequential: [nn.Linear: 0.0033304593525827 nn.Linear: 0.008836374618113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10027315944433	TD error	0.022134961374104	Qmax	1	

Steps: 4500000 (frames: 18000000), score: 1849.37, higheset score: 5932, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 90s, testing rate: 5551fps,  num. ep.: 373,  num. rewards: 18340	
   4    2   16    2
   2    4   32    4
   4   16  256   32
   2    4   16  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643624057952 nn.Linear: 0.06368536792294 nn.Linear: 0.044737653544301 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031418620621333 nn.Linear: 0.042508345965075] nn.Sequential: [nn.Linear: 0.031365345309544 nn.Linear: 0.030129574532796]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42231503129005 nn.Linear: 0.1956253349781 nn.Linear: 0.12894533574581 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094134069979191 nn.Linear: 0.19209299981594] nn.Sequential: [nn.Linear: 0.085672840476036 nn.Linear: 0.16505777835846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017160039783436 nn.Linear: 0.0010497794791164 nn.Linear: 0.00049099567784595 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015782704679365 nn.Linear: 0.0019281365988659] nn.Sequential: [nn.Linear: 0.00015504292927782 nn.Linear: 0.001226219576314]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011311138980091 nn.Linear: 0.015277205966413 nn.Linear: 0.0082289036363363 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075352438725531 nn.Linear: 0.018147639930248] nn.Sequential: [nn.Linear: 0.0066257477737963 nn.Linear: 0.014116344042122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062654376826337 nn.Linear: 0.06369203012955 nn.Linear: 0.044739291691856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031418762844595 nn.Linear: 0.042541739993126] nn.Sequential: [nn.Linear: 0.031365842336617 nn.Linear: 0.030165382033473]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42203822731972 nn.Linear: 0.19583268463612 nn.Linear: 0.12930457293987 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094275392591953 nn.Linear: 0.19184266030788] nn.Sequential: [nn.Linear: 0.085699811577797 nn.Linear: 0.1655608266592]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015991564848702 nn.Linear: 0.0009978880116847 nn.Linear: 0.00045268752355721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016630122813504 nn.Linear: 0.0027245495384589] nn.Sequential: [nn.Linear: 0.00013033820634266 nn.Linear: 0.0015173722636191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011831441894174 nn.Linear: 0.020867018029094 nn.Linear: 0.012392890639603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053959162905812 nn.Linear: 0.015506026335061] nn.Sequential: [nn.Linear: 0.0045041423290968 nn.Linear: 0.017432786524296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062652476581603 nn.Linear: 0.063695115901294 nn.Linear: 0.044741125712808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031418901875597 nn.Linear: 0.042566689542983] nn.Sequential: [nn.Linear: 0.031366163331814 nn.Linear: 0.030169459553557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42253977060318 nn.Linear: 0.19619031250477 nn.Linear: 0.12964545190334 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094406090676785 nn.Linear: 0.19176858663559] nn.Sequential: [nn.Linear: 0.085842326283455 nn.Linear: 0.16549244523048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010013813039036 nn.Linear: 0.00073407958160494 nn.Linear: 0.00035657296751294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011836408584739 nn.Linear: 0.0013086388128186] nn.Sequential: [nn.Linear: 0.00012391091527777 nn.Linear: 0.0011853629430094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072891628369689 nn.Linear: 0.0091677773743868 nn.Linear: 0.0075512798503041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054120528511703 nn.Linear: 0.0096769649535418] nn.Sequential: [nn.Linear: 0.0042997081764042 nn.Linear: 0.014859538525343]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062655145519835 nn.Linear: 0.063699550944601 nn.Linear: 0.044743714796749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031419381625457 nn.Linear: 0.042625478381488] nn.Sequential: [nn.Linear: 0.031366495531757 nn.Linear: 0.030199947298006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42266920208931 nn.Linear: 0.19529648125172 nn.Linear: 0.12966348230839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094404354691505 nn.Linear: 0.19256840646267] nn.Sequential: [nn.Linear: 0.085576392710209 nn.Linear: 0.16559249162674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012451233547097 nn.Linear: 0.00082752774951676 nn.Linear: 0.00046088514675379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019444224396373 nn.Linear: 0.0033622646007507] nn.Sequential: [nn.Linear: 0.00014368205649482 nn.Linear: 0.0014039301364746]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010262569412589 nn.Linear: 0.013458819128573 nn.Linear: 0.013302035629749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071326936595142 nn.Linear: 0.023780189454556] nn.Sequential: [nn.Linear: 0.0048750014975667 nn.Linear: 0.019039256498218]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062663323584144 nn.Linear: 0.06370169534185 nn.Linear: 0.044745098116065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031419711305222 nn.Linear: 0.042687012095584] nn.Sequential: [nn.Linear: 0.03136673374987 nn.Linear: 0.030228215183401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42295008897781 nn.Linear: 0.19620582461357 nn.Linear: 0.1296035349369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094053886830807 nn.Linear: 0.19274477660656] nn.Sequential: [nn.Linear: 0.085781030356884 nn.Linear: 0.16532781720161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082467184030571 nn.Linear: 0.00053457974138329 nn.Linear: 0.00028915282883805 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.9021903568189e-05 nn.Linear: 0.0010532656714728] nn.Sequential: [nn.Linear: 0.00013323770787188 nn.Linear: 0.0013349109648709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062344395555556 nn.Linear: 0.0077906372025609 nn.Linear: 0.0074922521598637 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047944909892976 nn.Linear: 0.0074367341585457] nn.Sequential: [nn.Linear: 0.0060404296964407 nn.Linear: 0.012550174258649]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06266300658512 nn.Linear: 0.063708559460778 nn.Linear: 0.044746715798592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031420065080428 nn.Linear: 0.042735849287055] nn.Sequential: [nn.Linear: 0.031367213714198 nn.Linear: 0.030266005924]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42271956801414 nn.Linear: 0.1956765204668 nn.Linear: 0.12996849417686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094253428280354 nn.Linear: 0.19402223825455] nn.Sequential: [nn.Linear: 0.086063846945763 nn.Linear: 0.16567146778107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096965074045769 nn.Linear: 0.00065644967534243 nn.Linear: 0.00038027077188412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015200964818021 nn.Linear: 0.0022952685776456] nn.Sequential: [nn.Linear: 0.00015682906962544 nn.Linear: 0.0017859072769936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056666908785701 nn.Linear: 0.012979683466256 nn.Linear: 0.0076139224693179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057711466215551 nn.Linear: 0.014607378281653] nn.Sequential: [nn.Linear: 0.005396593362093 nn.Linear: 0.020466776564717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062661171039656 nn.Linear: 0.063713306017968 nn.Linear: 0.04474914885985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031420174002057 nn.Linear: 0.042725248143512] nn.Sequential: [nn.Linear: 0.031367923749465 nn.Linear: 0.030293003328554]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42390817403793 nn.Linear: 0.19588929414749 nn.Linear: 0.13004027307034 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094300113618374 nn.Linear: 0.19423744082451] nn.Sequential: [nn.Linear: 0.086079820990562 nn.Linear: 0.16594623029232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018329702364644 nn.Linear: 0.0010879850676971 nn.Linear: 0.00050004144354066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018190244173689 nn.Linear: 0.0026900171317044] nn.Sequential: [nn.Linear: 0.00012237924431975 nn.Linear: 0.0010728065285611]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096109369769692 nn.Linear: 0.017875384539366 nn.Linear: 0.01110821403563 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007782518863678 nn.Linear: 0.017685152590275] nn.Sequential: [nn.Linear: 0.0043591279536486 nn.Linear: 0.013229236006737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062668251928538 nn.Linear: 0.063720754639115 nn.Linear: 0.044751609733393 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031420544459323 nn.Linear: 0.042789690249151] nn.Sequential: [nn.Linear: 0.031368705805874 nn.Linear: 0.030335991121316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42432415485382 nn.Linear: 0.1966824233532 nn.Linear: 0.13022015988827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.093775801360607 nn.Linear: 0.19485965371132] nn.Sequential: [nn.Linear: 0.086408831179142 nn.Linear: 0.16655904054642]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011659471042605 nn.Linear: 0.00085071498393785 nn.Linear: 0.00042916238886991 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021079338614263 nn.Linear: 0.0037722212934011] nn.Sequential: [nn.Linear: 9.8902786191367e-05 nn.Linear: 0.00076916038856411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087715880945325 nn.Linear: 0.013635202310979 nn.Linear: 0.0069805039092898 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010386598296463 nn.Linear: 0.022432155907154] nn.Sequential: [nn.Linear: 0.0026746010407805 nn.Linear: 0.0073509970679879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672155844474 nn.Linear: 0.063726393639828 nn.Linear: 0.044753929606498 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142091501321 nn.Linear: 0.042851216638809] nn.Sequential: [nn.Linear: 0.031368993829644 nn.Linear: 0.030353975539184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42440348863602 nn.Linear: 0.19766512513161 nn.Linear: 0.13002113997936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094382166862488 nn.Linear: 0.19495695829391] nn.Sequential: [nn.Linear: 0.086626417934895 nn.Linear: 0.1666951328516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016212075454994 nn.Linear: 0.00096800479205917 nn.Linear: 0.00046783667059346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012180984502168 nn.Linear: 0.0013896491569073] nn.Sequential: [nn.Linear: 0.00017492133752221 nn.Linear: 0.0019603437075228]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011319516226649 nn.Linear: 0.012909713201225 nn.Linear: 0.011590334586799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059235473163426 nn.Linear: 0.0093321343883872] nn.Sequential: [nn.Linear: 0.0055854334495962 nn.Linear: 0.018522115424275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062677071600479 nn.Linear: 0.063731637164328 nn.Linear: 0.04475664374894 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031421342730674 nn.Linear: 0.042908362370042] nn.Sequential: [nn.Linear: 0.031369518327396 nn.Linear: 0.030370679473588]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42597630620003 nn.Linear: 0.19833643734455 nn.Linear: 0.13007780909538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094799034297466 nn.Linear: 0.19522716104984] nn.Sequential: [nn.Linear: 0.086481034755707 nn.Linear: 0.16672310233116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010825620340796 nn.Linear: 0.00072978863317966 nn.Linear: 0.00042995194719272 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018593213312327 nn.Linear: 0.0029363513182628] nn.Sequential: [nn.Linear: 0.0001799965089819 nn.Linear: 0.001721327032658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0093391928821802 nn.Linear: 0.0082602268084884 nn.Linear: 0.0081823850050569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056641856208444 nn.Linear: 0.017001438885927] nn.Sequential: [nn.Linear: 0.0046948497183621 nn.Linear: 0.013441611081362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062674839629691 nn.Linear: 0.063740539629699 nn.Linear: 0.044758146971016 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031421402219555 nn.Linear: 0.042947434259418] nn.Sequential: [nn.Linear: 0.031369986205241 nn.Linear: 0.030400393020951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42612740397453 nn.Linear: 0.19680646061897 nn.Linear: 0.12986335158348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094810001552105 nn.Linear: 0.19557988643646] nn.Sequential: [nn.Linear: 0.086617261171341 nn.Linear: 0.16639302670956]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015077371500098 nn.Linear: 0.0010075974831996 nn.Linear: 0.00048756070761931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024422614037686 nn.Linear: 0.0042559473347752] nn.Sequential: [nn.Linear: 0.00012152651477882 nn.Linear: 0.0010691166623899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091474317014217 nn.Linear: 0.015227845869958 nn.Linear: 0.01047285925597 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099875871092081 nn.Linear: 0.027772476896644] nn.Sequential: [nn.Linear: 0.0028507821261883 nn.Linear: 0.0094874696806073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678132523101 nn.Linear: 0.063745490564686 nn.Linear: 0.04476030289777 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031421717033143 nn.Linear: 0.043011123730736] nn.Sequential: [nn.Linear: 0.031370406949522 nn.Linear: 0.030433399498993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42613896727562 nn.Linear: 0.19738481938839 nn.Linear: 0.12967851758003 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094635717570782 nn.Linear: 0.19608923792839] nn.Sequential: [nn.Linear: 0.086674802005291 nn.Linear: 0.16674543917179]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020222126265536 nn.Linear: 0.0013114462541399 nn.Linear: 0.00066886046398028 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023449234821133 nn.Linear: 0.0032292631593465] nn.Sequential: [nn.Linear: 0.00021895148343725 nn.Linear: 0.0022852872537363]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015193697065115 nn.Linear: 0.02157018519938 nn.Linear: 0.017512656748295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013152937404811 nn.Linear: 0.02797925658524] nn.Sequential: [nn.Linear: 0.0086911339312792 nn.Linear: 0.028000140562654]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062679897461378 nn.Linear: 0.063753240470539 nn.Linear: 0.044763067896373 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031421949123527 nn.Linear: 0.043054394761594] nn.Sequential: [nn.Linear: 0.031370969769176 nn.Linear: 0.030467778277158]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42724943161011 nn.Linear: 0.19740083813667 nn.Linear: 0.13037763535976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094611831009388 nn.Linear: 0.1969368159771] nn.Sequential: [nn.Linear: 0.086929962038994 nn.Linear: 0.16709980368614]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021311243347731 nn.Linear: 0.0014637173316431 nn.Linear: 0.00072946358680343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003085690014661 nn.Linear: 0.0042125536663265] nn.Sequential: [nn.Linear: 0.0002398663647807 nn.Linear: 0.0019863282003914]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010122229345143 nn.Linear: 0.021756263449788 nn.Linear: 0.016019131988287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011883968487382 nn.Linear: 0.024617461487651] nn.Sequential: [nn.Linear: 0.0065651023760438 nn.Linear: 0.020785538479686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062688389884677 nn.Linear: 0.063763408156226 nn.Linear: 0.04476618141779 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142224295354 nn.Linear: 0.04311562991596] nn.Sequential: [nn.Linear: 0.031371492150074 nn.Linear: 0.030488983518884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42773431539536 nn.Linear: 0.19737879931927 nn.Linear: 0.13012400269508 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0948705971241 nn.Linear: 0.19696268439293] nn.Sequential: [nn.Linear: 0.08686925470829 nn.Linear: 0.16713100671768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012993649002176 nn.Linear: 0.00091030625374372 nn.Linear: 0.00041875284136224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012866588270107 nn.Linear: 0.0017863764134782] nn.Sequential: [nn.Linear: 0.00018762302577203 nn.Linear: 0.0017463890036384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012859085574746 nn.Linear: 0.014526125974953 nn.Linear: 0.0099831493571401 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052811168134212 nn.Linear: 0.012408019974828] nn.Sequential: [nn.Linear: 0.005289594642818 nn.Linear: 0.017025863751769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062683512693694 nn.Linear: 0.063766302943784 nn.Linear: 0.044767481976371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031423052138085 nn.Linear: 0.043221531377057] nn.Sequential: [nn.Linear: 0.031371525925168 nn.Linear: 0.030512608047616]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42865628004074 nn.Linear: 0.19663785398006 nn.Linear: 0.13048553466797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094626978039742 nn.Linear: 0.19664968550205] nn.Sequential: [nn.Linear: 0.086561731994152 nn.Linear: 0.16707068681717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014235946324751 nn.Linear: 0.00096307502681526 nn.Linear: 0.00051687028066224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018940091985126 nn.Linear: 0.0024770859978105] nn.Sequential: [nn.Linear: 0.00019168458433894 nn.Linear: 0.0019577351956932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012020767666399 nn.Linear: 0.011669437400997 nn.Linear: 0.011218341067433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088736237958074 nn.Linear: 0.019502179697156] nn.Sequential: [nn.Linear: 0.0061520291492343 nn.Linear: 0.02021480165422]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062690290261163 nn.Linear: 0.063774324000226 nn.Linear: 0.044770344799624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031423357116915 nn.Linear: 0.043277742726445] nn.Sequential: [nn.Linear: 0.031372069708359 nn.Linear: 0.0305351033557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42901402711868 nn.Linear: 0.19685795903206 nn.Linear: 0.13008749485016 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094754070043564 nn.Linear: 0.19736671447754] nn.Sequential: [nn.Linear: 0.086900219321251 nn.Linear: 0.16754400730133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0006468338099844 nn.Linear: 0.00038742653692406 nn.Linear: 0.00021022522146324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.3075565992337e-05 nn.Linear: 0.00084149948708312] nn.Sequential: [nn.Linear: 8.2758672767992e-05 nn.Linear: 0.00090508894768138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043989885598421 nn.Linear: 0.0084876278415322 nn.Linear: 0.0050175315700471 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033098696731031 nn.Linear: 0.0056938990019262] nn.Sequential: [nn.Linear: 0.0023586566094309 nn.Linear: 0.0097617730498314]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698446983887 nn.Linear: 0.063781070217805 nn.Linear: 0.044771934587896 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142340334053 nn.Linear: 0.04327279937425] nn.Sequential: [nn.Linear: 0.031372595152186 nn.Linear: 0.030557949342934]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42915531992912 nn.Linear: 0.1973265260458 nn.Linear: 0.13042178750038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094754785299301 nn.Linear: 0.19750860333443] nn.Sequential: [nn.Linear: 0.086983129382133 nn.Linear: 0.16743615269661]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030109276903261 nn.Linear: 0.0019336705932134 nn.Linear: 0.00088061137046831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033467182575845 nn.Linear: 0.0048593209852239] nn.Sequential: [nn.Linear: 0.00023979919168382 nn.Linear: 0.0022853546823415]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021099742501974 nn.Linear: 0.035179823637009 nn.Linear: 0.018813041970134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018037106841803 nn.Linear: 0.035388514399529] nn.Sequential: [nn.Linear: 0.0085561219602823 nn.Linear: 0.017920035868883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698121497154 nn.Linear: 0.063788387469207 nn.Linear: 0.04477367265077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031423539029205 nn.Linear: 0.043286201475691] nn.Sequential: [nn.Linear: 0.031373010745777 nn.Linear: 0.030587786525123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42931124567986 nn.Linear: 0.19729235768318 nn.Linear: 0.13008943200111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094842575490475 nn.Linear: 0.19772431254387] nn.Sequential: [nn.Linear: 0.086989559233189 nn.Linear: 0.16754513978958]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011155735804292 nn.Linear: 0.00076258327579189 nn.Linear: 0.00041419941077182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018433935247452 nn.Linear: 0.0022319216067378] nn.Sequential: [nn.Linear: 0.00014353967688678 nn.Linear: 0.0013195963018499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060075526125729 nn.Linear: 0.010743148624897 nn.Linear: 0.009679070673883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013227146118879 nn.Linear: 0.015287767164409] nn.Sequential: [nn.Linear: 0.0033545373007655 nn.Linear: 0.01286480948329]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062699703889292 nn.Linear: 0.063795517671688 nn.Linear: 0.044776734387339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424160209126 nn.Linear: 0.043337340917347] nn.Sequential: [nn.Linear: 0.031373246017259 nn.Linear: 0.030609151440313]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42971286177635 nn.Linear: 0.19672894477844 nn.Linear: 0.13014931976795 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094771385192871 nn.Linear: 0.19818043708801] nn.Sequential: [nn.Linear: 0.086991839110851 nn.Linear: 0.16756923496723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010126467316516 nn.Linear: 0.00063436224607336 nn.Linear: 0.00036828290231543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001562374573835 nn.Linear: 0.0025893988062458] nn.Sequential: [nn.Linear: 0.00014050175618672 nn.Linear: 0.0012618146893643]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072591523639858 nn.Linear: 0.0099435355514288 nn.Linear: 0.00769222388044 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049285758286715 nn.Linear: 0.015536084771156] nn.Sequential: [nn.Linear: 0.0036554567050189 nn.Linear: 0.0095897242426872]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06269734704873 nn.Linear: 0.063800696179382 nn.Linear: 0.044778369229926 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424380320334 nn.Linear: 0.043400417733352] nn.Sequential: [nn.Linear: 0.03137367672217 nn.Linear: 0.030628652896173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.42981469631195 nn.Linear: 0.19705279171467 nn.Linear: 0.13023060560226 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094921253621578 nn.Linear: 0.19909279048443] nn.Sequential: [nn.Linear: 0.087271593511105 nn.Linear: 0.16762918233871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094840172300623 nn.Linear: 0.00056682512047597 nn.Linear: 0.00030331432000168 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011327169831331 nn.Linear: 0.0014599549228686] nn.Sequential: [nn.Linear: 0.00010287811409161 nn.Linear: 0.0009528879216281]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052883005701005 nn.Linear: 0.0062182638794184 nn.Linear: 0.0056287427432835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0041811498813331 nn.Linear: 0.010543812997639] nn.Sequential: [nn.Linear: 0.0038058084901422 nn.Linear: 0.0078868949785829]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062706138866572 nn.Linear: 0.063807315515286 nn.Linear: 0.044780660444324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424776049568 nn.Linear: 0.043484376295623] nn.Sequential: [nn.Linear: 0.03137432651974 nn.Linear: 0.030679031287466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4305177628994 nn.Linear: 0.19854660332203 nn.Linear: 0.13039627671242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094619750976562 nn.Linear: 0.19952015578747] nn.Sequential: [nn.Linear: 0.087170764803886 nn.Linear: 0.16817505657673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086878280693667 nn.Linear: 0.00057429019386695 nn.Linear: 0.00031509304729402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010600129962755 nn.Linear: 0.0012277691958725] nn.Sequential: [nn.Linear: 0.00010651918566163 nn.Linear: 0.00089372360316125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079781394451857 nn.Linear: 0.009770599193871 nn.Linear: 0.0055515146814287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007535157725215 nn.Linear: 0.0085816970095038] nn.Sequential: [nn.Linear: 0.0044029150158167 nn.Linear: 0.0091254087164998]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062712348025982 nn.Linear: 0.063813710002831 nn.Linear: 0.044783149561359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424855559461 nn.Linear: 0.043554576031454] nn.Sequential: [nn.Linear: 0.03137487657711 nn.Linear: 0.030718844604319]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43073409795761 nn.Linear: 0.19806832075119 nn.Linear: 0.13052432239056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094314947724342 nn.Linear: 0.20003832876682] nn.Sequential: [nn.Linear: 0.087570063769817 nn.Linear: 0.16847242414951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001449673004584 nn.Linear: 0.001003994525969 nn.Linear: 0.00049222330436218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022592012698306 nn.Linear: 0.0038238585764176] nn.Sequential: [nn.Linear: 0.00012025447324494 nn.Linear: 0.0010967601286724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008858835324645 nn.Linear: 0.013931084424257 nn.Linear: 0.0085004270076752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011271264404058 nn.Linear: 0.030210534110665] nn.Sequential: [nn.Linear: 0.0034936256706715 nn.Linear: 0.014582824893296]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062717477119948 nn.Linear: 0.063820066974099 nn.Linear: 0.044785605294745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425414488376 nn.Linear: 0.04363044365391] nn.Sequential: [nn.Linear: 0.031375271124974 nn.Linear: 0.030743415853774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43140694499016 nn.Linear: 0.1983118802309 nn.Linear: 0.13047511875629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094281174242496 nn.Linear: 0.20014564692974] nn.Sequential: [nn.Linear: 0.087679766118526 nn.Linear: 0.16856878995895]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097271496202606 nn.Linear: 0.00057598078331637 nn.Linear: 0.00032967083565745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013025530019903 nn.Linear: 0.0019087473202886] nn.Sequential: [nn.Linear: 0.00012046846498435 nn.Linear: 0.0010073699308494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062008746899664 nn.Linear: 0.0092682307586074 nn.Linear: 0.0057463049888611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053946361877024 nn.Linear: 0.01379721891135] nn.Sequential: [nn.Linear: 0.0042789899744093 nn.Linear: 0.0075098183006048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062719326188616 nn.Linear: 0.063827157771308 nn.Linear: 0.044788929570825 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425982432921 nn.Linear: 0.043723462537855] nn.Sequential: [nn.Linear: 0.031375760329941 nn.Linear: 0.030765717206499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43248075246811 nn.Linear: 0.19914145767689 nn.Linear: 0.13053928315639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094129666686058 nn.Linear: 0.20139072835445] nn.Sequential: [nn.Linear: 0.087654881179333 nn.Linear: 0.16903127729893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018219967874261 nn.Linear: 0.0011729369006999 nn.Linear: 0.0005196996436565 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018636468240063 nn.Linear: 0.0026225542131448] nn.Sequential: [nn.Linear: 0.00013857826583475 nn.Linear: 0.0011690502779981]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014421803876758 nn.Linear: 0.027740981429815 nn.Linear: 0.016730759292841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075570340268314 nn.Linear: 0.022716332226992] nn.Sequential: [nn.Linear: 0.0036685625091195 nn.Linear: 0.012260081246495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062724807410895 nn.Linear: 0.063837337740088 nn.Linear: 0.044792485484197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426510534769 nn.Linear: 0.043758637960764] nn.Sequential: [nn.Linear: 0.031376506346662 nn.Linear: 0.030788421269123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43303826451302 nn.Linear: 0.19917783141136 nn.Linear: 0.1304823756218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094201803207397 nn.Linear: 0.20144985616207] nn.Sequential: [nn.Linear: 0.087751641869545 nn.Linear: 0.16903321444988]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015318830129436 nn.Linear: 0.00086812696493358 nn.Linear: 0.00039513978145403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001260721828613 nn.Linear: 0.001632448039521] nn.Sequential: [nn.Linear: 0.00017089805613739 nn.Linear: 0.0019998194731554]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097114481031895 nn.Linear: 0.018223909661174 nn.Linear: 0.010970747098327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066390386782587 nn.Linear: 0.011504141613841] nn.Sequential: [nn.Linear: 0.0062274667434394 nn.Linear: 0.025548815727234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.10477069433033	TD error	0.021216032028198	Qmax	1	

Steps: 4750000 (frames: 19000000), score: 1587.82, higheset score: 6176, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1810fps, testing time: 90s, testing rate: 5530fps,  num. ep.: 547,  num. rewards: 21634	
   2    4    8    2
   4   16   32    4
   8    2   64    8
   2   32  256  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062710933518061 nn.Linear: 0.063831561350404 nn.Linear: 0.044789075214787 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425819873497 nn.Linear: 0.043659450630742] nn.Sequential: [nn.Linear: 0.031375885889911 nn.Linear: 0.030754384109066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43218609690666 nn.Linear: 0.1988719701767 nn.Linear: 0.13050620257854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094057165086269 nn.Linear: 0.2007759064436] nn.Sequential: [nn.Linear: 0.087856285274029 nn.Linear: 0.16833640635014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00058125684969444 nn.Linear: 0.00040341036387546 nn.Linear: 0.00019566918156752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.513833467329e-05 nn.Linear: 0.00084234459841299] nn.Sequential: [nn.Linear: 7.1530670895144e-05 nn.Linear: 0.0005175224502514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046225697733462 nn.Linear: 0.0075023425742984 nn.Linear: 0.004610990639776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030267750844359 nn.Linear: 0.0065846522338688] nn.Sequential: [nn.Linear: 0.0024474586825818 nn.Linear: 0.0057903882116079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062702637533443 nn.Linear: 0.063827663765464 nn.Linear: 0.044787647002597 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425581321964 nn.Linear: 0.043585990605564] nn.Sequential: [nn.Linear: 0.031375647470886 nn.Linear: 0.030733117244387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43223550915718 nn.Linear: 0.19846507906914 nn.Linear: 0.13014222681522 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094467304646969 nn.Linear: 0.20041696727276] nn.Sequential: [nn.Linear: 0.087699599564075 nn.Linear: 0.16843241453171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010112443987573 nn.Linear: 0.00070658023550271 nn.Linear: 0.00038790855513907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016784320555173 nn.Linear: 0.0027344592270114] nn.Sequential: [nn.Linear: 8.7928601560831e-05 nn.Linear: 0.00067292773102662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070090596564114 nn.Linear: 0.0099460817873478 nn.Linear: 0.008987688459456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060196267440915 nn.Linear: 0.015260949730873] nn.Sequential: [nn.Linear: 0.0023485766723752 nn.Linear: 0.007096872664988]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062685606903809 nn.Linear: 0.063823181892233 nn.Linear: 0.044786356971905 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425102890108 nn.Linear: 0.043516462992784] nn.Sequential: [nn.Linear: 0.031375346430306 nn.Linear: 0.030708000918114]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43286997079849 nn.Linear: 0.19835013151169 nn.Linear: 0.13014224171638 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094580173492432 nn.Linear: 0.20007021725178] nn.Sequential: [nn.Linear: 0.087848380208015 nn.Linear: 0.16836230456829]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00074981366087064 nn.Linear: 0.00043523868628559 nn.Linear: 0.00023057322152324 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.0413688886905e-05 nn.Linear: 0.00096833765918314] nn.Sequential: [nn.Linear: 0.00010505038691815 nn.Linear: 0.00119639575266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054360628128052 nn.Linear: 0.0058953766711056 nn.Linear: 0.004377584438771 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034043847117573 nn.Linear: 0.007043045014143] nn.Sequential: [nn.Linear: 0.0030906612519175 nn.Linear: 0.014711695723236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06267936204629 nn.Linear: 0.063820525624708 nn.Linear: 0.044785636742187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424929453977 nn.Linear: 0.043467061796363] nn.Sequential: [nn.Linear: 0.031375120691574 nn.Linear: 0.030699583034381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43259048461914 nn.Linear: 0.19816580414772 nn.Linear: 0.13039134442806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094773322343826 nn.Linear: 0.20001788437366] nn.Sequential: [nn.Linear: 0.087802805006504 nn.Linear: 0.16813522577286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013741232355506 nn.Linear: 0.0010254984379612 nn.Linear: 0.00051366306724529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027178411414495 nn.Linear: 0.0050727244970037] nn.Sequential: [nn.Linear: 0.00010598613909158 nn.Linear: 0.00085235832560639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012413690797985 nn.Linear: 0.01764458604157 nn.Linear: 0.013014278374612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087135033681989 nn.Linear: 0.041740089654922] nn.Sequential: [nn.Linear: 0.0039609023369849 nn.Linear: 0.0070450748316944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062676917595447 nn.Linear: 0.063823885461062 nn.Linear: 0.044785536994501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424804786806 nn.Linear: 0.04343481583112] nn.Sequential: [nn.Linear: 0.031375200894154 nn.Linear: 0.030703303555773]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43255805969238 nn.Linear: 0.1971343755722 nn.Linear: 0.13039200007915 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094460442662239 nn.Linear: 0.20058096945286] nn.Sequential: [nn.Linear: 0.087880745530128 nn.Linear: 0.16802270710468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021270709986136 nn.Linear: 0.0011277351632906 nn.Linear: 0.0004620827024985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018242789034398 nn.Linear: 0.0027865733400414] nn.Sequential: [nn.Linear: 0.00014218155319202 nn.Linear: 0.001493151294164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018234444782138 nn.Linear: 0.018347837030888 nn.Linear: 0.013930088840425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093405311927199 nn.Linear: 0.021316127851605] nn.Sequential: [nn.Linear: 0.0039824815467 nn.Linear: 0.013461266644299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672016652531 nn.Linear: 0.063821760077295 nn.Linear: 0.044784510693675 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0314245778223 nn.Linear: 0.043399024358564] nn.Sequential: [nn.Linear: 0.031375204602927 nn.Linear: 0.030709186685426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43201696872711 nn.Linear: 0.19751092791557 nn.Linear: 0.13044752180576 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094326414167881 nn.Linear: 0.2001414000988] nn.Sequential: [nn.Linear: 0.087874539196491 nn.Linear: 0.16786907613277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0053598297298662 nn.Linear: 0.0036717018222069 nn.Linear: 0.0012811648538148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003471250062163 nn.Linear: 0.0059061722347565] nn.Sequential: [nn.Linear: 0.00031141508431035 nn.Linear: 0.0034814003018623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.054015696048737 nn.Linear: 0.070330455899239 nn.Linear: 0.047105237841606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019653571769595 nn.Linear: 0.045303624123335] nn.Sequential: [nn.Linear: 0.016129041090608 nn.Linear: 0.049957871437073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062667906360793 nn.Linear: 0.063823685747906 nn.Linear: 0.044784773355086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424469787259 nn.Linear: 0.043359293070353] nn.Sequential: [nn.Linear: 0.03137510677408 nn.Linear: 0.030700916769405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43190762400627 nn.Linear: 0.19721944630146 nn.Linear: 0.13061918318272 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094372138381004 nn.Linear: 0.20021834969521] nn.Sequential: [nn.Linear: 0.088031403720379 nn.Linear: 0.16755141317844]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018121600363108 nn.Linear: 0.00108060148673 nn.Linear: 0.00050765468128955 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017028410299456 nn.Linear: 0.002356915451809] nn.Sequential: [nn.Linear: 0.00020228944919158 nn.Linear: 0.0022346625042844]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014184984378517 nn.Linear: 0.021840248256922 nn.Linear: 0.018094319850206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076475329697132 nn.Linear: 0.017841275781393] nn.Sequential: [nn.Linear: 0.0050208643078804 nn.Linear: 0.021245025098324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062657293995744 nn.Linear: 0.063821069769319 nn.Linear: 0.04478467027226 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424214464006 nn.Linear: 0.043321372857804] nn.Sequential: [nn.Linear: 0.031375152887622 nn.Linear: 0.03070077857713]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43173065781593 nn.Linear: 0.19757734239101 nn.Linear: 0.13009516894817 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094648152589798 nn.Linear: 0.20018847286701] nn.Sequential: [nn.Linear: 0.088067829608917 nn.Linear: 0.16755971312523]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014603611603175 nn.Linear: 0.0011269972277292 nn.Linear: 0.00057871485264934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027362790590439 nn.Linear: 0.0050768179950396] nn.Sequential: [nn.Linear: 0.00018558880853824 nn.Linear: 0.0019480397748157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010241535492241 nn.Linear: 0.017696278169751 nn.Linear: 0.010036268271506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086127920076251 nn.Linear: 0.024415675550699] nn.Sequential: [nn.Linear: 0.005563426297158 nn.Linear: 0.022347260266542]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062660111352811 nn.Linear: 0.063822963005809 nn.Linear: 0.044785362042252 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424510096009 nn.Linear: 0.043342528494122] nn.Sequential: [nn.Linear: 0.031375349680096 nn.Linear: 0.030719226862192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4325116276741 nn.Linear: 0.19773538410664 nn.Linear: 0.13037887215614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094714097678661 nn.Linear: 0.20062391459942] nn.Sequential: [nn.Linear: 0.088101588189602 nn.Linear: 0.1677048355341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013337331403824 nn.Linear: 0.00093990739711086 nn.Linear: 0.00046795778924049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021774948810843 nn.Linear: 0.0035042780028142] nn.Sequential: [nn.Linear: 0.00012712027493274 nn.Linear: 0.0011686169240583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010235127992928 nn.Linear: 0.014317873865366 nn.Linear: 0.0094050299376249 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013335560448468 nn.Linear: 0.033103834837675] nn.Sequential: [nn.Linear: 0.0050295544788241 nn.Linear: 0.013115037232637]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062655345145728 nn.Linear: 0.063824123800899 nn.Linear: 0.044786331964896 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424402707196 nn.Linear: 0.043342822332079] nn.Sequential: [nn.Linear: 0.031375538312756 nn.Linear: 0.030731652628696]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43204081058502 nn.Linear: 0.19769276678562 nn.Linear: 0.13044604659081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094975717365742 nn.Linear: 0.20045138895512] nn.Sequential: [nn.Linear: 0.088085278868675 nn.Linear: 0.16755044460297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014240984127282 nn.Linear: 0.00085392690904254 nn.Linear: 0.00038559114679477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018748435812744 nn.Linear: 0.0028627256819951] nn.Sequential: [nn.Linear: 0.00012319667479426 nn.Linear: 0.0011765533782797]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082285730168223 nn.Linear: 0.012960611842573 nn.Linear: 0.0083942702040076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070741553790867 nn.Linear: 0.020746868103743] nn.Sequential: [nn.Linear: 0.0029197090771049 nn.Linear: 0.010359491221607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062654505163757 nn.Linear: 0.063822871288258 nn.Linear: 0.044785460722362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424344207209 nn.Linear: 0.043314553512317] nn.Sequential: [nn.Linear: 0.031375591967484 nn.Linear: 0.030738569815046]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43182173371315 nn.Linear: 0.19829228520393 nn.Linear: 0.13076947629452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095377676188946 nn.Linear: 0.20087952911854] nn.Sequential: [nn.Linear: 0.088071048259735 nn.Linear: 0.16753493249416]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076388572577172 nn.Linear: 0.00064015418926993 nn.Linear: 0.00032316419733954 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012258097613661 nn.Linear: 0.0016200585765562] nn.Sequential: [nn.Linear: 9.7167127233077e-05 nn.Linear: 0.0007658369526171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069384826347232 nn.Linear: 0.0098512303084135 nn.Linear: 0.0054369796998799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057309279218316 nn.Linear: 0.010768136009574] nn.Sequential: [nn.Linear: 0.0022330840583891 nn.Linear: 0.0066471775062382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062652549065406 nn.Linear: 0.063825412830312 nn.Linear: 0.044787036075132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424283327077 nn.Linear: 0.043288630804796] nn.Sequential: [nn.Linear: 0.031376036027381 nn.Linear: 0.030743128447626]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43217664957047 nn.Linear: 0.19848237931728 nn.Linear: 0.13088589906693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095076657831669 nn.Linear: 0.20109355449677] nn.Sequential: [nn.Linear: 0.088185116648674 nn.Linear: 0.16764365136623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00077376150853674 nn.Linear: 0.00047063064161566 nn.Linear: 0.00025939815026785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011338490947656 nn.Linear: 0.001981660661709] nn.Sequential: [nn.Linear: 9.2154897596107e-05 nn.Linear: 0.00097252477625259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006726729683578 nn.Linear: 0.0084373895078897 nn.Linear: 0.0058967806398869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047558005899191 nn.Linear: 0.016052015125751] nn.Sequential: [nn.Linear: 0.0044346651993692 nn.Linear: 0.011718527413905]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	4880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062646940081847 nn.Linear: 0.063826680500951 nn.Linear: 0.044787756329863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424322651926 nn.Linear: 0.043299169206932] nn.Sequential: [nn.Linear: 0.031376067967666 nn.Linear: 0.03074994718272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43269771337509 nn.Linear: 0.19814828038216 nn.Linear: 0.13112379610538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09497956931591 nn.Linear: 0.20101571083069] nn.Sequential: [nn.Linear: 0.088306851685047 nn.Linear: 0.16770733892918]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013287241501648 nn.Linear: 0.00089776998185136 nn.Linear: 0.00044060218950224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012938556205617 nn.Linear: 0.0016259422424523] nn.Sequential: [nn.Linear: 0.00014763313367733 nn.Linear: 0.0012828194586739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010044583119452 nn.Linear: 0.014817779883742 nn.Linear: 0.0069065992720425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058797341771424 nn.Linear: 0.0107507025823] nn.Sequential: [nn.Linear: 0.0039935493841767 nn.Linear: 0.011818430386484]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062647091258262 nn.Linear: 0.063828311264159 nn.Linear: 0.04478888167265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424447620823 nn.Linear: 0.043300966370396] nn.Sequential: [nn.Linear: 0.031376432896474 nn.Linear: 0.030767856904097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43322205543518 nn.Linear: 0.19846570491791 nn.Linear: 0.13099762797356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094989284873009 nn.Linear: 0.20133803784847] nn.Sequential: [nn.Linear: 0.088138841092587 nn.Linear: 0.16772012412548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013468006107284 nn.Linear: 0.00071807344699934 nn.Linear: 0.00034665935585526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010728437906378 nn.Linear: 0.0012123714075572] nn.Sequential: [nn.Linear: 0.00011673931521898 nn.Linear: 0.0010902786306062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007966329343617 nn.Linear: 0.01129144243896 nn.Linear: 0.0088174855336547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043149432167411 nn.Linear: 0.0088462820276618] nn.Sequential: [nn.Linear: 0.0033392712939531 nn.Linear: 0.012000834569335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062646188174966 nn.Linear: 0.063830775000978 nn.Linear: 0.044789330354961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424388710809 nn.Linear: 0.04330193611122] nn.Sequential: [nn.Linear: 0.031376577357302 nn.Linear: 0.030792383909681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43291267752647 nn.Linear: 0.19918364286423 nn.Linear: 0.13079711794853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094867281615734 nn.Linear: 0.20123092830181] nn.Sequential: [nn.Linear: 0.088337816298008 nn.Linear: 0.16760544478893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015048153161317 nn.Linear: 0.0011115093184342 nn.Linear: 0.00053403525840031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020786382012948 nn.Linear: 0.003238820455965] nn.Sequential: [nn.Linear: 0.00018108371865406 nn.Linear: 0.0016838632483786]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017622888088226 nn.Linear: 0.016215911135077 nn.Linear: 0.013691464439034 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013620003126562 nn.Linear: 0.027692532166839] nn.Sequential: [nn.Linear: 0.0080861812457442 nn.Linear: 0.02045863494277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062645811190828 nn.Linear: 0.063833745838482 nn.Linear: 0.044790263079903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424689787948 nn.Linear: 0.043352309290356] nn.Sequential: [nn.Linear: 0.031376828499021 nn.Linear: 0.030806885719192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43242081999779 nn.Linear: 0.19927050173283 nn.Linear: 0.13125236332417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095188826322556 nn.Linear: 0.20155756175518] nn.Sequential: [nn.Linear: 0.088388383388519 nn.Linear: 0.16774289309978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018887217775345 nn.Linear: 0.0011980629684168 nn.Linear: 0.000632908318601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028229463730405 nn.Linear: 0.004731672483772] nn.Sequential: [nn.Linear: 0.00016015218845975 nn.Linear: 0.0015906843335319]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013708995655179 nn.Linear: 0.019671140238643 nn.Linear: 0.01300672441721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011466289870441 nn.Linear: 0.04286077991128] nn.Sequential: [nn.Linear: 0.0068502654321492 nn.Linear: 0.017551111057401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062646595638809 nn.Linear: 0.063836413875654 nn.Linear: 0.044791204541917 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424660608794 nn.Linear: 0.043358065220332] nn.Sequential: [nn.Linear: 0.031376904072847 nn.Linear: 0.030816445462365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43278044462204 nn.Linear: 0.19893173873425 nn.Linear: 0.13108439743519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094715386629105 nn.Linear: 0.20149151980877] nn.Sequential: [nn.Linear: 0.08845666795969 nn.Linear: 0.16759629547596]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012751880248905 nn.Linear: 0.0009004288485491 nn.Linear: 0.00055987373787291 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023293116623191 nn.Linear: 0.0039046377986775] nn.Sequential: [nn.Linear: 0.00019744451403943 nn.Linear: 0.0017259716646807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096642160788178 nn.Linear: 0.012241339311004 nn.Linear: 0.010783976875246 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090459976345301 nn.Linear: 0.023521402850747] nn.Sequential: [nn.Linear: 0.0077021345496178 nn.Linear: 0.014859955757856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062648056529825 nn.Linear: 0.063839921328081 nn.Linear: 0.044792162835804 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424818599277 nn.Linear: 0.043394332287107] nn.Sequential: [nn.Linear: 0.031377303339487 nn.Linear: 0.030828224826836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43307676911354 nn.Linear: 0.19902786612511 nn.Linear: 0.13098360598087 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094731889665127 nn.Linear: 0.20171037316322] nn.Sequential: [nn.Linear: 0.088423728942871 nn.Linear: 0.16739912331104]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097722687461361 nn.Linear: 0.00066125825994576 nn.Linear: 0.00033439812568798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015437977285373 nn.Linear: 0.0022830873477009] nn.Sequential: [nn.Linear: 0.00010968541101503 nn.Linear: 0.00097538024365535]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086053013801575 nn.Linear: 0.0094764120876789 nn.Linear: 0.0062360283918679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051861274987459 nn.Linear: 0.014598431997001] nn.Sequential: [nn.Linear: 0.0028148901183158 nn.Linear: 0.0084998849779367]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062642577365291 nn.Linear: 0.063837956828913 nn.Linear: 0.044791563542321 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031424741045699 nn.Linear: 0.04337664485189] nn.Sequential: [nn.Linear: 0.031377252995161 nn.Linear: 0.030830727274264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4331237077713 nn.Linear: 0.19898822903633 nn.Linear: 0.13124702870846 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094817288219929 nn.Linear: 0.20121878385544] nn.Sequential: [nn.Linear: 0.088428914546967 nn.Linear: 0.16730454564095]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010777426661059 nn.Linear: 0.0005372027819132 nn.Linear: 0.00026722826658615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010195793859481 nn.Linear: 0.001370112284101] nn.Sequential: [nn.Linear: 0.00010888524773679 nn.Linear: 0.00097698662232442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082498900592327 nn.Linear: 0.0068599595688283 nn.Linear: 0.005975779145956 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040462189354002 nn.Linear: 0.0093053989112377] nn.Sequential: [nn.Linear: 0.0037070610560477 nn.Linear: 0.010469574481249]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062641985513909 nn.Linear: 0.063841149843668 nn.Linear: 0.044794257359406 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425021674359 nn.Linear: 0.043427668696268] nn.Sequential: [nn.Linear: 0.031377766444077 nn.Linear: 0.030856114412108]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4335358440876 nn.Linear: 0.19915391504765 nn.Linear: 0.13125765323639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094864174723625 nn.Linear: 0.20185543596745] nn.Sequential: [nn.Linear: 0.088539443910122 nn.Linear: 0.16750212013721]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012289408728128 nn.Linear: 0.00085756436482365 nn.Linear: 0.00042182483943936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018281983533143 nn.Linear: 0.0027382444733569] nn.Sequential: [nn.Linear: 0.00012950829980307 nn.Linear: 0.0011889511060592]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010067596100271 nn.Linear: 0.0092638414353132 nn.Linear: 0.0074905813671649 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073223491199315 nn.Linear: 0.018027095124125] nn.Sequential: [nn.Linear: 0.0039893947541714 nn.Linear: 0.012485410086811]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062645006982813 nn.Linear: 0.063845577252711 nn.Linear: 0.044795191218855 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425140952392 nn.Linear: 0.043453358366719] nn.Sequential: [nn.Linear: 0.031378089190518 nn.Linear: 0.030862475944602]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43444216251373 nn.Linear: 0.19884139299393 nn.Linear: 0.13097304105759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095170699059963 nn.Linear: 0.20209211111069] nn.Sequential: [nn.Linear: 0.088607721030712 nn.Linear: 0.16781876981258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071881748049681 nn.Linear: 0.00048925505929205 nn.Linear: 0.00028603312445407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010322311348486 nn.Linear: 0.0014952783670905] nn.Sequential: [nn.Linear: 0.00013344441846378 nn.Linear: 0.0013790872508054]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049156709574163 nn.Linear: 0.0083338133990765 nn.Linear: 0.0065920725464821 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00405546836555 nn.Linear: 0.0092796990647912] nn.Sequential: [nn.Linear: 0.0039312518201768 nn.Linear: 0.01731645129621]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062640164831916 nn.Linear: 0.063848096679408 nn.Linear: 0.044795797018449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142526558778 nn.Linear: 0.043468366388879] nn.Sequential: [nn.Linear: 0.031378117594714 nn.Linear: 0.030859523337455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43474507331848 nn.Linear: 0.19885240495205 nn.Linear: 0.13106033205986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095180004835129 nn.Linear: 0.20227904617786] nn.Sequential: [nn.Linear: 0.088614851236343 nn.Linear: 0.1677308678627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012512815709142 nn.Linear: 0.00076098280684619 nn.Linear: 0.00041740795326534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015501896025636 nn.Linear: 0.0019151027494427] nn.Sequential: [nn.Linear: 0.00018359232308075 nn.Linear: 0.0017147464870773]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075591574423015 nn.Linear: 0.012645577080548 nn.Linear: 0.0085507743060589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069443369284272 nn.Linear: 0.013706958852708] nn.Sequential: [nn.Linear: 0.005822557490319 nn.Linear: 0.016972346231341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062646321557528 nn.Linear: 0.063850432084906 nn.Linear: 0.044798054303675 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425577781971 nn.Linear: 0.043491671477142] nn.Sequential: [nn.Linear: 0.031378331415498 nn.Linear: 0.030884792629547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43435654044151 nn.Linear: 0.19846335053444 nn.Linear: 0.13118483126163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095168843865395 nn.Linear: 0.20203441381454] nn.Sequential: [nn.Linear: 0.088576577603817 nn.Linear: 0.16777668893337]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010705373578753 nn.Linear: 0.00056412884370556 nn.Linear: 0.00032062880716221 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012628835977885 nn.Linear: 0.0018217193915872] nn.Sequential: [nn.Linear: 0.00011699609444278 nn.Linear: 0.0012868362874401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073408712632954 nn.Linear: 0.011122419498861 nn.Linear: 0.005954016931355 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059203132987022 nn.Linear: 0.0115338973701] nn.Sequential: [nn.Linear: 0.0041799787431955 nn.Linear: 0.014133333228528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	4990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643954058089 nn.Linear: 0.063850297058632 nn.Linear: 0.044798994448578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425826417601 nn.Linear: 0.043568099525658] nn.Sequential: [nn.Linear: 0.031378422597238 nn.Linear: 0.030909294859653]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43533286452293 nn.Linear: 0.19834658503532 nn.Linear: 0.13140796124935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094981461763382 nn.Linear: 0.20234356820583] nn.Sequential: [nn.Linear: 0.088706754148006 nn.Linear: 0.16806028783321]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021416916409226 nn.Linear: 0.0015271363276486 nn.Linear: 0.00067822597398027 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029156568000353 nn.Linear: 0.0041405829840753] nn.Sequential: [nn.Linear: 0.0002202965831702 nn.Linear: 0.0021563408241234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015538611449301 nn.Linear: 0.032774686813354 nn.Linear: 0.020944263786077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010373631492257 nn.Linear: 0.028592813760042] nn.Sequential: [nn.Linear: 0.0070980279706419 nn.Linear: 0.024812577292323]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062638758845007 nn.Linear: 0.063852719198863 nn.Linear: 0.044799704294075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142580431332 nn.Linear: 0.043549062018542] nn.Sequential: [nn.Linear: 0.031378733021973 nn.Linear: 0.030919022859331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43564143776894 nn.Linear: 0.19884312152863 nn.Linear: 0.13112081587315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094670198857784 nn.Linear: 0.20293442904949] nn.Sequential: [nn.Linear: 0.088710613548756 nn.Linear: 0.16817013919353]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019721614276914 nn.Linear: 0.0011603348129547 nn.Linear: 0.00047879742663812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014142806920229 nn.Linear: 0.001724230804755] nn.Sequential: [nn.Linear: 0.00016583480932981 nn.Linear: 0.0014588426452359]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010880733840168 nn.Linear: 0.019045766443014 nn.Linear: 0.010011010803282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077125304378569 nn.Linear: 0.014051876030862] nn.Sequential: [nn.Linear: 0.0051138033159077 nn.Linear: 0.012990376912057]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.097260812394321	TD error	0.019670956708491	Qmax	1	

Steps: 5000000 (frames: 20000000), score: 1918.41, higheset score: 6392, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 90s, testing rate: 5544fps,  num. ep.: 335,  num. rewards: 17160	
   2    4    8   16
   8   16   64  512
   4   64  256    8
   2    4    8    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643200800889 nn.Linear: 0.063856226223151 nn.Linear: 0.04480106048601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031425910801463 nn.Linear: 0.043555718823882] nn.Sequential: [nn.Linear: 0.031378913424231 nn.Linear: 0.030921187111982]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43566557765007 nn.Linear: 0.19867950677872 nn.Linear: 0.13125658035278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094531789422035 nn.Linear: 0.2034295797348] nn.Sequential: [nn.Linear: 0.088776238262653 nn.Linear: 0.16804425418377]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020589472088013 nn.Linear: 0.0011733046472356 nn.Linear: 0.00052700756908493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019606090965596 nn.Linear: 0.0025636879167276] nn.Sequential: [nn.Linear: 0.00015771338996005 nn.Linear: 0.0013425142244106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018988016992807 nn.Linear: 0.030620094388723 nn.Linear: 0.015756392851472 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091670891270041 nn.Linear: 0.017122115939856] nn.Sequential: [nn.Linear: 0.010426362045109 nn.Linear: 0.019476946443319]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637245933595 nn.Linear: 0.063860811991291 nn.Linear: 0.044801586035799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426122954793 nn.Linear: 0.043600383124414] nn.Sequential: [nn.Linear: 0.031378973911377 nn.Linear: 0.030925113028832]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4355916082859 nn.Linear: 0.19868464767933 nn.Linear: 0.13120695948601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094434536993504 nn.Linear: 0.20358069241047] nn.Sequential: [nn.Linear: 0.088814340531826 nn.Linear: 0.16802340745926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010938922473075 nn.Linear: 0.00074852876918614 nn.Linear: 0.00036880048322976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014481998102452 nn.Linear: 0.0022374721173023] nn.Sequential: [nn.Linear: 9.8249602434488e-05 nn.Linear: 0.00077225650854509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083235623314977 nn.Linear: 0.01184278447181 nn.Linear: 0.0089486856013536 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060202423483133 nn.Linear: 0.015640208497643] nn.Sequential: [nn.Linear: 0.0029850217979401 nn.Linear: 0.0077796299010515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634340685126 nn.Linear: 0.063864712211778 nn.Linear: 0.044803190284898 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426197887478 nn.Linear: 0.04360762905651] nn.Sequential: [nn.Linear: 0.031379209204094 nn.Linear: 0.030945595533089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43487483263016 nn.Linear: 0.19842338562012 nn.Linear: 0.13098238408566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094607889652252 nn.Linear: 0.20339027047157] nn.Sequential: [nn.Linear: 0.088907539844513 nn.Linear: 0.16797298192978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097491430610201 nn.Linear: 0.00059314882828386 nn.Linear: 0.00031979068362713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014175373380244 nn.Linear: 0.0023463471863625] nn.Sequential: [nn.Linear: 0.00010724068814577 nn.Linear: 0.00092944976407491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006803072988987 nn.Linear: 0.0089789908379316 nn.Linear: 0.0050374935381114 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049964524805546 nn.Linear: 0.014044363982975] nn.Sequential: [nn.Linear: 0.0047944211401045 nn.Linear: 0.0076343044638634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631597396992 nn.Linear: 0.063865683713706 nn.Linear: 0.044802921029487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426376028608 nn.Linear: 0.043629138355215] nn.Sequential: [nn.Linear: 0.031379335396086 nn.Linear: 0.03096068872149]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43497782945633 nn.Linear: 0.19869923591614 nn.Linear: 0.13114133477211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094527840614319 nn.Linear: 0.20346012711525] nn.Sequential: [nn.Linear: 0.088824853301048 nn.Linear: 0.16772855818272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00078500299321909 nn.Linear: 0.00046729579744671 nn.Linear: 0.00028215220156127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011752962612952 nn.Linear: 0.0016153668115995] nn.Sequential: [nn.Linear: 0.00010573594987058 nn.Linear: 0.00097136532791956]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062768063507974 nn.Linear: 0.0076302024535835 nn.Linear: 0.0068394583649933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042058071121573 nn.Linear: 0.011035559698939] nn.Sequential: [nn.Linear: 0.0029831081628799 nn.Linear: 0.0077800895087421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062627767554382 nn.Linear: 0.063865505929865 nn.Linear: 0.044803117873529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426356890951 nn.Linear: 0.043615553660004] nn.Sequential: [nn.Linear: 0.031379478794098 nn.Linear: 0.030973015377905]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4349727332592 nn.Linear: 0.19864739477634 nn.Linear: 0.13122698664665 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094827242195606 nn.Linear: 0.20312383770943] nn.Sequential: [nn.Linear: 0.088975049555302 nn.Linear: 0.16793984174728]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092351953097765 nn.Linear: 0.00062277056391203 nn.Linear: 0.00030660967839807 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013294191904758 nn.Linear: 0.0022958719737567] nn.Sequential: [nn.Linear: 9.9046761744625e-05 nn.Linear: 0.00087457807621633]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084237093105912 nn.Linear: 0.010191992856562 nn.Linear: 0.0069373901933432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042823092080653 nn.Linear: 0.014796857722104] nn.Sequential: [nn.Linear: 0.0044891447760165 nn.Linear: 0.0088225938379765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062624631079505 nn.Linear: 0.063868086749347 nn.Linear: 0.044804326922547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426460178164 nn.Linear: 0.043621778916989] nn.Sequential: [nn.Linear: 0.031379777049687 nn.Linear: 0.030995350121747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43502271175385 nn.Linear: 0.19855843484402 nn.Linear: 0.13117031753063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094797775149345 nn.Linear: 0.20383411645889] nn.Sequential: [nn.Linear: 0.089028231799603 nn.Linear: 0.16843536496162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091893612512867 nn.Linear: 0.00059152451089145 nn.Linear: 0.00034788359384401 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011083544637015 nn.Linear: 0.0013572844234161] nn.Sequential: [nn.Linear: 0.00014995061894355 nn.Linear: 0.0013069023419884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056746224872768 nn.Linear: 0.0070196334272623 nn.Linear: 0.0080654984340072 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040160161443055 nn.Linear: 0.012170723639429] nn.Sequential: [nn.Linear: 0.0046594045124948 nn.Linear: 0.011579595506191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062626927508253 nn.Linear: 0.063871608274237 nn.Linear: 0.044805657367866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426700814777 nn.Linear: 0.043663586193162] nn.Sequential: [nn.Linear: 0.031380067464122 nn.Linear: 0.031007588052276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43576550483704 nn.Linear: 0.1993932723999 nn.Linear: 0.13115580379963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095182448625565 nn.Linear: 0.20409393310547] nn.Sequential: [nn.Linear: 0.089269861578941 nn.Linear: 0.16851806640625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00063136243419212 nn.Linear: 0.00036954085769581 nn.Linear: 0.0002321883772048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010166073675748 nn.Linear: 0.001469185272128] nn.Sequential: [nn.Linear: 9.1056842323746e-05 nn.Linear: 0.00069612557451178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0045297564938664 nn.Linear: 0.005038920789957 nn.Linear: 0.0043046604841948 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047981715761125 nn.Linear: 0.010663591325283] nn.Sequential: [nn.Linear: 0.0030630158726126 nn.Linear: 0.0055831791833043]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637531034012 nn.Linear: 0.063880596709818 nn.Linear: 0.044807630143161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031426971155104 nn.Linear: 0.043714080993858] nn.Sequential: [nn.Linear: 0.031380427219015 nn.Linear: 0.031031173680837]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43620133399963 nn.Linear: 0.19911022484303 nn.Linear: 0.13135449588299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094812363386154 nn.Linear: 0.20431464910507] nn.Sequential: [nn.Linear: 0.089196734130383 nn.Linear: 0.16822277009487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076021492964924 nn.Linear: 0.00051955480113877 nn.Linear: 0.00028086018052839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013152157572221 nn.Linear: 0.0019025929916494] nn.Sequential: [nn.Linear: 0.00012214370609975 nn.Linear: 0.0010327211308056]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0047872080467641 nn.Linear: 0.0090148067101836 nn.Linear: 0.0057674944400787 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052696946077049 nn.Linear: 0.015818133950233] nn.Sequential: [nn.Linear: 0.0036658891476691 nn.Linear: 0.0096166180446744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636623126045 nn.Linear: 0.063881441011522 nn.Linear: 0.044808432394686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427103371874 nn.Linear: 0.043733161277657] nn.Sequential: [nn.Linear: 0.031380636603951 nn.Linear: 0.031047647071013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43647384643555 nn.Linear: 0.19969148933887 nn.Linear: 0.13156445324421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094794027507305 nn.Linear: 0.20432312786579] nn.Sequential: [nn.Linear: 0.089441709220409 nn.Linear: 0.168581366539]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080029057289001 nn.Linear: 0.0004991201680863 nn.Linear: 0.00024703413655755 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.1697241680196e-05 nn.Linear: 0.00080976637203267] nn.Sequential: [nn.Linear: 0.00011204218085463 nn.Linear: 0.0010516383157931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067467540502548 nn.Linear: 0.008312676101923 nn.Linear: 0.0054792119190097 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030290640424937 nn.Linear: 0.0049670166336] nn.Sequential: [nn.Linear: 0.0038308079820126 nn.Linear: 0.012874541804194]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06263466689235 nn.Linear: 0.063883688888025 nn.Linear: 0.044809798159168 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427200467892 nn.Linear: 0.043747212772161] nn.Sequential: [nn.Linear: 0.031381129902219 nn.Linear: 0.031066253916972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43687489628792 nn.Linear: 0.19994035363197 nn.Linear: 0.13160382211208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095033600926399 nn.Linear: 0.20462296903133] nn.Sequential: [nn.Linear: 0.089315436780453 nn.Linear: 0.16859935224056]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099775211688266 nn.Linear: 0.00073832410906193 nn.Linear: 0.00042787022345136 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023691989395092 nn.Linear: 0.0039586253403863] nn.Sequential: [nn.Linear: 0.00015963102267685 nn.Linear: 0.0016176556838337]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064858770929277 nn.Linear: 0.015050939284265 nn.Linear: 0.012821779586375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01147263776511 nn.Linear: 0.028757778927684] nn.Sequential: [nn.Linear: 0.0064054052345455 nn.Linear: 0.018980817869306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062644868665183 nn.Linear: 0.06388965714257 nn.Linear: 0.044812224944273 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427478966912 nn.Linear: 0.043752351113346] nn.Sequential: [nn.Linear: 0.031381475635769 nn.Linear: 0.031084739079681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43695044517517 nn.Linear: 0.19997139275074 nn.Linear: 0.13146303594112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.094905443489552 nn.Linear: 0.20496940612793] nn.Sequential: [nn.Linear: 0.089448891580105 nn.Linear: 0.16866800189018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095707276736355 nn.Linear: 0.00082625992106646 nn.Linear: 0.00042239196936263 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013045853783249 nn.Linear: 0.0016102162420366] nn.Sequential: [nn.Linear: 0.0001558295904855 nn.Linear: 0.0014120669440808]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064412467181683 nn.Linear: 0.01144399587065 nn.Linear: 0.0079750725999475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047297989949584 nn.Linear: 0.013801733963192] nn.Sequential: [nn.Linear: 0.0041617164388299 nn.Linear: 0.016335489228368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643630048514 nn.Linear: 0.063894192934996 nn.Linear: 0.044813375155709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427594923118 nn.Linear: 0.043762449156134] nn.Sequential: [nn.Linear: 0.03138174532648 nn.Linear: 0.031089552967413]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43782544136047 nn.Linear: 0.20038130879402 nn.Linear: 0.13142152130604 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095001213252544 nn.Linear: 0.2044560611248] nn.Sequential: [nn.Linear: 0.089427880942822 nn.Linear: 0.16850188374519]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0005702123004976 nn.Linear: 0.00052029560522714 nn.Linear: 0.00027226530880833 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.629475879532e-05 nn.Linear: 0.0009945965970104] nn.Sequential: [nn.Linear: 0.00012445706844614 nn.Linear: 0.001213060622957]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043543954379857 nn.Linear: 0.0066831531003118 nn.Linear: 0.0049292142502964 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035143378190696 nn.Linear: 0.0069803162477911] nn.Sequential: [nn.Linear: 0.0040597817860544 nn.Linear: 0.011522861197591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637244902583 nn.Linear: 0.063894338751952 nn.Linear: 0.044814541406763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427711423227 nn.Linear: 0.043781422098878] nn.Sequential: [nn.Linear: 0.03138176431421 nn.Linear: 0.03110647812405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43737828731537 nn.Linear: 0.20053432881832 nn.Linear: 0.13125661015511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09490829706192 nn.Linear: 0.20447534322739] nn.Sequential: [nn.Linear: 0.089414693415165 nn.Linear: 0.16853168606758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013654723410305 nn.Linear: 0.00094595081367556 nn.Linear: 0.00046654396220691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016425977075024 nn.Linear: 0.0018481855316131] nn.Sequential: [nn.Linear: 0.00015969547807038 nn.Linear: 0.0014259198848531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090678315609694 nn.Linear: 0.019490372389555 nn.Linear: 0.010418677702546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066586122848094 nn.Linear: 0.015459910966456] nn.Sequential: [nn.Linear: 0.0046066488139331 nn.Linear: 0.013191272504628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637412968843 nn.Linear: 0.06390093987021 nn.Linear: 0.044815920164596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031427909299012 nn.Linear: 0.043815578825551] nn.Sequential: [nn.Linear: 0.031382004152988 nn.Linear: 0.031123585616109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43780669569969 nn.Linear: 0.20048689842224 nn.Linear: 0.13147038221359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095267906785011 nn.Linear: 0.20478650927544] nn.Sequential: [nn.Linear: 0.08958338201046 nn.Linear: 0.16889108717442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010486387549986 nn.Linear: 0.0007052319196411 nn.Linear: 0.0003960406628536 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015213169043952 nn.Linear: 0.001699242268504] nn.Sequential: [nn.Linear: 0.00012568450653657 nn.Linear: 0.0010812512963094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006272871978581 nn.Linear: 0.010971341282129 nn.Linear: 0.0094518531113863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083720963448286 nn.Linear: 0.014400805346668] nn.Sequential: [nn.Linear: 0.0053055537864566 nn.Linear: 0.013015621341765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631044627324 nn.Linear: 0.063900928908205 nn.Linear: 0.044816046348321 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031428029312809 nn.Linear: 0.043811111784091] nn.Sequential: [nn.Linear: 0.031382270813366 nn.Linear: 0.031136613531878]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43806058168411 nn.Linear: 0.20093885064125 nn.Linear: 0.13129495084286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095031000673771 nn.Linear: 0.20489498972893] nn.Sequential: [nn.Linear: 0.089320532977581 nn.Linear: 0.16941626369953]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010723045350572 nn.Linear: 0.00073279279052542 nn.Linear: 0.00041504568764316 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015849899530964 nn.Linear: 0.0024558122764096] nn.Sequential: [nn.Linear: 0.00011470705628964 nn.Linear: 0.00094962326956702]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071376799605787 nn.Linear: 0.012571703642607 nn.Linear: 0.0063996003009379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084740659222007 nn.Linear: 0.015931904315948] nn.Sequential: [nn.Linear: 0.0038521478418261 nn.Linear: 0.0128821907565]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634104765923 nn.Linear: 0.06390691530709 nn.Linear: 0.044817906326806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031428337380717 nn.Linear: 0.043879037252509] nn.Sequential: [nn.Linear: 0.031382771316352 nn.Linear: 0.031165018973149]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43793573975563 nn.Linear: 0.20085363090038 nn.Linear: 0.13145193457603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095392979681492 nn.Linear: 0.20457488298416] nn.Sequential: [nn.Linear: 0.089636698365211 nn.Linear: 0.16989614069462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094722318382712 nn.Linear: 0.00061019162239886 nn.Linear: 0.00037658088340145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016191325998869 nn.Linear: 0.0026253546803311] nn.Sequential: [nn.Linear: 0.00012817641007669 nn.Linear: 0.0011643683943018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0055574057623744 nn.Linear: 0.010980227962136 nn.Linear: 0.0057871355675161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073628011159599 nn.Linear: 0.016652708873153] nn.Sequential: [nn.Linear: 0.005049001891166 nn.Linear: 0.013402086682618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06263184578962 nn.Linear: 0.063911124417775 nn.Linear: 0.04481914689013 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031428552822604 nn.Linear: 0.043896528716743] nn.Sequential: [nn.Linear: 0.031383043190309 nn.Linear: 0.031171731618933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43851011991501 nn.Linear: 0.2015426158905 nn.Linear: 0.13108609616756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095455810427666 nn.Linear: 0.20487789809704] nn.Sequential: [nn.Linear: 0.089716888964176 nn.Linear: 0.16959457099438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012331415410494 nn.Linear: 0.00076078307681732 nn.Linear: 0.000438271357015 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016629068690792 nn.Linear: 0.002554047304822] nn.Sequential: [nn.Linear: 0.00016122482781255 nn.Linear: 0.0015737578510607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071051316335797 nn.Linear: 0.0099516520276666 nn.Linear: 0.0094745764508843 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0080772582441568 nn.Linear: 0.016268368810415] nn.Sequential: [nn.Linear: 0.0051569081842899 nn.Linear: 0.017085637897253]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062628320386171 nn.Linear: 0.063914050097803 nn.Linear: 0.044820166430085 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03142891177946 nn.Linear: 0.043988307861618] nn.Sequential: [nn.Linear: 0.031383206941143 nn.Linear: 0.031186405566178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43869060277939 nn.Linear: 0.20159152150154 nn.Linear: 0.1312717795372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095347709953785 nn.Linear: 0.205003708601] nn.Sequential: [nn.Linear: 0.089798770844936 nn.Linear: 0.16953037679195]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00066064522507293 nn.Linear: 0.00056950690196167 nn.Linear: 0.00030130179119057 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011341546785014 nn.Linear: 0.0016204420963611] nn.Sequential: [nn.Linear: 0.00011658785716947 nn.Linear: 0.0010565471223633]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052070920355618 nn.Linear: 0.0067087784409523 nn.Linear: 0.0060468642041087 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052339327521622 nn.Linear: 0.012412433512509] nn.Sequential: [nn.Linear: 0.0039726221002638 nn.Linear: 0.0095920516178012]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06262607851828 nn.Linear: 0.063917270920323 nn.Linear: 0.044819984802853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031429062401567 nn.Linear: 0.043988098727255] nn.Sequential: [nn.Linear: 0.031383262937861 nn.Linear: 0.031192700695051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43886351585388 nn.Linear: 0.2018877863884 nn.Linear: 0.13123717904091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095097839832306 nn.Linear: 0.2050403803587] nn.Sequential: [nn.Linear: 0.089779384434223 nn.Linear: 0.16941840946674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00070966376126003 nn.Linear: 0.00056714035712318 nn.Linear: 0.00031375889986774 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013477576895154 nn.Linear: 0.0019377582033782] nn.Sequential: [nn.Linear: 9.6916915101779e-05 nn.Linear: 0.00099184232303058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052686664275825 nn.Linear: 0.0068569169379771 nn.Linear: 0.0062334570102394 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045812921598554 nn.Linear: 0.014043818227947] nn.Sequential: [nn.Linear: 0.0030074343085289 nn.Linear: 0.0099370926618576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062628972976483 nn.Linear: 0.063919140027498 nn.Linear: 0.044821657960224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031429188922152 nn.Linear: 0.044001440349518] nn.Sequential: [nn.Linear: 0.031383520943558 nn.Linear: 0.031214804435054]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43872484564781 nn.Linear: 0.20185829699039 nn.Linear: 0.13132277131081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095356620848179 nn.Linear: 0.20453414320946] nn.Sequential: [nn.Linear: 0.089825958013535 nn.Linear: 0.16969503462315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011332949077361 nn.Linear: 0.00071446148096258 nn.Linear: 0.00034681515356204 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001309849023788 nn.Linear: 0.001588122634116] nn.Sequential: [nn.Linear: 0.0001068381772147 nn.Linear: 0.00097178555965745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075438455678523 nn.Linear: 0.0077733313664794 nn.Linear: 0.0068337116390467 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062814545817673 nn.Linear: 0.01149904821068] nn.Sequential: [nn.Linear: 0.0032759855967015 nn.Linear: 0.011863450519741]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062630206229022 nn.Linear: 0.063925287781516 nn.Linear: 0.044823502199736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031429481133295 nn.Linear: 0.044020116909195] nn.Sequential: [nn.Linear: 0.031383957652038 nn.Linear: 0.03124386346961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43862256407738 nn.Linear: 0.20160484313965 nn.Linear: 0.13126748800278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095617353916168 nn.Linear: 0.20513197779655] nn.Sequential: [nn.Linear: 0.089853778481483 nn.Linear: 0.1701585650444]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012914195712994 nn.Linear: 0.0008276853534795 nn.Linear: 0.00038849066351959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015797377403922 nn.Linear: 0.002316832400223] nn.Sequential: [nn.Linear: 0.00012865812510098 nn.Linear: 0.0010290462982907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095393406227231 nn.Linear: 0.0093569038435817 nn.Linear: 0.0085377227514982 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010238722898066 nn.Linear: 0.020597707480192] nn.Sequential: [nn.Linear: 0.0034330452326685 nn.Linear: 0.0095854979008436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636246115151 nn.Linear: 0.0639307374523 nn.Linear: 0.044826132296913 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031429816895174 nn.Linear: 0.044047659447035] nn.Sequential: [nn.Linear: 0.031384419145817 nn.Linear: 0.03125777917608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43898621201515 nn.Linear: 0.20117427408695 nn.Linear: 0.13169187307358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095781534910202 nn.Linear: 0.20580768585205] nn.Sequential: [nn.Linear: 0.089893519878387 nn.Linear: 0.16999913752079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011872425404033 nn.Linear: 0.0006679532943488 nn.Linear: 0.0003032580269344 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010891574651777 nn.Linear: 0.0014412721312813] nn.Sequential: [nn.Linear: 9.2285609501619e-05 nn.Linear: 0.00084886852305915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066184094175696 nn.Linear: 0.0098611451685429 nn.Linear: 0.00614944845438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049318675883114 nn.Linear: 0.011127098463476] nn.Sequential: [nn.Linear: 0.0027018703985959 nn.Linear: 0.007396777626127]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062642424004989 nn.Linear: 0.063933039967329 nn.Linear: 0.044826065360626 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031430062227013 nn.Linear: 0.044061684542669] nn.Sequential: [nn.Linear: 0.031384507991191 nn.Linear: 0.03126802197678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43889963626862 nn.Linear: 0.20149329304695 nn.Linear: 0.13180406391621 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.095963671803474 nn.Linear: 0.20555540919304] nn.Sequential: [nn.Linear: 0.089783392846584 nn.Linear: 0.16999237239361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007622209318413 nn.Linear: 0.00050362639845195 nn.Linear: 0.00026616408474418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.9619670863616e-05 nn.Linear: 0.0010786184350058] nn.Sequential: [nn.Linear: 0.00010051051544614 nn.Linear: 0.00090205536003574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051410058513284 nn.Linear: 0.011114143766463 nn.Linear: 0.0043733483180404 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061315218918025 nn.Linear: 0.007139699999243] nn.Sequential: [nn.Linear: 0.00238215806894 nn.Linear: 0.0078476704657078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062641931234185 nn.Linear: 0.06393709022064 nn.Linear: 0.044827190168131 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031430171178196 nn.Linear: 0.044098537920718] nn.Sequential: [nn.Linear: 0.031384699911025 nn.Linear: 0.031279196300456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43883317708969 nn.Linear: 0.20192985236645 nn.Linear: 0.13155011832714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096078716218472 nn.Linear: 0.20597514510155] nn.Sequential: [nn.Linear: 0.08981654047966 nn.Linear: 0.17009557783604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017220161567352 nn.Linear: 0.001308334375957 nn.Linear: 0.00064835987114381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024954961140997 nn.Linear: 0.0035692944747896] nn.Sequential: [nn.Linear: 0.0002111228513907 nn.Linear: 0.0021128961846237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012858144007623 nn.Linear: 0.013740483671427 nn.Linear: 0.013907010667026 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010149911977351 nn.Linear: 0.029024250805378] nn.Sequential: [nn.Linear: 0.0090404562652111 nn.Linear: 0.024953892454505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06263832326944 nn.Linear: 0.063938427736129 nn.Linear: 0.044827407926383 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03143007745017 nn.Linear: 0.044089362342596] nn.Sequential: [nn.Linear: 0.031384899559305 nn.Linear: 0.031285487382608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43917921185493 nn.Linear: 0.20129789412022 nn.Linear: 0.13177585601807 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096064224839211 nn.Linear: 0.20590603351593] nn.Sequential: [nn.Linear: 0.089913234114647 nn.Linear: 0.1701440513134]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001111776784198 nn.Linear: 0.00068039605669638 nn.Linear: 0.00031278614038405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001098480745555 nn.Linear: 0.0013050364785707] nn.Sequential: [nn.Linear: 9.9348243591053e-05 nn.Linear: 0.00090201176562763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080557027831674 nn.Linear: 0.011117356829345 nn.Linear: 0.0055980449542403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044020963832736 nn.Linear: 0.0077202403917909] nn.Sequential: [nn.Linear: 0.0032185229938477 nn.Linear: 0.0097018601372838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.09009445348382	TD error	0.01916348657757	Qmax	1	

Steps: 5250000 (frames: 21000000), score: 1937.76, higheset score: 5396, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1812fps, testing time: 89s, testing rate: 5556fps,  num. ep.: 391,  num. rewards: 18970	
   8    2   64    2
   2    4   32   16
   8   16  128    4
  16   32    2  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637927151087 nn.Linear: 0.063944105510152 nn.Linear: 0.044829597936647 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031430467609561 nn.Linear: 0.044131558402619] nn.Sequential: [nn.Linear: 0.03138537330654 nn.Linear: 0.031316107896814]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43982297182083 nn.Linear: 0.20166705548763 nn.Linear: 0.13182225823402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096039466559887 nn.Linear: 0.20566464960575] nn.Sequential: [nn.Linear: 0.090229444205761 nn.Linear: 0.17034563422203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085854586252826 nn.Linear: 0.00054988612877329 nn.Linear: 0.00028774077003592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012353999879422 nn.Linear: 0.0016746016488749] nn.Sequential: [nn.Linear: 8.7181128370754e-05 nn.Linear: 0.00077872952801369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0053457133471966 nn.Linear: 0.0069207632914186 nn.Linear: 0.0058743157424033 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045174616388977 nn.Linear: 0.014267329126596] nn.Sequential: [nn.Linear: 0.0030911967623979 nn.Linear: 0.0097563797608018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062645301131744 nn.Linear: 0.06395114903087 nn.Linear: 0.04483242999235 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031430590766462 nn.Linear: 0.044166557123937] nn.Sequential: [nn.Linear: 0.031385930155586 nn.Linear: 0.031358431252662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43997052311897 nn.Linear: 0.20198701322079 nn.Linear: 0.13182166218758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096583671867847 nn.Linear: 0.20572106540203] nn.Sequential: [nn.Linear: 0.090419851243496 nn.Linear: 0.17045018076897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0046366139861959 nn.Linear: 0.0027207312202706 nn.Linear: 0.0012558048565419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00051837163960014 nn.Linear: 0.0093502008455442] nn.Sequential: [nn.Linear: 0.0003915156647159 nn.Linear: 0.0044700119308102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.041170634329319 nn.Linear: 0.035303272306919 nn.Linear: 0.044202752411366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02129945717752 nn.Linear: 0.069020412862301] nn.Sequential: [nn.Linear: 0.017112590372562 nn.Linear: 0.052156578749418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062637513325908 nn.Linear: 0.06394885529513 nn.Linear: 0.044832429570585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03143079278369 nn.Linear: 0.044171850708111] nn.Sequential: [nn.Linear: 0.031385975637555 nn.Linear: 0.031367128496917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44021531939507 nn.Linear: 0.202258259058 nn.Linear: 0.13190101087093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096611224114895 nn.Linear: 0.20565044879913] nn.Sequential: [nn.Linear: 0.090559080243111 nn.Linear: 0.17039301991463]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00064479664078965 nn.Linear: 0.00044994301994708 nn.Linear: 0.00026215656543294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.7530512685992e-05 nn.Linear: 0.0010095099738265] nn.Sequential: [nn.Linear: 0.00012551162682168 nn.Linear: 0.0014312118716402]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004836980253458 nn.Linear: 0.0097628803923726 nn.Linear: 0.0050333929248154 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0029530969914049 nn.Linear: 0.0061057712882757] nn.Sequential: [nn.Linear: 0.0037118277978152 nn.Linear: 0.015558505430818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062635195733648 nn.Linear: 0.063952046654427 nn.Linear: 0.044833286109064 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031430903320276 nn.Linear: 0.044188576896374] nn.Sequential: [nn.Linear: 0.031386193769882 nn.Linear: 0.031383666480524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43952375650406 nn.Linear: 0.20218980312347 nn.Linear: 0.13172122836113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096733413636684 nn.Linear: 0.20548264682293] nn.Sequential: [nn.Linear: 0.090495206415653 nn.Linear: 0.17030742764473]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001333523662685 nn.Linear: 0.00091407141291435 nn.Linear: 0.00040913629838618 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001664844270326 nn.Linear: 0.0023678824231803] nn.Sequential: [nn.Linear: 0.00015129745882073 nn.Linear: 0.0014055292936848]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085148997604847 nn.Linear: 0.011900473386049 nn.Linear: 0.010665625333786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010370940901339 nn.Linear: 0.021263357251883] nn.Sequential: [nn.Linear: 0.0062517798505723 nn.Linear: 0.020428247749805]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062630615668176 nn.Linear: 0.063951891143057 nn.Linear: 0.044833984368161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431077305608 nn.Linear: 0.044222521656494] nn.Sequential: [nn.Linear: 0.031386345207907 nn.Linear: 0.031389430277954]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43890342116356 nn.Linear: 0.20269684493542 nn.Linear: 0.13164736330509 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096986725926399 nn.Linear: 0.20568138360977] nn.Sequential: [nn.Linear: 0.090389579534531 nn.Linear: 0.17071881890297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090291900541862 nn.Linear: 0.00075679426381365 nn.Linear: 0.00037741891226749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001705296339912 nn.Linear: 0.0028672698741069] nn.Sequential: [nn.Linear: 0.0001390625478686 nn.Linear: 0.001151687999811]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068001113831997 nn.Linear: 0.010852430015802 nn.Linear: 0.0079863518476486 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008406019769609 nn.Linear: 0.023916631937027] nn.Sequential: [nn.Linear: 0.0043241917155683 nn.Linear: 0.011057445779443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633497482486 nn.Linear: 0.063955712423585 nn.Linear: 0.04483506911526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431178245349 nn.Linear: 0.044214363202983] nn.Sequential: [nn.Linear: 0.031386560857214 nn.Linear: 0.031409460187163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43949118256569 nn.Linear: 0.20326292514801 nn.Linear: 0.13163854181767 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096796229481697 nn.Linear: 0.20650957524776] nn.Sequential: [nn.Linear: 0.09046783298254 nn.Linear: 0.17059861123562]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00070876072895211 nn.Linear: 0.00041963631342386 nn.Linear: 0.00022626688253965 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.6737668601828e-05 nn.Linear: 0.00094481063727625] nn.Sequential: [nn.Linear: 0.00010186523674397 nn.Linear: 0.001066332874994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046645528636873 nn.Linear: 0.0072120437398553 nn.Linear: 0.0072189453057945 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030165493953973 nn.Linear: 0.0070920148864388] nn.Sequential: [nn.Linear: 0.0041727162897587 nn.Linear: 0.01360091753304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634417901492 nn.Linear: 0.063961148971856 nn.Linear: 0.044835569487545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431079914631 nn.Linear: 0.044211097168102] nn.Sequential: [nn.Linear: 0.031386724230578 nn.Linear: 0.031424378848444]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.43961906433105 nn.Linear: 0.20259217917919 nn.Linear: 0.13188473880291 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096766546368599 nn.Linear: 0.20644401013851] nn.Sequential: [nn.Linear: 0.090248599648476 nn.Linear: 0.17018932104111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015656684153734 nn.Linear: 0.0009905458391358 nn.Linear: 0.00048185217804544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017725111402896 nn.Linear: 0.002315888449538] nn.Sequential: [nn.Linear: 0.00015316130060912 nn.Linear: 0.0013938498093727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096631329506636 nn.Linear: 0.013241997919977 nn.Linear: 0.0085000013932586 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058814496733248 nn.Linear: 0.017102846875787] nn.Sequential: [nn.Linear: 0.004998791962862 nn.Linear: 0.012459943071008]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633734917503 nn.Linear: 0.063965122458056 nn.Linear: 0.044836737988407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431388441236 nn.Linear: 0.044237326569373] nn.Sequential: [nn.Linear: 0.031387099457922 nn.Linear: 0.031454104204335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4401663839817 nn.Linear: 0.20195020735264 nn.Linear: 0.1321228146553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.096891365945339 nn.Linear: 0.20648801326752] nn.Sequential: [nn.Linear: 0.090605475008488 nn.Linear: 0.17023381590843]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013852519617266 nn.Linear: 0.00099110565226857 nn.Linear: 0.00060032809659887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022597546274764 nn.Linear: 0.0034057077946907] nn.Sequential: [nn.Linear: 0.00029554754733804 nn.Linear: 0.0032895873913061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081152794882655 nn.Linear: 0.017148973420262 nn.Linear: 0.012314833700657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012219630181789 nn.Linear: 0.020094703882933] nn.Sequential: [nn.Linear: 0.0083080427721143 nn.Linear: 0.032731607556343]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633162077395 nn.Linear: 0.063967626091235 nn.Linear: 0.04483771168031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431601969039 nn.Linear: 0.044237770068861] nn.Sequential: [nn.Linear: 0.031387533548348 nn.Linear: 0.031476523215118]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44023102521896 nn.Linear: 0.20206779241562 nn.Linear: 0.13190194964409 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097199931740761 nn.Linear: 0.20627410709858] nn.Sequential: [nn.Linear: 0.090663693845272 nn.Linear: 0.17011438310146]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001022310778292 nn.Linear: 0.00076903560673315 nn.Linear: 0.00045691897429782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019348964815239 nn.Linear: 0.002785821012009] nn.Sequential: [nn.Linear: 0.00016260485205949 nn.Linear: 0.0014201000712076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071855476126075 nn.Linear: 0.012645427137613 nn.Linear: 0.0089480541646481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072832508012652 nn.Linear: 0.020241543650627] nn.Sequential: [nn.Linear: 0.0041988980956376 nn.Linear: 0.01480226777494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633595521986 nn.Linear: 0.063971428725646 nn.Linear: 0.044838836159417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031431870615827 nn.Linear: 0.04430025886964] nn.Sequential: [nn.Linear: 0.031387894690038 nn.Linear: 0.031493498314878]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44089657068253 nn.Linear: 0.20250444114208 nn.Linear: 0.13175313174725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097358092665672 nn.Linear: 0.20726156234741] nn.Sequential: [nn.Linear: 0.090667307376862 nn.Linear: 0.17022052407265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031590959857872 nn.Linear: 0.0016562078256086 nn.Linear: 0.00069480179897839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020846892497375 nn.Linear: 0.0029936158370891] nn.Sequential: [nn.Linear: 0.00020763848670261 nn.Linear: 0.0018266998002335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025217557325959 nn.Linear: 0.026950187981129 nn.Linear: 0.018437014892697 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010978610254824 nn.Linear: 0.015431691892445] nn.Sequential: [nn.Linear: 0.0073003810830414 nn.Linear: 0.015215251594782]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0626302044691 nn.Linear: 0.063973076160006 nn.Linear: 0.044839147514425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031432129280438 nn.Linear: 0.044332510901882] nn.Sequential: [nn.Linear: 0.031387886718155 nn.Linear: 0.03150568789885]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44075635075569 nn.Linear: 0.20258581638336 nn.Linear: 0.13195757567883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097243681550026 nn.Linear: 0.2077190130949] nn.Sequential: [nn.Linear: 0.090826958417892 nn.Linear: 0.16960799694061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011608606628543 nn.Linear: 0.00079291802171073 nn.Linear: 0.00046214232587095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015579955273858 nn.Linear: 0.0019108086738107] nn.Sequential: [nn.Linear: 0.00016897726505587 nn.Linear: 0.0017023136186656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0093369940295815 nn.Linear: 0.014094984158874 nn.Linear: 0.0080099832266569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070710126310587 nn.Linear: 0.013736363500357] nn.Sequential: [nn.Linear: 0.0051521398127079 nn.Linear: 0.018122628331184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629533591718 nn.Linear: 0.063977595994572 nn.Linear: 0.044841122788161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031432679986416 nn.Linear: 0.044396160737847] nn.Sequential: [nn.Linear: 0.031388151288342 nn.Linear: 0.031525501378419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44154480099678 nn.Linear: 0.20208387076855 nn.Linear: 0.13164639472961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097549013793468 nn.Linear: 0.20863254368305] nn.Sequential: [nn.Linear: 0.090920589864254 nn.Linear: 0.16976223886013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083994607481661 nn.Linear: 0.00056644869498348 nn.Linear: 0.00035712571120797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012727140853221 nn.Linear: 0.0015079794813229] nn.Sequential: [nn.Linear: 0.0001453500936264 nn.Linear: 0.0013236463085038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070636933669448 nn.Linear: 0.009145618416369 nn.Linear: 0.00754250632599 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050637805834413 nn.Linear: 0.014673396013677] nn.Sequential: [nn.Linear: 0.0067277266643941 nn.Linear: 0.014918638393283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633414349293 nn.Linear: 0.063981994720315 nn.Linear: 0.044842593082139 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03143286652748 nn.Linear: 0.044389263465064] nn.Sequential: [nn.Linear: 0.031388490671926 nn.Linear: 0.031540537193191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4412961602211 nn.Linear: 0.20316489040852 nn.Linear: 0.13162755966187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097671426832676 nn.Linear: 0.20842441916466] nn.Sequential: [nn.Linear: 0.091149196028709 nn.Linear: 0.16981978714466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001612715271429 nn.Linear: 0.00093966900514816 nn.Linear: 0.00043469992118222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001605070156829 nn.Linear: 0.0023930088555657] nn.Sequential: [nn.Linear: 0.0001369150265875 nn.Linear: 0.0011912617174159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011630796827376 nn.Linear: 0.019466429948807 nn.Linear: 0.010534642264247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079722488299012 nn.Linear: 0.020193077623844] nn.Sequential: [nn.Linear: 0.0048776557669044 nn.Linear: 0.013272827491164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062627826172137 nn.Linear: 0.063982927887111 nn.Linear: 0.044843957995418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031432818974905 nn.Linear: 0.044415469210435] nn.Sequential: [nn.Linear: 0.031388660638513 nn.Linear: 0.031562703793723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44171613454819 nn.Linear: 0.2032438069582 nn.Linear: 0.13151769340038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097784720361233 nn.Linear: 0.2083221077919] nn.Sequential: [nn.Linear: 0.091149881482124 nn.Linear: 0.16975605487823]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011693751900771 nn.Linear: 0.00098346629461987 nn.Linear: 0.00047092136811038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019218185225833 nn.Linear: 0.0027261624988382] nn.Sequential: [nn.Linear: 0.00014587054793359 nn.Linear: 0.0011741541289914]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077349776402116 nn.Linear: 0.011435278691351 nn.Linear: 0.01003535836935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013613663613796 nn.Linear: 0.020031664520502] nn.Sequential: [nn.Linear: 0.0060403221286833 nn.Linear: 0.013969578780234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062628891900492 nn.Linear: 0.063985408709606 nn.Linear: 0.044845228443443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03143308468903 nn.Linear: 0.044435204125989] nn.Sequential: [nn.Linear: 0.031388861957481 nn.Linear: 0.031580129348838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4416039288044 nn.Linear: 0.20314860343933 nn.Linear: 0.13156090676785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097875975072384 nn.Linear: 0.20926275849342] nn.Sequential: [nn.Linear: 0.091162264347076 nn.Linear: 0.16975267231464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017666663771311 nn.Linear: 0.0010056814113514 nn.Linear: 0.00055438307436832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017573984677408 nn.Linear: 0.0023291341682024] nn.Sequential: [nn.Linear: 0.00022462551894305 nn.Linear: 0.0025876369169277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013553817756474 nn.Linear: 0.019433166831732 nn.Linear: 0.016907811164856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082513121888041 nn.Linear: 0.0206363145262] nn.Sequential: [nn.Linear: 0.007893044501543 nn.Linear: 0.032432202249765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629444550324 nn.Linear: 0.063986346458718 nn.Linear: 0.04484503754487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031433119894768 nn.Linear: 0.044429256657565] nn.Sequential: [nn.Linear: 0.031389084995433 nn.Linear: 0.031578003066808]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44228720664978 nn.Linear: 0.2030141800642 nn.Linear: 0.13176801800728 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.098001718521118 nn.Linear: 0.20964492857456] nn.Sequential: [nn.Linear: 0.091009795665741 nn.Linear: 0.16982741653919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096681048806208 nn.Linear: 0.00073701232831729 nn.Linear: 0.00039095791420115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015018660497215 nn.Linear: 0.0023305231291193] nn.Sequential: [nn.Linear: 0.00015783121831934 nn.Linear: 0.0014825233316763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060565173625946 nn.Linear: 0.011014742776752 nn.Linear: 0.0063893548212945 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051811733283103 nn.Linear: 0.015200548805296] nn.Sequential: [nn.Linear: 0.0051892763003707 nn.Linear: 0.014191063120961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631367915371 nn.Linear: 0.063991465891777 nn.Linear: 0.044846623649687 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03143341076099 nn.Linear: 0.044462897164749] nn.Sequential: [nn.Linear: 0.031389590534469 nn.Linear: 0.031610872898072]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44186329841614 nn.Linear: 0.2030870616436 nn.Linear: 0.13190564513206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09802919626236 nn.Linear: 0.21048045158386] nn.Sequential: [nn.Linear: 0.091054365038872 nn.Linear: 0.16996797919273]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020850367493138 nn.Linear: 0.0011429491368692 nn.Linear: 0.00048938556510211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001940981339979 nn.Linear: 0.0027719401320334] nn.Sequential: [nn.Linear: 0.00011656344430177 nn.Linear: 0.0010520389835268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011591974645853 nn.Linear: 0.013749050907791 nn.Linear: 0.0076837241649628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0095085939392447 nn.Linear: 0.02421966008842] nn.Sequential: [nn.Linear: 0.0038820572663099 nn.Linear: 0.01166470348835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634740465104 nn.Linear: 0.063995953655523 nn.Linear: 0.044848483552616 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031433527599295 nn.Linear: 0.044494112620953] nn.Sequential: [nn.Linear: 0.031389791650311 nn.Linear: 0.031622552164853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44168943166733 nn.Linear: 0.20318798720837 nn.Linear: 0.131826415658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.097890071570873 nn.Linear: 0.21097730100155] nn.Sequential: [nn.Linear: 0.091282866895199 nn.Linear: 0.17019131779671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00056084514230351 nn.Linear: 0.00044762268240914 nn.Linear: 0.00024217551213017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.9910625467329e-05 nn.Linear: 0.0010577962991991] nn.Sequential: [nn.Linear: 8.0887207130939e-05 nn.Linear: 0.00070234748663305]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0038232596125454 nn.Linear: 0.0058726877905428 nn.Linear: 0.0044387639500201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030460525304079 nn.Linear: 0.0090167978778481] nn.Sequential: [nn.Linear: 0.002034384990111 nn.Linear: 0.007060382515192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062623566218551 nn.Linear: 0.063994754894644 nn.Linear: 0.044849566030062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031433827721494 nn.Linear: 0.044512032096947] nn.Sequential: [nn.Linear: 0.031389944947903 nn.Linear: 0.031631449580973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44252851605415 nn.Linear: 0.20385439693928 nn.Linear: 0.13194116950035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.098301015794277 nn.Linear: 0.21176794171333] nn.Sequential: [nn.Linear: 0.09123956412077 nn.Linear: 0.17063704133034]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089644427661089 nn.Linear: 0.00057240087887677 nn.Linear: 0.00031079286107727 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011600914861238 nn.Linear: 0.0017220249702957] nn.Sequential: [nn.Linear: 9.6766464900279e-05 nn.Linear: 0.00087659973092302]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066116973757744 nn.Linear: 0.0094814486801624 nn.Linear: 0.0087196724489331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004098720382899 nn.Linear: 0.011835293844342] nn.Sequential: [nn.Linear: 0.0026547673624009 nn.Linear: 0.0078570004552603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062628635032778 nn.Linear: 0.063999996161441 nn.Linear: 0.044850468020448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031434055125344 nn.Linear: 0.044542982795804] nn.Sequential: [nn.Linear: 0.031390254135391 nn.Linear: 0.031651117620168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44231086969376 nn.Linear: 0.20431600511074 nn.Linear: 0.13239270448685 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.09856840968132 nn.Linear: 0.21266433596611] nn.Sequential: [nn.Linear: 0.091316811740398 nn.Linear: 0.17081217467785]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085519898890758 nn.Linear: 0.00055370501253187 nn.Linear: 0.00031094188497437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011565963367019 nn.Linear: 0.0015980916502015] nn.Sequential: [nn.Linear: 0.00010880310837925 nn.Linear: 0.00092210942956158]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068963249213994 nn.Linear: 0.0086360396817327 nn.Linear: 0.0054885353893042 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068962601944804 nn.Linear: 0.012182082980871] nn.Sequential: [nn.Linear: 0.0045080571435392 nn.Linear: 0.01155224442482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629541081779 nn.Linear: 0.064003950044281 nn.Linear: 0.044852946787196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031434362791472 nn.Linear: 0.044612047517695] nn.Sequential: [nn.Linear: 0.03139074207575 nn.Linear: 0.031675192182706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44263499975204 nn.Linear: 0.20455998182297 nn.Linear: 0.13252434134483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.098922491073608 nn.Linear: 0.21355640888214] nn.Sequential: [nn.Linear: 0.091432459652424 nn.Linear: 0.17131932079792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00073474708944099 nn.Linear: 0.00044544506351256 nn.Linear: 0.00027244865466112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011608144135582 nn.Linear: 0.00170868782602] nn.Sequential: [nn.Linear: 0.00011410227368062 nn.Linear: 0.0011513898990652]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059440513141453 nn.Linear: 0.0087742758914828 nn.Linear: 0.0054252832196653 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00442462740466 nn.Linear: 0.0091947764158249] nn.Sequential: [nn.Linear: 0.002907061483711 nn.Linear: 0.0098090535029769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629732666922 nn.Linear: 0.064006480196677 nn.Linear: 0.044853750630149 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031434714872043 nn.Linear: 0.044647124118953] nn.Sequential: [nn.Linear: 0.031390819629397 nn.Linear: 0.031694736273888]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44321185350418 nn.Linear: 0.20445165038109 nn.Linear: 0.1324440985918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.099237896502018 nn.Linear: 0.21434408426285] nn.Sequential: [nn.Linear: 0.091410420835018 nn.Linear: 0.17127880454063]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013168227151363 nn.Linear: 0.00062420123308537 nn.Linear: 0.00031215592143129 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010180764717798 nn.Linear: 0.0013307603417659] nn.Sequential: [nn.Linear: 0.0001082428157826 nn.Linear: 0.0010381344264873]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010062172077596 nn.Linear: 0.011322292499244 nn.Linear: 0.011695916764438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061015943065286 nn.Linear: 0.011581944301724] nn.Sequential: [nn.Linear: 0.0030921366997063 nn.Linear: 0.011069643311203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062628710624974 nn.Linear: 0.06400930804912 nn.Linear: 0.044855638125891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031434685344443 nn.Linear: 0.044679197470714] nn.Sequential: [nn.Linear: 0.031391189583852 nn.Linear: 0.031710355604181]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4435185790062 nn.Linear: 0.2043089568615 nn.Linear: 0.13209789991379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.099691644310951 nn.Linear: 0.21480117738247] nn.Sequential: [nn.Linear: 0.091480247676373 nn.Linear: 0.17159935832024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021963050563929 nn.Linear: 0.0011461778904533 nn.Linear: 0.0005022503956122 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023807309214849 nn.Linear: 0.0039547148990673] nn.Sequential: [nn.Linear: 0.00015761228664302 nn.Linear: 0.0015020182353665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013439651578665 nn.Linear: 0.018051439896226 nn.Linear: 0.017016181722283 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012778994627297 nn.Linear: 0.029219599440694] nn.Sequential: [nn.Linear: 0.0062601352110505 nn.Linear: 0.014929737895727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631238987982 nn.Linear: 0.064012341790822 nn.Linear: 0.044856951768996 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031434761469769 nn.Linear: 0.044688448249872] nn.Sequential: [nn.Linear: 0.031391543531477 nn.Linear: 0.031736123825526]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44404473900795 nn.Linear: 0.20465286076069 nn.Linear: 0.13204577565193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.099822074174881 nn.Linear: 0.21524332463741] nn.Sequential: [nn.Linear: 0.091540224850178 nn.Linear: 0.17158050835133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011335167556694 nn.Linear: 0.00069102404505088 nn.Linear: 0.00039557491624008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014096524743477 nn.Linear: 0.0017246012301507] nn.Sequential: [nn.Linear: 0.00014909861758202 nn.Linear: 0.0011776094024106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081347925588489 nn.Linear: 0.0092560863122344 nn.Linear: 0.0087267067283392 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044318847358227 nn.Linear: 0.011393909342587] nn.Sequential: [nn.Linear: 0.0033203344792128 nn.Linear: 0.010374831035733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062641337018945 nn.Linear: 0.064021550193819 nn.Linear: 0.044859551302003 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031435143254642 nn.Linear: 0.044710482331993] nn.Sequential: [nn.Linear: 0.031392046430177 nn.Linear: 0.031745422504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44398227334023 nn.Linear: 0.20494922995567 nn.Linear: 0.1319442242384 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10018770396709 nn.Linear: 0.21601773798466] nn.Sequential: [nn.Linear: 0.091700226068497 nn.Linear: 0.17171613872051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011842737716656 nn.Linear: 0.0007531696252408 nn.Linear: 0.00041937399168297 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002059104457239 nn.Linear: 0.0031572374932765] nn.Sequential: [nn.Linear: 0.00011206486753909 nn.Linear: 0.00096968790886932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074946237728 nn.Linear: 0.012902148999274 nn.Linear: 0.013918530195951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074292980134487 nn.Linear: 0.023673256859183] nn.Sequential: [nn.Linear: 0.0028132942970842 nn.Linear: 0.011798944324255]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.092042975708842	TD error	0.019087671011686	Qmax	1	

Steps: 5500000 (frames: 22000000), score: 1660.78, higheset score: 5496, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1809fps, testing time: 89s, testing rate: 5559fps,  num. ep.: 499,  num. rewards: 20002	
   4    8    4    2
   2   16   64   32
   8   64    4  128
  16    4    8  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062632744337916 nn.Linear: 0.064022130859835 nn.Linear: 0.044859111762574 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031435396877947 nn.Linear: 0.044750275911639] nn.Sequential: [nn.Linear: 0.031391946447371 nn.Linear: 0.031746263022514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44433459639549 nn.Linear: 0.20420418679714 nn.Linear: 0.132160410285 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10024002194405 nn.Linear: 0.2160152643919] nn.Sequential: [nn.Linear: 0.091674372553825 nn.Linear: 0.17170032858849]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061429433956733 nn.Linear: 0.00040211400892427 nn.Linear: 0.00024800604979491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010980349973563 nn.Linear: 0.001625806297415] nn.Sequential: [nn.Linear: 9.9002881914203e-05 nn.Linear: 0.00088513644769974]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043222918175161 nn.Linear: 0.0073351128958166 nn.Linear: 0.0061395182274282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039947256445885 nn.Linear: 0.012729403562844] nn.Sequential: [nn.Linear: 0.0035716246347874 nn.Linear: 0.0097785135731101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631505744664 nn.Linear: 0.064024905818042 nn.Linear: 0.044859837447782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031435627554752 nn.Linear: 0.044806335176816] nn.Sequential: [nn.Linear: 0.031392305193824 nn.Linear: 0.031785269813887]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44394534826279 nn.Linear: 0.20433542132378 nn.Linear: 0.13216470181942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10017322748899 nn.Linear: 0.21703210473061] nn.Sequential: [nn.Linear: 0.091610811650753 nn.Linear: 0.17175254225731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010678167939421 nn.Linear: 0.00062297423172989 nn.Linear: 0.00032206312282366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012439419817739 nn.Linear: 0.0014310746573193] nn.Sequential: [nn.Linear: 0.00011608531598049 nn.Linear: 0.00077129964043986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076601463370025 nn.Linear: 0.0099746063351631 nn.Linear: 0.0069112866185606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061589353717864 nn.Linear: 0.0098248589783907] nn.Sequential: [nn.Linear: 0.0029754140414298 nn.Linear: 0.0095799695700407]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062638388754943 nn.Linear: 0.064030367326177 nn.Linear: 0.044861803500763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031435739413587 nn.Linear: 0.04481919692094] nn.Sequential: [nn.Linear: 0.031392578185762 nn.Linear: 0.031789182778717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44418153166771 nn.Linear: 0.20404827594757 nn.Linear: 0.13206447660923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10060396790504 nn.Linear: 0.21781432628632] nn.Sequential: [nn.Linear: 0.09177877753973 nn.Linear: 0.17152538895607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017899949721811 nn.Linear: 0.0011190188587842 nn.Linear: 0.00052663629009056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025810391050947 nn.Linear: 0.0032817136186716] nn.Sequential: [nn.Linear: 0.0001556478482915 nn.Linear: 0.0013428001827491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013375828973949 nn.Linear: 0.022174226120114 nn.Linear: 0.013700311072171 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011516157537699 nn.Linear: 0.021221065893769] nn.Sequential: [nn.Linear: 0.0048595680855215 nn.Linear: 0.014250731095672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631663204839 nn.Linear: 0.064029772222464 nn.Linear: 0.044863450438827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031436213625036 nn.Linear: 0.044846382345838] nn.Sequential: [nn.Linear: 0.031392954882819 nn.Linear: 0.031805943442465]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4451359808445 nn.Linear: 0.20458044111729 nn.Linear: 0.1326080262661 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10092359036207 nn.Linear: 0.21849891543388] nn.Sequential: [nn.Linear: 0.092061102390289 nn.Linear: 0.17136265337467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00054045339299381 nn.Linear: 0.00039835162619805 nn.Linear: 0.00025844605904118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010641433626607 nn.Linear: 0.0016123762420959] nn.Sequential: [nn.Linear: 9.3259124238848e-05 nn.Linear: 0.00088086579461914]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0031017933506519 nn.Linear: 0.0067517943680286 nn.Linear: 0.0058926250785589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043142372742295 nn.Linear: 0.010951939038932] nn.Sequential: [nn.Linear: 0.0028846191707999 nn.Linear: 0.0096246544271708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062630291808646 nn.Linear: 0.064033219379921 nn.Linear: 0.044864539528098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031436325616966 nn.Linear: 0.044891507330789] nn.Sequential: [nn.Linear: 0.031393199196708 nn.Linear: 0.031820723976685]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44565662741661 nn.Linear: 0.2047770768404 nn.Linear: 0.13224282860756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10088251531124 nn.Linear: 0.2188396602869] nn.Sequential: [nn.Linear: 0.092208035290241 nn.Linear: 0.17183214426041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080083048071403 nn.Linear: 0.00052181475809599 nn.Linear: 0.000295011865832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015900150460738 nn.Linear: 0.0027080202274106] nn.Sequential: [nn.Linear: 0.00010329498839676 nn.Linear: 0.00088938400514492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062052048742771 nn.Linear: 0.0087826428934932 nn.Linear: 0.005541680380702 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004920840729028 nn.Linear: 0.014053853228688] nn.Sequential: [nn.Linear: 0.0031838288996369 nn.Linear: 0.0091851856559515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062623595954556 nn.Linear: 0.064035413912609 nn.Linear: 0.044865909886346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031436680505307 nn.Linear: 0.044919745652123] nn.Sequential: [nn.Linear: 0.031393454898869 nn.Linear: 0.03184710468372]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44646036624908 nn.Linear: 0.20469732582569 nn.Linear: 0.13268887996674 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10140968114138 nn.Linear: 0.21980512142181] nn.Sequential: [nn.Linear: 0.092215351760387 nn.Linear: 0.17214843630791]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018067606250335 nn.Linear: 0.0012283634421698 nn.Linear: 0.00059488212339601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023269939535315 nn.Linear: 0.0032474887772604] nn.Sequential: [nn.Linear: 0.00022574155672043 nn.Linear: 0.0024174277031359]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010591405443847 nn.Linear: 0.018281452357769 nn.Linear: 0.013239229097962 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079268580302596 nn.Linear: 0.019111540168524] nn.Sequential: [nn.Linear: 0.0059057101607323 nn.Linear: 0.019031627103686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062631224324671 nn.Linear: 0.064041367350115 nn.Linear: 0.044867284131218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031436909261537 nn.Linear: 0.044922742877759] nn.Sequential: [nn.Linear: 0.031393825208864 nn.Linear: 0.031850228896264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44678354263306 nn.Linear: 0.20472869277 nn.Linear: 0.13298258185387 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10106474161148 nn.Linear: 0.22010512650013] nn.Sequential: [nn.Linear: 0.092302337288857 nn.Linear: 0.17209765315056]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020255297523399 nn.Linear: 0.0014591398360491 nn.Linear: 0.00071583943201619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00036912993427742 nn.Linear: 0.0060773314975853] nn.Sequential: [nn.Linear: 0.00023339615860529 nn.Linear: 0.0021689957039073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01306885574013 nn.Linear: 0.024971470236778 nn.Linear: 0.013901548460126 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016017857939005 nn.Linear: 0.035418082028627] nn.Sequential: [nn.Linear: 0.0077255661599338 nn.Linear: 0.022299068048596]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062633986197575 nn.Linear: 0.064044841426231 nn.Linear: 0.044868066211019 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437170743565 nn.Linear: 0.044965668228542] nn.Sequential: [nn.Linear: 0.031394024837398 nn.Linear: 0.031859743840083]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4466036260128 nn.Linear: 0.20472832024097 nn.Linear: 0.13269390165806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10135515779257 nn.Linear: 0.22063946723938] nn.Sequential: [nn.Linear: 0.092384316027164 nn.Linear: 0.17218209803104]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010461532619083 nn.Linear: 0.00064498768045421 nn.Linear: 0.00035601448752352 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014161698290575 nn.Linear: 0.0018880216568524] nn.Sequential: [nn.Linear: 0.00012069169062629 nn.Linear: 0.0011489834448023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072609814815223 nn.Linear: 0.0084382528439164 nn.Linear: 0.0065516936592758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051448885351419 nn.Linear: 0.011641265824437] nn.Sequential: [nn.Linear: 0.0044948286376894 nn.Linear: 0.011718604713678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06263263846857 nn.Linear: 0.064048154327403 nn.Linear: 0.044869246665712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437271544879 nn.Linear: 0.04498281880953] nn.Sequential: [nn.Linear: 0.031394118353284 nn.Linear: 0.031877182994812]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44637385010719 nn.Linear: 0.20524731278419 nn.Linear: 0.13277959823608 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10156641900539 nn.Linear: 0.22150525450706] nn.Sequential: [nn.Linear: 0.092256166040897 nn.Linear: 0.1721733212471]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089946461200102 nn.Linear: 0.00062279400751121 nn.Linear: 0.00036638493564871 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016651201100628 nn.Linear: 0.0022396362720865] nn.Sequential: [nn.Linear: 0.00013843527841026 nn.Linear: 0.0011397293936602]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066557237878442 nn.Linear: 0.0081860525533557 nn.Linear: 0.0060520693659782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065582892857492 nn.Linear: 0.017430275678635] nn.Sequential: [nn.Linear: 0.0041830139234662 nn.Linear: 0.013063161633909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062635739650695 nn.Linear: 0.064054291262277 nn.Linear: 0.044871226095915 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437782593924 nn.Linear: 0.045019574815086] nn.Sequential: [nn.Linear: 0.031394467243211 nn.Linear: 0.031894922238839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44566580653191 nn.Linear: 0.20529079437256 nn.Linear: 0.13271436095238 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10149011015892 nn.Linear: 0.2221827507019] nn.Sequential: [nn.Linear: 0.092323735356331 nn.Linear: 0.17242765426636]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080343934660981 nn.Linear: 0.00057459627186831 nn.Linear: 0.0002704871529575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.5960506557879e-05 nn.Linear: 0.00099905627868555] nn.Sequential: [nn.Linear: 9.0665250005554e-05 nn.Linear: 0.00072210627646604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058392593637109 nn.Linear: 0.0072194463573396 nn.Linear: 0.0064506148919463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039181727916002 nn.Linear: 0.0071141384541988] nn.Sequential: [nn.Linear: 0.0034147868864238 nn.Linear: 0.0071956464089453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062625822399569 nn.Linear: 0.064055075036382 nn.Linear: 0.044871207980607 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437976378831 nn.Linear: 0.045032654133621] nn.Sequential: [nn.Linear: 0.031394548313597 nn.Linear: 0.031904325524671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44627809524536 nn.Linear: 0.20523253083229 nn.Linear: 0.13279823958874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10171023756266 nn.Linear: 0.22266200184822] nn.Sequential: [nn.Linear: 0.092246547341347 nn.Linear: 0.1723335981369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00072874928029927 nn.Linear: 0.00047577831822656 nn.Linear: 0.00025796079728832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6645733742484e-05 nn.Linear: 0.0011231597656271] nn.Sequential: [nn.Linear: 8.751695809945e-05 nn.Linear: 0.00076322214450719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059135654009879 nn.Linear: 0.0088112251833081 nn.Linear: 0.0049394397065043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054076397791505 nn.Linear: 0.006861865054816] nn.Sequential: [nn.Linear: 0.0030577022116631 nn.Linear: 0.0070321233943105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062621610110871 nn.Linear: 0.064056766038928 nn.Linear: 0.044871334725668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437763586454 nn.Linear: 0.045029340279768] nn.Sequential: [nn.Linear: 0.031394836989434 nn.Linear: 0.031931863348703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44663894176483 nn.Linear: 0.20563754439354 nn.Linear: 0.13290885090828 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10168042778969 nn.Linear: 0.22298143804073] nn.Sequential: [nn.Linear: 0.092322990298271 nn.Linear: 0.17249113321304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015201380298548 nn.Linear: 0.00099425971665788 nn.Linear: 0.00050437196338688 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017443383358103 nn.Linear: 0.0023317198135027] nn.Sequential: [nn.Linear: 0.00017592881796273 nn.Linear: 0.001624670034487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01295696105808 nn.Linear: 0.020360395312309 nn.Linear: 0.016869075596333 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076782363466918 nn.Linear: 0.016457878053188] nn.Sequential: [nn.Linear: 0.0063042235560715 nn.Linear: 0.022865789011121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062624098119683 nn.Linear: 0.064062674677611 nn.Linear: 0.044873068231563 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031437864745982 nn.Linear: 0.04501181765464] nn.Sequential: [nn.Linear: 0.031395300682939 nn.Linear: 0.031946152212571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44649550318718 nn.Linear: 0.20551574230194 nn.Linear: 0.13282831013203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10155063122511 nn.Linear: 0.22382533550262] nn.Sequential: [nn.Linear: 0.09233408421278 nn.Linear: 0.17276667058468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00059893930494509 nn.Linear: 0.00042094356426363 nn.Linear: 0.00022653620312823 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010131799748055 nn.Linear: 0.0015078073735354] nn.Sequential: [nn.Linear: 7.6760447382709e-05 nn.Linear: 0.00058534212959543]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004838062915951 nn.Linear: 0.0052205729298294 nn.Linear: 0.0037244560662657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033426752779633 nn.Linear: 0.010640106163919] nn.Sequential: [nn.Linear: 0.0015217937761918 nn.Linear: 0.004644613713026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0626141273246 nn.Linear: 0.064062675718308 nn.Linear: 0.044873857021757 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031438002731404 nn.Linear: 0.045036708949077] nn.Sequential: [nn.Linear: 0.031395544651074 nn.Linear: 0.031959175172517]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44733300805092 nn.Linear: 0.20592132210732 nn.Linear: 0.1329083442688 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10157381743193 nn.Linear: 0.22435508668423] nn.Sequential: [nn.Linear: 0.092542044818401 nn.Linear: 0.17286226153374]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010877627325538 nn.Linear: 0.00069414470924447 nn.Linear: 0.00032199899301073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014659710255577 nn.Linear: 0.0019359125123914] nn.Sequential: [nn.Linear: 0.0001048438056069 nn.Linear: 0.00072185339244251]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0093813110142946 nn.Linear: 0.010324224829674 nn.Linear: 0.013030618429184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0067192716524005 nn.Linear: 0.015037405304611] nn.Sequential: [nn.Linear: 0.003021546639502 nn.Linear: 0.0089629609137774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062615455823924 nn.Linear: 0.064066900898185 nn.Linear: 0.044875013471406 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031438330464763 nn.Linear: 0.045089105659372] nn.Sequential: [nn.Linear: 0.031395850421598 nn.Linear: 0.031985251988028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44649142026901 nn.Linear: 0.20524503290653 nn.Linear: 0.1330376714468 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10166800767183 nn.Linear: 0.22493442893028] nn.Sequential: [nn.Linear: 0.092596501111984 nn.Linear: 0.1728683412075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012677137894854 nn.Linear: 0.00081744251880403 nn.Linear: 0.00043530821798281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016048742285983 nn.Linear: 0.0021620775849217] nn.Sequential: [nn.Linear: 0.00014613785291955 nn.Linear: 0.0014625852289106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073197153396904 nn.Linear: 0.01273700594902 nn.Linear: 0.0076518664136529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011108913458884 nn.Linear: 0.016358887776732] nn.Sequential: [nn.Linear: 0.0048274951986969 nn.Linear: 0.021368546411395]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0626211617161 nn.Linear: 0.06407466270043 nn.Linear: 0.044876994187433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031438516772433 nn.Linear: 0.045086194561478] nn.Sequential: [nn.Linear: 0.031396333675703 nn.Linear: 0.031995113848726]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44646248221397 nn.Linear: 0.20613844692707 nn.Linear: 0.13322715461254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10097748041153 nn.Linear: 0.22521112859249] nn.Sequential: [nn.Linear: 0.092635348439217 nn.Linear: 0.17278419435024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016992849498653 nn.Linear: 0.0010102387359879 nn.Linear: 0.00048376034457727 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022004264137095 nn.Linear: 0.0034550351417829] nn.Sequential: [nn.Linear: 0.00011367795497488 nn.Linear: 0.0009605027842443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011779773980379 nn.Linear: 0.013888728804886 nn.Linear: 0.015414440073073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076892930082977 nn.Linear: 0.023699082434177] nn.Sequential: [nn.Linear: 0.0036522294394672 nn.Linear: 0.007229651324451]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062621023088149 nn.Linear: 0.064078867126388 nn.Linear: 0.044878002972612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031439006000205 nn.Linear: 0.045158997561018] nn.Sequential: [nn.Linear: 0.031396527634939 nn.Linear: 0.032021923361405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44712936878204 nn.Linear: 0.20578338205814 nn.Linear: 0.1331188082695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1014391630888 nn.Linear: 0.2265243679285] nn.Sequential: [nn.Linear: 0.092651210725307 nn.Linear: 0.17296075820923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014214575754126 nn.Linear: 0.00084035269775122 nn.Linear: 0.00038692677469341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015941675688729 nn.Linear: 0.001881185748966] nn.Sequential: [nn.Linear: 0.00013337435447811 nn.Linear: 0.0011360169555364]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01054132450372 nn.Linear: 0.0091714132577181 nn.Linear: 0.0081129362806678 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058269496075809 nn.Linear: 0.011295084841549] nn.Sequential: [nn.Linear: 0.0032341305632144 nn.Linear: 0.010505092330277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06261154872725 nn.Linear: 0.064082306046538 nn.Linear: 0.044879601370614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031439234380495 nn.Linear: 0.045176637716139] nn.Sequential: [nn.Linear: 0.031396868554152 nn.Linear: 0.032042417799893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44788959622383 nn.Linear: 0.2056920081377 nn.Linear: 0.13306537270546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10165450721979 nn.Linear: 0.22724314033985] nn.Sequential: [nn.Linear: 0.092602603137493 nn.Linear: 0.17284674942493]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012923060536364 nn.Linear: 0.0007688108387571 nn.Linear: 0.00037085010048557 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016436554244188 nn.Linear: 0.0025293743165351] nn.Sequential: [nn.Linear: 0.00015041319413028 nn.Linear: 0.0014027842143812]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096663059666753 nn.Linear: 0.013302731327713 nn.Linear: 0.017573170363903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071567175909877 nn.Linear: 0.019926914945245] nn.Sequential: [nn.Linear: 0.0055219167843461 nn.Linear: 0.01230719126761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06261355532618 nn.Linear: 0.064088361294691 nn.Linear: 0.044881378833359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031439697193691 nn.Linear: 0.045205589024832] nn.Sequential: [nn.Linear: 0.031397175971219 nn.Linear: 0.032079160196069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44788691401482 nn.Linear: 0.2059903293848 nn.Linear: 0.13325214385986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10203238576651 nn.Linear: 0.22770847380161] nn.Sequential: [nn.Linear: 0.092928446829319 nn.Linear: 0.17320197820663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002228569383405 nn.Linear: 0.0013964435399894 nn.Linear: 0.0006805320071734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022195432617184 nn.Linear: 0.0026317536986507] nn.Sequential: [nn.Linear: 0.0002624807591715 nn.Linear: 0.0027557548174156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016848040744662 nn.Linear: 0.023730959743261 nn.Linear: 0.017030961811543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012983363121748 nn.Linear: 0.017712950706482] nn.Sequential: [nn.Linear: 0.010871114209294 nn.Linear: 0.030422246083617]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062618133363102 nn.Linear: 0.064093075817255 nn.Linear: 0.044883635665056 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031439886524641 nn.Linear: 0.045211434136121] nn.Sequential: [nn.Linear: 0.03139768412221 nn.Linear: 0.032086469845126]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44793519377708 nn.Linear: 0.20628400146961 nn.Linear: 0.13331367075443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10198566317558 nn.Linear: 0.2281789034605] nn.Sequential: [nn.Linear: 0.092819258570671 nn.Linear: 0.17343777418137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069935541285386 nn.Linear: 0.00044053876305576 nn.Linear: 0.00025226000585476 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011918246563658 nn.Linear: 0.001925432882556] nn.Sequential: [nn.Linear: 8.131947414364e-05 nn.Linear: 0.00070452723101085]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005182730499655 nn.Linear: 0.0071042669005692 nn.Linear: 0.0050295274704695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052328486926854 nn.Linear: 0.011731076054275] nn.Sequential: [nn.Linear: 0.0019214560743421 nn.Linear: 0.0067303758114576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062616581816605 nn.Linear: 0.064095376766868 nn.Linear: 0.044885101658614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031440333189297 nn.Linear: 0.045268686774847] nn.Sequential: [nn.Linear: 0.031397859373667 nn.Linear: 0.032107809781348]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44782808423042 nn.Linear: 0.20563247799873 nn.Linear: 0.1335514485836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10257750749588 nn.Linear: 0.22893881797791] nn.Sequential: [nn.Linear: 0.092890374362469 nn.Linear: 0.1735065728426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099258323388195 nn.Linear: 0.00068019705196712 nn.Linear: 0.00036018749076935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017215542557952 nn.Linear: 0.0027375694953007] nn.Sequential: [nn.Linear: 0.0001144895987959 nn.Linear: 0.00087742285818577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062869810499251 nn.Linear: 0.0089316805824637 nn.Linear: 0.0080133797600865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082159489393234 nn.Linear: 0.02130514010787] nn.Sequential: [nn.Linear: 0.0037280295509845 nn.Linear: 0.0098070055246353]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062613350208471 nn.Linear: 0.064099720196812 nn.Linear: 0.044886395110097 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031440223015888 nn.Linear: 0.045271547107603] nn.Sequential: [nn.Linear: 0.031398014989543 nn.Linear: 0.032126620370548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44790056347847 nn.Linear: 0.20583410561085 nn.Linear: 0.13368794322014 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10262759029865 nn.Linear: 0.22964583337307] nn.Sequential: [nn.Linear: 0.092960685491562 nn.Linear: 0.17350944876671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092232850100885 nn.Linear: 0.00064109165558734 nn.Linear: 0.00034647116703543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001597075524771 nn.Linear: 0.0022583799732534] nn.Sequential: [nn.Linear: 0.00011046583753077 nn.Linear: 0.00085355243870254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051151048392057 nn.Linear: 0.0068091289140284 nn.Linear: 0.0081341424956918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075710187666118 nn.Linear: 0.01745249517262] nn.Sequential: [nn.Linear: 0.0036264092195779 nn.Linear: 0.01290928479284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062611953195699 nn.Linear: 0.064101784868888 nn.Linear: 0.044886835544496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031440440773406 nn.Linear: 0.045279213236888] nn.Sequential: [nn.Linear: 0.031398247744003 nn.Linear: 0.032134259836308]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44785341620445 nn.Linear: 0.20622189342976 nn.Linear: 0.13333564996719 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10268704593182 nn.Linear: 0.2300708591938] nn.Sequential: [nn.Linear: 0.092935092747211 nn.Linear: 0.17353329062462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010101825568962 nn.Linear: 0.00070536453876986 nn.Linear: 0.00032509647858646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011395027328234 nn.Linear: 0.001530336519818] nn.Sequential: [nn.Linear: 0.00011587974557536 nn.Linear: 0.00097624935999603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080924592912197 nn.Linear: 0.011955165304244 nn.Linear: 0.007421666290611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058543323539197 nn.Linear: 0.011228926479816] nn.Sequential: [nn.Linear: 0.0035211651120335 nn.Linear: 0.010182906873524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062617569640902 nn.Linear: 0.06410974346936 nn.Linear: 0.044888830619084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031440611641591 nn.Linear: 0.045285584795295] nn.Sequential: [nn.Linear: 0.031398523177285 nn.Linear: 0.032149472611053]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44850930571556 nn.Linear: 0.20678402483463 nn.Linear: 0.13347214460373 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10271819680929 nn.Linear: 0.23051883280277] nn.Sequential: [nn.Linear: 0.092966079711914 nn.Linear: 0.1734426766634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010788857510147 nn.Linear: 0.000758503535123 nn.Linear: 0.00035767187953742 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012721089340223 nn.Linear: 0.0014674514429611] nn.Sequential: [nn.Linear: 0.0001405972026929 nn.Linear: 0.0012752928231143]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092323115095496 nn.Linear: 0.011207520030439 nn.Linear: 0.0063775274902582 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059884800575674 nn.Linear: 0.0089403176680207] nn.Sequential: [nn.Linear: 0.0035432591103017 nn.Linear: 0.0099475914612412]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062616616276944 nn.Linear: 0.064110815708552 nn.Linear: 0.044889866001235 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031440955744823 nn.Linear: 0.045319149845632] nn.Sequential: [nn.Linear: 0.031398722833921 nn.Linear: 0.032174260338341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44844564795494 nn.Linear: 0.20709624886513 nn.Linear: 0.13346576690674 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10274315625429 nn.Linear: 0.23144218325615] nn.Sequential: [nn.Linear: 0.0929856300354 nn.Linear: 0.17375260591507]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00046981228274375 nn.Linear: 0.0003410880521701 nn.Linear: 0.0001625507802504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.5073201808453e-05 nn.Linear: 0.00070899916642209] nn.Sequential: [nn.Linear: 5.1347138386929e-05 nn.Linear: 0.00035179762768085]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0030465498566628 nn.Linear: 0.0047454163432121 nn.Linear: 0.0028259190730751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0020525401923805 nn.Linear: 0.0044615608640015] nn.Sequential: [nn.Linear: 0.0015062924940139 nn.Linear: 0.0037333187647164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.083572932705283	TD error	0.018652566313744	Qmax	1	

Steps: 5750000 (frames: 23000000), score: 1928.82, higheset score: 6184, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1813fps, testing time: 89s, testing rate: 5575fps,  num. ep.: 289,  num. rewards: 15235	
   2    4    2    4
   4   16  512    8
  16   64   16    2
   4   32    2  256
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062613189022106 nn.Linear: 0.064115467230497 nn.Linear: 0.044891168663241 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031441040898423 nn.Linear: 0.045365811440405] nn.Sequential: [nn.Linear: 0.03139894862477 nn.Linear: 0.032177515074382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44777557253838 nn.Linear: 0.20643855631351 nn.Linear: 0.1335638910532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10309857130051 nn.Linear: 0.23210228979588] nn.Sequential: [nn.Linear: 0.093087062239647 nn.Linear: 0.1735323369503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061803322290112 nn.Linear: 0.00043688318221311 nn.Linear: 0.00024316997298169 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011282593989396 nn.Linear: 0.0014725404810927] nn.Sequential: [nn.Linear: 8.677993286435e-05 nn.Linear: 0.00071923668166237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048385295085609 nn.Linear: 0.0088812615722418 nn.Linear: 0.0045731998980045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031336129177362 nn.Linear: 0.011552126146853] nn.Sequential: [nn.Linear: 0.0020186989568174 nn.Linear: 0.0057446882128716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062611394877654 nn.Linear: 0.064116806207673 nn.Linear: 0.044892601619011 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03144143272247 nn.Linear: 0.045410850985945] nn.Sequential: [nn.Linear: 0.031398993212698 nn.Linear: 0.032194453459045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4482294023037 nn.Linear: 0.20590473711491 nn.Linear: 0.1336625367403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10272131115198 nn.Linear: 0.23270094394684] nn.Sequential: [nn.Linear: 0.093034587800503 nn.Linear: 0.17368638515472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086598844358735 nn.Linear: 0.00055113010879095 nn.Linear: 0.00029872322794578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011741034546343 nn.Linear: 0.0013878372777774] nn.Sequential: [nn.Linear: 0.0001065799795461 nn.Linear: 0.00086575676699556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070761004462838 nn.Linear: 0.0079747103154659 nn.Linear: 0.0057732895947993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0039943396113813 nn.Linear: 0.0077289962209761] nn.Sequential: [nn.Linear: 0.0022041825577617 nn.Linear: 0.0072396090254188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062610142245238 nn.Linear: 0.064120567212236 nn.Linear: 0.044894089805761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031441606112482 nn.Linear: 0.045458809258719] nn.Sequential: [nn.Linear: 0.031399226398344 nn.Linear: 0.032207007141714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44824761152267 nn.Linear: 0.20602862536907 nn.Linear: 0.13354420661926 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10275437682867 nn.Linear: 0.2331809848547] nn.Sequential: [nn.Linear: 0.093124508857727 nn.Linear: 0.1737939864397]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015668540844412 nn.Linear: 0.0011208355786359 nn.Linear: 0.00057017713211503 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020010008534249 nn.Linear: 0.0027453612399002] nn.Sequential: [nn.Linear: 0.00020428956055352 nn.Linear: 0.0019882837515909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010350939817727 nn.Linear: 0.018307784572244 nn.Linear: 0.018394980579615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010355670005083 nn.Linear: 0.017677204683423] nn.Sequential: [nn.Linear: 0.0079075247049332 nn.Linear: 0.020552327856421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062614028971617 nn.Linear: 0.064123824906633 nn.Linear: 0.044895753189857 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031441699563465 nn.Linear: 0.045447553983024] nn.Sequential: [nn.Linear: 0.031399778551977 nn.Linear: 0.032235260315737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44856917858124 nn.Linear: 0.20587742328644 nn.Linear: 0.13373976945877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10344059020281 nn.Linear: 0.23339605331421] nn.Sequential: [nn.Linear: 0.092828504741192 nn.Linear: 0.17382960021496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082293403224142 nn.Linear: 0.00054104440975064 nn.Linear: 0.00028662238534712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012888931292503 nn.Linear: 0.0015936614839385] nn.Sequential: [nn.Linear: 0.00010090765891951 nn.Linear: 0.00082717430754058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051000076346099 nn.Linear: 0.0090933172032237 nn.Linear: 0.006812690757215 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053576403297484 nn.Linear: 0.011063291691244] nn.Sequential: [nn.Linear: 0.0025716461241245 nn.Linear: 0.0070504141040146]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062611169772726 nn.Linear: 0.064128595445399 nn.Linear: 0.044897067820512 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031441874188501 nn.Linear: 0.045472623880784] nn.Sequential: [nn.Linear: 0.031399920434626 nn.Linear: 0.032247958838159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4488000869751 nn.Linear: 0.2064056545496 nn.Linear: 0.13357102870941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10412316024303 nn.Linear: 0.23414772748947] nn.Sequential: [nn.Linear: 0.092710725963116 nn.Linear: 0.17383345961571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013058594145975 nn.Linear: 0.00095545623102509 nn.Linear: 0.00048063043834258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013891747733454 nn.Linear: 0.0014155075768413] nn.Sequential: [nn.Linear: 0.00018287668728794 nn.Linear: 0.0015936273961638]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088591938838363 nn.Linear: 0.013985431753099 nn.Linear: 0.0089667737483978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0067032780498266 nn.Linear: 0.0088000521063805] nn.Sequential: [nn.Linear: 0.0055951285175979 nn.Linear: 0.021097149699926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062608593057436 nn.Linear: 0.064131450732156 nn.Linear: 0.044898207090503 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031441970680044 nn.Linear: 0.045480005386025] nn.Sequential: [nn.Linear: 0.03140004222467 nn.Linear: 0.032259020415406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44879722595215 nn.Linear: 0.20714676380157 nn.Linear: 0.13365702331066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10397277772427 nn.Linear: 0.23439525067806] nn.Sequential: [nn.Linear: 0.092852599918842 nn.Linear: 0.17343303561211]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019005440445903 nn.Linear: 0.0010829833227599 nn.Linear: 0.00053333933164033 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020258161762457 nn.Linear: 0.0025919094126146] nn.Sequential: [nn.Linear: 0.00020021671155002 nn.Linear: 0.0019626648958167]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010586814954877 nn.Linear: 0.020528862252831 nn.Linear: 0.012790916487575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014713188633323 nn.Linear: 0.021141942590475] nn.Sequential: [nn.Linear: 0.0067731230519712 nn.Linear: 0.022278845310211]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062605319117569 nn.Linear: 0.064133964049465 nn.Linear: 0.044900002701247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031442098646664 nn.Linear: 0.045477969968005] nn.Sequential: [nn.Linear: 0.03140034698644 nn.Linear: 0.032273975880295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44949275255203 nn.Linear: 0.20777526497841 nn.Linear: 0.13394501805305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10398652404547 nn.Linear: 0.23478028178215] nn.Sequential: [nn.Linear: 0.092977121472359 nn.Linear: 0.17380110919476]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011432932132143 nn.Linear: 0.00070136844482532 nn.Linear: 0.0003815730723329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016114538786787 nn.Linear: 0.0024331970879397] nn.Sequential: [nn.Linear: 0.0001392463362435 nn.Linear: 0.0012234763330548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075828745029867 nn.Linear: 0.012201034463942 nn.Linear: 0.0084687266498804 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060376645997167 nn.Linear: 0.017157351598144] nn.Sequential: [nn.Linear: 0.0050063263624907 nn.Linear: 0.011755689047277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062601428021065 nn.Linear: 0.064138083882631 nn.Linear: 0.044901499078039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031442470461027 nn.Linear: 0.045523867455529] nn.Sequential: [nn.Linear: 0.031400392311203 nn.Linear: 0.032285486701447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44997438788414 nn.Linear: 0.2075442224741 nn.Linear: 0.13402642309666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10400675982237 nn.Linear: 0.23590864241123] nn.Sequential: [nn.Linear: 0.09308709949255 nn.Linear: 0.17364631593227]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092167443321692 nn.Linear: 0.00061997422313016 nn.Linear: 0.00031198750889074 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014162482713866 nn.Linear: 0.0019171531859368] nn.Sequential: [nn.Linear: 0.0001051423661235 nn.Linear: 0.00076279340514632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060882247053087 nn.Linear: 0.0093866679817438 nn.Linear: 0.0069325119256973 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043926094658673 nn.Linear: 0.013524604029953] nn.Sequential: [nn.Linear: 0.004652873147279 nn.Linear: 0.0069876834750175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062597315616282 nn.Linear: 0.06414280381078 nn.Linear: 0.044903107634734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031442593666383 nn.Linear: 0.045544552890874] nn.Sequential: [nn.Linear: 0.031400569941737 nn.Linear: 0.0323006769837]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44979962706566 nn.Linear: 0.20726308226585 nn.Linear: 0.13434267044067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10408300161362 nn.Linear: 0.23634652793407] nn.Sequential: [nn.Linear: 0.093201339244843 nn.Linear: 0.17357325553894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090727142841478 nn.Linear: 0.0005865549326984 nn.Linear: 0.00029715973457872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013244782986309 nn.Linear: 0.0017743988151946] nn.Sequential: [nn.Linear: 0.00010708125413791 nn.Linear: 0.00095723037950641]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073956307023764 nn.Linear: 0.0085946256294847 nn.Linear: 0.0069417865015566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043242117390037 nn.Linear: 0.011415258981287] nn.Sequential: [nn.Linear: 0.0025427562650293 nn.Linear: 0.0097750583663583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062600602168953 nn.Linear: 0.064147983629192 nn.Linear: 0.044904430934903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0314428473159 nn.Linear: 0.045569140501868] nn.Sequential: [nn.Linear: 0.031400937843132 nn.Linear: 0.032310732988535]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.44946831464767 nn.Linear: 0.20801655948162 nn.Linear: 0.13458487391472 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10386383533478 nn.Linear: 0.23670439422131] nn.Sequential: [nn.Linear: 0.09327307343483 nn.Linear: 0.17345477640629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012920457880579 nn.Linear: 0.00081452330810968 nn.Linear: 0.00040883961492524 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016482576085495 nn.Linear: 0.0020201798348114] nn.Sequential: [nn.Linear: 0.00015232993052571 nn.Linear: 0.0013413322529379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012309887446463 nn.Linear: 0.0096662444993854 nn.Linear: 0.010623895563185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076704956591129 nn.Linear: 0.011519217863679] nn.Sequential: [nn.Linear: 0.0042199776507914 nn.Linear: 0.014080641791224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062591072869409 nn.Linear: 0.064147388128599 nn.Linear: 0.044904051573444 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031442999832681 nn.Linear: 0.045568774099536] nn.Sequential: [nn.Linear: 0.03140105669467 nn.Linear: 0.032332173898247]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45045721530914 nn.Linear: 0.20800989866257 nn.Linear: 0.13455744087696 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10422612726688 nn.Linear: 0.2371810823679] nn.Sequential: [nn.Linear: 0.093257337808609 nn.Linear: 0.17397020757198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019823711660469 nn.Linear: 0.0011966903481585 nn.Linear: 0.00054872665156534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023239962504576 nn.Linear: 0.0030890759638749] nn.Sequential: [nn.Linear: 0.00015459703598502 nn.Linear: 0.0012836925515254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010438293218613 nn.Linear: 0.020260743796825 nn.Linear: 0.0083263386040926 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01029066927731 nn.Linear: 0.024130664765835] nn.Sequential: [nn.Linear: 0.0033080377615988 nn.Linear: 0.0093394806608558]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062588581772746 nn.Linear: 0.064151816601308 nn.Linear: 0.044906460289773 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031443253467847 nn.Linear: 0.045593281891257] nn.Sequential: [nn.Linear: 0.03140140098152 nn.Linear: 0.032340213555223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45090073347092 nn.Linear: 0.207997828722 nn.Linear: 0.13433501124382 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10435210168362 nn.Linear: 0.2380568087101] nn.Sequential: [nn.Linear: 0.093405522406101 nn.Linear: 0.17370368540287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061602318508616 nn.Linear: 0.0004604036815641 nn.Linear: 0.00025388355228712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.6685645146482e-05 nn.Linear: 0.0010139965793845] nn.Sequential: [nn.Linear: 9.7692503104724e-05 nn.Linear: 0.00088114614011851]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004109816160053 nn.Linear: 0.0068312045186758 nn.Linear: 0.0046913712285459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035049065481871 nn.Linear: 0.0080327028408647] nn.Sequential: [nn.Linear: 0.0028021172620356 nn.Linear: 0.0080631515011191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	5880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062599804208473 nn.Linear: 0.064159134640373 nn.Linear: 0.044909563633878 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03144345402793 nn.Linear: 0.045652047975025] nn.Sequential: [nn.Linear: 0.031401890886804 nn.Linear: 0.032359804747306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4508815407753 nn.Linear: 0.2089926302433 nn.Linear: 0.13415113091469 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10452608019114 nn.Linear: 0.23918874561787] nn.Sequential: [nn.Linear: 0.093487806618214 nn.Linear: 0.17376464605331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00064916403702626 nn.Linear: 0.00039459283859711 nn.Linear: 0.00023638106134949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010247650028995 nn.Linear: 0.0012483124069598] nn.Sequential: [nn.Linear: 9.0400606007504e-05 nn.Linear: 0.00073686401539682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0038745854981244 nn.Linear: 0.0064355912618339 nn.Linear: 0.0072587658651173 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038431109860539 nn.Linear: 0.008041013032198] nn.Sequential: [nn.Linear: 0.002536429092288 nn.Linear: 0.0060253581032157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062595253690537 nn.Linear: 0.064163231904901 nn.Linear: 0.044910863006744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031443775185709 nn.Linear: 0.045695993831487] nn.Sequential: [nn.Linear: 0.031401979298117 nn.Linear: 0.032377459373516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45090624690056 nn.Linear: 0.20818889141083 nn.Linear: 0.13383150100708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10458704084158 nn.Linear: 0.24002662301064] nn.Sequential: [nn.Linear: 0.093754023313522 nn.Linear: 0.17373290657997]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076793787997799 nn.Linear: 0.00067436358919509 nn.Linear: 0.0003292922444824 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011586502124109 nn.Linear: 0.0015066224040002] nn.Sequential: [nn.Linear: 0.00013617315080014 nn.Linear: 0.0011065942136902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0061643212102354 nn.Linear: 0.011263309046626 nn.Linear: 0.0070352582260966 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045697274617851 nn.Linear: 0.011768730357289] nn.Sequential: [nn.Linear: 0.0040724063292146 nn.Linear: 0.0090311588719487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062600302477176 nn.Linear: 0.06416826024683 nn.Linear: 0.044912125486034 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031443914618899 nn.Linear: 0.045729840930505] nn.Sequential: [nn.Linear: 0.031402338080148 nn.Linear: 0.032389080939112]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45035350322723 nn.Linear: 0.20813758671284 nn.Linear: 0.13390988111496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10471917688847 nn.Linear: 0.24093934893608] nn.Sequential: [nn.Linear: 0.093747287988663 nn.Linear: 0.17410871386528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010653262670492 nn.Linear: 0.00066906903220753 nn.Linear: 0.00041979659125903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024637991991726 nn.Linear: 0.0041358582009023] nn.Sequential: [nn.Linear: 0.00011133539786104 nn.Linear: 0.00095917025913777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073684826493263 nn.Linear: 0.011613597162068 nn.Linear: 0.01075379922986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072904666885734 nn.Linear: 0.020937733352184] nn.Sequential: [nn.Linear: 0.0029009494464844 nn.Linear: 0.0088361650705338]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596769818431 nn.Linear: 0.064170975685305 nn.Linear: 0.044912218572901 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031444204433207 nn.Linear: 0.045742444055861] nn.Sequential: [nn.Linear: 0.0314022335356 nn.Linear: 0.03239481834308]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45036879181862 nn.Linear: 0.2075001001358 nn.Linear: 0.1341762393713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10475745052099 nn.Linear: 0.24179628491402] nn.Sequential: [nn.Linear: 0.093710787594318 nn.Linear: 0.17414753139019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099372672667424 nn.Linear: 0.00059803883632782 nn.Linear: 0.0003457210904452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013399747260757 nn.Linear: 0.0016127224858578] nn.Sequential: [nn.Linear: 0.00012415635320537 nn.Linear: 0.0010418958849199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057832673192024 nn.Linear: 0.0080077806487679 nn.Linear: 0.0063759116455913 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069258394651115 nn.Linear: 0.011218504048884] nn.Sequential: [nn.Linear: 0.0041309548541903 nn.Linear: 0.014561302028596]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062598838375086 nn.Linear: 0.064174326297089 nn.Linear: 0.044912859972703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031444348052101 nn.Linear: 0.045762063681536] nn.Sequential: [nn.Linear: 0.031402521215609 nn.Linear: 0.032414998261478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45081326365471 nn.Linear: 0.20816071331501 nn.Linear: 0.13399089872837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10484815388918 nn.Linear: 0.24272136390209] nn.Sequential: [nn.Linear: 0.093673542141914 nn.Linear: 0.17435145378113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013228726844945 nn.Linear: 0.00079399462871053 nn.Linear: 0.00034752222440341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012234106247546 nn.Linear: 0.0013219266368565] nn.Sequential: [nn.Linear: 0.00010781001237857 nn.Linear: 0.00075820035431667]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010239791125059 nn.Linear: 0.012037767097354 nn.Linear: 0.009931605309248 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045143039897084 nn.Linear: 0.0075913020409644] nn.Sequential: [nn.Linear: 0.003302444005385 nn.Linear: 0.008222128264606]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062600560559054 nn.Linear: 0.064177270598829 nn.Linear: 0.044914555468494 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031444461004411 nn.Linear: 0.045804328845406] nn.Sequential: [nn.Linear: 0.031402659201105 nn.Linear: 0.032430974878558]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45069843530655 nn.Linear: 0.20854666829109 nn.Linear: 0.13392671942711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10526506602764 nn.Linear: 0.24373227357864] nn.Sequential: [nn.Linear: 0.093631103634834 nn.Linear: 0.1744821369648]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016060718230736 nn.Linear: 0.0011131851539458 nn.Linear: 0.00055034121575817 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018023711923038 nn.Linear: 0.002274076518647] nn.Sequential: [nn.Linear: 0.00022295667389073 nn.Linear: 0.0020027226569197]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013305081054568 nn.Linear: 0.014159508049488 nn.Linear: 0.014124223962426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097734369337559 nn.Linear: 0.021742824465036] nn.Sequential: [nn.Linear: 0.008558003231883 nn.Linear: 0.027690071612597]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062599044894412 nn.Linear: 0.064183231047334 nn.Linear: 0.044915936464765 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031444890528922 nn.Linear: 0.045842408758347] nn.Sequential: [nn.Linear: 0.031402669240638 nn.Linear: 0.032427056444414]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45104396343231 nn.Linear: 0.20848676562309 nn.Linear: 0.13403603434563 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1055071502924 nn.Linear: 0.24441279470921] nn.Sequential: [nn.Linear: 0.093664176762104 nn.Linear: 0.17453959584236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019266603668904 nn.Linear: 0.0015041246287407 nn.Linear: 0.00078780004843924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023595085967735 nn.Linear: 0.0027186350977367] nn.Sequential: [nn.Linear: 0.00031829145720934 nn.Linear: 0.0028060408716124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011755103245378 nn.Linear: 0.030669866129756 nn.Linear: 0.017648112028837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010797356255352 nn.Linear: 0.017390627413988] nn.Sequential: [nn.Linear: 0.00977404974401 nn.Linear: 0.022718673571944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062590463311862 nn.Linear: 0.064183445925758 nn.Linear: 0.044916598466 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031445053776869 nn.Linear: 0.045852870960232] nn.Sequential: [nn.Linear: 0.031402877572337 nn.Linear: 0.032445323991553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45206859707832 nn.Linear: 0.20929746329784 nn.Linear: 0.13372303545475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10554219037294 nn.Linear: 0.24498882889748] nn.Sequential: [nn.Linear: 0.093730881810188 nn.Linear: 0.17504443228245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025080588561663 nn.Linear: 0.0015982591190218 nn.Linear: 0.00077309511281043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032248807771965 nn.Linear: 0.0039427445994047] nn.Sequential: [nn.Linear: 0.00025136157229115 nn.Linear: 0.0020735385196674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013796083629131 nn.Linear: 0.018163656815886 nn.Linear: 0.014245303347707 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011850636452436 nn.Linear: 0.024580856785178] nn.Sequential: [nn.Linear: 0.010038160718977 nn.Linear: 0.028192089870572]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062593788160664 nn.Linear: 0.064192223119623 nn.Linear: 0.044919250408531 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031445287884438 nn.Linear: 0.04587025179444] nn.Sequential: [nn.Linear: 0.031403326352788 nn.Linear: 0.032456554080978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45200547575951 nn.Linear: 0.20919774472713 nn.Linear: 0.13374142348766 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10565847158432 nn.Linear: 0.24642886221409] nn.Sequential: [nn.Linear: 0.093739904463291 nn.Linear: 0.17485800385475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069460475067663 nn.Linear: 0.00051277096800492 nn.Linear: 0.00030649002022812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015173310779183 nn.Linear: 0.0023541904559092] nn.Sequential: [nn.Linear: 0.00011607393406808 nn.Linear: 0.0011564176650708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054561719298363 nn.Linear: 0.0080425469204783 nn.Linear: 0.005918066482991 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050949491560459 nn.Linear: 0.015188071876764] nn.Sequential: [nn.Linear: 0.003455325961113 nn.Linear: 0.0078515205532312]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062593441015583 nn.Linear: 0.064200629606994 nn.Linear: 0.044922023073781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031445724328529 nn.Linear: 0.045915049073045] nn.Sequential: [nn.Linear: 0.031403760959687 nn.Linear: 0.032481183213934]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45250698924065 nn.Linear: 0.20970723032951 nn.Linear: 0.13361090421677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10583500564098 nn.Linear: 0.24796095490456] nn.Sequential: [nn.Linear: 0.093684040009975 nn.Linear: 0.17508780956268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011425858569478 nn.Linear: 0.00071095104829601 nn.Linear: 0.00041670155860705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016349254161134 nn.Linear: 0.0022963968475613] nn.Sequential: [nn.Linear: 0.00014631611699088 nn.Linear: 0.0011403560174982]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007839810103178 nn.Linear: 0.011068622581661 nn.Linear: 0.010287210345268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056453533470631 nn.Linear: 0.01397190708667] nn.Sequential: [nn.Linear: 0.0038798961322755 nn.Linear: 0.011550817638636]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062591901356619 nn.Linear: 0.064203314105612 nn.Linear: 0.044922873439979 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031445764279494 nn.Linear: 0.045934127960209] nn.Sequential: [nn.Linear: 0.031403985475012 nn.Linear: 0.032488364058871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45279297232628 nn.Linear: 0.2094653993845 nn.Linear: 0.13345970213413 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10642205923796 nn.Linear: 0.24913409352303] nn.Sequential: [nn.Linear: 0.093706153333187 nn.Linear: 0.1751281619072]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098546450683113 nn.Linear: 0.00052299004862389 nn.Linear: 0.0002960953627588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011563033786476 nn.Linear: 0.0015483244363774] nn.Sequential: [nn.Linear: 0.00010210986108156 nn.Linear: 0.00081869720388933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060708746314049 nn.Linear: 0.0079853283241391 nn.Linear: 0.006176324095577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00581912137568 nn.Linear: 0.012202892452478] nn.Sequential: [nn.Linear: 0.0049889637157321 nn.Linear: 0.011253951117396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	5990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587088296817 nn.Linear: 0.064203854820161 nn.Linear: 0.044924170475822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031445928110245 nn.Linear: 0.045945433114532] nn.Sequential: [nn.Linear: 0.03140424829594 nn.Linear: 0.032520033606927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4535738825798 nn.Linear: 0.20971503853798 nn.Linear: 0.1335441917181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10661014169455 nn.Linear: 0.24951332807541] nn.Sequential: [nn.Linear: 0.093675695359707 nn.Linear: 0.17536434531212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099158076437018 nn.Linear: 0.00074222364468124 nn.Linear: 0.0003783813111931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021153114194844 nn.Linear: 0.003879607553694] nn.Sequential: [nn.Linear: 0.00010926923494152 nn.Linear: 0.00088381042018908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078447125852108 nn.Linear: 0.013658228330314 nn.Linear: 0.010753835551441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010384581051767 nn.Linear: 0.029078889638186] nn.Sequential: [nn.Linear: 0.0036066852044314 nn.Linear: 0.0083295749500394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062586507393283 nn.Linear: 0.064207952250805 nn.Linear: 0.044925617982353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031446070183896 nn.Linear: 0.045952585361693] nn.Sequential: [nn.Linear: 0.03140453644856 nn.Linear: 0.032542174817688]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4527862071991 nn.Linear: 0.21039831638336 nn.Linear: 0.1340290158987 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10668300837278 nn.Linear: 0.24970602989197] nn.Sequential: [nn.Linear: 0.093681454658508 nn.Linear: 0.17559851706028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010753274472281 nn.Linear: 0.00072379804890671 nn.Linear: 0.00041504329974958 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016630005845853 nn.Linear: 0.0023700786369466] nn.Sequential: [nn.Linear: 0.00015890972568015 nn.Linear: 0.0012812080200966]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079325549304485 nn.Linear: 0.011234946548939 nn.Linear: 0.0089917406439781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071132811717689 nn.Linear: 0.017384219914675] nn.Sequential: [nn.Linear: 0.0045659700408578 nn.Linear: 0.01090036239475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.084522277966142	TD error	0.018984185948968	Qmax	1	

Steps: 6000000 (frames: 24000000), score: 1884.47, higheset score: 6548, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 89s, testing rate: 5563fps,  num. ep.: 306,  num. rewards: 16287	
   2    8    4    2
   4    2   16    4
   2    8  128   32
   8  256  512    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596226490037 nn.Linear: 0.064215528425004 nn.Linear: 0.04492810967979 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031446530779465 nn.Linear: 0.046011640937166] nn.Sequential: [nn.Linear: 0.03140531418433 nn.Linear: 0.032560618469116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.452023178339 nn.Linear: 0.20980441570282 nn.Linear: 0.13387426733971 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10689858347178 nn.Linear: 0.25071704387665] nn.Sequential: [nn.Linear: 0.093723848462105 nn.Linear: 0.17555221915245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010488714507293 nn.Linear: 0.00071739363057804 nn.Linear: 0.00040658196776443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014057327512822 nn.Linear: 0.0014511282529259] nn.Sequential: [nn.Linear: 0.00015630214036211 nn.Linear: 0.0013381148908796]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085599469020963 nn.Linear: 0.0090770535171032 nn.Linear: 0.006282864138484 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049153934232891 nn.Linear: 0.0088347792625427] nn.Sequential: [nn.Linear: 0.0040438091382384 nn.Linear: 0.011357040144503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062588329706658 nn.Linear: 0.064221552304921 nn.Linear: 0.044929871232081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031446926009715 nn.Linear: 0.046033855021008] nn.Sequential: [nn.Linear: 0.031405438782664 nn.Linear: 0.032578834013039]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45319059491158 nn.Linear: 0.21011254191399 nn.Linear: 0.13379633426666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10698951780796 nn.Linear: 0.25177195668221] nn.Sequential: [nn.Linear: 0.093539752066135 nn.Linear: 0.17531092464924]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011273067038494 nn.Linear: 0.0007117020207361 nn.Linear: 0.00042165586530043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022909208612228 nn.Linear: 0.0034967983143634] nn.Sequential: [nn.Linear: 0.0001252673469452 nn.Linear: 0.0010665545967393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084079960361123 nn.Linear: 0.0089804390445352 nn.Linear: 0.0070823547430336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011999393813312 nn.Linear: 0.021039307117462] nn.Sequential: [nn.Linear: 0.0042962082661688 nn.Linear: 0.0084266941994429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596164416704 nn.Linear: 0.064225825586931 nn.Linear: 0.04493251991063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447219990168 nn.Linear: 0.046089126663713] nn.Sequential: [nn.Linear: 0.03140581771452 nn.Linear: 0.032600164450083]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45426544547081 nn.Linear: 0.21004423499107 nn.Linear: 0.13339567184448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10734673589468 nn.Linear: 0.25347900390625] nn.Sequential: [nn.Linear: 0.093604885041714 nn.Linear: 0.17551471292973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013902539786483 nn.Linear: 0.00086162578184373 nn.Linear: 0.00050491649071663 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022095834240804 nn.Linear: 0.0035381762192483] nn.Sequential: [nn.Linear: 0.00017048439216168 nn.Linear: 0.0015224126101738]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084496010094881 nn.Linear: 0.014851483516395 nn.Linear: 0.011179286986589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01099688000977 nn.Linear: 0.024508459493518] nn.Sequential: [nn.Linear: 0.0069615081883967 nn.Linear: 0.024440674111247]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062586270769637 nn.Linear: 0.064228518998341 nn.Linear: 0.044933111307821 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447254883996 nn.Linear: 0.046101623136988] nn.Sequential: [nn.Linear: 0.031406034470909 nn.Linear: 0.032603599642531]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45423021912575 nn.Linear: 0.21000324189663 nn.Linear: 0.13352786004543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10707936435938 nn.Linear: 0.25437879562378] nn.Sequential: [nn.Linear: 0.093754351139069 nn.Linear: 0.17560270428658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00078426976329966 nn.Linear: 0.00049701913383348 nn.Linear: 0.00029236907460206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001175470244515 nn.Linear: 0.0015715803830158] nn.Sequential: [nn.Linear: 0.00010464858204835 nn.Linear: 0.00088183247067527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056838085874915 nn.Linear: 0.0075744763016701 nn.Linear: 0.008677308447659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004228194244206 nn.Linear: 0.012976738624275] nn.Sequential: [nn.Linear: 0.0030713209416717 nn.Linear: 0.008492355234921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062580892224631 nn.Linear: 0.06422985686524 nn.Linear: 0.044933729641712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447451715567 nn.Linear: 0.046133638435791] nn.Sequential: [nn.Linear: 0.031406070428084 nn.Linear: 0.0326149530298]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45414504408836 nn.Linear: 0.21032336354256 nn.Linear: 0.13343250751495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10686486214399 nn.Linear: 0.25521576404572] nn.Sequential: [nn.Linear: 0.093777030706406 nn.Linear: 0.17556670308113]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011371324289673 nn.Linear: 0.0007177653409762 nn.Linear: 0.00039208464379274 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011123128615136 nn.Linear: 0.0013497696557898] nn.Sequential: [nn.Linear: 0.00018326299370773 nn.Linear: 0.0015128034366681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085040703415871 nn.Linear: 0.015507576055825 nn.Linear: 0.0079989302903414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069120931439102 nn.Linear: 0.0088371196761727] nn.Sequential: [nn.Linear: 0.0069053792394698 nn.Linear: 0.017784705385566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062589656100219 nn.Linear: 0.064233621931579 nn.Linear: 0.04493510647731 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447658417568 nn.Linear: 0.046152916464109] nn.Sequential: [nn.Linear: 0.031406236791296 nn.Linear: 0.032634350645393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4536544084549 nn.Linear: 0.21068024635315 nn.Linear: 0.13363760709763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10676779597998 nn.Linear: 0.25570896267891] nn.Sequential: [nn.Linear: 0.093817785382271 nn.Linear: 0.17555333673954]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011680637007522 nn.Linear: 0.00075027538468284 nn.Linear: 0.00040995572785761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015254354822967 nn.Linear: 0.0018152049772248] nn.Sequential: [nn.Linear: 0.00011457293586376 nn.Linear: 0.00081546718806882]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066252048127353 nn.Linear: 0.0093343947082758 nn.Linear: 0.0081316567957401 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079401843249798 nn.Linear: 0.014767678454518] nn.Sequential: [nn.Linear: 0.0033600882161409 nn.Linear: 0.0065827029757202]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062582836879641 nn.Linear: 0.064237012258245 nn.Linear: 0.044936047577143 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447652248785 nn.Linear: 0.046146596850292] nn.Sequential: [nn.Linear: 0.031406633454386 nn.Linear: 0.03264326067398]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45399948954582 nn.Linear: 0.2105015963316 nn.Linear: 0.13381215929985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10695158690214 nn.Linear: 0.25625404715538] nn.Sequential: [nn.Linear: 0.093850687146187 nn.Linear: 0.17569033801556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00051789398384283 nn.Linear: 0.00029788319204658 nn.Linear: 0.00016205873431601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 5.7647382263695e-05 nn.Linear: 0.00066095335350358] nn.Sequential: [nn.Linear: 6.5422433546828e-05 nn.Linear: 0.0004899056414329]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0040398044511676 nn.Linear: 0.0039266110397875 nn.Linear: 0.0038112695328891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.002652091672644 nn.Linear: 0.0056926710531116] nn.Sequential: [nn.Linear: 0.001892066677101 nn.Linear: 0.0048016444779932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062586421080015 nn.Linear: 0.064239168616201 nn.Linear: 0.044936881912404 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447827032212 nn.Linear: 0.046137796746109] nn.Sequential: [nn.Linear: 0.031406756414527 nn.Linear: 0.032650512734965]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45365023612976 nn.Linear: 0.21069607138634 nn.Linear: 0.13341264426708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10719553381205 nn.Linear: 0.25656831264496] nn.Sequential: [nn.Linear: 0.093828164041042 nn.Linear: 0.1757473051548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031976362028547 nn.Linear: 0.0019458298368782 nn.Linear: 0.00091407866595306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00035418116623916 nn.Linear: 0.0053833852423651] nn.Sequential: [nn.Linear: 0.00034691370418467 nn.Linear: 0.0033526214368192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023445835337043 nn.Linear: 0.028030402958393 nn.Linear: 0.020981777459383 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012611702084541 nn.Linear: 0.046574525535107] nn.Sequential: [nn.Linear: 0.0090906322002411 nn.Linear: 0.028082706034184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062589301822469 nn.Linear: 0.064242077301294 nn.Linear: 0.044938554859931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031447953514202 nn.Linear: 0.046131065271481] nn.Sequential: [nn.Linear: 0.031407075672775 nn.Linear: 0.032677155338313]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45440769195557 nn.Linear: 0.21131314337254 nn.Linear: 0.13311211764812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10753893852234 nn.Linear: 0.25813138484955] nn.Sequential: [nn.Linear: 0.093637138605118 nn.Linear: 0.17634762823582]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010225788872763 nn.Linear: 0.00063887178865015 nn.Linear: 0.00033359888596431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014810868874597 nn.Linear: 0.0021513402073718] nn.Sequential: [nn.Linear: 8.61121032194e-05 nn.Linear: 0.00066132966396931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0061733038164675 nn.Linear: 0.015985002741218 nn.Linear: 0.010713711380959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00573909888044 nn.Linear: 0.014836687594652] nn.Sequential: [nn.Linear: 0.0022950489073992 nn.Linear: 0.0057656895369291]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587253372544 nn.Linear: 0.064246143176906 nn.Linear: 0.044939596475894 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448040218066 nn.Linear: 0.046138526619359] nn.Sequential: [nn.Linear: 0.031407448836232 nn.Linear: 0.032688024053718]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45415857434273 nn.Linear: 0.21167123317719 nn.Linear: 0.13399928808212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10778526216745 nn.Linear: 0.25886470079422] nn.Sequential: [nn.Linear: 0.093709036707878 nn.Linear: 0.1763142645359]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00067986379304606 nn.Linear: 0.00042032322188768 nn.Linear: 0.00022366599051121 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8271543120444e-05 nn.Linear: 0.0012802050646304] nn.Sequential: [nn.Linear: 8.4883603128438e-05 nn.Linear: 0.00058933155645929]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0043822298757732 nn.Linear: 0.0063734431751072 nn.Linear: 0.0042915474623442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040696254000068 nn.Linear: 0.009949111379683] nn.Sequential: [nn.Linear: 0.0027935088146478 nn.Linear: 0.0059022284112871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584758748514 nn.Linear: 0.064247895729605 nn.Linear: 0.044940370479049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448206043984 nn.Linear: 0.046159392732534] nn.Sequential: [nn.Linear: 0.031407640666664 nn.Linear: 0.032706130830766]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45433926582336 nn.Linear: 0.21128825843334 nn.Linear: 0.13400802016258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10817266255617 nn.Linear: 0.25958237051964] nn.Sequential: [nn.Linear: 0.093742415308952 nn.Linear: 0.1762448400259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0048374982613886 nn.Linear: 0.0022826488820617 nn.Linear: 0.0010879718993834 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00041554500191511 nn.Linear: 0.0061164312097497] nn.Sequential: [nn.Linear: 0.00033788320976297 nn.Linear: 0.0030606586349561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.03871676325798 nn.Linear: 0.052764195948839 nn.Linear: 0.0338384360075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031384225934744 nn.Linear: 0.05029160156846] nn.Sequential: [nn.Linear: 0.015300595201552 nn.Linear: 0.040683124214411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062582509895242 nn.Linear: 0.064252753303532 nn.Linear: 0.044942383585572 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448473451508 nn.Linear: 0.046184230334347] nn.Sequential: [nn.Linear: 0.031408025099417 nn.Linear: 0.03274256560233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45470255613327 nn.Linear: 0.21105171740055 nn.Linear: 0.13416782021523 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10858079791069 nn.Linear: 0.26022487878799] nn.Sequential: [nn.Linear: 0.093721739947796 nn.Linear: 0.17636360228062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012161608036874 nn.Linear: 0.00091158280550718 nn.Linear: 0.00055723697379977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033757117308823 nn.Linear: 0.0058656763388045] nn.Sequential: [nn.Linear: 0.00015129367371734 nn.Linear: 0.00161839077895]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008704430423677 nn.Linear: 0.015263593755662 nn.Linear: 0.010359669104218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01120266225189 nn.Linear: 0.032808549702168] nn.Sequential: [nn.Linear: 0.0038895432371646 nn.Linear: 0.016228871420026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062582582907493 nn.Linear: 0.064252399251076 nn.Linear: 0.044943018328936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448530321094 nn.Linear: 0.046193493339445] nn.Sequential: [nn.Linear: 0.031408228167243 nn.Linear: 0.032755082872384]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45468202233315 nn.Linear: 0.21174767613411 nn.Linear: 0.13535808026791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1084136068821 nn.Linear: 0.26054185628891] nn.Sequential: [nn.Linear: 0.093754835426807 nn.Linear: 0.17659828066826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010076157434401 nn.Linear: 0.00059117233075342 nn.Linear: 0.00026477604354156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8585358323639e-05 nn.Linear: 0.00095076958884432] nn.Sequential: [nn.Linear: 0.00010670552004306 nn.Linear: 0.00094895671160249]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070178969763219 nn.Linear: 0.0094300862401724 nn.Linear: 0.006980727892369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.003180579515174 nn.Linear: 0.0054912273772061] nn.Sequential: [nn.Linear: 0.0026613695081323 nn.Linear: 0.0098918527364731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062579895888597 nn.Linear: 0.06425651139134 nn.Linear: 0.044944643358571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448510741635 nn.Linear: 0.046187801125882] nn.Sequential: [nn.Linear: 0.031408575188446 nn.Linear: 0.032770031887658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45497927069664 nn.Linear: 0.21152001619339 nn.Linear: 0.13506032526493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10836051404476 nn.Linear: 0.26145753264427] nn.Sequential: [nn.Linear: 0.093824617564678 nn.Linear: 0.17684769630432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001445119715545 nn.Linear: 0.00091079687330903 nn.Linear: 0.00048906374670335 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022201757515624 nn.Linear: 0.0032222621723507] nn.Sequential: [nn.Linear: 0.00013741286478016 nn.Linear: 0.001065279008815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089150639250875 nn.Linear: 0.017055058851838 nn.Linear: 0.011055611073971 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010360046289861 nn.Linear: 0.028143992647529] nn.Sequential: [nn.Linear: 0.0047944709658623 nn.Linear: 0.01205079164356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062585145074746 nn.Linear: 0.064262551357819 nn.Linear: 0.044946642577049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031448965054454 nn.Linear: 0.046233608226089] nn.Sequential: [nn.Linear: 0.031408918026668 nn.Linear: 0.032787984972067]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45583096146584 nn.Linear: 0.21191544830799 nn.Linear: 0.13511911034584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10865172743797 nn.Linear: 0.26193454861641] nn.Sequential: [nn.Linear: 0.09391525387764 nn.Linear: 0.17769213020802]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016803797091788 nn.Linear: 0.0010635844598843 nn.Linear: 0.00056576809610094 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028518216130714 nn.Linear: 0.0047834281466579] nn.Sequential: [nn.Linear: 0.00016496889539513 nn.Linear: 0.001588140337666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010800280608237 nn.Linear: 0.02513144724071 nn.Linear: 0.011086788028479 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011035663075745 nn.Linear: 0.031145254150033] nn.Sequential: [nn.Linear: 0.0067350040189922 nn.Linear: 0.017739461734891]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062587153485769 nn.Linear: 0.064269526355135 nn.Linear: 0.044949658247104 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031449574249363 nn.Linear: 0.046280369038016] nn.Sequential: [nn.Linear: 0.031409419737835 nn.Linear: 0.032820792473368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45559492707253 nn.Linear: 0.212701395154 nn.Linear: 0.13581529259682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10864907503128 nn.Linear: 0.26303595304489] nn.Sequential: [nn.Linear: 0.093987450003624 nn.Linear: 0.17779748141766]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010271307460646 nn.Linear: 0.00065555161404433 nn.Linear: 0.00035598573142475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015286741327463 nn.Linear: 0.0019763606835479] nn.Sequential: [nn.Linear: 0.0001218618589751 nn.Linear: 0.00090965599859799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081516457721591 nn.Linear: 0.0072583253495395 nn.Linear: 0.0064815734513104 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048679215833545 nn.Linear: 0.014326559379697] nn.Sequential: [nn.Linear: 0.0031032613478601 nn.Linear: 0.0080247856676579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062577660897316 nn.Linear: 0.064269445603336 nn.Linear: 0.0449505081405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031449612495788 nn.Linear: 0.046262475399946] nn.Sequential: [nn.Linear: 0.031409628183679 nn.Linear: 0.032835316935952]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45535749197006 nn.Linear: 0.21243700385094 nn.Linear: 0.13592912256718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10916128009558 nn.Linear: 0.26336696743965] nn.Sequential: [nn.Linear: 0.093984961509705 nn.Linear: 0.17817245423794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092263436063 nn.Linear: 0.00054583302734582 nn.Linear: 0.0002877917590353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012882174034229 nn.Linear: 0.0019637340591954] nn.Sequential: [nn.Linear: 0.00011168924249261 nn.Linear: 0.00098218357384481]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0047424933873117 nn.Linear: 0.0071692848578095 nn.Linear: 0.0087907388806343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046473876573145 nn.Linear: 0.015654779970646] nn.Sequential: [nn.Linear: 0.0029470336157829 nn.Linear: 0.0096559757366776]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581143688721 nn.Linear: 0.064277873604772 nn.Linear: 0.044952806716927 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03144995621446 nn.Linear: 0.046328270475101] nn.Sequential: [nn.Linear: 0.031409994086677 nn.Linear: 0.032857318682598]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45568507909775 nn.Linear: 0.2123015075922 nn.Linear: 0.1358157992363 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10926371067762 nn.Linear: 0.26417851448059] nn.Sequential: [nn.Linear: 0.094184428453445 nn.Linear: 0.17847894132137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014757851580841 nn.Linear: 0.00094420688701078 nn.Linear: 0.00054011382988167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018462998207311 nn.Linear: 0.0018735121218798] nn.Sequential: [nn.Linear: 0.00025417049052333 nn.Linear: 0.0024994128697742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010498961433768 nn.Linear: 0.013231454417109 nn.Linear: 0.0095992516726255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0078689577057958 nn.Linear: 0.012594346888363] nn.Sequential: [nn.Linear: 0.0075223692692816 nn.Linear: 0.022228857502341]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584794870189 nn.Linear: 0.064276590772446 nn.Linear: 0.044955030700672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031450254417723 nn.Linear: 0.046364075236795] nn.Sequential: [nn.Linear: 0.031410258366403 nn.Linear: 0.032877577154323]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45579704642296 nn.Linear: 0.21275693178177 nn.Linear: 0.13559521734715 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10968063026667 nn.Linear: 0.26507771015167] nn.Sequential: [nn.Linear: 0.094194538891315 nn.Linear: 0.17865243554115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012041478982053 nn.Linear: 0.00080203341923371 nn.Linear: 0.000377986160919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013414726472958 nn.Linear: 0.0014409195350369] nn.Sequential: [nn.Linear: 0.0001322572499314 nn.Linear: 0.00090019162541094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095533290877938 nn.Linear: 0.010463265702128 nn.Linear: 0.012532631866634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053727813065052 nn.Linear: 0.010022537782788] nn.Sequential: [nn.Linear: 0.0044248751364648 nn.Linear: 0.009017032571137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062574059731405 nn.Linear: 0.064277258661882 nn.Linear: 0.044954559348933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031450168468941 nn.Linear: 0.046332025038794] nn.Sequential: [nn.Linear: 0.031410283808962 nn.Linear: 0.032873670326753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45590454339981 nn.Linear: 0.21248939633369 nn.Linear: 0.13634514808655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10964024066925 nn.Linear: 0.2656524181366] nn.Sequential: [nn.Linear: 0.094278499484062 nn.Linear: 0.1784476339817]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091342198647847 nn.Linear: 0.00056980510857064 nn.Linear: 0.00031545617742906 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015171166120085 nn.Linear: 0.00253669427498] nn.Sequential: [nn.Linear: 0.00010902326315049 nn.Linear: 0.0010070492334792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052826614119112 nn.Linear: 0.0083865383639932 nn.Linear: 0.0097919143736362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057700499892235 nn.Linear: 0.021307855844498] nn.Sequential: [nn.Linear: 0.0046223783865571 nn.Linear: 0.012984684668481]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06257220936175 nn.Linear: 0.064279667170673 nn.Linear: 0.044955743417005 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031450323603069 nn.Linear: 0.046363828698475] nn.Sequential: [nn.Linear: 0.031410472476618 nn.Linear: 0.032882980500444]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45571991801262 nn.Linear: 0.21234436333179 nn.Linear: 0.13665999472141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10950738191605 nn.Linear: 0.26620325446129] nn.Sequential: [nn.Linear: 0.094175688922405 nn.Linear: 0.17849147319794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097368119283364 nn.Linear: 0.00079413558384391 nn.Linear: 0.00040348690691311 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015174418824975 nn.Linear: 0.0021304465984129] nn.Sequential: [nn.Linear: 0.00017947495269015 nn.Linear: 0.0016454246239692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066949599422514 nn.Linear: 0.010852778330445 nn.Linear: 0.0076448852196336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049401386640966 nn.Linear: 0.015114890411496] nn.Sequential: [nn.Linear: 0.0051105814054608 nn.Linear: 0.015217863954604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062563768752482 nn.Linear: 0.064282972088008 nn.Linear: 0.044957211739738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031450416668882 nn.Linear: 0.046371519177853] nn.Sequential: [nn.Linear: 0.031410705679605 nn.Linear: 0.032899750204397]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45592573285103 nn.Linear: 0.21170499920845 nn.Linear: 0.13720516860485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10975573211908 nn.Linear: 0.26672026515007] nn.Sequential: [nn.Linear: 0.094155691564083 nn.Linear: 0.17842583358288]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015067870482325 nn.Linear: 0.00083905879650472 nn.Linear: 0.00042661561732143 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015258585548671 nn.Linear: 0.0024745958291312] nn.Sequential: [nn.Linear: 0.00019465420201663 nn.Linear: 0.0020837679467753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010806464590132 nn.Linear: 0.017289485782385 nn.Linear: 0.0099192224442959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049610435962677 nn.Linear: 0.016058187931776] nn.Sequential: [nn.Linear: 0.0056196446530521 nn.Linear: 0.023647401481867]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062563326503861 nn.Linear: 0.064288801965912 nn.Linear: 0.044959153324265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031450945102149 nn.Linear: 0.046438966417327] nn.Sequential: [nn.Linear: 0.031411002706708 nn.Linear: 0.03291347804677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45644602179527 nn.Linear: 0.21259170770645 nn.Linear: 0.13751514256001 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10995293408632 nn.Linear: 0.26742565631866] nn.Sequential: [nn.Linear: 0.094138465821743 nn.Linear: 0.17837706208229]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022835537001629 nn.Linear: 0.0013090863657607 nn.Linear: 0.00065709783878151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025309622444935 nn.Linear: 0.0033172319400593] nn.Sequential: [nn.Linear: 0.00026089709343622 nn.Linear: 0.0025612298551395]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011314350180328 nn.Linear: 0.023676102980971 nn.Linear: 0.017471313476562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016873875632882 nn.Linear: 0.02901079133153] nn.Sequential: [nn.Linear: 0.011035327799618 nn.Linear: 0.028412943705916]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062566032109435 nn.Linear: 0.064290257299299 nn.Linear: 0.044960467066699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031451295462017 nn.Linear: 0.046499584330888] nn.Sequential: [nn.Linear: 0.03141125864691 nn.Linear: 0.032931289906691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45654404163361 nn.Linear: 0.21233071386814 nn.Linear: 0.13746806979179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11002294719219 nn.Linear: 0.26833009719849] nn.Sequential: [nn.Linear: 0.094231739640236 nn.Linear: 0.17856737971306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086503551558974 nn.Linear: 0.00064484528440009 nn.Linear: 0.00032740414517874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012351586611946 nn.Linear: 0.0015579636755382] nn.Sequential: [nn.Linear: 0.00013050543840266 nn.Linear: 0.0010495335829946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068706311285496 nn.Linear: 0.0090983314439654 nn.Linear: 0.0060700098983943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044319638982415 nn.Linear: 0.011157879605889] nn.Sequential: [nn.Linear: 0.0037218334618956 nn.Linear: 0.0080516235902905]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062561910591701 nn.Linear: 0.06429692630316 nn.Linear: 0.04496181835174 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031451506155198 nn.Linear: 0.046527910064754] nn.Sequential: [nn.Linear: 0.031411565819598 nn.Linear: 0.032949299914538]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45586934685707 nn.Linear: 0.21221607923508 nn.Linear: 0.1380258500576 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10971596091986 nn.Linear: 0.26904383301735] nn.Sequential: [nn.Linear: 0.094303958117962 nn.Linear: 0.17894540727139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016578476361403 nn.Linear: 0.00094674992226256 nn.Linear: 0.00043327937147861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014235961483606 nn.Linear: 0.001750937985443] nn.Sequential: [nn.Linear: 0.00015903922411983 nn.Linear: 0.0012626747661751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010841285809875 nn.Linear: 0.01504042185843 nn.Linear: 0.012724820524454 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010764147154987 nn.Linear: 0.012135416269302] nn.Sequential: [nn.Linear: 0.0070448000915349 nn.Linear: 0.019393302500248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.091277256280184	TD error	0.019278445579112	Qmax	1	

Steps: 6250000 (frames: 25000000), score: 2008.24, higheset score: 6908, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1812fps, testing time: 89s, testing rate: 5556fps,  num. ep.: 356,  num. rewards: 17805	
   2    4   16    4
   4   64    4    2
 256  512   32    4
   2  128    8   16
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062556525194768 nn.Linear: 0.064303297353359 nn.Linear: 0.044963013195106 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031451637733771 nn.Linear: 0.046548191370249] nn.Sequential: [nn.Linear: 0.03141166091143 nn.Linear: 0.032952072233289]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45672112703323 nn.Linear: 0.21185360848904 nn.Linear: 0.13817225396633 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1098448112607 nn.Linear: 0.26993095874786] nn.Sequential: [nn.Linear: 0.094331420958042 nn.Linear: 0.17864529788494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080240542585327 nn.Linear: 0.00046866293197439 nn.Linear: 0.00025340049196511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001137928740913 nn.Linear: 0.001547402434322] nn.Sequential: [nn.Linear: 9.8664136815069e-05 nn.Linear: 0.00075798048751065]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0042915903031826 nn.Linear: 0.0070750280283391 nn.Linear: 0.0070073041133583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073493248783052 nn.Linear: 0.012345298193395] nn.Sequential: [nn.Linear: 0.003136831568554 nn.Linear: 0.006735269445926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062556266181653 nn.Linear: 0.064304611250655 nn.Linear: 0.044965144993151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031452033140973 nn.Linear: 0.046581537418206] nn.Sequential: [nn.Linear: 0.03141207185341 nn.Linear: 0.032979579314998]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4571490585804 nn.Linear: 0.21259790658951 nn.Linear: 0.1381324082613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10998425632715 nn.Linear: 0.27037915587425] nn.Sequential: [nn.Linear: 0.094194196164608 nn.Linear: 0.17870973050594]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001402505694016 nn.Linear: 0.00075964005170185 nn.Linear: 0.00033782854852112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012411269061468 nn.Linear: 0.0014832572392653] nn.Sequential: [nn.Linear: 0.00012247523298445 nn.Linear: 0.0011656017262839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084780156612396 nn.Linear: 0.012873198837042 nn.Linear: 0.0072879898361862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007186031434685 nn.Linear: 0.011886954307556] nn.Sequential: [nn.Linear: 0.0039583435282111 nn.Linear: 0.014391367323697]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062556551568301 nn.Linear: 0.064305742218917 nn.Linear: 0.044965919983812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031452248550807 nn.Linear: 0.046600606125025] nn.Sequential: [nn.Linear: 0.031412366742762 nn.Linear: 0.032989888676799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45783123373985 nn.Linear: 0.21237833797932 nn.Linear: 0.1389539539814 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10960000753403 nn.Linear: 0.27127942442894] nn.Sequential: [nn.Linear: 0.094123706221581 nn.Linear: 0.17854772508144]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023790999495484 nn.Linear: 0.001135475633027 nn.Linear: 0.00047400644553747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015783205136144 nn.Linear: 0.0020984379485716] nn.Sequential: [nn.Linear: 0.00016513886292441 nn.Linear: 0.001489715589181]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019907213747501 nn.Linear: 0.021599343046546 nn.Linear: 0.026390230283141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01073463819921 nn.Linear: 0.017763555049896] nn.Sequential: [nn.Linear: 0.0053987093269825 nn.Linear: 0.014839524403214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062556893074453 nn.Linear: 0.06431536340837 nn.Linear: 0.044967964883704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031452589000491 nn.Linear: 0.046657508837228] nn.Sequential: [nn.Linear: 0.031412825942308 nn.Linear: 0.033006738177564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45854413509369 nn.Linear: 0.21179646253586 nn.Linear: 0.13951472938061 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.10947043448687 nn.Linear: 0.27244660258293] nn.Sequential: [nn.Linear: 0.094262085855007 nn.Linear: 0.17919115722179]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015032763744022 nn.Linear: 0.00096378337214023 nn.Linear: 0.00050042496954488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022603554396546 nn.Linear: 0.0034932604853849] nn.Sequential: [nn.Linear: 0.00013986694301386 nn.Linear: 0.0010921232572908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099566765129566 nn.Linear: 0.016567325219512 nn.Linear: 0.0089241722598672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081434352323413 nn.Linear: 0.023540640249848] nn.Sequential: [nn.Linear: 0.0033857170492411 nn.Linear: 0.0091835930943489]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062568430846297 nn.Linear: 0.064322938150084 nn.Linear: 0.044971500473227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453005429542 nn.Linear: 0.046710051105947] nn.Sequential: [nn.Linear: 0.031413217845098 nn.Linear: 0.033032553804743]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45893409848213 nn.Linear: 0.21246042847633 nn.Linear: 0.13984994590282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11003731191158 nn.Linear: 0.27376061677933] nn.Sequential: [nn.Linear: 0.094239979982376 nn.Linear: 0.17929820716381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025290935022201 nn.Linear: 0.0014995980920763 nn.Linear: 0.00062545712065134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002041490044843 nn.Linear: 0.0027354198586262] nn.Sequential: [nn.Linear: 0.00021874024026375 nn.Linear: 0.0017287524717528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019476223737001 nn.Linear: 0.018576016649604 nn.Linear: 0.017342813313007 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0095501020550728 nn.Linear: 0.027460234239697] nn.Sequential: [nn.Linear: 0.010171719826758 nn.Linear: 0.016970068216324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062567891029707 nn.Linear: 0.064328901945828 nn.Linear: 0.044973253736145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453539336188 nn.Linear: 0.046765878792442] nn.Sequential: [nn.Linear: 0.03141343687888 nn.Linear: 0.033051244776224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45844605565071 nn.Linear: 0.21205538511276 nn.Linear: 0.13986168801785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11015499383211 nn.Linear: 0.27447259426117] nn.Sequential: [nn.Linear: 0.094268746674061 nn.Linear: 0.17961691319942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033648436492773 nn.Linear: 0.0022156673671153 nn.Linear: 0.00092577776573006 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00035405988840402 nn.Linear: 0.0056861285234837] nn.Sequential: [nn.Linear: 0.00026030846748251 nn.Linear: 0.0020021285498772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.028031691908836 nn.Linear: 0.038935404270887 nn.Linear: 0.026707824319601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015598339959979 nn.Linear: 0.043788842856884] nn.Sequential: [nn.Linear: 0.012619345448911 nn.Linear: 0.017495028674603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062575661977523 nn.Linear: 0.064330491872592 nn.Linear: 0.044973790603184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453737282425 nn.Linear: 0.046781383643065] nn.Sequential: [nn.Linear: 0.031413824643384 nn.Linear: 0.033082667787199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45841100811958 nn.Linear: 0.21289049088955 nn.Linear: 0.14063075184822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11042791604996 nn.Linear: 0.27520218491554] nn.Sequential: [nn.Linear: 0.094147384166718 nn.Linear: 0.17944283783436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019664287798824 nn.Linear: 0.001476140877614 nn.Linear: 0.00063413488439846 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022403854472784 nn.Linear: 0.002688603984403] nn.Sequential: [nn.Linear: 0.00020847817550959 nn.Linear: 0.0019207762391448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013507019728422 nn.Linear: 0.021325876936316 nn.Linear: 0.015239926986396 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099426927044988 nn.Linear: 0.017519123852253] nn.Sequential: [nn.Linear: 0.0079060979187489 nn.Linear: 0.019067572429776]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062577423100644 nn.Linear: 0.064332909200199 nn.Linear: 0.044974034818048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453672251827 nn.Linear: 0.046766162038004] nn.Sequential: [nn.Linear: 0.031414075975019 nn.Linear: 0.033089640670957]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45838910341263 nn.Linear: 0.21292996406555 nn.Linear: 0.14022029936314 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11053989827633 nn.Linear: 0.27563270926476] nn.Sequential: [nn.Linear: 0.094240374863148 nn.Linear: 0.17962838709354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00059618287531199 nn.Linear: 0.00044821841661296 nn.Linear: 0.00026552201419667 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010197733427973 nn.Linear: 0.0012699526552271] nn.Sequential: [nn.Linear: 9.8418574517884e-05 nn.Linear: 0.0007352036007925]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048573729582131 nn.Linear: 0.0061167483218014 nn.Linear: 0.0057373172603548 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043734707869589 nn.Linear: 0.010784987360239] nn.Sequential: [nn.Linear: 0.0032698649447411 nn.Linear: 0.0071043558418751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062573476784655 nn.Linear: 0.064339980290443 nn.Linear: 0.044976354345336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453761329452 nn.Linear: 0.046781122569797] nn.Sequential: [nn.Linear: 0.031414574645682 nn.Linear: 0.03310463809107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4592013657093 nn.Linear: 0.21215145289898 nn.Linear: 0.140460729599 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11063534021378 nn.Linear: 0.27675631642342] nn.Sequential: [nn.Linear: 0.09420157968998 nn.Linear: 0.1797464042902]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013185471958157 nn.Linear: 0.00076385019485657 nn.Linear: 0.00038223177681287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000158452905821 nn.Linear: 0.002115319902045] nn.Sequential: [nn.Linear: 0.00013780650033099 nn.Linear: 0.0011128170970789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082702878862619 nn.Linear: 0.011166719719768 nn.Linear: 0.0086488658562303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074775898829103 nn.Linear: 0.019406409934163] nn.Sequential: [nn.Linear: 0.0046855695545673 nn.Linear: 0.01040487550199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062568938443295 nn.Linear: 0.064343009434233 nn.Linear: 0.044978187732059 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031453930677332 nn.Linear: 0.046807809247184] nn.Sequential: [nn.Linear: 0.031414631051379 nn.Linear: 0.033118136450216]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45972377061844 nn.Linear: 0.21276925504208 nn.Linear: 0.14024341106415 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11115066707134 nn.Linear: 0.27803206443787] nn.Sequential: [nn.Linear: 0.094381086528301 nn.Linear: 0.1797081977129]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071066875721947 nn.Linear: 0.00050363885737809 nn.Linear: 0.00028584417115192 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011759110534621 nn.Linear: 0.001664513940734] nn.Sequential: [nn.Linear: 0.00013556139520859 nn.Linear: 0.0011585422891427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067097977735102 nn.Linear: 0.0087303845211864 nn.Linear: 0.0054543889127672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0045072925277054 nn.Linear: 0.0099126193672419] nn.Sequential: [nn.Linear: 0.0041929529979825 nn.Linear: 0.011705847457051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581012270658 nn.Linear: 0.064348659391935 nn.Linear: 0.044980473598647 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031454392908692 nn.Linear: 0.046869692774465] nn.Sequential: [nn.Linear: 0.031415022736793 nn.Linear: 0.03314993907674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46008467674255 nn.Linear: 0.21267946064472 nn.Linear: 0.13989996910095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11091931164265 nn.Linear: 0.27882826328278] nn.Sequential: [nn.Linear: 0.094368025660515 nn.Linear: 0.17973648011684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012891352411268 nn.Linear: 0.00085180245352422 nn.Linear: 0.00047820331835013 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001535929123527 nn.Linear: 0.001739692508286] nn.Sequential: [nn.Linear: 0.00016765132372305 nn.Linear: 0.0012371640696965]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010097147896886 nn.Linear: 0.014521484263241 nn.Linear: 0.0085237789899111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0098430728539824 nn.Linear: 0.01206462085247] nn.Sequential: [nn.Linear: 0.0054448754526675 nn.Linear: 0.011683730408549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06258183983497 nn.Linear: 0.064356019605107 nn.Linear: 0.044983327030582 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031454706749263 nn.Linear: 0.046881250940885] nn.Sequential: [nn.Linear: 0.031415452635966 nn.Linear: 0.033172419897806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45990964770317 nn.Linear: 0.2136722356081 nn.Linear: 0.14088688790798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11116426438093 nn.Linear: 0.28034737706184] nn.Sequential: [nn.Linear: 0.094178810715675 nn.Linear: 0.17996601760387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010469635111174 nn.Linear: 0.00068887884918379 nn.Linear: 0.0003958101067255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016814585846592 nn.Linear: 0.0019464557797533] nn.Sequential: [nn.Linear: 0.00016439056808376 nn.Linear: 0.0014296624211859]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077158687636256 nn.Linear: 0.0098910424858332 nn.Linear: 0.0096959285438061 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056076757609844 nn.Linear: 0.010853487066925] nn.Sequential: [nn.Linear: 0.0057807271368802 nn.Linear: 0.016402760520577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062589032057126 nn.Linear: 0.064365571639376 nn.Linear: 0.04498505310432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031455018363801 nn.Linear: 0.046907489701823] nn.Sequential: [nn.Linear: 0.031415592417013 nn.Linear: 0.033175296462292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45929318666458 nn.Linear: 0.21359544992447 nn.Linear: 0.14116364717484 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11062753200531 nn.Linear: 0.28086179494858] nn.Sequential: [nn.Linear: 0.094376668334007 nn.Linear: 0.17995584011078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013305122999291 nn.Linear: 0.00081387724588619 nn.Linear: 0.00045111825514978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016841968234391 nn.Linear: 0.0019663590899304] nn.Sequential: [nn.Linear: 0.00016426988475729 nn.Linear: 0.0012941948930932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096497116610408 nn.Linear: 0.011852577328682 nn.Linear: 0.011034453287721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076861805282533 nn.Linear: 0.015887333080173] nn.Sequential: [nn.Linear: 0.00610287534073 nn.Linear: 0.01405658852309]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062583799973761 nn.Linear: 0.064363555907111 nn.Linear: 0.044985102619967 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031455450303925 nn.Linear: 0.046997149131585] nn.Sequential: [nn.Linear: 0.031415590636344 nn.Linear: 0.033195883245368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45921170711517 nn.Linear: 0.21335017681122 nn.Linear: 0.14045897126198 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1108048632741 nn.Linear: 0.28118520975113] nn.Sequential: [nn.Linear: 0.09424040466547 nn.Linear: 0.18002051115036]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007824558622934 nn.Linear: 0.00047668328352959 nn.Linear: 0.00026656335322012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.6866061705933e-05 nn.Linear: 0.0012304088674253] nn.Sequential: [nn.Linear: 0.00012308846720614 nn.Linear: 0.0013371805142011]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074027259834111 nn.Linear: 0.0057084485888481 nn.Linear: 0.0048019429668784 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034919437021017 nn.Linear: 0.0067872442305088] nn.Sequential: [nn.Linear: 0.0027813073247671 nn.Linear: 0.010388472117484]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062585299395868 nn.Linear: 0.064368448666371 nn.Linear: 0.044987367995955 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031455740775651 nn.Linear: 0.047015409827623] nn.Sequential: [nn.Linear: 0.031416067681159 nn.Linear: 0.033231906856654]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.45956110954285 nn.Linear: 0.21319252252579 nn.Linear: 0.14017082750797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11183565855026 nn.Linear: 0.28232672810555] nn.Sequential: [nn.Linear: 0.094059452414513 nn.Linear: 0.18033234775066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013868998154376 nn.Linear: 0.00088491145864309 nn.Linear: 0.00043466280168506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020174755530025 nn.Linear: 0.003038902554156] nn.Sequential: [nn.Linear: 0.00016554198821809 nn.Linear: 0.0014187336896148]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010299487039447 nn.Linear: 0.01648379676044 nn.Linear: 0.021454811096191 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076063121668994 nn.Linear: 0.022081026807427] nn.Sequential: [nn.Linear: 0.0041511505842209 nn.Linear: 0.014927635900676]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062575671160592 nn.Linear: 0.064368225952737 nn.Linear: 0.044987718339518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031455877798745 nn.Linear: 0.046999908377003] nn.Sequential: [nn.Linear: 0.031416119296798 nn.Linear: 0.033251528425689]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46033102273941 nn.Linear: 0.213419303298 nn.Linear: 0.14115372300148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11149795353413 nn.Linear: 0.28291961550713] nn.Sequential: [nn.Linear: 0.093868590891361 nn.Linear: 0.18027110397816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015084711404732 nn.Linear: 0.0010870773161639 nn.Linear: 0.00055478929672294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020318000867255 nn.Linear: 0.0023664819142887] nn.Sequential: [nn.Linear: 0.00019517012458722 nn.Linear: 0.0015611100410302]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013239244930446 nn.Linear: 0.014209292829037 nn.Linear: 0.010669053532183 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012578793801367 nn.Linear: 0.017027644440532] nn.Sequential: [nn.Linear: 0.0070725777186453 nn.Linear: 0.016042992472649]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06257725986221 nn.Linear: 0.064374542099021 nn.Linear: 0.044990203200966 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031455922872758 nn.Linear: 0.047044898143781] nn.Sequential: [nn.Linear: 0.031416677068312 nn.Linear: 0.033259844680777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46059557795525 nn.Linear: 0.21388648450375 nn.Linear: 0.14202597737312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11165115237236 nn.Linear: 0.28408363461494] nn.Sequential: [nn.Linear: 0.094153247773647 nn.Linear: 0.18014171719551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090392590920862 nn.Linear: 0.00061712550668265 nn.Linear: 0.00036440705656392 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014378261051728 nn.Linear: 0.0015724829186794] nn.Sequential: [nn.Linear: 0.00012988107003328 nn.Linear: 0.0010336025675161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054914765059948 nn.Linear: 0.0092825880274177 nn.Linear: 0.0053511043079197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056891283020377 nn.Linear: 0.01043136138469] nn.Sequential: [nn.Linear: 0.0039014180656523 nn.Linear: 0.0097518973052502]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062579297941777 nn.Linear: 0.064381634004145 nn.Linear: 0.044991544454255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03145645273846 nn.Linear: 0.047075626477806] nn.Sequential: [nn.Linear: 0.03141680840232 nn.Linear: 0.033274833860033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4612250328064 nn.Linear: 0.21387489140034 nn.Linear: 0.14206589758396 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11155756562948 nn.Linear: 0.28477537631989] nn.Sequential: [nn.Linear: 0.09411134570837 nn.Linear: 0.17992693185806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011517331958062 nn.Linear: 0.00069400680693498 nn.Linear: 0.00038571282267649 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015336635792515 nn.Linear: 0.0018535564855051] nn.Sequential: [nn.Linear: 0.00018526206291467 nn.Linear: 0.0015767309293176]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007852784357965 nn.Linear: 0.0095035396516323 nn.Linear: 0.0071801003068686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069909491576254 nn.Linear: 0.013254337012768] nn.Sequential: [nn.Linear: 0.0056379474699497 nn.Linear: 0.016346175223589]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06258085759824 nn.Linear: 0.064386863510904 nn.Linear: 0.044993867447895 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031456913040969 nn.Linear: 0.047082393630092] nn.Sequential: [nn.Linear: 0.031417292280502 nn.Linear: 0.033298103950639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46151089668274 nn.Linear: 0.21351534128189 nn.Linear: 0.14275707304478 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11144971847534 nn.Linear: 0.2853896021843] nn.Sequential: [nn.Linear: 0.094268292188644 nn.Linear: 0.18040123581886]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015174386354505 nn.Linear: 0.0011129691482671 nn.Linear: 0.00057949641349894 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020838180112881 nn.Linear: 0.0027429816995173] nn.Sequential: [nn.Linear: 0.00019634037713935 nn.Linear: 0.0017239287336135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012189521454275 nn.Linear: 0.01492580678314 nn.Linear: 0.015759246423841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013813398778439 nn.Linear: 0.022713987156749] nn.Sequential: [nn.Linear: 0.0087671773508191 nn.Linear: 0.023577373474836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062585071440667 nn.Linear: 0.064392625681932 nn.Linear: 0.044996195204299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031457151676463 nn.Linear: 0.047137791715159] nn.Sequential: [nn.Linear: 0.031417551645265 nn.Linear: 0.033322366228452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46124479174614 nn.Linear: 0.21356326341629 nn.Linear: 0.14259947836399 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1118250861764 nn.Linear: 0.28635689616203] nn.Sequential: [nn.Linear: 0.094210207462311 nn.Linear: 0.18083912134171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015237996084881 nn.Linear: 0.0009472033807905 nn.Linear: 0.00045853075509782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016488298327967 nn.Linear: 0.0021055323341828] nn.Sequential: [nn.Linear: 0.00020889899759321 nn.Linear: 0.0020961135378339]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097687402740121 nn.Linear: 0.012498259544373 nn.Linear: 0.013845114037395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007989389821887 nn.Linear: 0.020757114514709] nn.Sequential: [nn.Linear: 0.0063948160968721 nn.Linear: 0.026100920513272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062585781771264 nn.Linear: 0.064395677793694 nn.Linear: 0.044998831760706 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031457428912363 nn.Linear: 0.047174905908207] nn.Sequential: [nn.Linear: 0.03141780624244 nn.Linear: 0.033334684882315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46123588085175 nn.Linear: 0.21437636017799 nn.Linear: 0.14273370802402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11170147359371 nn.Linear: 0.28666141629219] nn.Sequential: [nn.Linear: 0.094105131924152 nn.Linear: 0.18081919848919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011288894206658 nn.Linear: 0.00068724436128482 nn.Linear: 0.00031918162630138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014022009864006 nn.Linear: 0.001937972046011] nn.Sequential: [nn.Linear: 0.00012114205433463 nn.Linear: 0.00092052150587203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076728886924684 nn.Linear: 0.010308789089322 nn.Linear: 0.014465807937086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052798124961555 nn.Linear: 0.013925217092037] nn.Sequential: [nn.Linear: 0.0042884284630418 nn.Linear: 0.011229899711907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062591994443848 nn.Linear: 0.064402738397636 nn.Linear: 0.045001384332217 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031457902042982 nn.Linear: 0.047251294487353] nn.Sequential: [nn.Linear: 0.03141815943892 nn.Linear: 0.033355356582811]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46137472987175 nn.Linear: 0.21400843560696 nn.Linear: 0.14371031522751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1118127182126 nn.Linear: 0.28812482953072] nn.Sequential: [nn.Linear: 0.094053849577904 nn.Linear: 0.18095473945141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00062683969320164 nn.Linear: 0.00043743002467092 nn.Linear: 0.00025236761196986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.682084397229e-05 nn.Linear: 0.0011795254987759] nn.Sequential: [nn.Linear: 0.0001007417792835 nn.Linear: 0.00078589142308544]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0050524761900306 nn.Linear: 0.0048288321122527 nn.Linear: 0.0056680594570935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0033762755338103 nn.Linear: 0.0070806252770126] nn.Sequential: [nn.Linear: 0.0023849355056882 nn.Linear: 0.0066043329425156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062590342660876 nn.Linear: 0.064406293880117 nn.Linear: 0.045003020292696 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031458220392011 nn.Linear: 0.047301093697286] nn.Sequential: [nn.Linear: 0.031418148783812 nn.Linear: 0.03335568018659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46168252825737 nn.Linear: 0.21357321739197 nn.Linear: 0.14376477897167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11213375627995 nn.Linear: 0.28866577148438] nn.Sequential: [nn.Linear: 0.094111084938049 nn.Linear: 0.18066364526749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010044374595491 nn.Linear: 0.00063089817043386 nn.Linear: 0.00030797792582144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015538134576273 nn.Linear: 0.0022464884141051] nn.Sequential: [nn.Linear: 0.00013263331606427 nn.Linear: 0.0012868217956349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064876303076744 nn.Linear: 0.0088361538946629 nn.Linear: 0.0086260121315718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.009366556070745 nn.Linear: 0.022036267444491] nn.Sequential: [nn.Linear: 0.0048468289896846 nn.Linear: 0.015134396031499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06258948865811 nn.Linear: 0.064408815869707 nn.Linear: 0.045004738184366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031458776282404 nn.Linear: 0.047357675758519] nn.Sequential: [nn.Linear: 0.031418298355268 nn.Linear: 0.033377816111079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46158882975578 nn.Linear: 0.2133823633194 nn.Linear: 0.14403013885021 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1122777685523 nn.Linear: 0.28899511694908] nn.Sequential: [nn.Linear: 0.093910112977028 nn.Linear: 0.1807694286108]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012113698761415 nn.Linear: 0.00074023504014772 nn.Linear: 0.0003561300370933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017140315780702 nn.Linear: 0.0025929308988935] nn.Sequential: [nn.Linear: 0.00011673636082176 nn.Linear: 0.00084511715977299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090950923040509 nn.Linear: 0.0094737345352769 nn.Linear: 0.014466933906078 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072040124796331 nn.Linear: 0.025276565924287] nn.Sequential: [nn.Linear: 0.004260613117367 nn.Linear: 0.009489256888628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584140910548 nn.Linear: 0.064415090956018 nn.Linear: 0.045006433604243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031459136127115 nn.Linear: 0.047384652290248] nn.Sequential: [nn.Linear: 0.031418428836216 nn.Linear: 0.033394631827552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46201822161674 nn.Linear: 0.21273837983608 nn.Linear: 0.14445248246193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11222022026777 nn.Linear: 0.28957915306091] nn.Sequential: [nn.Linear: 0.09389041364193 nn.Linear: 0.18090192973614]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012139476140162 nn.Linear: 0.00080964702219594 nn.Linear: 0.00051264965155791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022498885697011 nn.Linear: 0.0029009244602341] nn.Sequential: [nn.Linear: 0.00020705259108883 nn.Linear: 0.0015496037204873]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099911838769913 nn.Linear: 0.013049930334091 nn.Linear: 0.021052327007055 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077125444076955 nn.Linear: 0.021100174635649] nn.Sequential: [nn.Linear: 0.0080910641700029 nn.Linear: 0.020164394751191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.08949581772089	TD error	0.019532771788538	Qmax	1	

Steps: 6500000 (frames: 26000000), score: 1981.81, higheset score: 6760, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1812fps, testing time: 89s, testing rate: 5560fps,  num. ep.: 361,  num. rewards: 18173	
   2    8   16    2
   4   16   32    4
   8   32  128  256
   4   16    2  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062579768619905 nn.Linear: 0.064416493279058 nn.Linear: 0.04500737706323 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03145937934591 nn.Linear: 0.047420380800986] nn.Sequential: [nn.Linear: 0.03141887331182 nn.Linear: 0.033408098951229]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4621205329895 nn.Linear: 0.21358460187912 nn.Linear: 0.14468060433865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11238025873899 nn.Linear: 0.28997960686684] nn.Sequential: [nn.Linear: 0.093847863376141 nn.Linear: 0.18117864429951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001141363842654 nn.Linear: 0.000806896883521 nn.Linear: 0.00050454219808823 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023652375817012 nn.Linear: 0.0034786118726982] nn.Sequential: [nn.Linear: 0.00018953038106309 nn.Linear: 0.001559936016706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073193395510316 nn.Linear: 0.014994982630014 nn.Linear: 0.01214421633631 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011324577964842 nn.Linear: 0.027073744684458] nn.Sequential: [nn.Linear: 0.005000336561352 nn.Linear: 0.015978192910552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581540238254 nn.Linear: 0.064422880085808 nn.Linear: 0.045009921574396 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031459737210902 nn.Linear: 0.047442452990424] nn.Sequential: [nn.Linear: 0.031419107712962 nn.Linear: 0.033427419488219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46259433031082 nn.Linear: 0.21361577510834 nn.Linear: 0.14485056698322 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11223012953997 nn.Linear: 0.29089856147766] nn.Sequential: [nn.Linear: 0.093755647540092 nn.Linear: 0.18117180466652]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069747500927088 nn.Linear: 0.00042057675463409 nn.Linear: 0.00024241061994764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.7900385988379e-05 nn.Linear: 0.0010745350762155] nn.Sequential: [nn.Linear: 0.00012668139801368 nn.Linear: 0.0012223407363279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057415459305048 nn.Linear: 0.0068711275234818 nn.Linear: 0.0045652743428946 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038209892809391 nn.Linear: 0.0091972155496478] nn.Sequential: [nn.Linear: 0.0041290759108961 nn.Linear: 0.01425613462925]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062581596120196 nn.Linear: 0.064429304834674 nn.Linear: 0.045012155837293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031459922610847 nn.Linear: 0.047511878767466] nn.Sequential: [nn.Linear: 0.03141947791238 nn.Linear: 0.033452316072268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46302101016045 nn.Linear: 0.21348713338375 nn.Linear: 0.14474532008171 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11277406662703 nn.Linear: 0.29222646355629] nn.Sequential: [nn.Linear: 0.093900367617607 nn.Linear: 0.18150505423546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095731738142839 nn.Linear: 0.00062275261218252 nn.Linear: 0.00033131452796437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017630131982763 nn.Linear: 0.0028910556776309] nn.Sequential: [nn.Linear: 0.00010017503264817 nn.Linear: 0.00073835734605662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072465310804546 nn.Linear: 0.0086789382621646 nn.Linear: 0.0088651217520237 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090187555179 nn.Linear: 0.017131498083472] nn.Sequential: [nn.Linear: 0.002982861129567 nn.Linear: 0.0066974651999772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062583254194268 nn.Linear: 0.064433299341393 nn.Linear: 0.045013032033763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031460235028994 nn.Linear: 0.04752094834754] nn.Sequential: [nn.Linear: 0.031419692245475 nn.Linear: 0.033462779489998]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4627939760685 nn.Linear: 0.21401169896126 nn.Linear: 0.14454850554466 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11315435171127 nn.Linear: 0.29271024465561] nn.Sequential: [nn.Linear: 0.093863308429718 nn.Linear: 0.18148678541183]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010399102846606 nn.Linear: 0.0007931377655098 nn.Linear: 0.00043535920288222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017840771502673 nn.Linear: 0.0021151008751614] nn.Sequential: [nn.Linear: 0.00017338938191596 nn.Linear: 0.0014332988669369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095867998898029 nn.Linear: 0.012663183733821 nn.Linear: 0.01031250320375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093650845810771 nn.Linear: 0.012383781373501] nn.Sequential: [nn.Linear: 0.0041607078164816 nn.Linear: 0.012731001712382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062579714141107 nn.Linear: 0.064440128725239 nn.Linear: 0.045014698524824 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031460439696631 nn.Linear: 0.04752812160649] nn.Sequential: [nn.Linear: 0.031420051753007 nn.Linear: 0.03347918020143]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46274673938751 nn.Linear: 0.21376207470894 nn.Linear: 0.14572827517986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11383878439665 nn.Linear: 0.29386910796165] nn.Sequential: [nn.Linear: 0.0938700735569 nn.Linear: 0.18106858432293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00145638100126 nn.Linear: 0.00099476161022884 nn.Linear: 0.00052990411188526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001881516739072 nn.Linear: 0.0019557034705144] nn.Sequential: [nn.Linear: 0.00020031884857262 nn.Linear: 0.001448561918779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090007809922099 nn.Linear: 0.013374571688473 nn.Linear: 0.0096091143786907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076967617496848 nn.Linear: 0.012795480899513] nn.Sequential: [nn.Linear: 0.0074123460799456 nn.Linear: 0.014718404971063]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062578941998839 nn.Linear: 0.064442455434526 nn.Linear: 0.045017482318809 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031460777275885 nn.Linear: 0.047571401686014] nn.Sequential: [nn.Linear: 0.031420383105034 nn.Linear: 0.033490214790521]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46294063329697 nn.Linear: 0.21372877061367 nn.Linear: 0.1454164981842 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11434498429298 nn.Linear: 0.29502838850021] nn.Sequential: [nn.Linear: 0.09404368698597 nn.Linear: 0.18114532530308]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010954190000233 nn.Linear: 0.00071102183409937 nn.Linear: 0.00038751809166189 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001542012593555 nn.Linear: 0.0022306348673644] nn.Sequential: [nn.Linear: 0.00016925849720018 nn.Linear: 0.0015121363083775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065839574672282 nn.Linear: 0.0087028546258807 nn.Linear: 0.0082718674093485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043044462800026 nn.Linear: 0.015784939751029] nn.Sequential: [nn.Linear: 0.0053276875987649 nn.Linear: 0.010864205658436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062584437298774 nn.Linear: 0.06444912603253 nn.Linear: 0.045018663967836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031460924165944 nn.Linear: 0.047590327640862] nn.Sequential: [nn.Linear: 0.031420419708356 nn.Linear: 0.033499464639332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46357426047325 nn.Linear: 0.21421746909618 nn.Linear: 0.14626656472683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11516791582108 nn.Linear: 0.29540076851845] nn.Sequential: [nn.Linear: 0.094183705747128 nn.Linear: 0.18054385483265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013270199453137 nn.Linear: 0.00077797328948958 nn.Linear: 0.00042513943174699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002569863720851 nn.Linear: 0.0040304298349685] nn.Sequential: [nn.Linear: 0.00012718383742034 nn.Linear: 0.0010308981525706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081041920930147 nn.Linear: 0.014050155878067 nn.Linear: 0.012709254398942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083836112171412 nn.Linear: 0.026508713141084] nn.Sequential: [nn.Linear: 0.0041816169396043 nn.Linear: 0.010235314257443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062589564550253 nn.Linear: 0.064455655497095 nn.Linear: 0.045020367504242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031461473956997 nn.Linear: 0.04764451054325] nn.Sequential: [nn.Linear: 0.031420788186536 nn.Linear: 0.033519667366268]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46376252174377 nn.Linear: 0.21454626321793 nn.Linear: 0.14615032076836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11584801226854 nn.Linear: 0.29658377170563] nn.Sequential: [nn.Linear: 0.094029769301414 nn.Linear: 0.18092039227486]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011528741437205 nn.Linear: 0.00072451067445214 nn.Linear: 0.00037049041478524 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011625331317768 nn.Linear: 0.0012997915724178] nn.Sequential: [nn.Linear: 0.00013973382714311 nn.Linear: 0.0010312036775913]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063896821811795 nn.Linear: 0.0081920176744461 nn.Linear: 0.0079230144619942 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084334053099155 nn.Linear: 0.011278607882559] nn.Sequential: [nn.Linear: 0.0055007259361446 nn.Linear: 0.016613598912954]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06259081751296 nn.Linear: 0.064464558036797 nn.Linear: 0.045022915843639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031461929979656 nn.Linear: 0.047711236750565] nn.Sequential: [nn.Linear: 0.031421329291731 nn.Linear: 0.033545136807517]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46491807699203 nn.Linear: 0.21419596672058 nn.Linear: 0.14637218415737 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11625692248344 nn.Linear: 0.29784101247787] nn.Sequential: [nn.Linear: 0.093991592526436 nn.Linear: 0.18091702461243]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00051326725426673 nn.Linear: 0.0003923280382662 nn.Linear: 0.0002108940883745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.9540782851193e-05 nn.Linear: 0.0010473889723472] nn.Sequential: [nn.Linear: 8.1553892060327e-05 nn.Linear: 0.0006767027031022]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.004133184440434 nn.Linear: 0.0055074384436011 nn.Linear: 0.0039114211685956 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0031276366207749 nn.Linear: 0.0076396437361836] nn.Sequential: [nn.Linear: 0.0026346789672971 nn.Linear: 0.0072012739256024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062591413713227 nn.Linear: 0.064465846622891 nn.Linear: 0.045024095224713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031461975562783 nn.Linear: 0.047722637555353] nn.Sequential: [nn.Linear: 0.031421356861444 nn.Linear: 0.033558267931854]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46438843011856 nn.Linear: 0.21512097120285 nn.Linear: 0.14655339717865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11674650758505 nn.Linear: 0.29827973246574] nn.Sequential: [nn.Linear: 0.094029121100903 nn.Linear: 0.18086215853691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092416816034316 nn.Linear: 0.00061321780080849 nn.Linear: 0.00034460215611076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017330048389624 nn.Linear: 0.0022667989460191] nn.Sequential: [nn.Linear: 0.00010997660718976 nn.Linear: 0.0007680801249906]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078392950817943 nn.Linear: 0.0077715376392007 nn.Linear: 0.0081456620246172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072007561102509 nn.Linear: 0.020407093688846] nn.Sequential: [nn.Linear: 0.0032703336328268 nn.Linear: 0.0080711124464869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062595673106183 nn.Linear: 0.064474281303186 nn.Linear: 0.045026734044497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031462472314072 nn.Linear: 0.047780536066085] nn.Sequential: [nn.Linear: 0.031421873102656 nn.Linear: 0.033575331548738]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46482118964195 nn.Linear: 0.214869171381 nn.Linear: 0.1471843868494 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11782615631819 nn.Linear: 0.29951611161232] nn.Sequential: [nn.Linear: 0.093843124806881 nn.Linear: 0.18102930486202]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011224742488881 nn.Linear: 0.00068555823951079 nn.Linear: 0.0003360412815062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4997641948826e-05 nn.Linear: 0.00094609998385661] nn.Sequential: [nn.Linear: 0.00013447961941243 nn.Linear: 0.0011522823217561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00848922226578 nn.Linear: 0.011606676504016 nn.Linear: 0.0054559302516282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042568878270686 nn.Linear: 0.0069485912099481] nn.Sequential: [nn.Linear: 0.0041812625713646 nn.Linear: 0.013650919310749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062593706202858 nn.Linear: 0.064479353714003 nn.Linear: 0.045029305979201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031462945969767 nn.Linear: 0.047843558942702] nn.Sequential: [nn.Linear: 0.031422046698198 nn.Linear: 0.033599584482754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46472489833832 nn.Linear: 0.21573784947395 nn.Linear: 0.14819534122944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11869022995234 nn.Linear: 0.30062940716743] nn.Sequential: [nn.Linear: 0.093903169035912 nn.Linear: 0.18095195293427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098755277274806 nn.Linear: 0.00073107576686926 nn.Linear: 0.00036568574704577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012441350606018 nn.Linear: 0.0012764797926335] nn.Sequential: [nn.Linear: 0.00013783002720214 nn.Linear: 0.0012566224412645]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069760414771736 nn.Linear: 0.010839001275599 nn.Linear: 0.0076912492513657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068857977166772 nn.Linear: 0.010598006658256] nn.Sequential: [nn.Linear: 0.005082983057946 nn.Linear: 0.012150595895946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062593404861416 nn.Linear: 0.064486448738327 nn.Linear: 0.045031672259819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031463367288814 nn.Linear: 0.047898193782999] nn.Sequential: [nn.Linear: 0.031422321341335 nn.Linear: 0.03360449290392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46569737792015 nn.Linear: 0.21550884842873 nn.Linear: 0.14806053042412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.11932894587517 nn.Linear: 0.30153328180313] nn.Sequential: [nn.Linear: 0.093924961984158 nn.Linear: 0.18077202141285]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016656492159643 nn.Linear: 0.0011895151906083 nn.Linear: 0.00056621548103113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001514468992561 nn.Linear: 0.0015449634372935] nn.Sequential: [nn.Linear: 0.00023854992434086 nn.Linear: 0.0018848260668953]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014588733203709 nn.Linear: 0.016311440616846 nn.Linear: 0.012063530273736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0080673350021243 nn.Linear: 0.011254133656621] nn.Sequential: [nn.Linear: 0.01216428540647 nn.Linear: 0.019896294921637]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062594267877301 nn.Linear: 0.064492445363327 nn.Linear: 0.045034128454248 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031463594891672 nn.Linear: 0.04792934780258] nn.Sequential: [nn.Linear: 0.031422520969828 nn.Linear: 0.033625953672792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46634137630463 nn.Linear: 0.21620683372021 nn.Linear: 0.1474547535181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12008558213711 nn.Linear: 0.30234381556511] nn.Sequential: [nn.Linear: 0.094419911503792 nn.Linear: 0.18098323047161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017100754382226 nn.Linear: 0.00094687540369558 nn.Linear: 0.00049136860627683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020376977447142 nn.Linear: 0.0029399402387978] nn.Sequential: [nn.Linear: 0.00016233250515672 nn.Linear: 0.0011808338684207]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010407271794975 nn.Linear: 0.016120603308082 nn.Linear: 0.010021084919572 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008623955771327 nn.Linear: 0.019615171477199] nn.Sequential: [nn.Linear: 0.0040893363766372 nn.Linear: 0.011848620139062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062598020273773 nn.Linear: 0.06449653510135 nn.Linear: 0.045035809362369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03146370815151 nn.Linear: 0.047963038058128] nn.Sequential: [nn.Linear: 0.031423134940873 nn.Linear: 0.033661987934281]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46657025814056 nn.Linear: 0.21538989245892 nn.Linear: 0.14828710258007 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12081609666348 nn.Linear: 0.30300751328468] nn.Sequential: [nn.Linear: 0.094451099634171 nn.Linear: 0.1811021566391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031834607144774 nn.Linear: 0.0018499540898478 nn.Linear: 0.00069113190015532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025133020247513 nn.Linear: 0.0033987817305859] nn.Sequential: [nn.Linear: 0.00019161719065914 nn.Linear: 0.0015240744587187]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.030109940096736 nn.Linear: 0.033882491290569 nn.Linear: 0.035802643746138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018040033057332 nn.Linear: 0.027080107480288] nn.Sequential: [nn.Linear: 0.0065364567562938 nn.Linear: 0.018216783180833]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062602125145814 nn.Linear: 0.064502916959708 nn.Linear: 0.045037768500288 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031464165718431 nn.Linear: 0.047982472332336] nn.Sequential: [nn.Linear: 0.031423310863125 nn.Linear: 0.033684512762407]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4672144651413 nn.Linear: 0.21558956801891 nn.Linear: 0.14840130507946 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12139628827572 nn.Linear: 0.30371469259262] nn.Sequential: [nn.Linear: 0.094337157905102 nn.Linear: 0.1813351213932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010927042708674 nn.Linear: 0.00070064828223389 nn.Linear: 0.00039070317780818 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017409410196191 nn.Linear: 0.0020497799958653] nn.Sequential: [nn.Linear: 0.00012854569317589 nn.Linear: 0.0011721548491951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074012447148561 nn.Linear: 0.010910259559751 nn.Linear: 0.0065032746642828 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081756105646491 nn.Linear: 0.013120994903147] nn.Sequential: [nn.Linear: 0.0039732549339533 nn.Linear: 0.012273019179702]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062601658385011 nn.Linear: 0.064503886725694 nn.Linear: 0.045038177710658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03146437453831 nn.Linear: 0.047994198905158] nn.Sequential: [nn.Linear: 0.031423520722777 nn.Linear: 0.033701985014506]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46779790520668 nn.Linear: 0.21592947840691 nn.Linear: 0.14835332334042 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12225003540516 nn.Linear: 0.30427402257919] nn.Sequential: [nn.Linear: 0.094469502568245 nn.Linear: 0.18183282017708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018763386207075 nn.Linear: 0.0014585420114699 nn.Linear: 0.0006205909798388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002177693023539 nn.Linear: 0.0033685577318306] nn.Sequential: [nn.Linear: 0.00017167065733745 nn.Linear: 0.0013580205210101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012618372216821 nn.Linear: 0.018798438832164 nn.Linear: 0.012434745207429 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0078760841861367 nn.Linear: 0.026197090744972] nn.Sequential: [nn.Linear: 0.0066566462628543 nn.Linear: 0.016269298270345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062599621001048 nn.Linear: 0.064509255294838 nn.Linear: 0.045039892178146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031464502514077 nn.Linear: 0.048034373576741] nn.Sequential: [nn.Linear: 0.031423866431166 nn.Linear: 0.033712445759946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46796828508377 nn.Linear: 0.21590186655521 nn.Linear: 0.1491312533617 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12293643504381 nn.Linear: 0.30486565828323] nn.Sequential: [nn.Linear: 0.094769641757011 nn.Linear: 0.18172177672386]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00072132006381281 nn.Linear: 0.00048023782811157 nn.Linear: 0.00027288428852923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014283024251973 nn.Linear: 0.0021642329471465] nn.Sequential: [nn.Linear: 9.0774933336836e-05 nn.Linear: 0.00070355087777708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0050892503932118 nn.Linear: 0.0077138096094131 nn.Linear: 0.010198251344264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049408278428018 nn.Linear: 0.013537267223001] nn.Sequential: [nn.Linear: 0.0023339551407844 nn.Linear: 0.0054322551004589]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06260013512401 nn.Linear: 0.064515931988201 nn.Linear: 0.045041762342715 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031464810572251 nn.Linear: 0.048052960228055] nn.Sequential: [nn.Linear: 0.031424398690764 nn.Linear: 0.03374146989168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4678401350975 nn.Linear: 0.21649160981178 nn.Linear: 0.14860691130161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12351654469967 nn.Linear: 0.30558374524117] nn.Sequential: [nn.Linear: 0.094673655927181 nn.Linear: 0.18208153545856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00079717201747468 nn.Linear: 0.00053712175856635 nn.Linear: 0.0003175963390851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012851589874004 nn.Linear: 0.0015455945765689] nn.Sequential: [nn.Linear: 0.00014133830779148 nn.Linear: 0.0011428215372432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072046988643706 nn.Linear: 0.0068666613660753 nn.Linear: 0.0078097558580339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050578652881086 nn.Linear: 0.012028109282255] nn.Sequential: [nn.Linear: 0.0049922224134207 nn.Linear: 0.010108861140907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062602084713867 nn.Linear: 0.064520848170694 nn.Linear: 0.045044426099655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031465178119844 nn.Linear: 0.048088521482697] nn.Sequential: [nn.Linear: 0.031425018315689 nn.Linear: 0.033768356216503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46844831109047 nn.Linear: 0.21644707024097 nn.Linear: 0.14902417361736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12466287612915 nn.Linear: 0.30640006065369] nn.Sequential: [nn.Linear: 0.095142774283886 nn.Linear: 0.18221959471703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001317018892285 nn.Linear: 0.00084436931144921 nn.Linear: 0.00042178911665518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014895967531187 nn.Linear: 0.0017643632946122] nn.Sequential: [nn.Linear: 0.00018882786167296 nn.Linear: 0.0017518443880747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082481428980827 nn.Linear: 0.0094212098047137 nn.Linear: 0.0095763895660639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060298452153802 nn.Linear: 0.017737116664648] nn.Sequential: [nn.Linear: 0.0055000446736813 nn.Linear: 0.018315499648452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062605040422669 nn.Linear: 0.064527979630505 nn.Linear: 0.0450474880777 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031465582734877 nn.Linear: 0.048146542764982] nn.Sequential: [nn.Linear: 0.031425531225005 nn.Linear: 0.033792470100042]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46895307302475 nn.Linear: 0.21726134419441 nn.Linear: 0.14875856041908 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12496254593134 nn.Linear: 0.30697822570801] nn.Sequential: [nn.Linear: 0.095291562378407 nn.Linear: 0.1824117898941]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015151111308672 nn.Linear: 0.0010410792086153 nn.Linear: 0.00044991846987411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021088191420458 nn.Linear: 0.0029287339246715] nn.Sequential: [nn.Linear: 0.00014834043057373 nn.Linear: 0.0010470049830355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090783024206758 nn.Linear: 0.011738774366677 nn.Linear: 0.0087779946625233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072003831155598 nn.Linear: 0.016830433160067] nn.Sequential: [nn.Linear: 0.004432316403836 nn.Linear: 0.0078914305195212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062603326659119 nn.Linear: 0.064530657618772 nn.Linear: 0.045048751756934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031465773022644 nn.Linear: 0.048176866584267] nn.Sequential: [nn.Linear: 0.031425859812906 nn.Linear: 0.033810397488806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.46988299489021 nn.Linear: 0.21754018962383 nn.Linear: 0.14935700595379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12591168284416 nn.Linear: 0.30800333619118] nn.Sequential: [nn.Linear: 0.095539078116417 nn.Linear: 0.18265198171139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013556903649569 nn.Linear: 0.00085930456337225 nn.Linear: 0.00038116717172852 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002023847206253 nn.Linear: 0.0032991088394716] nn.Sequential: [nn.Linear: 0.00018209232167254 nn.Linear: 0.0016401542205104]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011431924067438 nn.Linear: 0.011666173115373 nn.Linear: 0.017865281552076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011987136676908 nn.Linear: 0.025578754022717] nn.Sequential: [nn.Linear: 0.011756648309529 nn.Linear: 0.021744577214122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062612255567408 nn.Linear: 0.0645346726946 nn.Linear: 0.045050963254518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031466114545016 nn.Linear: 0.048226953227413] nn.Sequential: [nn.Linear: 0.031426207699298 nn.Linear: 0.033824758838206]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47069752216339 nn.Linear: 0.21786470711231 nn.Linear: 0.14912679791451 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12632600963116 nn.Linear: 0.30922463536263] nn.Sequential: [nn.Linear: 0.095473721623421 nn.Linear: 0.18300688266754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092074805895698 nn.Linear: 0.00061299541462639 nn.Linear: 0.00035957639302196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001841488175417 nn.Linear: 0.0028077842938656] nn.Sequential: [nn.Linear: 0.0001323114929441 nn.Linear: 0.00108945979716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069990647025406 nn.Linear: 0.011293479241431 nn.Linear: 0.013110379688442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064740949310362 nn.Linear: 0.018955074250698] nn.Sequential: [nn.Linear: 0.003638114547357 nn.Linear: 0.010824925266206]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062612490988741 nn.Linear: 0.064539975940644 nn.Linear: 0.045052706786164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031466434785149 nn.Linear: 0.048261668637579] nn.Sequential: [nn.Linear: 0.031426563608241 nn.Linear: 0.033850091763721]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47114944458008 nn.Linear: 0.21818959712982 nn.Linear: 0.14974766969681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12689135968685 nn.Linear: 0.30992838740349] nn.Sequential: [nn.Linear: 0.095655642449856 nn.Linear: 0.18334622681141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018177522186104 nn.Linear: 0.0012067698493746 nn.Linear: 0.00056283108344082 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016541533832872 nn.Linear: 0.001626381871662] nn.Sequential: [nn.Linear: 0.00021899951420161 nn.Linear: 0.0015840125058945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013368597254157 nn.Linear: 0.015371228568256 nn.Linear: 0.012986110523343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092546874657273 nn.Linear: 0.010925395414233] nn.Sequential: [nn.Linear: 0.0073743378743529 nn.Linear: 0.017757838591933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062613406319833 nn.Linear: 0.064542457112001 nn.Linear: 0.045054946917869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031467003096215 nn.Linear: 0.048297221224416] nn.Sequential: [nn.Linear: 0.03142705865758 nn.Linear: 0.033880181486437]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47153300046921 nn.Linear: 0.21873936057091 nn.Linear: 0.15014824271202 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12751339375973 nn.Linear: 0.31188848614693] nn.Sequential: [nn.Linear: 0.095899820327759 nn.Linear: 0.18384346365929]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0035368312017162 nn.Linear: 0.0018756534260536 nn.Linear: 0.00089551144534029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034596781665215 nn.Linear: 0.0047933534363989] nn.Sequential: [nn.Linear: 0.00036670431786566 nn.Linear: 0.0035641623311909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023731011897326 nn.Linear: 0.033523343503475 nn.Linear: 0.029632054269314 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018497051671147 nn.Linear: 0.048118181526661] nn.Sequential: [nn.Linear: 0.011473733000457 nn.Linear: 0.045352578163147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.099632092237473	TD error	0.019690468579531	Qmax	1	

Steps: 6750000 (frames: 27000000), score: 1865.85, higheset score: 6816, epsilon: 0.05, lr: 0.0005, training time: 551s, training rate: 1812fps, testing time: 90s, testing rate: 5543fps,  num. ep.: 275,  num. rewards: 14063	
   2    4    2    8
   4    8   32    2
   8   32  128  256
   2   16   32  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062619620163148 nn.Linear: 0.064553573958214 nn.Linear: 0.045058619804891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031467343798766 nn.Linear: 0.048350250129474] nn.Sequential: [nn.Linear: 0.031427847464243 nn.Linear: 0.03390371395421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4719865322113 nn.Linear: 0.21928688883781 nn.Linear: 0.15136463940144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12849816679955 nn.Linear: 0.31275513768196] nn.Sequential: [nn.Linear: 0.095929928123951 nn.Linear: 0.1843299716711]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00065676927739422 nn.Linear: 0.0003745498300798 nn.Linear: 0.0002076657135135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.4322171896016e-05 nn.Linear: 0.0010750166951458] nn.Sequential: [nn.Linear: 0.00010244104489048 nn.Linear: 0.00085132134842752]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0041896179318428 nn.Linear: 0.0050229309126735 nn.Linear: 0.0063089388422668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0026627711486071 nn.Linear: 0.0078514060005546] nn.Sequential: [nn.Linear: 0.0032941608224064 nn.Linear: 0.0090651391074061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0626145953299 nn.Linear: 0.064557136698656 nn.Linear: 0.045060715224454 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031467539697639 nn.Linear: 0.048361043807148] nn.Sequential: [nn.Linear: 0.031428294853751 nn.Linear: 0.033932194385813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47266086935997 nn.Linear: 0.21952278912067 nn.Linear: 0.15155832469463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12890408933163 nn.Linear: 0.31380927562714] nn.Sequential: [nn.Linear: 0.09606945514679 nn.Linear: 0.18485502898693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011922733512892 nn.Linear: 0.00070974476729067 nn.Linear: 0.00040958312094156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014499345390845 nn.Linear: 0.0017684013264909] nn.Sequential: [nn.Linear: 0.00016816370557261 nn.Linear: 0.0013863581014133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074241054244339 nn.Linear: 0.011899976059794 nn.Linear: 0.0085952840745449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0078861052170396 nn.Linear: 0.013982254080474] nn.Sequential: [nn.Linear: 0.005917823407799 nn.Linear: 0.013169788755476]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06262349730077 nn.Linear: 0.064563408104114 nn.Linear: 0.04506307143579 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03146776098379 nn.Linear: 0.048391954086128] nn.Sequential: [nn.Linear: 0.031428497015282 nn.Linear: 0.033941550166336]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47290250658989 nn.Linear: 0.21922336518764 nn.Linear: 0.15138505399227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.12971232831478 nn.Linear: 0.31539076566696] nn.Sequential: [nn.Linear: 0.096001945436001 nn.Linear: 0.18530158698559]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093839939813138 nn.Linear: 0.00058454553812832 nn.Linear: 0.0003086262512734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010657109698351 nn.Linear: 0.0011707923402851] nn.Sequential: [nn.Linear: 0.0001159486385927 nn.Linear: 0.00077445481276178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073221256025136 nn.Linear: 0.0091064581647515 nn.Linear: 0.0096518658101559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0041522532701492 nn.Linear: 0.0075203310698271] nn.Sequential: [nn.Linear: 0.0033184865023941 nn.Linear: 0.0057009966112673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062621252134571 nn.Linear: 0.064566793685272 nn.Linear: 0.045064533182381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031467782269869 nn.Linear: 0.048371096521265] nn.Sequential: [nn.Linear: 0.031428980629655 nn.Linear: 0.033968077315013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47256752848625 nn.Linear: 0.21919456124306 nn.Linear: 0.15114279091358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13112083077431 nn.Linear: 0.31582236289978] nn.Sequential: [nn.Linear: 0.096643790602684 nn.Linear: 0.18548902869225]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014794416078293 nn.Linear: 0.000786215368638 nn.Linear: 0.00039401417656111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017667885640231 nn.Linear: 0.0020785448431427] nn.Sequential: [nn.Linear: 0.00013712985652581 nn.Linear: 0.00098583642029432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010528663173318 nn.Linear: 0.011553320102394 nn.Linear: 0.0081132892519236 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059959357604384 nn.Linear: 0.014741745777428] nn.Sequential: [nn.Linear: 0.0038477976340801 nn.Linear: 0.0083142789080739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062618188191575 nn.Linear: 0.064567882319959 nn.Linear: 0.045065004908486 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0314681950165 nn.Linear: 0.048397272170064] nn.Sequential: [nn.Linear: 0.031429089676217 nn.Linear: 0.033988437328327]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4729867875576 nn.Linear: 0.21895837783813 nn.Linear: 0.15121296048164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13163791596889 nn.Linear: 0.31714478135109] nn.Sequential: [nn.Linear: 0.096116170287132 nn.Linear: 0.18550863862038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001703306068471 nn.Linear: 0.00089492168757806 nn.Linear: 0.00034413891503031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012528199877209 nn.Linear: 0.0015437461358812] nn.Sequential: [nn.Linear: 0.0001074984249688 nn.Linear: 0.00086389894039392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013317212462425 nn.Linear: 0.013423074036837 nn.Linear: 0.013800222426653 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005500101018697 nn.Linear: 0.01153695397079] nn.Sequential: [nn.Linear: 0.0038626312743872 nn.Linear: 0.008269271813333]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062617850505704 nn.Linear: 0.064576200001693 nn.Linear: 0.045067717294959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031468658398433 nn.Linear: 0.048456786512787] nn.Sequential: [nn.Linear: 0.031429470610439 nn.Linear: 0.033982731993635]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47331181168556 nn.Linear: 0.21975091099739 nn.Linear: 0.15232603251934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13239288330078 nn.Linear: 0.31792563199997] nn.Sequential: [nn.Linear: 0.096200563013554 nn.Linear: 0.18577407300472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011621902625769 nn.Linear: 0.00073001413203256 nn.Linear: 0.00038819837304912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015044119952409 nn.Linear: 0.0017680813267391] nn.Sequential: [nn.Linear: 0.00011849185073457 nn.Linear: 0.00080852938107024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071584200486541 nn.Linear: 0.010789141058922 nn.Linear: 0.0095823528245091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083521213382483 nn.Linear: 0.014294403605163] nn.Sequential: [nn.Linear: 0.0048754564486444 nn.Linear: 0.0081033548340201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062617612820882 nn.Linear: 0.064577116515617 nn.Linear: 0.045068712135746 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031469089005205 nn.Linear: 0.048489253953107] nn.Sequential: [nn.Linear: 0.031429489390366 nn.Linear: 0.033991984483009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47420367598534 nn.Linear: 0.21917060017586 nn.Linear: 0.15220311284065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13336850702763 nn.Linear: 0.31865218281746] nn.Sequential: [nn.Linear: 0.096607401967049 nn.Linear: 0.18607866764069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020368874522661 nn.Linear: 0.0012750663876269 nn.Linear: 0.00058074189473445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016750430366537 nn.Linear: 0.0019105805661062] nn.Sequential: [nn.Linear: 0.00017586483790943 nn.Linear: 0.0013605735418127]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015752295032144 nn.Linear: 0.017073679715395 nn.Linear: 0.017898531630635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076383943669498 nn.Linear: 0.020200775936246] nn.Sequential: [nn.Linear: 0.0072068679146469 nn.Linear: 0.017180712893605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062612275251944 nn.Linear: 0.064579141207482 nn.Linear: 0.045069591089993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031469380400385 nn.Linear: 0.048523524836014] nn.Sequential: [nn.Linear: 0.03142968592717 nn.Linear: 0.033989136354028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47429209947586 nn.Linear: 0.21973861753941 nn.Linear: 0.15232400596142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13412764668465 nn.Linear: 0.31968322396278] nn.Sequential: [nn.Linear: 0.095621004700661 nn.Linear: 0.18633861839771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014399981633807 nn.Linear: 0.00098064827014078 nn.Linear: 0.00058131570326086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016180118063091 nn.Linear: 0.0018467014879817] nn.Sequential: [nn.Linear: 0.00026647112580145 nn.Linear: 0.0021384571359286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082540884613991 nn.Linear: 0.013988719321787 nn.Linear: 0.013965173624456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074130105786026 nn.Linear: 0.01109367609024] nn.Sequential: [nn.Linear: 0.0094696162268519 nn.Linear: 0.024126902222633]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062614445538105 nn.Linear: 0.064583413293968 nn.Linear: 0.045071216596999 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03146974591081 nn.Linear: 0.04853295560666] nn.Sequential: [nn.Linear: 0.0314303661121 nn.Linear: 0.034033620969463]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47507834434509 nn.Linear: 0.21975447237492 nn.Linear: 0.15243943035603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13534788787365 nn.Linear: 0.32064080238342] nn.Sequential: [nn.Linear: 0.09644590318203 nn.Linear: 0.18699391186237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014823862631289 nn.Linear: 0.00091184269326437 nn.Linear: 0.0004674036748551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002240643375814 nn.Linear: 0.0033908905822138] nn.Sequential: [nn.Linear: 0.00014549993170274 nn.Linear: 0.0010764411302177]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077104950323701 nn.Linear: 0.01325858104974 nn.Linear: 0.0094321593642235 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079114055261016 nn.Linear: 0.019487043842673] nn.Sequential: [nn.Linear: 0.0042386003769934 nn.Linear: 0.010420490987599]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062610257181831 nn.Linear: 0.064590039552771 nn.Linear: 0.045073212415242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031470008980401 nn.Linear: 0.048586767407073] nn.Sequential: [nn.Linear: 0.031431071140793 nn.Linear: 0.034077588415037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47556132078171 nn.Linear: 0.22058203816414 nn.Linear: 0.15325945615768 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13575813174248 nn.Linear: 0.32204085588455] nn.Sequential: [nn.Linear: 0.096450388431549 nn.Linear: 0.18763725459576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.003822354314894 nn.Linear: 0.0019523232380089 nn.Linear: 0.00084864605089588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032345974506831 nn.Linear: 0.0041198754031844] nn.Sequential: [nn.Linear: 0.00029278642999426 nn.Linear: 0.0026902406239933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024860095232725 nn.Linear: 0.034738689661026 nn.Linear: 0.028193559497595 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016667291522026 nn.Linear: 0.029842313379049] nn.Sequential: [nn.Linear: 0.014127927832305 nn.Linear: 0.02975426055491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062605127367164 nn.Linear: 0.064593103015042 nn.Linear: 0.045073649497665 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0314701106793 nn.Linear: 0.048617362921959] nn.Sequential: [nn.Linear: 0.031431067153266 nn.Linear: 0.034059213740391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47545343637466 nn.Linear: 0.22095647454262 nn.Linear: 0.15296977758408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13644635677338 nn.Linear: 0.32289958000183] nn.Sequential: [nn.Linear: 0.096750542521477 nn.Linear: 0.18807531893253]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015733390072315 nn.Linear: 0.00093839394439608 nn.Linear: 0.00049444337821493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019169231063527 nn.Linear: 0.0023480108049664] nn.Sequential: [nn.Linear: 0.00019001156983945 nn.Linear: 0.0016529327761495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086689293384552 nn.Linear: 0.017112007364631 nn.Linear: 0.0099980589002371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0067150671966374 nn.Linear: 0.017555175349116] nn.Sequential: [nn.Linear: 0.0052291117608547 nn.Linear: 0.013839135877788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062606190267976 nn.Linear: 0.064597128299056 nn.Linear: 0.045074721368601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031470382406665 nn.Linear: 0.048640889601359] nn.Sequential: [nn.Linear: 0.031431123243007 nn.Linear: 0.034058638793379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47531712055206 nn.Linear: 0.22162458300591 nn.Linear: 0.15311887860298 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13724859058857 nn.Linear: 0.32379925251007] nn.Sequential: [nn.Linear: 0.096628069877625 nn.Linear: 0.18865652382374]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012404157025922 nn.Linear: 0.00072699421421745 nn.Linear: 0.00036707320695216 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014506231159972 nn.Linear: 0.0015716936654795] nn.Sequential: [nn.Linear: 0.00013040851383325 nn.Linear: 0.00088332269833583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076060527935624 nn.Linear: 0.0093098599463701 nn.Linear: 0.015651516616344 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060632028616965 nn.Linear: 0.0092307720333338] nn.Sequential: [nn.Linear: 0.0054067759774625 nn.Linear: 0.0074501298367977]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	6880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062609244656486 nn.Linear: 0.064604204505035 nn.Linear: 0.045076803746401 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031470696929642 nn.Linear: 0.048684450733703] nn.Sequential: [nn.Linear: 0.031431519038279 nn.Linear: 0.034078858996757]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47528237104416 nn.Linear: 0.22154226899147 nn.Linear: 0.15302214026451 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13825266063213 nn.Linear: 0.32495146989822] nn.Sequential: [nn.Linear: 0.096793331205845 nn.Linear: 0.18917459249496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097217296193235 nn.Linear: 0.00076760043565259 nn.Linear: 0.00043301373173042 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019473311251374 nn.Linear: 0.0030546256234864] nn.Sequential: [nn.Linear: 0.00020691951085018 nn.Linear: 0.0019519492940544]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062750056385994 nn.Linear: 0.015609071590006 nn.Linear: 0.011330940760672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075783180072904 nn.Linear: 0.021155700087547] nn.Sequential: [nn.Linear: 0.0050074686296284 nn.Linear: 0.023331632837653]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062607654795826 nn.Linear: 0.064608737699275 nn.Linear: 0.0450790344067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031470964763293 nn.Linear: 0.048714260929199] nn.Sequential: [nn.Linear: 0.031431875262011 nn.Linear: 0.034085949805013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47545427083969 nn.Linear: 0.22196754813194 nn.Linear: 0.1535802334547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13864210247993 nn.Linear: 0.32580208778381] nn.Sequential: [nn.Linear: 0.09683870524168 nn.Linear: 0.18912760913372]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033982390727617 nn.Linear: 0.0016050268670788 nn.Linear: 0.00061062759952573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023170098818293 nn.Linear: 0.0034375499500188] nn.Sequential: [nn.Linear: 0.00018055950581786 nn.Linear: 0.0015587805630998]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.02440445497632 nn.Linear: 0.022350147366524 nn.Linear: 0.024033049121499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01088073477149 nn.Linear: 0.023099252954125] nn.Sequential: [nn.Linear: 0.004995689727366 nn.Linear: 0.014717422425747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062606140111192 nn.Linear: 0.064612056611564 nn.Linear: 0.045080783583652 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031471358117548 nn.Linear: 0.048785392517487] nn.Sequential: [nn.Linear: 0.031432171661601 nn.Linear: 0.034122728205224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47631871700287 nn.Linear: 0.22241604328156 nn.Linear: 0.15312446653843 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.13950224220753 nn.Linear: 0.32755449414253] nn.Sequential: [nn.Linear: 0.097305439412594 nn.Linear: 0.1891858279705]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023667875963953 nn.Linear: 0.0014566680428689 nn.Linear: 0.00062168779726641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023005112975396 nn.Linear: 0.003135259786794] nn.Sequential: [nn.Linear: 0.00019028116056806 nn.Linear: 0.00129694481111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018074169754982 nn.Linear: 0.03385716676712 nn.Linear: 0.020471787080169 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013052778318524 nn.Linear: 0.024975340813398] nn.Sequential: [nn.Linear: 0.013622596859932 nn.Linear: 0.017653770744801]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062604251705281 nn.Linear: 0.064616384271665 nn.Linear: 0.045082734810912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031471634570246 nn.Linear: 0.048812226502605] nn.Sequential: [nn.Linear: 0.031432415939102 nn.Linear: 0.034130938729831]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47714355587959 nn.Linear: 0.22304345667362 nn.Linear: 0.15437410771847 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14042161405087 nn.Linear: 0.32873004674911] nn.Sequential: [nn.Linear: 0.097673341631889 nn.Linear: 0.18957257270813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013273369755561 nn.Linear: 0.0010293837577138 nn.Linear: 0.00061265069759757 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028987386248036 nn.Linear: 0.0044190234086021] nn.Sequential: [nn.Linear: 0.00020873213354979 nn.Linear: 0.00145290958089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088520469143987 nn.Linear: 0.012751692906022 nn.Linear: 0.012915755622089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011742796748877 nn.Linear: 0.024012548848987] nn.Sequential: [nn.Linear: 0.0054453276097775 nn.Linear: 0.011176702566445]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062608929962952 nn.Linear: 0.064624362314939 nn.Linear: 0.045085382852602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031472065307077 nn.Linear: 0.04887841441348] nn.Sequential: [nn.Linear: 0.031432811034593 nn.Linear: 0.034158757420835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47718954086304 nn.Linear: 0.22326284646988 nn.Linear: 0.15368631482124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14131054282188 nn.Linear: 0.32938903570175] nn.Sequential: [nn.Linear: 0.097718238830566 nn.Linear: 0.19028301537037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0041158640686056 nn.Linear: 0.0020199848277998 nn.Linear: 0.00079537086184093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027873382638989 nn.Linear: 0.0038904469853563] nn.Sequential: [nn.Linear: 0.00026346371014142 nn.Linear: 0.0024361185344612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.042881175875664 nn.Linear: 0.042946185916662 nn.Linear: 0.052324019372463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01554480753839 nn.Linear: 0.036484964191914] nn.Sequential: [nn.Linear: 0.016203686594963 nn.Linear: 0.032022923231125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062601930026648 nn.Linear: 0.064626581228682 nn.Linear: 0.045087042208045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031472284126558 nn.Linear: 0.048904150587063] nn.Sequential: [nn.Linear: 0.031433106584386 nn.Linear: 0.034169581615425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47758519649506 nn.Linear: 0.2235219180584 nn.Linear: 0.15435320138931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14205515384674 nn.Linear: 0.33026000857353] nn.Sequential: [nn.Linear: 0.097524218261242 nn.Linear: 0.19059857726097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00047156324058893 nn.Linear: 0.00031142761346089 nn.Linear: 0.00019590951521717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.3063928572805e-05 nn.Linear: 0.00093000805372662] nn.Sequential: [nn.Linear: 8.4016320934442e-05 nn.Linear: 0.00070344696154074]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0037183896638453 nn.Linear: 0.0048806602135301 nn.Linear: 0.0041839624755085 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0030984897166491 nn.Linear: 0.0077936141751707] nn.Sequential: [nn.Linear: 0.0031713182106614 nn.Linear: 0.0068395338021219]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062602067830229 nn.Linear: 0.064632957977549 nn.Linear: 0.045089120810677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031472869744829 nn.Linear: 0.048954673864117] nn.Sequential: [nn.Linear: 0.031433226710808 nn.Linear: 0.034179980548654]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47813478112221 nn.Linear: 0.22338382899761 nn.Linear: 0.15518656373024 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14304178953171 nn.Linear: 0.3312341272831] nn.Sequential: [nn.Linear: 0.097494944930077 nn.Linear: 0.19130681455135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011107169809594 nn.Linear: 0.00067607103534962 nn.Linear: 0.00031674053308714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012555539487889 nn.Linear: 0.0018423389789848] nn.Sequential: [nn.Linear: 0.00010110933459038 nn.Linear: 0.00092766673366237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0091986572369933 nn.Linear: 0.01346467807889 nn.Linear: 0.013936684466898 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070329424925148 nn.Linear: 0.014029167592525] nn.Sequential: [nn.Linear: 0.0040706247091293 nn.Linear: 0.0071706399321556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062604584159933 nn.Linear: 0.0646339665872 nn.Linear: 0.045089673940026 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03147292422004 nn.Linear: 0.048953405593657] nn.Sequential: [nn.Linear: 0.031433231742824 nn.Linear: 0.034182568567422]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47794994711876 nn.Linear: 0.22346015274525 nn.Linear: 0.15590108931065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14324110746384 nn.Linear: 0.33165827393532] nn.Sequential: [nn.Linear: 0.097620382905006 nn.Linear: 0.19178211688995]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010159033182985 nn.Linear: 0.00074169221166082 nn.Linear: 0.00044465364767105 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016285311583561 nn.Linear: 0.0020954163751461] nn.Sequential: [nn.Linear: 0.00021710708715561 nn.Linear: 0.0016834531355941]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006004688795656 nn.Linear: 0.010862180031836 nn.Linear: 0.013723216019571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064091524109244 nn.Linear: 0.014066034927964] nn.Sequential: [nn.Linear: 0.0081635406240821 nn.Linear: 0.015638926997781]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062602216803591 nn.Linear: 0.064636951417343 nn.Linear: 0.04509166982383 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031473143012806 nn.Linear: 0.048995872963957] nn.Sequential: [nn.Linear: 0.031433593540826 nn.Linear: 0.034191257142366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47800454497337 nn.Linear: 0.22320978343487 nn.Linear: 0.1563041806221 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14394801855087 nn.Linear: 0.33220839500427] nn.Sequential: [nn.Linear: 0.097884200513363 nn.Linear: 0.19195073843002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018023057812359 nn.Linear: 0.0012737003281035 nn.Linear: 0.00054657668879664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000267149002414 nn.Linear: 0.0042875238267448] nn.Sequential: [nn.Linear: 0.00013734882141238 nn.Linear: 0.0012755373064839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011986275203526 nn.Linear: 0.020182205364108 nn.Linear: 0.018589165061712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099459886550903 nn.Linear: 0.029888667166233] nn.Sequential: [nn.Linear: 0.0047341035678983 nn.Linear: 0.011695543304086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596669792175 nn.Linear: 0.064640080672262 nn.Linear: 0.045092692640938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031473258216207 nn.Linear: 0.048998570178298] nn.Sequential: [nn.Linear: 0.031433824797339 nn.Linear: 0.034205634853017]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47886887192726 nn.Linear: 0.22378182411194 nn.Linear: 0.15642604231834 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14496690034866 nn.Linear: 0.33369112014771] nn.Sequential: [nn.Linear: 0.098144389688969 nn.Linear: 0.19261361658573]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012084522172391 nn.Linear: 0.0007331259890077 nn.Linear: 0.00036075142060132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001499136622127 nn.Linear: 0.0019332416268608] nn.Sequential: [nn.Linear: 0.00012964057887339 nn.Linear: 0.0010531828478282]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081099113449454 nn.Linear: 0.0086115961894393 nn.Linear: 0.0075335679575801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008992075920105 nn.Linear: 0.017186090350151] nn.Sequential: [nn.Linear: 0.0039446405135095 nn.Linear: 0.0092961583286524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596632234939 nn.Linear: 0.064648185150492 nn.Linear: 0.045095207532106 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031473808729935 nn.Linear: 0.049069414634062] nn.Sequential: [nn.Linear: 0.031434229249301 nn.Linear: 0.034235319384592]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47884544730186 nn.Linear: 0.2240094691515 nn.Linear: 0.15637345612049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14588624238968 nn.Linear: 0.33489936590195] nn.Sequential: [nn.Linear: 0.098291024565697 nn.Linear: 0.19382746517658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.003543188569504 nn.Linear: 0.0018798004291746 nn.Linear: 0.00075585607591598 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00037457058358991 nn.Linear: 0.0055492491030402] nn.Sequential: [nn.Linear: 0.00023695142265668 nn.Linear: 0.0020591269384983]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027333041653037 nn.Linear: 0.025260105729103 nn.Linear: 0.013439852744341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017720207571983 nn.Linear: 0.034206435084343] nn.Sequential: [nn.Linear: 0.008198237977922 nn.Linear: 0.022777564823627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	6990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062596510236876 nn.Linear: 0.064653809501265 nn.Linear: 0.045097416118963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031474008596634 nn.Linear: 0.049085359828837] nn.Sequential: [nn.Linear: 0.031434397920489 nn.Linear: 0.034237190505475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47881674766541 nn.Linear: 0.22390088438988 nn.Linear: 0.15641185641289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14673212170601 nn.Linear: 0.33595651388168] nn.Sequential: [nn.Linear: 0.098747558891773 nn.Linear: 0.19400659203529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010680048336185 nn.Linear: 0.0007431410666765 nn.Linear: 0.000485465987713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024686402068614 nn.Linear: 0.003384961627904] nn.Sequential: [nn.Linear: 0.00021682839430447 nn.Linear: 0.0016201421713078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010225110687315 nn.Linear: 0.0098609551787376 nn.Linear: 0.010136486031115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011105791665614 nn.Linear: 0.029219573363662] nn.Sequential: [nn.Linear: 0.009136863052845 nn.Linear: 0.022002212703228]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062598411520476 nn.Linear: 0.064655333250458 nn.Linear: 0.04509928298152 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031474526850154 nn.Linear: 0.049127892189688] nn.Sequential: [nn.Linear: 0.0314347897642 nn.Linear: 0.034269431514547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47942194342613 nn.Linear: 0.22436815500259 nn.Linear: 0.15625992417336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14751589298248 nn.Linear: 0.33627396821976] nn.Sequential: [nn.Linear: 0.099098913371563 nn.Linear: 0.194285556674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00102985249061 nn.Linear: 0.00063538349790628 nn.Linear: 0.00031631806509789 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012431276748164 nn.Linear: 0.0017193112220503] nn.Sequential: [nn.Linear: 0.00011036970785246 nn.Linear: 0.0009027021112851]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064203748479486 nn.Linear: 0.0087866699323058 nn.Linear: 0.011331246234477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085212541744113 nn.Linear: 0.013465993106365] nn.Sequential: [nn.Linear: 0.0042036981321871 nn.Linear: 0.0075079719536006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.093571685835719	TD error	0.019336825564504	Qmax	1	

Steps: 7000000 (frames: 28000000), score: 2107.54, higheset score: 6388, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1811fps, testing time: 89s, testing rate: 5576fps,  num. ep.: 260,  num. rewards: 14749	
   2    8   16    2
   4    2  128    4
  16    4   32  128
   2   16  128  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062601844004742 nn.Linear: 0.064656813874805 nn.Linear: 0.045100117563869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031474670527221 nn.Linear: 0.049130762308884] nn.Sequential: [nn.Linear: 0.031434863096313 nn.Linear: 0.03427174471369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47934478521347 nn.Linear: 0.22439137101173 nn.Linear: 0.15654672682285 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14873097836971 nn.Linear: 0.33709135651588] nn.Sequential: [nn.Linear: 0.099393054842949 nn.Linear: 0.19471289217472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017311295564419 nn.Linear: 0.0011048635907841 nn.Linear: 0.00065515145202187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029198339812272 nn.Linear: 0.004268975954747] nn.Sequential: [nn.Linear: 0.00021111125279993 nn.Linear: 0.0019102622828475]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011056818068027 nn.Linear: 0.021242940798402 nn.Linear: 0.014414120465517 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012634742073715 nn.Linear: 0.034187342971563] nn.Sequential: [nn.Linear: 0.0074812578968704 nn.Linear: 0.023900428786874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062600210916469 nn.Linear: 0.06465979607675 nn.Linear: 0.045102091898992 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03147466369329 nn.Linear: 0.049143163748909] nn.Sequential: [nn.Linear: 0.031435283495158 nn.Linear: 0.034284773227666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.47967627644539 nn.Linear: 0.22479590773582 nn.Linear: 0.15712642669678 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.14924523234367 nn.Linear: 0.33779063820839] nn.Sequential: [nn.Linear: 0.0996925085783 nn.Linear: 0.19486358761787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018711306099325 nn.Linear: 0.0012104699166559 nn.Linear: 0.00074084019492061 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034261588479086 nn.Linear: 0.004564440934161] nn.Sequential: [nn.Linear: 0.00027818835188436 nn.Linear: 0.0020775103625063]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011207698844373 nn.Linear: 0.019042439758778 nn.Linear: 0.021683225408196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015723174437881 nn.Linear: 0.027707731351256] nn.Sequential: [nn.Linear: 0.0061966716311872 nn.Linear: 0.019768416881561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062606303443295 nn.Linear: 0.064670123791413 nn.Linear: 0.04510497738052 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031475250281941 nn.Linear: 0.049202537792183] nn.Sequential: [nn.Linear: 0.031435469867419 nn.Linear: 0.034304099926893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48062515258789 nn.Linear: 0.22542615234852 nn.Linear: 0.15791080892086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15027394890785 nn.Linear: 0.33987951278687] nn.Sequential: [nn.Linear: 0.099987700581551 nn.Linear: 0.19516314566135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002481827841598 nn.Linear: 0.00140670947431 nn.Linear: 0.00069332145662724 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034192120372082 nn.Linear: 0.0051781107596751] nn.Sequential: [nn.Linear: 0.00025024232859447 nn.Linear: 0.0023592922847439]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016489744186401 nn.Linear: 0.018315391615033 nn.Linear: 0.016585176810622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011130408383906 nn.Linear: 0.040465883910656] nn.Sequential: [nn.Linear: 0.0085206897929311 nn.Linear: 0.030507212504745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06260527864707 nn.Linear: 0.064671894843817 nn.Linear: 0.045105484266426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031475662657025 nn.Linear: 0.049245007281058] nn.Sequential: [nn.Linear: 0.031435307566889 nn.Linear: 0.034295134917783]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48096546530724 nn.Linear: 0.22606632113457 nn.Linear: 0.15809193253517 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.151024132967 nn.Linear: 0.34008687734604] nn.Sequential: [nn.Linear: 0.10008635371923 nn.Linear: 0.19534350931644]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012954912258674 nn.Linear: 0.00074426276689241 nn.Linear: 0.00037348725513106 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014194289645106 nn.Linear: 0.0016918579760721] nn.Sequential: [nn.Linear: 0.00015880352116676 nn.Linear: 0.0012094874727226]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081566870212555 nn.Linear: 0.015920549631119 nn.Linear: 0.0076121655292809 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0043489201925695 nn.Linear: 0.016182024031878] nn.Sequential: [nn.Linear: 0.0048413285985589 nn.Linear: 0.010098640806973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0626154114116 nn.Linear: 0.064679188442568 nn.Linear: 0.045107779826286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031475985359016 nn.Linear: 0.049287926513298] nn.Sequential: [nn.Linear: 0.031435877043489 nn.Linear: 0.034326874056474]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48048734664917 nn.Linear: 0.22641840577126 nn.Linear: 0.15880031883717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15228062868118 nn.Linear: 0.34176030755043] nn.Sequential: [nn.Linear: 0.10032051801682 nn.Linear: 0.19556467235088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016084197466457 nn.Linear: 0.00099495975922097 nn.Linear: 0.00053622383523772 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026443669557007 nn.Linear: 0.0041876375340371] nn.Sequential: [nn.Linear: 0.000149782657742 nn.Linear: 0.0012574919342358]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013985266909003 nn.Linear: 0.018381403759122 nn.Linear: 0.02164120785892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011943749152124 nn.Linear: 0.028334349393845] nn.Sequential: [nn.Linear: 0.0042758830823004 nn.Linear: 0.012964564375579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062615979559823 nn.Linear: 0.0646842028046 nn.Linear: 0.045109544842639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031476293289909 nn.Linear: 0.049282046263457] nn.Sequential: [nn.Linear: 0.031436159541898 nn.Linear: 0.034343535827395]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48102295398712 nn.Linear: 0.22607119381428 nn.Linear: 0.15959000587463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15279780328274 nn.Linear: 0.34286299347878] nn.Sequential: [nn.Linear: 0.10058854520321 nn.Linear: 0.19585700333118]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092453045373166 nn.Linear: 0.00075914770036289 nn.Linear: 0.00047784607555738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023036022155803 nn.Linear: 0.0033814358577176] nn.Sequential: [nn.Linear: 0.00016889175889751 nn.Linear: 0.0012821325893724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057643726468086 nn.Linear: 0.012859587557614 nn.Linear: 0.013013172894716 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013253473676741 nn.Linear: 0.021708387881517] nn.Sequential: [nn.Linear: 0.0053208889439702 nn.Linear: 0.013080432079732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06261989115299 nn.Linear: 0.064691706834003 nn.Linear: 0.045112523195266 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031477051131684 nn.Linear: 0.049388384409696] nn.Sequential: [nn.Linear: 0.031436577130487 nn.Linear: 0.034357807327814]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48171520233154 nn.Linear: 0.2271663248539 nn.Linear: 0.16015011072159 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15408183634281 nn.Linear: 0.34378454089165] nn.Sequential: [nn.Linear: 0.10076021403074 nn.Linear: 0.19680190086365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013990312568062 nn.Linear: 0.00082582641581468 nn.Linear: 0.0004084824703537 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014314805176551 nn.Linear: 0.0014819651973532] nn.Sequential: [nn.Linear: 0.00013234002448651 nn.Linear: 0.00092384986174961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087643032893538 nn.Linear: 0.011407831683755 nn.Linear: 0.010986278764904 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01055261772126 nn.Linear: 0.011233410798013] nn.Sequential: [nn.Linear: 0.0038701430894434 nn.Linear: 0.0090057281777263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062623479902927 nn.Linear: 0.06469318054142 nn.Linear: 0.045112930347693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031477216582272 nn.Linear: 0.049419117556965] nn.Sequential: [nn.Linear: 0.031436483837945 nn.Linear: 0.034359962109125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48135679960251 nn.Linear: 0.22680257260799 nn.Linear: 0.15908406674862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15467867255211 nn.Linear: 0.34412676095963] nn.Sequential: [nn.Linear: 0.10115543752909 nn.Linear: 0.19685061275959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0043181498401573 nn.Linear: 0.0023944720471672 nn.Linear: 0.00094592971837369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00043516416748361 nn.Linear: 0.0065220766531584] nn.Sequential: [nn.Linear: 0.00022906053711483 nn.Linear: 0.001450426966184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027308568358421 nn.Linear: 0.038461480289698 nn.Linear: 0.026929764077067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014372749254107 nn.Linear: 0.039597757160664] nn.Sequential: [nn.Linear: 0.010746373794973 nn.Linear: 0.012835127301514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062622548985213 nn.Linear: 0.064697856049745 nn.Linear: 0.045114242352967 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031477515955398 nn.Linear: 0.04944038956242] nn.Sequential: [nn.Linear: 0.031436694069804 nn.Linear: 0.034381500262817]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48166784644127 nn.Linear: 0.22676403820515 nn.Linear: 0.1603065431118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1556313931942 nn.Linear: 0.34523871541023] nn.Sequential: [nn.Linear: 0.10143492370844 nn.Linear: 0.19745020568371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021835807827344 nn.Linear: 0.0012107783110558 nn.Linear: 0.00060323291688839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021261192516454 nn.Linear: 0.0025148031834181] nn.Sequential: [nn.Linear: 0.0001984582662921 nn.Linear: 0.0013226970991646]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012388247996569 nn.Linear: 0.014606133103371 nn.Linear: 0.010407360270619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0078695099800825 nn.Linear: 0.016820611432195] nn.Sequential: [nn.Linear: 0.0068078660406172 nn.Linear: 0.013934752903879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062627130722896 nn.Linear: 0.064705908305755 nn.Linear: 0.045117130497038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03147761410639 nn.Linear: 0.049471483276676] nn.Sequential: [nn.Linear: 0.031437008837078 nn.Linear: 0.03441365065833]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48227629065514 nn.Linear: 0.22693492472172 nn.Linear: 0.16094088554382 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15622791647911 nn.Linear: 0.34672492742538] nn.Sequential: [nn.Linear: 0.10137163102627 nn.Linear: 0.19781601428986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015640323451386 nn.Linear: 0.00081102940855791 nn.Linear: 0.00041456138729094 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021989518135477 nn.Linear: 0.003040695784867] nn.Sequential: [nn.Linear: 0.00014757920147077 nn.Linear: 0.0011906229183019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013032310642302 nn.Linear: 0.012373186647892 nn.Linear: 0.012630729936063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096563864499331 nn.Linear: 0.030779328197241] nn.Sequential: [nn.Linear: 0.0049610962159932 nn.Linear: 0.0163529869169]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062635737219282 nn.Linear: 0.064719976060794 nn.Linear: 0.045121763506127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031478390764148 nn.Linear: 0.049576209784675] nn.Sequential: [nn.Linear: 0.031437746260297 nn.Linear: 0.034434268285239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48241007328033 nn.Linear: 0.22681176662445 nn.Linear: 0.16121631860733 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15759392082691 nn.Linear: 0.34873193502426] nn.Sequential: [nn.Linear: 0.10174365341663 nn.Linear: 0.19837462902069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022375595134527 nn.Linear: 0.0010316282156862 nn.Linear: 0.00044496239491839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012662041625679 nn.Linear: 0.0011910552984165] nn.Sequential: [nn.Linear: 0.00015795489430511 nn.Linear: 0.0010650900383992]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015531031414866 nn.Linear: 0.015571500174701 nn.Linear: 0.011758103966713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058811707422137 nn.Linear: 0.0069317650049925] nn.Sequential: [nn.Linear: 0.004525130148977 nn.Linear: 0.010441144928336]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062641874610729 nn.Linear: 0.064726456379431 nn.Linear: 0.045123777879552 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03147887398736 nn.Linear: 0.049623011505219] nn.Sequential: [nn.Linear: 0.03143805194485 nn.Linear: 0.034445903633768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48207071423531 nn.Linear: 0.2271720468998 nn.Linear: 0.16169418394566 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15894278883934 nn.Linear: 0.35014948248863] nn.Sequential: [nn.Linear: 0.10187390446663 nn.Linear: 0.19880440831184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019744469850831 nn.Linear: 0.00098587536312524 nn.Linear: 0.00038531915802781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019405642145353 nn.Linear: 0.0028631691311225] nn.Sequential: [nn.Linear: 9.9706672129368e-05 nn.Linear: 0.00066372500057318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012536646798253 nn.Linear: 0.019899662584066 nn.Linear: 0.029539659619331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087912725284696 nn.Linear: 0.023006217554212] nn.Sequential: [nn.Linear: 0.0042429766617715 nn.Linear: 0.0062830583192408]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062644305805263 nn.Linear: 0.064731179505344 nn.Linear: 0.045125430331291 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031479499999629 nn.Linear: 0.049669072505203] nn.Sequential: [nn.Linear: 0.031438267345189 nn.Linear: 0.034476340943188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48284184932709 nn.Linear: 0.22785851359367 nn.Linear: 0.16168762743473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.15999110043049 nn.Linear: 0.35088574886322] nn.Sequential: [nn.Linear: 0.10192612558603 nn.Linear: 0.19888743758202]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025616416596662 nn.Linear: 0.0016194557879964 nn.Linear: 0.00068230099313068 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026089203878014 nn.Linear: 0.0035994318231769] nn.Sequential: [nn.Linear: 0.00018723414535713 nn.Linear: 0.0014097731565292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016549877822399 nn.Linear: 0.029308427125216 nn.Linear: 0.015042215585709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017222858965397 nn.Linear: 0.033603347837925] nn.Sequential: [nn.Linear: 0.0087202033028007 nn.Linear: 0.018061881884933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636507994697 nn.Linear: 0.064732730762973 nn.Linear: 0.045126897835933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031479720554967 nn.Linear: 0.049675588103185] nn.Sequential: [nn.Linear: 0.031438470300389 nn.Linear: 0.03448469598452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48314756155014 nn.Linear: 0.22839118540287 nn.Linear: 0.16239611804485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16103801131248 nn.Linear: 0.35174611210823] nn.Sequential: [nn.Linear: 0.10239742696285 nn.Linear: 0.19922162592411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076952326688998 nn.Linear: 0.00048659984862305 nn.Linear: 0.00030360997511339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015507210569592 nn.Linear: 0.002140665693027] nn.Sequential: [nn.Linear: 0.00012522393539149 nn.Linear: 0.0009676394938622]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048279990442097 nn.Linear: 0.0058669494464993 nn.Linear: 0.0076056262478232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064446851611137 nn.Linear: 0.016788182780147] nn.Sequential: [nn.Linear: 0.0031229229643941 nn.Linear: 0.011078129522502]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636850613681 nn.Linear: 0.064737891058645 nn.Linear: 0.045129691550582 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031480045126737 nn.Linear: 0.049697823940647] nn.Sequential: [nn.Linear: 0.031438835668729 nn.Linear: 0.034498072052532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48370137810707 nn.Linear: 0.22839790582657 nn.Linear: 0.16307723522186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16255377233028 nn.Linear: 0.35280555486679] nn.Sequential: [nn.Linear: 0.10266606509686 nn.Linear: 0.1995667219162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0049091805411487 nn.Linear: 0.0029574873352003 nn.Linear: 0.0012689377578813 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00050551997937507 nn.Linear: 0.007065739649708] nn.Sequential: [nn.Linear: 0.00042668018437954 nn.Linear: 0.0042693943634511]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.034922800958157 nn.Linear: 0.05083741620183 nn.Linear: 0.03377528488636 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.029168076813221 nn.Linear: 0.065867148339748] nn.Sequential: [nn.Linear: 0.018084648996592 nn.Linear: 0.065300174057484]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629939639734 nn.Linear: 0.064741043240867 nn.Linear: 0.045129631065575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031480192194493 nn.Linear: 0.049710351762883] nn.Sequential: [nn.Linear: 0.03143880857308 nn.Linear: 0.034511399036596]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48411798477173 nn.Linear: 0.22808130085468 nn.Linear: 0.16260923445225 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16298845410347 nn.Linear: 0.35380452871323] nn.Sequential: [nn.Linear: 0.10286720842123 nn.Linear: 0.19989797472954]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027242311778049 nn.Linear: 0.0012909680635111 nn.Linear: 0.00051400989566707 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016221854681136 nn.Linear: 0.0015289349966832] nn.Sequential: [nn.Linear: 0.000177072269925 nn.Linear: 0.0014635187751081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021066347137094 nn.Linear: 0.025498075410724 nn.Linear: 0.017571773380041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012487636879086 nn.Linear: 0.011926827952266] nn.Sequential: [nn.Linear: 0.0059095984324813 nn.Linear: 0.014904687181115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062625220566157 nn.Linear: 0.064745093300262 nn.Linear: 0.045131187464651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03148056439424 nn.Linear: 0.049745174264956] nn.Sequential: [nn.Linear: 0.031439118180968 nn.Linear: 0.034524271330383]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4841037094593 nn.Linear: 0.22854314744473 nn.Linear: 0.16273698210716 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16421362757683 nn.Linear: 0.35489976406097] nn.Sequential: [nn.Linear: 0.10296016931534 nn.Linear: 0.19997224211693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.000896080891217 nn.Linear: 0.00065971398598597 nn.Linear: 0.0003742887483232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016839259966557 nn.Linear: 0.0025558200022973] nn.Sequential: [nn.Linear: 0.000177374392104 nn.Linear: 0.0015854948487591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064651719294488 nn.Linear: 0.0093548856675625 nn.Linear: 0.0065640448592603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081105455756187 nn.Linear: 0.018176721408963] nn.Sequential: [nn.Linear: 0.0068320408463478 nn.Linear: 0.018973719328642]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062632466309482 nn.Linear: 0.064748116691093 nn.Linear: 0.045132351097242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031480877234841 nn.Linear: 0.049768713703941] nn.Sequential: [nn.Linear: 0.031439454492577 nn.Linear: 0.034549929031659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48485428094864 nn.Linear: 0.22873215377331 nn.Linear: 0.16310389339924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1649968624115 nn.Linear: 0.35591971874237] nn.Sequential: [nn.Linear: 0.10322677344084 nn.Linear: 0.19993880391121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010299088814939 nn.Linear: 0.00068089095530414 nn.Linear: 0.00041472546908555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014645755225524 nn.Linear: 0.0017272792047776] nn.Sequential: [nn.Linear: 0.00017879432593911 nn.Linear: 0.0014058733727968]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078535005450249 nn.Linear: 0.0086448704823852 nn.Linear: 0.015026579611003 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073357471264899 nn.Linear: 0.012717700563371] nn.Sequential: [nn.Linear: 0.009091486223042 nn.Linear: 0.018043356016278]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634828678561 nn.Linear: 0.06475477301306 nn.Linear: 0.045133952907654 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031481099979118 nn.Linear: 0.049790809236754] nn.Sequential: [nn.Linear: 0.031439609039627 nn.Linear: 0.034552878208777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48532176017761 nn.Linear: 0.22926071286201 nn.Linear: 0.16388362646103 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16633833944798 nn.Linear: 0.3580159842968] nn.Sequential: [nn.Linear: 0.10359116643667 nn.Linear: 0.20044699311256]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011265686658053 nn.Linear: 0.00076025693590459 nn.Linear: 0.00038768619773829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019678293786842 nn.Linear: 0.0031566089338919] nn.Sequential: [nn.Linear: 0.00016598813214294 nn.Linear: 0.0017070924155178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010320661589503 nn.Linear: 0.015431479550898 nn.Linear: 0.007467464543879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088333366438746 nn.Linear: 0.023578893393278] nn.Sequential: [nn.Linear: 0.0055877356790006 nn.Linear: 0.018086329102516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062642444409214 nn.Linear: 0.064760203685885 nn.Linear: 0.045136406107645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031481501233925 nn.Linear: 0.04983316580433] nn.Sequential: [nn.Linear: 0.031439918107956 nn.Linear: 0.034564247404335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48538452386856 nn.Linear: 0.22972041368484 nn.Linear: 0.16396479308605 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16708935797215 nn.Linear: 0.35925185680389] nn.Sequential: [nn.Linear: 0.1039909273386 nn.Linear: 0.20066040754318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018263293001723 nn.Linear: 0.0012908077347529 nn.Linear: 0.00056564068559603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016123952112731 nn.Linear: 0.0019899740638888] nn.Sequential: [nn.Linear: 0.00023046883939269 nn.Linear: 0.0019706672468943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012425538152456 nn.Linear: 0.022693127393723 nn.Linear: 0.015130656771362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084292721003294 nn.Linear: 0.020658645778894] nn.Sequential: [nn.Linear: 0.0083538834005594 nn.Linear: 0.023096973076463]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062646863647351 nn.Linear: 0.064766747348221 nn.Linear: 0.045137888136265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031481824061922 nn.Linear: 0.049864208789813] nn.Sequential: [nn.Linear: 0.031440233578846 nn.Linear: 0.034584262072254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48532792925835 nn.Linear: 0.22902294993401 nn.Linear: 0.16450694203377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16777592897415 nn.Linear: 0.36021944880486] nn.Sequential: [nn.Linear: 0.10409139096737 nn.Linear: 0.20129257440567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013884775749287 nn.Linear: 0.00082218056459005 nn.Linear: 0.00052672502179866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018576118837475 nn.Linear: 0.0018841845651885] nn.Sequential: [nn.Linear: 0.00018875785231751 nn.Linear: 0.0015172811278038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011345913633704 nn.Linear: 0.015805749222636 nn.Linear: 0.0082230446860194 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011463664472103 nn.Linear: 0.015689540654421] nn.Sequential: [nn.Linear: 0.005542382132262 nn.Linear: 0.014438251033425]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062649315382001 nn.Linear: 0.064769943188995 nn.Linear: 0.045138600736362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031482063451584 nn.Linear: 0.04991750704616] nn.Sequential: [nn.Linear: 0.031440194128222 nn.Linear: 0.034573611014141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48526084423065 nn.Linear: 0.22947530448437 nn.Linear: 0.1638291478157 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1682692617178 nn.Linear: 0.3609012067318] nn.Sequential: [nn.Linear: 0.10460387170315 nn.Linear: 0.20140385627747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026711742831027 nn.Linear: 0.0014530036498115 nn.Linear: 0.00064089613977063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023197509282461 nn.Linear: 0.0025997613216387] nn.Sequential: [nn.Linear: 0.00019690918895405 nn.Linear: 0.001531131448628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016185987740755 nn.Linear: 0.023569218814373 nn.Linear: 0.018287427723408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013947371393442 nn.Linear: 0.030584318563342] nn.Sequential: [nn.Linear: 0.007207443471998 nn.Linear: 0.016524944454432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062651746365739 nn.Linear: 0.064776548584465 nn.Linear: 0.045141185716666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031482433837099 nn.Linear: 0.049982373096896] nn.Sequential: [nn.Linear: 0.031440502434567 nn.Linear: 0.034601758800537]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48541676998138 nn.Linear: 0.22898794710636 nn.Linear: 0.16482846438885 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.16979040205479 nn.Linear: 0.36233371496201] nn.Sequential: [nn.Linear: 0.10496064275503 nn.Linear: 0.20173211395741]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010918457928906 nn.Linear: 0.00078410620067759 nn.Linear: 0.0003938078684782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015238751319214 nn.Linear: 0.0017661525273407] nn.Sequential: [nn.Linear: 0.00012802623375952 nn.Linear: 0.00077469313581661]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074222786352038 nn.Linear: 0.011233875527978 nn.Linear: 0.011498656123877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070361299440265 nn.Linear: 0.017852945253253] nn.Sequential: [nn.Linear: 0.0040138196200132 nn.Linear: 0.0079509718343616]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062653901292008 nn.Linear: 0.064783798128302 nn.Linear: 0.045142873825892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031482785435749 nn.Linear: 0.050028367057585] nn.Sequential: [nn.Linear: 0.031440789023749 nn.Linear: 0.034613724818279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48598837852478 nn.Linear: 0.22910219430923 nn.Linear: 0.1650814563036 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17009560763836 nn.Linear: 0.36311739683151] nn.Sequential: [nn.Linear: 0.10531754791737 nn.Linear: 0.20276595652103]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019764244500915 nn.Linear: 0.00097318319279029 nn.Linear: 0.00047027281077602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019572584358686 nn.Linear: 0.0025317315379891] nn.Sequential: [nn.Linear: 0.0001440883138567 nn.Linear: 0.0010730812607826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013425886631012 nn.Linear: 0.017343688756227 nn.Linear: 0.01831129938364 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081335697323084 nn.Linear: 0.01423776615411] nn.Sequential: [nn.Linear: 0.0035062294919044 nn.Linear: 0.010075187310576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062648235194672 nn.Linear: 0.064788476943255 nn.Linear: 0.045144463236832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031483079753722 nn.Linear: 0.050056646463247] nn.Sequential: [nn.Linear: 0.0314410657791 nn.Linear: 0.034618848791052]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48667851090431 nn.Linear: 0.228919968009 nn.Linear: 0.16609960794449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17113153636456 nn.Linear: 0.36378821730614] nn.Sequential: [nn.Linear: 0.10567615181208 nn.Linear: 0.20286585390568]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016081165554383 nn.Linear: 0.00093371927799564 nn.Linear: 0.00059027876349496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024835973359996 nn.Linear: 0.0034704329832578] nn.Sequential: [nn.Linear: 0.00021224316378454 nn.Linear: 0.0016484427205405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010614635422826 nn.Linear: 0.016916576772928 nn.Linear: 0.013614912517369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099752824753523 nn.Linear: 0.020280126482248] nn.Sequential: [nn.Linear: 0.0054656602442265 nn.Linear: 0.011758144013584]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.079200311928988	TD error	0.01864731445536	Qmax	1	

Steps: 7250000 (frames: 29000000), score: 1706.33, higheset score: 6532, epsilon: 0.05, lr: 0.0005, training time: 552s, training rate: 1810fps, testing time: 90s, testing rate: 5554fps,  num. ep.: 414,  num. rewards: 17540	
   2    4   16    4
   4   64   32   16
   8  256   64    8
  16    4   16  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643351075597 nn.Linear: 0.064789838005443 nn.Linear: 0.045145364228894 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031483416177528 nn.Linear: 0.050061826565866] nn.Sequential: [nn.Linear: 0.031441149963956 nn.Linear: 0.034628189786813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48738417029381 nn.Linear: 0.22847817838192 nn.Linear: 0.1656100153923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17204068601131 nn.Linear: 0.36465272307396] nn.Sequential: [nn.Linear: 0.10579177737236 nn.Linear: 0.20291149616241]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002071577189824 nn.Linear: 0.0010837550191219 nn.Linear: 0.00053724858434038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020750415393924 nn.Linear: 0.0026811155571458] nn.Sequential: [nn.Linear: 0.00017647883127819 nn.Linear: 0.0013801127653654]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013531465083361 nn.Linear: 0.015383183024824 nn.Linear: 0.015903605148196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010010827332735 nn.Linear: 0.024607323110104] nn.Sequential: [nn.Linear: 0.0056781335733831 nn.Linear: 0.01565345749259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643605995414 nn.Linear: 0.064793251200643 nn.Linear: 0.045146377311728 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031483863621572 nn.Linear: 0.05010293689449] nn.Sequential: [nn.Linear: 0.031441406817957 nn.Linear: 0.034642251960201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48795667290688 nn.Linear: 0.22841249406338 nn.Linear: 0.16546627879143 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17307007312775 nn.Linear: 0.36562716960907] nn.Sequential: [nn.Linear: 0.10600302368402 nn.Linear: 0.20336444675922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016375721796161 nn.Linear: 0.0010370238210824 nn.Linear: 0.00045965257624066 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016752759841903 nn.Linear: 0.0020872445969626] nn.Sequential: [nn.Linear: 0.00015827553634981 nn.Linear: 0.0011331056096375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012786841019988 nn.Linear: 0.017300151288509 nn.Linear: 0.011545677669346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077052423730493 nn.Linear: 0.015962203964591] nn.Sequential: [nn.Linear: 0.009515417739749 nn.Linear: 0.011168182827532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636989548129 nn.Linear: 0.064793501208136 nn.Linear: 0.045148259586232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03148440773246 nn.Linear: 0.050147188890008] nn.Sequential: [nn.Linear: 0.031441610108828 nn.Linear: 0.03465759569742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48844969272614 nn.Linear: 0.22929038107395 nn.Linear: 0.16576954722404 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17366795241833 nn.Linear: 0.36677065491676] nn.Sequential: [nn.Linear: 0.10610100626945 nn.Linear: 0.20349927246571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022324901729708 nn.Linear: 0.0016109685874609 nn.Linear: 0.00086234222721295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0004115555008868 nn.Linear: 0.0058591945944828] nn.Sequential: [nn.Linear: 0.0003166492910252 nn.Linear: 0.002759152414875]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014705490320921 nn.Linear: 0.019576525315642 nn.Linear: 0.014447039924562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015035173855722 nn.Linear: 0.039414715021849] nn.Sequential: [nn.Linear: 0.009243723936379 nn.Linear: 0.025181179866195]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062626710060871 nn.Linear: 0.064795715625669 nn.Linear: 0.045148880128547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031484265326848 nn.Linear: 0.050126368975242] nn.Sequential: [nn.Linear: 0.031441879619341 nn.Linear: 0.034667677091074]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48845088481903 nn.Linear: 0.22980783879757 nn.Linear: 0.16564098000526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17433553934097 nn.Linear: 0.36739882826805] nn.Sequential: [nn.Linear: 0.10611429065466 nn.Linear: 0.20381461083889]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00087564139266512 nn.Linear: 0.00052369823487902 nn.Linear: 0.00031403339798334 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014573786348422 nn.Linear: 0.0016400660335782] nn.Sequential: [nn.Linear: 0.00012889091577643 nn.Linear: 0.0008721157900922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067839622497559 nn.Linear: 0.0059095029719174 nn.Linear: 0.005985030438751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059175649657845 nn.Linear: 0.014795466326177] nn.Sequential: [nn.Linear: 0.0037810509093106 nn.Linear: 0.0080849034711719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062620560484066 nn.Linear: 0.064799616083514 nn.Linear: 0.045150047008266 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03148471759767 nn.Linear: 0.05013866165217] nn.Sequential: [nn.Linear: 0.031441983847327 nn.Linear: 0.034677188605571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48913839459419 nn.Linear: 0.230154722929 nn.Linear: 0.16631063818932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17528723180294 nn.Linear: 0.36836212873459] nn.Sequential: [nn.Linear: 0.10637295246124 nn.Linear: 0.20418314635754]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010235482276937 nn.Linear: 0.00057809119532911 nn.Linear: 0.0003392993892887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012400616531384 nn.Linear: 0.0013598886214609] nn.Sequential: [nn.Linear: 0.00016664671238033 nn.Linear: 0.0013281898804816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076647088862956 nn.Linear: 0.0099959960207343 nn.Linear: 0.0090816468000412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096739744767547 nn.Linear: 0.0088570741936564] nn.Sequential: [nn.Linear: 0.00969965942204 nn.Linear: 0.016173582524061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062629536208674 nn.Linear: 0.064806688547391 nn.Linear: 0.045152554113758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031485164452057 nn.Linear: 0.050197873453648] nn.Sequential: [nn.Linear: 0.031442248322956 nn.Linear: 0.034687107773932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48964008688927 nn.Linear: 0.23030130565166 nn.Linear: 0.16597977280617 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17591652274132 nn.Linear: 0.36915922164917] nn.Sequential: [nn.Linear: 0.10659193247557 nn.Linear: 0.20445619523525]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016496480750892 nn.Linear: 0.0010286147870454 nn.Linear: 0.00045497649847867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019789328435565 nn.Linear: 0.0027028904522716] nn.Sequential: [nn.Linear: 0.00013426702806042 nn.Linear: 0.0010119807448081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015123497694731 nn.Linear: 0.015801591798663 nn.Linear: 0.019387429580092 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071573918685317 nn.Linear: 0.021901721134782] nn.Sequential: [nn.Linear: 0.0044253682717681 nn.Linear: 0.010979074984789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062624774594136 nn.Linear: 0.064810874114209 nn.Linear: 0.045155384629017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031485485573928 nn.Linear: 0.050228854439531] nn.Sequential: [nn.Linear: 0.031442582538813 nn.Linear: 0.034699563742045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.48952174186707 nn.Linear: 0.23014555871487 nn.Linear: 0.16641336679459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17672121524811 nn.Linear: 0.3701229095459] nn.Sequential: [nn.Linear: 0.10701905936003 nn.Linear: 0.20522114634514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010047032380358 nn.Linear: 0.00056766523936827 nn.Linear: 0.00029831864265682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012351586779069 nn.Linear: 0.0014231664388769] nn.Sequential: [nn.Linear: 0.0001168966944877 nn.Linear: 0.00082393352358577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062898397445679 nn.Linear: 0.0067460001446307 nn.Linear: 0.005190865136683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049147955141962 nn.Linear: 0.0082955555990338] nn.Sequential: [nn.Linear: 0.0039881188422441 nn.Linear: 0.0098602063953876]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062623831128935 nn.Linear: 0.064813434121437 nn.Linear: 0.045156559317115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031486184459375 nn.Linear: 0.050298884311177] nn.Sequential: [nn.Linear: 0.031442544633637 nn.Linear: 0.034720723813246]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4898721575737 nn.Linear: 0.2302334010601 nn.Linear: 0.16606613993645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17784896492958 nn.Linear: 0.37144160270691] nn.Sequential: [nn.Linear: 0.10759226977825 nn.Linear: 0.20586329698563]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017589225492177 nn.Linear: 0.00095023721073411 nn.Linear: 0.00043499384402028 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015569785521848 nn.Linear: 0.0017888460152758] nn.Sequential: [nn.Linear: 0.00014674829011128 nn.Linear: 0.0011820050717349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01268374081701 nn.Linear: 0.014213876798749 nn.Linear: 0.012941626831889 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013533954508603 nn.Linear: 0.013356211595237] nn.Sequential: [nn.Linear: 0.0078750140964985 nn.Linear: 0.015417425893247]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062625276381002 nn.Linear: 0.064818177237489 nn.Linear: 0.045159322916522 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031486903781635 nn.Linear: 0.050365297874926] nn.Sequential: [nn.Linear: 0.031442753059783 nn.Linear: 0.034731556865342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.489855915308 nn.Linear: 0.23043420910835 nn.Linear: 0.16657534241676 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17847616970539 nn.Linear: 0.3728039264679] nn.Sequential: [nn.Linear: 0.10768691450357 nn.Linear: 0.20619951188564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0005442000865319 nn.Linear: 0.00036385935056381 nn.Linear: 0.00023637899304286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010654597741386 nn.Linear: 0.0012750538138975] nn.Sequential: [nn.Linear: 0.00010284137995321 nn.Linear: 0.00081431425167465]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0041791135445237 nn.Linear: 0.0053949793800712 nn.Linear: 0.0055001201108098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035739920567721 nn.Linear: 0.0098101161420345] nn.Sequential: [nn.Linear: 0.0027598186861724 nn.Linear: 0.0084190890192986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634534005938 nn.Linear: 0.064821629839411 nn.Linear: 0.045160348035172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031486924668986 nn.Linear: 0.050386645448032] nn.Sequential: [nn.Linear: 0.031442900328527 nn.Linear: 0.034737506509249]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4899083673954 nn.Linear: 0.23077014088631 nn.Linear: 0.166359141469 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17915767431259 nn.Linear: 0.37351056933403] nn.Sequential: [nn.Linear: 0.10777252167463 nn.Linear: 0.20628720521927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094332357663702 nn.Linear: 0.00062364540281956 nn.Linear: 0.00037322286797297 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015550447391965 nn.Linear: 0.0019645562360619] nn.Sequential: [nn.Linear: 0.00014172529047092 nn.Linear: 0.0011508472361639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005445116199553 nn.Linear: 0.0081411115825176 nn.Linear: 0.009296496398747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064650326967239 nn.Linear: 0.012067575007677] nn.Sequential: [nn.Linear: 0.0036620912142098 nn.Linear: 0.012008897960186]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06263265923392 nn.Linear: 0.064827282234923 nn.Linear: 0.045162288683427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031487143579047 nn.Linear: 0.050406270748113] nn.Sequential: [nn.Linear: 0.031443458788837 nn.Linear: 0.034757688639909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49072191119194 nn.Linear: 0.23041914403439 nn.Linear: 0.16658428311348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.17979365587234 nn.Linear: 0.37489408254623] nn.Sequential: [nn.Linear: 0.10812500119209 nn.Linear: 0.20694844424725]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013812816151433 nn.Linear: 0.00094790508921743 nn.Linear: 0.00047739296206734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016727919540511 nn.Linear: 0.0018696906287441] nn.Sequential: [nn.Linear: 0.00020745725492564 nn.Linear: 0.0018033142618717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092278495430946 nn.Linear: 0.014157000929117 nn.Linear: 0.010524814017117 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077687259763479 nn.Linear: 0.013467238284647] nn.Sequential: [nn.Linear: 0.0064090136438608 nn.Linear: 0.022325469180942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634887094719 nn.Linear: 0.064830669051679 nn.Linear: 0.045164204422068 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031487599495241 nn.Linear: 0.0504434570326] nn.Sequential: [nn.Linear: 0.031443631986654 nn.Linear: 0.034772914735693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49134373664856 nn.Linear: 0.23082087934017 nn.Linear: 0.16704222559929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.180768892169 nn.Linear: 0.37602293491364] nn.Sequential: [nn.Linear: 0.10847425460815 nn.Linear: 0.20742376148701]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0032274603837802 nn.Linear: 0.0016531446966037 nn.Linear: 0.0007716435833346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023317364509064 nn.Linear: 0.0028944147420519] nn.Sequential: [nn.Linear: 0.00028944071127676 nn.Linear: 0.0023841958928777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018116872757673 nn.Linear: 0.035048838704824 nn.Linear: 0.028580199927092 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020105578005314 nn.Linear: 0.033768013119698] nn.Sequential: [nn.Linear: 0.01619540899992 nn.Linear: 0.031273271888494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062640571953883 nn.Linear: 0.064834992822334 nn.Linear: 0.045165200962102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031487966792756 nn.Linear: 0.05046598862765] nn.Sequential: [nn.Linear: 0.031443812811575 nn.Linear: 0.034789774329678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49113765358925 nn.Linear: 0.23087832331657 nn.Linear: 0.16698408126831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18205215036869 nn.Linear: 0.37678226828575] nn.Sequential: [nn.Linear: 0.1086008399725 nn.Linear: 0.20731988549232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022941567608695 nn.Linear: 0.0012786161111733 nn.Linear: 0.00059820758203796 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020981815960336 nn.Linear: 0.0022309753468406] nn.Sequential: [nn.Linear: 0.00023478184413548 nn.Linear: 0.0017856043834056]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01387104857713 nn.Linear: 0.017383050173521 nn.Linear: 0.014795641414821 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089653506875038 nn.Linear: 0.014510604552925] nn.Sequential: [nn.Linear: 0.0072533753700554 nn.Linear: 0.023591993376613]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062643322763478 nn.Linear: 0.064841643870758 nn.Linear: 0.045168843854564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031488332055169 nn.Linear: 0.050488102943973] nn.Sequential: [nn.Linear: 0.031444176679771 nn.Linear: 0.034810708894582]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49199056625366 nn.Linear: 0.23090022802353 nn.Linear: 0.16679622232914 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18306902050972 nn.Linear: 0.37806326150894] nn.Sequential: [nn.Linear: 0.10895101726055 nn.Linear: 0.20791125297546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012995297285177 nn.Linear: 0.00075560799222819 nn.Linear: 0.00039885954284375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014244677820712 nn.Linear: 0.0017088859135383] nn.Sequential: [nn.Linear: 0.00016576974865193 nn.Linear: 0.0012820013113106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079778227955103 nn.Linear: 0.010741432197392 nn.Linear: 0.0091124940663576 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058207311667502 nn.Linear: 0.011288026347756] nn.Sequential: [nn.Linear: 0.0053665502928197 nn.Linear: 0.013386460021138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062640163884613 nn.Linear: 0.064844745606572 nn.Linear: 0.045171098931769 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031488633504029 nn.Linear: 0.050532156858111] nn.Sequential: [nn.Linear: 0.031444427364771 nn.Linear: 0.034825812536413]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49199447035789 nn.Linear: 0.23121407628059 nn.Linear: 0.16748175024986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18377344310284 nn.Linear: 0.37952971458435] nn.Sequential: [nn.Linear: 0.10918744653463 nn.Linear: 0.20848643779755]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013374683064879 nn.Linear: 0.00072219516892263 nn.Linear: 0.00037000784638498 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000135039669252 nn.Linear: 0.001378425591363] nn.Sequential: [nn.Linear: 0.00017777854449087 nn.Linear: 0.0017487048200583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00954351387918 nn.Linear: 0.011014675721526 nn.Linear: 0.0073972065001726 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086117209866643 nn.Linear: 0.0093047190457582] nn.Sequential: [nn.Linear: 0.0073901866562665 nn.Linear: 0.022275699302554]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062636677088554 nn.Linear: 0.064852864507562 nn.Linear: 0.045173134306747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031488984180945 nn.Linear: 0.050589511733335] nn.Sequential: [nn.Linear: 0.031444678202184 nn.Linear: 0.034827578936159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49176448583603 nn.Linear: 0.23166745901108 nn.Linear: 0.16774152219296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18474377691746 nn.Linear: 0.38071444630623] nn.Sequential: [nn.Linear: 0.1095756739378 nn.Linear: 0.20878551900387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021834910494918 nn.Linear: 0.0013344100829415 nn.Linear: 0.00065640945070573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026978498608646 nn.Linear: 0.0038656701749576] nn.Sequential: [nn.Linear: 0.00023009858051125 nn.Linear: 0.0018579264495813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020982788875699 nn.Linear: 0.023249944671988 nn.Linear: 0.017815863713622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019956598058343 nn.Linear: 0.021354192867875] nn.Sequential: [nn.Linear: 0.007012908346951 nn.Linear: 0.014308000914752]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062642546861394 nn.Linear: 0.064855740680572 nn.Linear: 0.04517489542776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031489398573964 nn.Linear: 0.050635847176892] nn.Sequential: [nn.Linear: 0.031444870342032 nn.Linear: 0.034848263253493]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49220454692841 nn.Linear: 0.23197090625763 nn.Linear: 0.16753682494164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18533973395824 nn.Linear: 0.38148739933968] nn.Sequential: [nn.Linear: 0.10969108343124 nn.Linear: 0.20908986032009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007845890918886 nn.Linear: 0.00045328402031859 nn.Linear: 0.00028730495456872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011095492851579 nn.Linear: 0.0013482962513345] nn.Sequential: [nn.Linear: 0.00013209692269846 nn.Linear: 0.0011331030362201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059635313227773 nn.Linear: 0.0087756868451834 nn.Linear: 0.0067979712039232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077815945260227 nn.Linear: 0.010219530202448] nn.Sequential: [nn.Linear: 0.0052170678973198 nn.Linear: 0.012909996323287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062638227377051 nn.Linear: 0.064858843375065 nn.Linear: 0.045175148757914 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031489596378998 nn.Linear: 0.050641331335989] nn.Sequential: [nn.Linear: 0.031445096983797 nn.Linear: 0.03485838982418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4925851225853 nn.Linear: 0.23177921772003 nn.Linear: 0.16807585954666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18591666221619 nn.Linear: 0.3823589682579] nn.Sequential: [nn.Linear: 0.10981594026089 nn.Linear: 0.20954744517803]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018509950453018 nn.Linear: 0.0013254173482671 nn.Linear: 0.00068729571815624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024708752185042 nn.Linear: 0.0027945539939109] nn.Sequential: [nn.Linear: 0.00024950435305981 nn.Linear: 0.002063559648529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011476989835501 nn.Linear: 0.015041802078485 nn.Linear: 0.014998194761574 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097439754754305 nn.Linear: 0.016601737588644] nn.Sequential: [nn.Linear: 0.007307339925319 nn.Linear: 0.021984474733472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062634880722545 nn.Linear: 0.06486361316752 nn.Linear: 0.045177388157258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031489965769954 nn.Linear: 0.050654452243847] nn.Sequential: [nn.Linear: 0.031445312291116 nn.Linear: 0.034855290588362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49308437108994 nn.Linear: 0.23237581551075 nn.Linear: 0.16820083558559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18699613213539 nn.Linear: 0.38291111588478] nn.Sequential: [nn.Linear: 0.10999069362879 nn.Linear: 0.21002165973186]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017705171035174 nn.Linear: 0.0010259757143435 nn.Linear: 0.00047325322456911 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019639743244418 nn.Linear: 0.0026066606914433] nn.Sequential: [nn.Linear: 0.00017767942041097 nn.Linear: 0.0012225956634836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014039043337107 nn.Linear: 0.01238093432039 nn.Linear: 0.011308429762721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011113852262497 nn.Linear: 0.018222747370601] nn.Sequential: [nn.Linear: 0.0039248638786376 nn.Linear: 0.011161047033966]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06264773817905 nn.Linear: 0.064868819305439 nn.Linear: 0.045179943776197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031490499161065 nn.Linear: 0.050701954822955] nn.Sequential: [nn.Linear: 0.031445712395618 nn.Linear: 0.034867151434771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49349728226662 nn.Linear: 0.23236760497093 nn.Linear: 0.16835731267929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18825943768024 nn.Linear: 0.38444167375565] nn.Sequential: [nn.Linear: 0.11025226861238 nn.Linear: 0.20998603105545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010009678506188 nn.Linear: 0.0007054302144929 nn.Linear: 0.00040841778160338 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013948529976695 nn.Linear: 0.0016328707099885] nn.Sequential: [nn.Linear: 0.00018774754339489 nn.Linear: 0.0015508863890456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070376619696617 nn.Linear: 0.0095232641324401 nn.Linear: 0.0075421193614602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058919382281601 nn.Linear: 0.010622191242874] nn.Sequential: [nn.Linear: 0.0047056921757758 nn.Linear: 0.014619385823607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062647000282593 nn.Linear: 0.06487298852059 nn.Linear: 0.045181069664989 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031490897991529 nn.Linear: 0.05073993962101] nn.Sequential: [nn.Linear: 0.031445869617476 nn.Linear: 0.034887785219644]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49358168244362 nn.Linear: 0.23289924860001 nn.Linear: 0.16830822825432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.18894097208977 nn.Linear: 0.38580766320229] nn.Sequential: [nn.Linear: 0.11054660379887 nn.Linear: 0.21009856462479]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020225734655943 nn.Linear: 0.0012036534081528 nn.Linear: 0.00062187436545405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023355193538209 nn.Linear: 0.0029694079529681] nn.Sequential: [nn.Linear: 0.00020014295535286 nn.Linear: 0.0015409744726623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013801580294967 nn.Linear: 0.02601708099246 nn.Linear: 0.012944585643709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087026292458177 nn.Linear: 0.028740141540766] nn.Sequential: [nn.Linear: 0.0060046236030757 nn.Linear: 0.019279170781374]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062660341822046 nn.Linear: 0.064879808660474 nn.Linear: 0.0451833109418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031491269345374 nn.Linear: 0.050751322660886] nn.Sequential: [nn.Linear: 0.031446298188645 nn.Linear: 0.034918053910225]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49372810125351 nn.Linear: 0.23327007889748 nn.Linear: 0.16885849833488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1896830946207 nn.Linear: 0.38709971308708] nn.Sequential: [nn.Linear: 0.1105982363224 nn.Linear: 0.21038112044334]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094254229662202 nn.Linear: 0.00058495220464587 nn.Linear: 0.00035211913712884 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015588178963559 nn.Linear: 0.0016674225801436] nn.Sequential: [nn.Linear: 0.00012565437518662 nn.Linear: 0.00090850465675097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074402024038136 nn.Linear: 0.0078473323956132 nn.Linear: 0.0080967275425792 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066991178318858 nn.Linear: 0.009823290631175] nn.Sequential: [nn.Linear: 0.003384433221072 nn.Linear: 0.0080464081838727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06266226621414 nn.Linear: 0.064889954797354 nn.Linear: 0.045186002466431 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031491967309003 nn.Linear: 0.050794348894868] nn.Sequential: [nn.Linear: 0.031446490058715 nn.Linear: 0.034925649278864]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49373790621758 nn.Linear: 0.23325429856777 nn.Linear: 0.1694760620594 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19046318531036 nn.Linear: 0.38865602016449] nn.Sequential: [nn.Linear: 0.11076607555151 nn.Linear: 0.21088750660419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023139523770633 nn.Linear: 0.0012559031956616 nn.Linear: 0.00063534719640447 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002121577817515 nn.Linear: 0.0023756179179615] nn.Sequential: [nn.Linear: 0.00024449250412229 nn.Linear: 0.0018998988065741]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023372633382678 nn.Linear: 0.021581334993243 nn.Linear: 0.015294986777008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087588373571634 nn.Linear: 0.017574081197381] nn.Sequential: [nn.Linear: 0.0055934628471732 nn.Linear: 0.019272888079286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062658337774483 nn.Linear: 0.064893848081686 nn.Linear: 0.045187878336753 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031492380014142 nn.Linear: 0.050872340643622] nn.Sequential: [nn.Linear: 0.031446924117084 nn.Linear: 0.034957245685446]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49394664168358 nn.Linear: 0.23401519656181 nn.Linear: 0.16994175314903 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.1910013705492 nn.Linear: 0.39038467407227] nn.Sequential: [nn.Linear: 0.11127196997404 nn.Linear: 0.21149705350399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012731906517762 nn.Linear: 0.00078178759821825 nn.Linear: 0.00043057701330806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016663375854495 nn.Linear: 0.0018240546621358] nn.Sequential: [nn.Linear: 0.00016155466208925 nn.Linear: 0.0013917197024139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097558125853539 nn.Linear: 0.012072587385774 nn.Linear: 0.0081249671056867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073727057315409 nn.Linear: 0.012786353938282] nn.Sequential: [nn.Linear: 0.0075744385831058 nn.Linear: 0.019367976114154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062661637990573 nn.Linear: 0.064898517431505 nn.Linear: 0.04518895557395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031492624960396 nn.Linear: 0.050894100175924] nn.Sequential: [nn.Linear: 0.031446898517405 nn.Linear: 0.034957709161874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49450397491455 nn.Linear: 0.23435890674591 nn.Linear: 0.17009268701077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19145904481411 nn.Linear: 0.39089950919151] nn.Sequential: [nn.Linear: 0.11144677549601 nn.Linear: 0.2115778028965]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020088311609293 nn.Linear: 0.0011660040067284 nn.Linear: 0.00065104892469881 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028103854030523 nn.Linear: 0.0036468734169857] nn.Sequential: [nn.Linear: 0.00030381006924592 nn.Linear: 0.0024228783016682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015013569034636 nn.Linear: 0.016999334096909 nn.Linear: 0.021872954443097 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0098276017233729 nn.Linear: 0.023502375930548] nn.Sequential: [nn.Linear: 0.0085274279117584 nn.Linear: 0.031813234090805]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.091556121438742	TD error	0.018639250665903	Qmax	1	

Steps: 7500000 (frames: 30000000), score: 1841.56, higheset score: 6900, epsilon: 0.05, lr: 0.0005, training time: 547s, training rate: 1825fps, testing time: 86s, testing rate: 5762fps,  num. ep.: 395,  num. rewards: 18762	
   4    2  256    2
   2    4    8    4
   4   32   64    8
  16  128    8  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062657602503484 nn.Linear: 0.064901264261462 nn.Linear: 0.045191324251293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031493323913036 nn.Linear: 0.050946558120149] nn.Sequential: [nn.Linear: 0.031447030414211 nn.Linear: 0.034960669540361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4951648414135 nn.Linear: 0.23441058397293 nn.Linear: 0.1700374931097 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19251212477684 nn.Linear: 0.39254426956177] nn.Sequential: [nn.Linear: 0.11154991388321 nn.Linear: 0.21181224286556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030697075000287 nn.Linear: 0.001807060912545 nn.Linear: 0.00089452362923489 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00036677507029963 nn.Linear: 0.0043030772673217] nn.Sequential: [nn.Linear: 0.00029948440868447 nn.Linear: 0.0021805006677877]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017241960391402 nn.Linear: 0.021583961322904 nn.Linear: 0.016997227445245 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013900092802942 nn.Linear: 0.031756985932589] nn.Sequential: [nn.Linear: 0.0081322342157364 nn.Linear: 0.024664176627994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06265897034327 nn.Linear: 0.064908029653851 nn.Linear: 0.045192675435275 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031493639035304 nn.Linear: 0.050988632318408] nn.Sequential: [nn.Linear: 0.031447477014785 nn.Linear: 0.034987755022377]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49540579319 nn.Linear: 0.23446562886238 nn.Linear: 0.17036601901054 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19312952458858 nn.Linear: 0.39355328679085] nn.Sequential: [nn.Linear: 0.11181934922934 nn.Linear: 0.21239623427391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00118763271834 nn.Linear: 0.00080056944369976 nn.Linear: 0.00039987192416127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012578353890546 nn.Linear: 0.0014946156403883] nn.Sequential: [nn.Linear: 0.00016894942844612 nn.Linear: 0.0014062345894141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074243471026421 nn.Linear: 0.012183673679829 nn.Linear: 0.010750998742878 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077708400785923 nn.Linear: 0.012201418168843] nn.Sequential: [nn.Linear: 0.0076832035556436 nn.Linear: 0.018391713500023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062655389736669 nn.Linear: 0.064915182166875 nn.Linear: 0.045194299774387 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031493909369654 nn.Linear: 0.051048070954863] nn.Sequential: [nn.Linear: 0.031447796834709 nn.Linear: 0.034995723811704]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49623733758926 nn.Linear: 0.23442712426186 nn.Linear: 0.17092081904411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19393102824688 nn.Linear: 0.39450067281723] nn.Sequential: [nn.Linear: 0.11201906949282 nn.Linear: 0.21281777322292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014703159983353 nn.Linear: 0.0010121681699891 nn.Linear: 0.00063425476009161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00039267182146651 nn.Linear: 0.0059646602474954] nn.Sequential: [nn.Linear: 0.00021651415896708 nn.Linear: 0.0016366163775011]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094904713332653 nn.Linear: 0.016236562281847 nn.Linear: 0.020962186157703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013212159276009 nn.Linear: 0.04537607729435] nn.Sequential: [nn.Linear: 0.0062938332557678 nn.Linear: 0.015090191736817]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672487128921 nn.Linear: 0.064920015000163 nn.Linear: 0.045196336538558 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03149422270179 nn.Linear: 0.051088714996908] nn.Sequential: [nn.Linear: 0.031448148001458 nn.Linear: 0.035008719367324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49601447582245 nn.Linear: 0.23474085330963 nn.Linear: 0.1710836738348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19477035105228 nn.Linear: 0.39515188336372] nn.Sequential: [nn.Linear: 0.11206353455782 nn.Linear: 0.21288356184959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099481698130734 nn.Linear: 0.00060015783050912 nn.Linear: 0.00035077973349619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014175931333181 nn.Linear: 0.0016221567962331] nn.Sequential: [nn.Linear: 0.0001085739085717 nn.Linear: 0.00063956002299426]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0075120558030903 nn.Linear: 0.0081715798005462 nn.Linear: 0.0095946006476879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059380498714745 nn.Linear: 0.013959883712232] nn.Sequential: [nn.Linear: 0.0040780017152429 nn.Linear: 0.0048521179705858]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062674382574574 nn.Linear: 0.064930080098492 nn.Linear: 0.04519858663354 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031494450958734 nn.Linear: 0.051082222221126] nn.Sequential: [nn.Linear: 0.031448673794008 nn.Linear: 0.035028433266985]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49647963047028 nn.Linear: 0.23552063107491 nn.Linear: 0.17150308191776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19561924040318 nn.Linear: 0.39587387442589] nn.Sequential: [nn.Linear: 0.1123923510313 nn.Linear: 0.21317943930626]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024147446578966 nn.Linear: 0.001333448309241 nn.Linear: 0.00059712310974964 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020350315413293 nn.Linear: 0.0026915709669618] nn.Sequential: [nn.Linear: 0.00022888321040906 nn.Linear: 0.0017853599124138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019755536690354 nn.Linear: 0.021298056468368 nn.Linear: 0.018128242343664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091098994016647 nn.Linear: 0.022544499486685] nn.Sequential: [nn.Linear: 0.009123588912189 nn.Linear: 0.016614962369204]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062669113480715 nn.Linear: 0.064932388225803 nn.Linear: 0.045199526108626 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031494939615121 nn.Linear: 0.051129595918209] nn.Sequential: [nn.Linear: 0.031448653602603 nn.Linear: 0.035048882956836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49708959460258 nn.Linear: 0.23564366996288 nn.Linear: 0.17260840535164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19663308560848 nn.Linear: 0.39782264828682] nn.Sequential: [nn.Linear: 0.11261973530054 nn.Linear: 0.21325260400772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030722560940943 nn.Linear: 0.0016304500193925 nn.Linear: 0.00081497017104051 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00038472045549986 nn.Linear: 0.0050104690665148] nn.Sequential: [nn.Linear: 0.00028594411153156 nn.Linear: 0.0023560941935664]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020233320072293 nn.Linear: 0.025871034711599 nn.Linear: 0.036154821515083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017097320407629 nn.Linear: 0.042662028223276] nn.Sequential: [nn.Linear: 0.0094943968579173 nn.Linear: 0.027869449928403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062675751167495 nn.Linear: 0.064936063038821 nn.Linear: 0.045201285278891 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031495146239589 nn.Linear: 0.051174587549841] nn.Sequential: [nn.Linear: 0.031448856841562 nn.Linear: 0.035048402065385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49771302938461 nn.Linear: 0.23571975529194 nn.Linear: 0.1722886711359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19719319045544 nn.Linear: 0.39896610379219] nn.Sequential: [nn.Linear: 0.1128943413496 nn.Linear: 0.21317091584206]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019510250503242 nn.Linear: 0.0012988510600053 nn.Linear: 0.00060058421404381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018693642914803 nn.Linear: 0.0022609258431872] nn.Sequential: [nn.Linear: 0.00017051206800593 nn.Linear: 0.0013130091402717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016426019370556 nn.Linear: 0.026902876794338 nn.Linear: 0.023626577109098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012876336462796 nn.Linear: 0.021663967519999] nn.Sequential: [nn.Linear: 0.0051870853640139 nn.Linear: 0.0099977115169168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062681080040689 nn.Linear: 0.064942220415372 nn.Linear: 0.045202482237947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03149528419843 nn.Linear: 0.051189299744379] nn.Sequential: [nn.Linear: 0.031448999133092 nn.Linear: 0.035065313891061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.4972685277462 nn.Linear: 0.23553141951561 nn.Linear: 0.17329271137714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19795404374599 nn.Linear: 0.40012663602829] nn.Sequential: [nn.Linear: 0.11308018118143 nn.Linear: 0.21363285183907]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010499374823179 nn.Linear: 0.0006125213612249 nn.Linear: 0.00032238575434487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013063167673568 nn.Linear: 0.001528136590933] nn.Sequential: [nn.Linear: 0.0001345493427611 nn.Linear: 0.0012310393631627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00679253321141 nn.Linear: 0.0077522844076157 nn.Linear: 0.0062023671343923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004760938230902 nn.Linear: 0.009051182307303] nn.Sequential: [nn.Linear: 0.0044536017812788 nn.Linear: 0.013674536719918]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678235572422 nn.Linear: 0.064948798800466 nn.Linear: 0.045205172813497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031495687783997 nn.Linear: 0.0512707786456] nn.Sequential: [nn.Linear: 0.031449433779747 nn.Linear: 0.035084523508775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49756687879562 nn.Linear: 0.2355832606554 nn.Linear: 0.17356695234776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19888730347157 nn.Linear: 0.40132668614388] nn.Sequential: [nn.Linear: 0.11311374604702 nn.Linear: 0.214006960392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095236032342334 nn.Linear: 0.00057236313382333 nn.Linear: 0.00027305374878437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011369868112173 nn.Linear: 0.001499543331186] nn.Sequential: [nn.Linear: 0.00010074177239464 nn.Linear: 0.00077926244050927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0061615561135113 nn.Linear: 0.00754453567788 nn.Linear: 0.013893997296691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057070688344538 nn.Linear: 0.012209946289659] nn.Sequential: [nn.Linear: 0.0031370387878269 nn.Linear: 0.0077732456848025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062686071755828 nn.Linear: 0.064954646452891 nn.Linear: 0.045208293488488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031496155531636 nn.Linear: 0.051337853887254] nn.Sequential: [nn.Linear: 0.031449784770646 nn.Linear: 0.035096817532999]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49794217944145 nn.Linear: 0.23579733073711 nn.Linear: 0.17174763977528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19942429661751 nn.Linear: 0.40321147441864] nn.Sequential: [nn.Linear: 0.113565787673 nn.Linear: 0.2148864120245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016644258390486 nn.Linear: 0.0010557120608825 nn.Linear: 0.00059579968101703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024972570059559 nn.Linear: 0.0026707203828389] nn.Sequential: [nn.Linear: 0.00026546855425695 nn.Linear: 0.0022183119868637]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010996887460351 nn.Linear: 0.016711819916964 nn.Linear: 0.014116959646344 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010207089595497 nn.Linear: 0.020730441436172] nn.Sequential: [nn.Linear: 0.0088326474651694 nn.Linear: 0.025517461821437]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062683631727326 nn.Linear: 0.064955226786495 nn.Linear: 0.045209508522603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031496414081142 nn.Linear: 0.051388631565928] nn.Sequential: [nn.Linear: 0.031449854516446 nn.Linear: 0.035110664647814]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49795579910278 nn.Linear: 0.23587134480476 nn.Linear: 0.1725627630949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.19971638917923 nn.Linear: 0.40390595793724] nn.Sequential: [nn.Linear: 0.1139053851366 nn.Linear: 0.21513091027737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020001923671049 nn.Linear: 0.0011670728716683 nn.Linear: 0.00056272954871606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018897203180165 nn.Linear: 0.002163982044313] nn.Sequential: [nn.Linear: 0.00022473480307139 nn.Linear: 0.0017921467475487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013402589596808 nn.Linear: 0.017756519839168 nn.Linear: 0.011865315958858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010111256502569 nn.Linear: 0.016814919188619] nn.Sequential: [nn.Linear: 0.009302943944931 nn.Linear: 0.020629873499274]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062686295162666 nn.Linear: 0.064958750008111 nn.Linear: 0.045211691794818 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031496695244011 nn.Linear: 0.051392104583389] nn.Sequential: [nn.Linear: 0.031450225786367 nn.Linear: 0.035115923494243]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49811124801636 nn.Linear: 0.23607759177685 nn.Linear: 0.17320591211319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20045460760593 nn.Linear: 0.40451085567474] nn.Sequential: [nn.Linear: 0.1141901910305 nn.Linear: 0.21524170041084]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010526680417084 nn.Linear: 0.00069382040978062 nn.Linear: 0.0003844503704974 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014677439305528 nn.Linear: 0.0018997554363858] nn.Sequential: [nn.Linear: 0.00020049590105515 nn.Linear: 0.0019319398775908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080527858808637 nn.Linear: 0.016622288152575 nn.Linear: 0.0078093651682138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064511597156525 nn.Linear: 0.013546172529459] nn.Sequential: [nn.Linear: 0.0055712689645588 nn.Linear: 0.022084645926952]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062685303298764 nn.Linear: 0.064958575492173 nn.Linear: 0.045212598607447 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031497024980503 nn.Linear: 0.051384989541702] nn.Sequential: [nn.Linear: 0.031450175326221 nn.Linear: 0.035131748412448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49831941723824 nn.Linear: 0.23583942651749 nn.Linear: 0.17404974997044 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20106492936611 nn.Linear: 0.40520456433296] nn.Sequential: [nn.Linear: 0.11466008424759 nn.Linear: 0.21582388877869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015624008443997 nn.Linear: 0.0010214558218852 nn.Linear: 0.00047608440999514 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019237011359258 nn.Linear: 0.0024249837831645] nn.Sequential: [nn.Linear: 0.00018761350759012 nn.Linear: 0.0015988646668367]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009121261537075 nn.Linear: 0.014286523684859 nn.Linear: 0.013416844420135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011248427443206 nn.Linear: 0.024027096107602] nn.Sequential: [nn.Linear: 0.0078763030469418 nn.Linear: 0.021879483014345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062693132849067 nn.Linear: 0.064963735667672 nn.Linear: 0.045214124299436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031497318034328 nn.Linear: 0.051424700881398] nn.Sequential: [nn.Linear: 0.031450538466288 nn.Linear: 0.035154920505598]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49860179424286 nn.Linear: 0.23625665903091 nn.Linear: 0.17297837138176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20132777094841 nn.Linear: 0.4064237177372] nn.Sequential: [nn.Linear: 0.11470106989145 nn.Linear: 0.21591594815254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012076089766244 nn.Linear: 0.00067313893882419 nn.Linear: 0.00035948788133279 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013771399313465 nn.Linear: 0.0015046068004347] nn.Sequential: [nn.Linear: 0.00015532411938774 nn.Linear: 0.0011737354624432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087261125445366 nn.Linear: 0.0083339996635914 nn.Linear: 0.0082168765366077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055001266300678 nn.Linear: 0.011387983337045] nn.Sequential: [nn.Linear: 0.0048253089189529 nn.Linear: 0.01262282487005]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062689510685338 nn.Linear: 0.064968677403141 nn.Linear: 0.045215201530673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03149727762133 nn.Linear: 0.051443656324693] nn.Sequential: [nn.Linear: 0.03145077656025 nn.Linear: 0.035155029035032]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49898114800453 nn.Linear: 0.23640547692776 nn.Linear: 0.17298930883408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20233377814293 nn.Linear: 0.40795096755028] nn.Sequential: [nn.Linear: 0.11522620171309 nn.Linear: 0.21608678996563]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026998449612264 nn.Linear: 0.0017114889703579 nn.Linear: 0.00083745460656243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00036220994100982 nn.Linear: 0.0047648032385595] nn.Sequential: [nn.Linear: 0.00021457986721658 nn.Linear: 0.0018295449561417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020241243764758 nn.Linear: 0.036724951118231 nn.Linear: 0.03850395232439 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02277160063386 nn.Linear: 0.042207680642605] nn.Sequential: [nn.Linear: 0.0099084107205272 nn.Linear: 0.019261980429292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062692039161444 nn.Linear: 0.064974818043974 nn.Linear: 0.045216959632304 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031497750747778 nn.Linear: 0.051506623157621] nn.Sequential: [nn.Linear: 0.031451037179465 nn.Linear: 0.035147895149043]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.49906641244888 nn.Linear: 0.23680347204208 nn.Linear: 0.17413531243801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2028784006834 nn.Linear: 0.40886333584785] nn.Sequential: [nn.Linear: 0.11515229940414 nn.Linear: 0.21617393195629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016039169175117 nn.Linear: 0.00097921758042716 nn.Linear: 0.00052122710731266 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022696701521815 nn.Linear: 0.0031053961301729] nn.Sequential: [nn.Linear: 0.00017251563777587 nn.Linear: 0.0012279599640655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014021047390997 nn.Linear: 0.011947281658649 nn.Linear: 0.011222459375858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092807626351714 nn.Linear: 0.021351423114538] nn.Sequential: [nn.Linear: 0.0057089570909739 nn.Linear: 0.012301408685744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062680932948394 nn.Linear: 0.064980185816887 nn.Linear: 0.045218774657289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031498136686883 nn.Linear: 0.051554173547686] nn.Sequential: [nn.Linear: 0.031451373025597 nn.Linear: 0.03518299387899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50009536743164 nn.Linear: 0.23690602183342 nn.Linear: 0.17401537299156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20372354984283 nn.Linear: 0.41037386655807] nn.Sequential: [nn.Linear: 0.11554738134146 nn.Linear: 0.21674777567387]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010434342171753 nn.Linear: 0.00066870615685597 nn.Linear: 0.00032550090458044 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013133713702352 nn.Linear: 0.0014767184945936] nn.Sequential: [nn.Linear: 0.00011400429839661 nn.Linear: 0.00074142156045756]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078122173435986 nn.Linear: 0.0089643271639943 nn.Linear: 0.0074658002704382 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053253900259733 nn.Linear: 0.0094703156501055] nn.Sequential: [nn.Linear: 0.0042949360795319 nn.Linear: 0.0069652548991144]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684371842876 nn.Linear: 0.064985135480485 nn.Linear: 0.0452207909628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03149863765838 nn.Linear: 0.051585569601912] nn.Sequential: [nn.Linear: 0.031451670121206 nn.Linear: 0.035196267426556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50093019008636 nn.Linear: 0.23692816495895 nn.Linear: 0.17487139999866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20472747087479 nn.Linear: 0.41137316823006] nn.Sequential: [nn.Linear: 0.11597347259521 nn.Linear: 0.21712230145931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021684309224155 nn.Linear: 0.0011529442841393 nn.Linear: 0.00048836475764268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018764509210324 nn.Linear: 0.0021614882567796] nn.Sequential: [nn.Linear: 0.00016258588266503 nn.Linear: 0.0012421265909145]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014109851792455 nn.Linear: 0.01512161269784 nn.Linear: 0.011773829348385 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011695053428411 nn.Linear: 0.015486801043153] nn.Sequential: [nn.Linear: 0.0043491767719388 nn.Linear: 0.013632728718221]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062687351987788 nn.Linear: 0.064988087746671 nn.Linear: 0.045221922994371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031498799776808 nn.Linear: 0.051629680841241] nn.Sequential: [nn.Linear: 0.031451618862227 nn.Linear: 0.035202084272132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50076919794083 nn.Linear: 0.23712627589703 nn.Linear: 0.1752712726593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20523422956467 nn.Linear: 0.41149029135704] nn.Sequential: [nn.Linear: 0.11638966202736 nn.Linear: 0.21727468073368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015259751839342 nn.Linear: 0.00094012594791494 nn.Linear: 0.00043125537615083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014946041942009 nn.Linear: 0.0017025492365162] nn.Sequential: [nn.Linear: 0.00013786924028453 nn.Linear: 0.0010823568528018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012766916304827 nn.Linear: 0.015274576842785 nn.Linear: 0.011722467839718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012614796869457 nn.Linear: 0.016052095219493] nn.Sequential: [nn.Linear: 0.0046008448116481 nn.Linear: 0.015277462080121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062688381883606 nn.Linear: 0.064996080721095 nn.Linear: 0.045223332180377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031499010713309 nn.Linear: 0.051640550689484] nn.Sequential: [nn.Linear: 0.031451901779473 nn.Linear: 0.03520731847943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50043195486069 nn.Linear: 0.23680682480335 nn.Linear: 0.17532858252525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20560337603092 nn.Linear: 0.41194161772728] nn.Sequential: [nn.Linear: 0.11663464456797 nn.Linear: 0.21790060400963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010854682041705 nn.Linear: 0.00083724808056381 nn.Linear: 0.00042936485015199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019333742745874 nn.Linear: 0.0026749265485202] nn.Sequential: [nn.Linear: 0.00016287198805784 nn.Linear: 0.0013560621820173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007878303527832 nn.Linear: 0.016105335205793 nn.Linear: 0.0099036563187838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084108430892229 nn.Linear: 0.025301771238446] nn.Sequential: [nn.Linear: 0.0038809592369944 nn.Linear: 0.010218808427453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062682013167541 nn.Linear: 0.064996072367141 nn.Linear: 0.045223737461976 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031499341472844 nn.Linear: 0.051657433612775] nn.Sequential: [nn.Linear: 0.031451868083564 nn.Linear: 0.035223769205135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50053173303604 nn.Linear: 0.2373373657465 nn.Linear: 0.17570379376411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20712745189667 nn.Linear: 0.41345083713531] nn.Sequential: [nn.Linear: 0.11688380688429 nn.Linear: 0.21783468127251]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0034460625638378 nn.Linear: 0.0022546881907518 nn.Linear: 0.00086522874315854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023675981622049 nn.Linear: 0.0027787440502185] nn.Sequential: [nn.Linear: 0.00023532045583434 nn.Linear: 0.0020052707690671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021076440811157 nn.Linear: 0.03873448446393 nn.Linear: 0.036941438913345 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02755257114768 nn.Linear: 0.024767458438873] nn.Sequential: [nn.Linear: 0.013607749715447 nn.Linear: 0.024532021954656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062685970638635 nn.Linear: 0.064999859641227 nn.Linear: 0.04522511656556 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031499410058312 nn.Linear: 0.051652130611899] nn.Sequential: [nn.Linear: 0.031452122715726 nn.Linear: 0.035219741840677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5000809431076 nn.Linear: 0.2376824170351 nn.Linear: 0.17508095502853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20828674733639 nn.Linear: 0.41403311491013] nn.Sequential: [nn.Linear: 0.11720369011164 nn.Linear: 0.21786049008369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017261760163461 nn.Linear: 0.0010810926445125 nn.Linear: 0.00049833069513781 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021919024177347 nn.Linear: 0.0031315048810583] nn.Sequential: [nn.Linear: 0.00011934162579956 nn.Linear: 0.00083879445039349]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010911936871707 nn.Linear: 0.017754800617695 nn.Linear: 0.019075244665146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087435068562627 nn.Linear: 0.021740429103374] nn.Sequential: [nn.Linear: 0.0050161108374596 nn.Linear: 0.0071409465745091]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062669930819484 nn.Linear: 0.065000498746046 nn.Linear: 0.045226642158797 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031499772508879 nn.Linear: 0.051689251985863] nn.Sequential: [nn.Linear: 0.031452314536413 nn.Linear: 0.035233085717996]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50003123283386 nn.Linear: 0.23774173855782 nn.Linear: 0.1754382699728 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.20928730070591 nn.Linear: 0.41538262367249] nn.Sequential: [nn.Linear: 0.11744059622288 nn.Linear: 0.21839101612568]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0049783650453821 nn.Linear: 0.0023495042704804 nn.Linear: 0.00096659198382873 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034712623022935 nn.Linear: 0.0044578530909902] nn.Sequential: [nn.Linear: 0.00033046719601271 nn.Linear: 0.0031301386743143]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.039634488523006 nn.Linear: 0.042986899614334 nn.Linear: 0.066449515521526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.034361772239208 nn.Linear: 0.036546546965837] nn.Sequential: [nn.Linear: 0.011077217757702 nn.Linear: 0.040473245084286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672163817706 nn.Linear: 0.065003878621301 nn.Linear: 0.045227150858365 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031499985200126 nn.Linear: 0.051702772101464] nn.Sequential: [nn.Linear: 0.031452655066314 nn.Linear: 0.035264472782714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50057876110077 nn.Linear: 0.23732942342758 nn.Linear: 0.17557746171951 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21025450527668 nn.Linear: 0.41598278284073] nn.Sequential: [nn.Linear: 0.11746141314507 nn.Linear: 0.21856521070004]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012672863595513 nn.Linear: 0.0006946626391035 nn.Linear: 0.00038449902264218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001155930835234 nn.Linear: 0.001187663670262] nn.Sequential: [nn.Linear: 0.00013279209176353 nn.Linear: 0.0010272814951904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010623786598444 nn.Linear: 0.011806258000433 nn.Linear: 0.02117995172739 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016117850318551 nn.Linear: 0.010356872342527] nn.Sequential: [nn.Linear: 0.0083236871287227 nn.Linear: 0.013403804972768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062666557704541 nn.Linear: 0.065005913927414 nn.Linear: 0.045227518545867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031500192848627 nn.Linear: 0.051728995210993] nn.Sequential: [nn.Linear: 0.031452680974975 nn.Linear: 0.03526055327276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50110447406769 nn.Linear: 0.23721840977669 nn.Linear: 0.17592558264732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21069933474064 nn.Linear: 0.41613054275513] nn.Sequential: [nn.Linear: 0.11779543012381 nn.Linear: 0.21864649653435]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010463309875211 nn.Linear: 0.00069996957232252 nn.Linear: 0.00044865289113648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017463504141588 nn.Linear: 0.0020503861730115] nn.Sequential: [nn.Linear: 0.00020707718569588 nn.Linear: 0.0016585685161782]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080928765237331 nn.Linear: 0.010526568628848 nn.Linear: 0.0066555999219418 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065263188444078 nn.Linear: 0.017146863043308] nn.Sequential: [nn.Linear: 0.0056052608415484 nn.Linear: 0.02211781218648]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.088750975564122	TD error	0.018884719021618	Qmax	1	

Steps: 7750000 (frames: 31000000), score: 1764.20, higheset score: 6044, epsilon: 0.05, lr: 0.0005, training time: 540s, training rate: 1850fps, testing time: 88s, testing rate: 5652fps,  num. ep.: 297,  num. rewards: 12910	
   4    2    4   16
   2   32    8    2
   4  256   32    8
   2   32    4  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062671276092396 nn.Linear: 0.065013287035977 nn.Linear: 0.045230196850448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031500526379065 nn.Linear: 0.051752392962783] nn.Sequential: [nn.Linear: 0.031453160493733 nn.Linear: 0.035282319145651]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50113850831985 nn.Linear: 0.23696786165237 nn.Linear: 0.17659990489483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21119694411755 nn.Linear: 0.4169687628746] nn.Sequential: [nn.Linear: 0.11794529110193 nn.Linear: 0.21872499585152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011090255376487 nn.Linear: 0.00075442689497879 nn.Linear: 0.00044555858263176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020141419498801 nn.Linear: 0.0027109926766973] nn.Sequential: [nn.Linear: 0.00020010370703518 nn.Linear: 0.0017100770726244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096592530608177 nn.Linear: 0.014705011621118 nn.Linear: 0.016688451170921 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01082309614867 nn.Linear: 0.021362964063883] nn.Sequential: [nn.Linear: 0.0061353635974228 nn.Linear: 0.012955241836607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062671574092608 nn.Linear: 0.065017761463924 nn.Linear: 0.045231796586887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03150113350161 nn.Linear: 0.051816924758896] nn.Sequential: [nn.Linear: 0.031453069834756 nn.Linear: 0.035283712498464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50213080644608 nn.Linear: 0.23721390962601 nn.Linear: 0.17641846835613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21182745695114 nn.Linear: 0.41798916459084] nn.Sequential: [nn.Linear: 0.1180909126997 nn.Linear: 0.21908354759216]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.003071471458836 nn.Linear: 0.0014043829625783 nn.Linear: 0.00057338190956365 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018706599385057 nn.Linear: 0.0019619943112903] nn.Sequential: [nn.Linear: 0.00017134628686227 nn.Linear: 0.0011726278049739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020411606878042 nn.Linear: 0.021463809534907 nn.Linear: 0.017582016065717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010938624851406 nn.Linear: 0.016993816941977] nn.Sequential: [nn.Linear: 0.011558032594621 nn.Linear: 0.011816739104688]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062668817728638 nn.Linear: 0.065024582542595 nn.Linear: 0.045233504244711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031501709447944 nn.Linear: 0.051864033469229] nn.Sequential: [nn.Linear: 0.03145327575042 nn.Linear: 0.035300929424666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50289911031723 nn.Linear: 0.2372489720583 nn.Linear: 0.17695961892605 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21212550997734 nn.Linear: 0.41945976018906] nn.Sequential: [nn.Linear: 0.1182015389204 nn.Linear: 0.2194514721632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096170490002945 nn.Linear: 0.00061254177149568 nn.Linear: 0.00036998940114685 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016483810517108 nn.Linear: 0.0018793040930295] nn.Sequential: [nn.Linear: 0.0001603705513121 nn.Linear: 0.001259160186549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077567184343934 nn.Linear: 0.0082613890990615 nn.Linear: 0.010748669505119 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069433785974979 nn.Linear: 0.012366917915642] nn.Sequential: [nn.Linear: 0.0064041828736663 nn.Linear: 0.011049622669816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062673959345951 nn.Linear: 0.065030156812883 nn.Linear: 0.045234932199161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031501906613544 nn.Linear: 0.051923434040646] nn.Sequential: [nn.Linear: 0.031453691885237 nn.Linear: 0.035299452558564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50300937891006 nn.Linear: 0.23786146938801 nn.Linear: 0.17773142457008 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21337623894215 nn.Linear: 0.42041218280792] nn.Sequential: [nn.Linear: 0.11843067407608 nn.Linear: 0.21977388858795]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012277710950943 nn.Linear: 0.00078082167752871 nn.Linear: 0.00048277258303819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024973667876378 nn.Linear: 0.003426138968658] nn.Sequential: [nn.Linear: 0.00017886475196457 nn.Linear: 0.0015279092097483]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085957525297999 nn.Linear: 0.015998378396034 nn.Linear: 0.018579488620162 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015768773853779 nn.Linear: 0.02371272072196] nn.Sequential: [nn.Linear: 0.0062784282490611 nn.Linear: 0.0153334653005]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06267216934755 nn.Linear: 0.065030928033743 nn.Linear: 0.045235764978752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031502319965592 nn.Linear: 0.051959136775707] nn.Sequential: [nn.Linear: 0.031453581934783 nn.Linear: 0.035320481061307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50342363119125 nn.Linear: 0.23853446543217 nn.Linear: 0.17733576893806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21463470160961 nn.Linear: 0.42168921232224] nn.Sequential: [nn.Linear: 0.11873839050531 nn.Linear: 0.22019743919373]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018179815512957 nn.Linear: 0.0010453060464304 nn.Linear: 0.00049843467082369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017016904230117 nn.Linear: 0.0019025939457582] nn.Sequential: [nn.Linear: 0.00015437982274959 nn.Linear: 0.00087137600134105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011463285423815 nn.Linear: 0.01526933349669 nn.Linear: 0.0085254143923521 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0071346927434206 nn.Linear: 0.016222454607487] nn.Sequential: [nn.Linear: 0.0055455435067415 nn.Linear: 0.0087805921211839]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062667999361495 nn.Linear: 0.065035508310534 nn.Linear: 0.045236535330448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031502635655163 nn.Linear: 0.05197277004622] nn.Sequential: [nn.Linear: 0.031453656287073 nn.Linear: 0.035319981195569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50333708524704 nn.Linear: 0.23811233043671 nn.Linear: 0.17786584794521 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21595199406147 nn.Linear: 0.42305320501328] nn.Sequential: [nn.Linear: 0.11921778321266 nn.Linear: 0.22046868503094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089763741678783 nn.Linear: 0.00053387280783853 nn.Linear: 0.00027719305653624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012586693887612 nn.Linear: 0.0016034967162777] nn.Sequential: [nn.Linear: 0.00013309496793368 nn.Linear: 0.00098375649287086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069318399764597 nn.Linear: 0.0090808970853686 nn.Linear: 0.012023823335767 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050200843252242 nn.Linear: 0.012234030291438] nn.Sequential: [nn.Linear: 0.0047899521887302 nn.Linear: 0.010840374976397]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06267390229805 nn.Linear: 0.065038934695323 nn.Linear: 0.045238704025269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03150296567345 nn.Linear: 0.052002593697637] nn.Sequential: [nn.Linear: 0.031453994961313 nn.Linear: 0.035347283535859]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50293797254562 nn.Linear: 0.2381696254015 nn.Linear: 0.17817963659763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21716782450676 nn.Linear: 0.42436301708221] nn.Sequential: [nn.Linear: 0.11974392831326 nn.Linear: 0.22084827721119]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023213402886525 nn.Linear: 0.0014446185515344 nn.Linear: 0.00084372569042018 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00037526292454354 nn.Linear: 0.0051560380802367] nn.Sequential: [nn.Linear: 0.00034594917801496 nn.Linear: 0.0027552286381587]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016306307166815 nn.Linear: 0.034737266600132 nn.Linear: 0.027760269120336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022640887647867 nn.Linear: 0.044025525450706] nn.Sequential: [nn.Linear: 0.01496546715498 nn.Linear: 0.031525045633316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062683895955789 nn.Linear: 0.065046151548075 nn.Linear: 0.045241063378414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031503473333892 nn.Linear: 0.052062893504782] nn.Sequential: [nn.Linear: 0.031454350799233 nn.Linear: 0.035363968200275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.502805352211 nn.Linear: 0.2381995767355 nn.Linear: 0.178567096591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21830888092518 nn.Linear: 0.42571955919266] nn.Sequential: [nn.Linear: 0.12010444700718 nn.Linear: 0.22098189592361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.008193433695973 nn.Linear: 0.0038284944905992 nn.Linear: 0.0012600453601137 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00047876503944686 nn.Linear: 0.0067039711287213] nn.Sequential: [nn.Linear: 0.00031215242656697 nn.Linear: 0.0023383542096223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.056847121566534 nn.Linear: 0.069413639605045 nn.Linear: 0.073361575603485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.039434395730495 nn.Linear: 0.060955055058002] nn.Sequential: [nn.Linear: 0.012084125541151 nn.Linear: 0.034372299909592]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684644924405 nn.Linear: 0.065051218579554 nn.Linear: 0.045243826598134 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031503834179496 nn.Linear: 0.052072789214947] nn.Sequential: [nn.Linear: 0.031454601100666 nn.Linear: 0.035374803795026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5028373003006 nn.Linear: 0.2381876707077 nn.Linear: 0.1789076179266 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2194532006979 nn.Linear: 0.42631104588509] nn.Sequential: [nn.Linear: 0.12025556713343 nn.Linear: 0.22125226259232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023946162788766 nn.Linear: 0.0015149086307205 nn.Linear: 0.0006533152162897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023309493295837 nn.Linear: 0.0031826133842125] nn.Sequential: [nn.Linear: 0.00019329138510656 nn.Linear: 0.0016396355104894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01479693967849 nn.Linear: 0.023567229509354 nn.Linear: 0.021859496831894 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010088942013681 nn.Linear: 0.026690041646361] nn.Sequential: [nn.Linear: 0.0089657995849848 nn.Linear: 0.015733692795038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062680391383243 nn.Linear: 0.065057995662595 nn.Linear: 0.045246104575263 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031504261856185 nn.Linear: 0.052135032992616] nn.Sequential: [nn.Linear: 0.031455188916272 nn.Linear: 0.035414877330018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50361204147339 nn.Linear: 0.23820289969444 nn.Linear: 0.17954134941101 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.21993319690228 nn.Linear: 0.4275683760643] nn.Sequential: [nn.Linear: 0.12061389535666 nn.Linear: 0.2217882424593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0032646898758364 nn.Linear: 0.0017465443670784 nn.Linear: 0.00068662438916328 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018701915572032 nn.Linear: 0.0020408468774697] nn.Sequential: [nn.Linear: 0.00017527380392128 nn.Linear: 0.0012690840056744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019635170698166 nn.Linear: 0.035010624676943 nn.Linear: 0.036574192345142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019118949770927 nn.Linear: 0.017164682969451] nn.Sequential: [nn.Linear: 0.0046836566179991 nn.Linear: 0.017564656212926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062685626125779 nn.Linear: 0.065063101879213 nn.Linear: 0.045248055874436 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031504569424775 nn.Linear: 0.052174039599457] nn.Sequential: [nn.Linear: 0.031455580926761 nn.Linear: 0.035416511535806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50355607271194 nn.Linear: 0.23819644749165 nn.Linear: 0.17948949337006 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22103227674961 nn.Linear: 0.42860415577888] nn.Sequential: [nn.Linear: 0.12097166478634 nn.Linear: 0.22175832092762]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013767257574365 nn.Linear: 0.00074469374706641 nn.Linear: 0.00038904770679875 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017981404869125 nn.Linear: 0.0020144680155445] nn.Sequential: [nn.Linear: 0.00015715049111641 nn.Linear: 0.0010747476845621]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077904188074172 nn.Linear: 0.014840674586594 nn.Linear: 0.0084349615499377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082937255501747 nn.Linear: 0.01646894030273] nn.Sequential: [nn.Linear: 0.0040385243482888 nn.Linear: 0.0085015827789903]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678870614027 nn.Linear: 0.065064716044944 nn.Linear: 0.045249832788877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031504866309738 nn.Linear: 0.052228797950676] nn.Sequential: [nn.Linear: 0.031455812318904 nn.Linear: 0.035432389448792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50273144245148 nn.Linear: 0.23923592269421 nn.Linear: 0.18044145405293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22145827114582 nn.Linear: 0.42881768941879] nn.Sequential: [nn.Linear: 0.12103977799416 nn.Linear: 0.22199587523937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0035898628244999 nn.Linear: 0.002063977459358 nn.Linear: 0.0009311679864601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00037506508068925 nn.Linear: 0.0051074676237541] nn.Sequential: [nn.Linear: 0.00025274887577168 nn.Linear: 0.0020271113578391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027328805997968 nn.Linear: 0.034806061536074 nn.Linear: 0.018575672060251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02060049213469 nn.Linear: 0.034016389399767] nn.Sequential: [nn.Linear: 0.011253380216658 nn.Linear: 0.026435751467943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	7880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062681545549434 nn.Linear: 0.065067591173679 nn.Linear: 0.04525064618798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031505305361906 nn.Linear: 0.052256656582728] nn.Sequential: [nn.Linear: 0.031455923390502 nn.Linear: 0.035443254166463]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50301921367645 nn.Linear: 0.23978093266487 nn.Linear: 0.18025708198547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22261212766171 nn.Linear: 0.42966678738594] nn.Sequential: [nn.Linear: 0.12099951505661 nn.Linear: 0.22214402258396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014735415656046 nn.Linear: 0.00090254738670711 nn.Linear: 0.00049425182945841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021960069629745 nn.Linear: 0.0028037546987472] nn.Sequential: [nn.Linear: 0.00021246728216478 nn.Linear: 0.0017631821708815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013479258865118 nn.Linear: 0.01407902687788 nn.Linear: 0.012405904009938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081276623532176 nn.Linear: 0.020002964884043] nn.Sequential: [nn.Linear: 0.0068318275734782 nn.Linear: 0.017030375078321]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062687497242885 nn.Linear: 0.065075860821381 nn.Linear: 0.045253493311159 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031505520626419 nn.Linear: 0.052277643110813] nn.Sequential: [nn.Linear: 0.031456460900447 nn.Linear: 0.035477687146755]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50367093086243 nn.Linear: 0.24016800522804 nn.Linear: 0.18074059486389 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22369919717312 nn.Linear: 0.43036207556725] nn.Sequential: [nn.Linear: 0.12093617022038 nn.Linear: 0.22220008075237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033518468942678 nn.Linear: 0.0017079762841019 nn.Linear: 0.00082336303637733 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030262080794273 nn.Linear: 0.0040360692676056] nn.Sequential: [nn.Linear: 0.00030492452163166 nn.Linear: 0.0023835492579436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.031017974019051 nn.Linear: 0.02383173815906 nn.Linear: 0.036482136696577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013892577961087 nn.Linear: 0.026360586285591] nn.Sequential: [nn.Linear: 0.0083891749382019 nn.Linear: 0.02962956763804]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062681286231886 nn.Linear: 0.065076238241298 nn.Linear: 0.045253418954964 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031505862371795 nn.Linear: 0.052274405579318] nn.Sequential: [nn.Linear: 0.031456645200133 nn.Linear: 0.035473093734165]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50421440601349 nn.Linear: 0.23984228074551 nn.Linear: 0.18054622411728 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22394691407681 nn.Linear: 0.43143433332443] nn.Sequential: [nn.Linear: 0.12129779160023 nn.Linear: 0.22222386300564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001602500643073 nn.Linear: 0.00075285359797459 nn.Linear: 0.00041173290570341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015815349350251 nn.Linear: 0.0018085940769215] nn.Sequential: [nn.Linear: 0.00016359135428841 nn.Linear: 0.0014825049989937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011695564724505 nn.Linear: 0.014281488023698 nn.Linear: 0.029469454661012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082905795425177 nn.Linear: 0.017624836415052] nn.Sequential: [nn.Linear: 0.0046479357406497 nn.Linear: 0.018095549196005]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062690654480062 nn.Linear: 0.065079705660627 nn.Linear: 0.045254675080031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031506129428917 nn.Linear: 0.052271350786413] nn.Sequential: [nn.Linear: 0.031456860673149 nn.Linear: 0.035484139551725]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50420945882797 nn.Linear: 0.24036213755608 nn.Linear: 0.18072479963303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22485481202602 nn.Linear: 0.43236726522446] nn.Sequential: [nn.Linear: 0.12142224609852 nn.Linear: 0.22240878641605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016901156972459 nn.Linear: 0.00092695299807579 nn.Linear: 0.00051505638786683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023898676185524 nn.Linear: 0.0029578378594426] nn.Sequential: [nn.Linear: 0.00019253388885211 nn.Linear: 0.0012785304907355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011415907181799 nn.Linear: 0.013219058513641 nn.Linear: 0.018406430259347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092920893803239 nn.Linear: 0.02155726775527] nn.Sequential: [nn.Linear: 0.0053435298614204 nn.Linear: 0.0099517097696662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062689136041633 nn.Linear: 0.065087941863825 nn.Linear: 0.045256117419258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031506386539216 nn.Linear: 0.052324584525365] nn.Sequential: [nn.Linear: 0.031457058293219 nn.Linear: 0.03547741638189]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5047395825386 nn.Linear: 0.23985402286053 nn.Linear: 0.18104046583176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22579120099545 nn.Linear: 0.43352508544922] nn.Sequential: [nn.Linear: 0.12176837027073 nn.Linear: 0.2222762554884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001857806134622 nn.Linear: 0.00099685157631972 nn.Linear: 0.00047334614193256 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018736371177208 nn.Linear: 0.0019496245362667] nn.Sequential: [nn.Linear: 0.00021956541893436 nn.Linear: 0.0017337544965093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011475183069706 nn.Linear: 0.016103774309158 nn.Linear: 0.017660470679402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085771586745977 nn.Linear: 0.01563779078424] nn.Sequential: [nn.Linear: 0.0089098950847983 nn.Linear: 0.014945873990655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062683497295545 nn.Linear: 0.065093069628033 nn.Linear: 0.045258227298745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031506838746528 nn.Linear: 0.052354338718601] nn.Sequential: [nn.Linear: 0.031457333978878 nn.Linear: 0.03551358869894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50525772571564 nn.Linear: 0.240328758955 nn.Linear: 0.18168474733829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22636194527149 nn.Linear: 0.43464493751526] nn.Sequential: [nn.Linear: 0.12185294926167 nn.Linear: 0.22281710803509]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017675422303888 nn.Linear: 0.0010070528190041 nn.Linear: 0.00053433345552571 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015742842753474 nn.Linear: 0.0016452172679695] nn.Sequential: [nn.Linear: 0.00022007763086385 nn.Linear: 0.0020958189741005]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013208655640483 nn.Linear: 0.02067593485117 nn.Linear: 0.016163129359484 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096974996849895 nn.Linear: 0.011104078032076] nn.Sequential: [nn.Linear: 0.0082509433850646 nn.Linear: 0.017629001289606]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684906562729 nn.Linear: 0.06509864485971 nn.Linear: 0.045260241734243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031507129325127 nn.Linear: 0.052406112538591] nn.Sequential: [nn.Linear: 0.031457782320001 nn.Linear: 0.035548215366551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50532501935959 nn.Linear: 0.2406210154295 nn.Linear: 0.18138857185841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22785468399525 nn.Linear: 0.4355057477951] nn.Sequential: [nn.Linear: 0.12238525599241 nn.Linear: 0.22367641329765]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028741416559289 nn.Linear: 0.0017419673535941 nn.Linear: 0.00077210284839727 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00031266419788045 nn.Linear: 0.0040109530667438] nn.Sequential: [nn.Linear: 0.00023430793457636 nn.Linear: 0.0017940188816892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020042324438691 nn.Linear: 0.026928244158626 nn.Linear: 0.019292315468192 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014946994371712 nn.Linear: 0.028142625465989] nn.Sequential: [nn.Linear: 0.0066336840391159 nn.Linear: 0.019651740789413]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062691100988232 nn.Linear: 0.065104905164924 nn.Linear: 0.045261052924394 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031507364294889 nn.Linear: 0.052415759724056] nn.Sequential: [nn.Linear: 0.031457787874689 nn.Linear: 0.035540224154293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50581443309784 nn.Linear: 0.24027089774609 nn.Linear: 0.18154388666153 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22871826589108 nn.Linear: 0.43634021282196] nn.Sequential: [nn.Linear: 0.12273426353931 nn.Linear: 0.2240252494812]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007776828977753 nn.Linear: 0.00057419107767828 nn.Linear: 0.00031675912412416 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013910562665394 nn.Linear: 0.001830558732707] nn.Sequential: [nn.Linear: 0.00013215141494009 nn.Linear: 0.0011706335775105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.005882385186851 nn.Linear: 0.0092615289613605 nn.Linear: 0.0105653507635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057594287209213 nn.Linear: 0.015329140238464] nn.Sequential: [nn.Linear: 0.0042091994546354 nn.Linear: 0.012245052494109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062689608761657 nn.Linear: 0.065111764680016 nn.Linear: 0.045263471783515 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031507909656695 nn.Linear: 0.052472152176845] nn.Sequential: [nn.Linear: 0.031458227906511 nn.Linear: 0.035563966346156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50527793169022 nn.Linear: 0.24048580229282 nn.Linear: 0.18110708892345 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.22933393716812 nn.Linear: 0.43770217895508] nn.Sequential: [nn.Linear: 0.12309040874243 nn.Linear: 0.22467611730099]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015234200750321 nn.Linear: 0.00081031521517978 nn.Linear: 0.00033352894824216 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001487520915486 nn.Linear: 0.0020486492062623] nn.Sequential: [nn.Linear: 0.00010330302058852 nn.Linear: 0.00073332759129284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012115892954171 nn.Linear: 0.01309082377702 nn.Linear: 0.024793967604637 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075785438530147 nn.Linear: 0.018884174525738] nn.Sequential: [nn.Linear: 0.0049765617586672 nn.Linear: 0.0083892103284597]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062703450132548 nn.Linear: 0.065113792500806 nn.Linear: 0.045264974906931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031508440283504 nn.Linear: 0.052511261329386] nn.Sequential: [nn.Linear: 0.03145835732277 nn.Linear: 0.035569212298315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50577837228775 nn.Linear: 0.24026027321815 nn.Linear: 0.18102103471756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23010502755642 nn.Linear: 0.43894776701927] nn.Sequential: [nn.Linear: 0.12335573881865 nn.Linear: 0.22504930198193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021602978853407 nn.Linear: 0.0010539521495121 nn.Linear: 0.00032310305056961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 7.9106910798793e-05 nn.Linear: 0.00072922692700232] nn.Sequential: [nn.Linear: 7.1425546323029e-05 nn.Linear: 0.00045142261540215]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016192303970456 nn.Linear: 0.013041637837887 nn.Linear: 0.017481001093984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096246739849448 nn.Linear: 0.0052228476852179] nn.Sequential: [nn.Linear: 0.0031517096795142 nn.Linear: 0.0047540836967528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062700686936903 nn.Linear: 0.065118604981972 nn.Linear: 0.045266723446505 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031509142904454 nn.Linear: 0.052535670702682] nn.Sequential: [nn.Linear: 0.031458191304698 nn.Linear: 0.035568886176405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50581878423691 nn.Linear: 0.24039648473263 nn.Linear: 0.18144357204437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23136048018932 nn.Linear: 0.4401490688324] nn.Sequential: [nn.Linear: 0.12372057139874 nn.Linear: 0.22537623345852]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026422638351329 nn.Linear: 0.0013828100185838 nn.Linear: 0.00070328571162159 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029661871358466 nn.Linear: 0.003530371036697] nn.Sequential: [nn.Linear: 0.00023337013471051 nn.Linear: 0.0017791238698464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016394425183535 nn.Linear: 0.027220072224736 nn.Linear: 0.016855156049132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012457913719118 nn.Linear: 0.021839069202542] nn.Sequential: [nn.Linear: 0.0084429392591119 nn.Linear: 0.022650780156255]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	7990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062694482177599 nn.Linear: 0.065124043583457 nn.Linear: 0.045267796171793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031509413224821 nn.Linear: 0.052595541971812] nn.Sequential: [nn.Linear: 0.031458358501323 nn.Linear: 0.035579415875212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50575482845306 nn.Linear: 0.24041593074799 nn.Linear: 0.18217679858208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23245747387409 nn.Linear: 0.44134360551834] nn.Sequential: [nn.Linear: 0.1239228323102 nn.Linear: 0.22570089995861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011899553272694 nn.Linear: 0.00082758694321955 nn.Linear: 0.00043582645339319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014567042553146 nn.Linear: 0.0015429758401899] nn.Sequential: [nn.Linear: 0.00019103198908246 nn.Linear: 0.0014469605397058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076630339026451 nn.Linear: 0.015459466725588 nn.Linear: 0.0089982775971293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064917528070509 nn.Linear: 0.012432791292667] nn.Sequential: [nn.Linear: 0.0060562430880964 nn.Linear: 0.014675243757665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062693642506327 nn.Linear: 0.06512965418004 nn.Linear: 0.045270214495117 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031510035205713 nn.Linear: 0.052664070797192] nn.Sequential: [nn.Linear: 0.031458625113544 nn.Linear: 0.035612072011856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50598126649857 nn.Linear: 0.24046120047569 nn.Linear: 0.18331991136074 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23370714485645 nn.Linear: 0.44292402267456] nn.Sequential: [nn.Linear: 0.12443161010742 nn.Linear: 0.22634175419807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011194550797611 nn.Linear: 0.00073672186938529 nn.Linear: 0.00040444351845906 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019665476267863 nn.Linear: 0.002417269929625] nn.Sequential: [nn.Linear: 0.00012845734810758 nn.Linear: 0.00091055408741936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008070413954556 nn.Linear: 0.013365969993174 nn.Linear: 0.008400009945035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072398358024657 nn.Linear: 0.014881030656397] nn.Sequential: [nn.Linear: 0.0033296754118055 nn.Linear: 0.006525766570121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.096184822641313	TD error	0.01859539463371	Qmax	1	

Steps: 8000000 (frames: 32000000), score: 2023.66, higheset score: 6284, epsilon: 0.05, lr: 0.0005, training time: 542s, training rate: 1841fps, testing time: 88s, testing rate: 5653fps,  num. ep.: 352,  num. rewards: 18004	
   8   32    4    2
   2    8   64    4
   4   32   16  256
   2    4  512    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698477368822 nn.Linear: 0.065134500529232 nn.Linear: 0.045272117076998 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031510420491227 nn.Linear: 0.052697675417221] nn.Sequential: [nn.Linear: 0.03145907233686 nn.Linear: 0.035630218733694]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50642293691635 nn.Linear: 0.24070248007774 nn.Linear: 0.18314063549042 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23404157161713 nn.Linear: 0.44369965791702] nn.Sequential: [nn.Linear: 0.12470812350512 nn.Linear: 0.22639746963978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010527805790894 nn.Linear: 0.0007398077697207 nn.Linear: 0.00043744384090351 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019271765780815 nn.Linear: 0.0023610628789695] nn.Sequential: [nn.Linear: 0.00015818564597965 nn.Linear: 0.0011257846734725]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078004184179008 nn.Linear: 0.010141931474209 nn.Linear: 0.013525625690818 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075086038559675 nn.Linear: 0.019460355862975] nn.Sequential: [nn.Linear: 0.0061302133835852 nn.Linear: 0.011895990930498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062696435040179 nn.Linear: 0.06513744439325 nn.Linear: 0.045272981926185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03151062151889 nn.Linear: 0.052689484186033] nn.Sequential: [nn.Linear: 0.031459090751217 nn.Linear: 0.035632635897473]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50673705339432 nn.Linear: 0.24086661636829 nn.Linear: 0.18358239531517 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23518075048923 nn.Linear: 0.44441828131676] nn.Sequential: [nn.Linear: 0.12511925399303 nn.Linear: 0.22657829523087]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017847232989724 nn.Linear: 0.0010956665267381 nn.Linear: 0.00055679724925089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002803256512934 nn.Linear: 0.003541622988574] nn.Sequential: [nn.Linear: 0.00019399593539876 nn.Linear: 0.0013349507920484]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011365875601768 nn.Linear: 0.018339540809393 nn.Linear: 0.014723573811352 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010807535611093 nn.Linear: 0.026804575696588] nn.Sequential: [nn.Linear: 0.0064213229343295 nn.Linear: 0.013396812602878]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062704331823948 nn.Linear: 0.065145452949197 nn.Linear: 0.045276042228786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031511107801396 nn.Linear: 0.052723121230741] nn.Sequential: [nn.Linear: 0.031459652741565 nn.Linear: 0.035662486388903]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50655293464661 nn.Linear: 0.24086472392082 nn.Linear: 0.18318109214306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23598127067089 nn.Linear: 0.44538742303848] nn.Sequential: [nn.Linear: 0.12526743113995 nn.Linear: 0.22666762769222]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020081622303394 nn.Linear: 0.0011946900865868 nn.Linear: 0.00065215416752724 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000284530446441 nn.Linear: 0.0038928746831264] nn.Sequential: [nn.Linear: 0.00025388772805397 nn.Linear: 0.0023259815446047]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017275605350733 nn.Linear: 0.021531365811825 nn.Linear: 0.020461276173592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014467678032815 nn.Linear: 0.029327841475606] nn.Sequential: [nn.Linear: 0.0074786492623389 nn.Linear: 0.024356808513403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062714616686348 nn.Linear: 0.06515620071508 nn.Linear: 0.045280098474448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031511597444877 nn.Linear: 0.052744675934171] nn.Sequential: [nn.Linear: 0.031460191265517 nn.Linear: 0.035681000558323]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50631684064865 nn.Linear: 0.24160872399807 nn.Linear: 0.18250575661659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23627063632011 nn.Linear: 0.44644612073898] nn.Sequential: [nn.Linear: 0.12531244754791 nn.Linear: 0.2269371598959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014991856098508 nn.Linear: 0.00086256101268496 nn.Linear: 0.00046648858463913 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019310388396122 nn.Linear: 0.002375304214314] nn.Sequential: [nn.Linear: 0.0001864873565578 nn.Linear: 0.0015429791707495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094135738909245 nn.Linear: 0.012667800299823 nn.Linear: 0.020491046831012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012266101315618 nn.Linear: 0.02343513071537] nn.Sequential: [nn.Linear: 0.0049291187897325 nn.Linear: 0.01425345428288]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062707920565591 nn.Linear: 0.065157591813465 nn.Linear: 0.045281555268095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031511752015531 nn.Linear: 0.052751032681897] nn.Sequential: [nn.Linear: 0.031460379850795 nn.Linear: 0.035704618238293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5070669054985 nn.Linear: 0.24177940189838 nn.Linear: 0.18237525224686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23737032711506 nn.Linear: 0.4476366341114] nn.Sequential: [nn.Linear: 0.12565267086029 nn.Linear: 0.22732117772102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014893427267743 nn.Linear: 0.00078011543087531 nn.Linear: 0.00038166525645528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011764666854212 nn.Linear: 0.0012833955261078] nn.Sequential: [nn.Linear: 0.00017648464333912 nn.Linear: 0.001451926200927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01081411819905 nn.Linear: 0.011133286170661 nn.Linear: 0.006402550265193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051375138573349 nn.Linear: 0.010734133422375] nn.Sequential: [nn.Linear: 0.0097735291346908 nn.Linear: 0.021534128114581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062706195519532 nn.Linear: 0.065167530238468 nn.Linear: 0.045283578957039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031512050145597 nn.Linear: 0.052813400173967] nn.Sequential: [nn.Linear: 0.03146100223728 nn.Linear: 0.035709228363096]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50757819414139 nn.Linear: 0.24209402501583 nn.Linear: 0.18339502811432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23821073770523 nn.Linear: 0.44930666685104] nn.Sequential: [nn.Linear: 0.12600262463093 nn.Linear: 0.22793102264404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016884905376518 nn.Linear: 0.00081675086087817 nn.Linear: 0.00047190653548799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016496994537336 nn.Linear: 0.0018753493925336] nn.Sequential: [nn.Linear: 0.00020052113389742 nn.Linear: 0.0018410680051868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010116527788341 nn.Linear: 0.014667930081487 nn.Linear: 0.014194657094777 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082796588540077 nn.Linear: 0.014993859454989] nn.Sequential: [nn.Linear: 0.012896966189146 nn.Linear: 0.023881485685706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062709269893756 nn.Linear: 0.065169796355613 nn.Linear: 0.045285500747785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031512518046395 nn.Linear: 0.052820527952747] nn.Sequential: [nn.Linear: 0.031461202042251 nn.Linear: 0.035721366051175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.508171916008 nn.Linear: 0.24217057228088 nn.Linear: 0.18399403989315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.23937498033047 nn.Linear: 0.450086414814] nn.Sequential: [nn.Linear: 0.12642341852188 nn.Linear: 0.2278266698122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012534213214047 nn.Linear: 0.00072032714413141 nn.Linear: 0.00034664401870867 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014216770729756 nn.Linear: 0.0016013769094663] nn.Sequential: [nn.Linear: 0.0001474828673273 nn.Linear: 0.0010755965078707]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090264035388827 nn.Linear: 0.0096981786191463 nn.Linear: 0.013257757760584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068789515644312 nn.Linear: 0.014613177627325] nn.Sequential: [nn.Linear: 0.0048911524936557 nn.Linear: 0.012057163752615]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716663200519 nn.Linear: 0.065176236678936 nn.Linear: 0.045289084061584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031513081752119 nn.Linear: 0.052893843390386] nn.Sequential: [nn.Linear: 0.031461564391765 nn.Linear: 0.03573180545513]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5083481669426 nn.Linear: 0.24202661216259 nn.Linear: 0.18335437774658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2402192056179 nn.Linear: 0.45096546411514] nn.Sequential: [nn.Linear: 0.12676657736301 nn.Linear: 0.22854846715927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0038377261987646 nn.Linear: 0.0025373864028068 nn.Linear: 0.0012502375548841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00051136436374319 nn.Linear: 0.0066107294161832] nn.Sequential: [nn.Linear: 0.00039707577117259 nn.Linear: 0.003113971366684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.034333758056164 nn.Linear: 0.043512184172869 nn.Linear: 0.040322128683329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.036164380609989 nn.Linear: 0.067421242594719] nn.Sequential: [nn.Linear: 0.018672749400139 nn.Linear: 0.050063610076904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716402778403 nn.Linear: 0.065181867406607 nn.Linear: 0.045290880029933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031513525183947 nn.Linear: 0.052930295470361] nn.Sequential: [nn.Linear: 0.031461869243348 nn.Linear: 0.035742706405961]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50845259428024 nn.Linear: 0.24226833879948 nn.Linear: 0.18270353972912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24116198718548 nn.Linear: 0.45161464810371] nn.Sequential: [nn.Linear: 0.12711225450039 nn.Linear: 0.22892937064171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0053454723031322 nn.Linear: 0.0026637480601289 nn.Linear: 0.0010438298323975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00036412380012065 nn.Linear: 0.0048563434980273] nn.Sequential: [nn.Linear: 0.00030999899772836 nn.Linear: 0.0024596896793862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.042050030082464 nn.Linear: 0.045596230775118 nn.Linear: 0.021906070411205 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024010153487325 nn.Linear: 0.043067790567875] nn.Sequential: [nn.Linear: 0.012802273035049 nn.Linear: 0.019701816141605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062714932811919 nn.Linear: 0.065184625563036 nn.Linear: 0.045292013283336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031513728360563 nn.Linear: 0.052949356593436] nn.Sequential: [nn.Linear: 0.031462108438473 nn.Linear: 0.035757580995363]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50845152139664 nn.Linear: 0.2424056828022 nn.Linear: 0.18305806815624 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24191612005234 nn.Linear: 0.4513895213604] nn.Sequential: [nn.Linear: 0.12707950174809 nn.Linear: 0.2290947586298]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012368512249261 nn.Linear: 0.00085336099218517 nn.Linear: 0.00041443183535802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018927510193941 nn.Linear: 0.0024237687165699] nn.Sequential: [nn.Linear: 0.00013081066921531 nn.Linear: 0.00092802956267363]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090943900868297 nn.Linear: 0.014195491559803 nn.Linear: 0.0078628165647388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011183039285243 nn.Linear: 0.0188431981951] nn.Sequential: [nn.Linear: 0.003162435721606 nn.Linear: 0.0092963362112641]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062714259094214 nn.Linear: 0.065187445008421 nn.Linear: 0.045292757070491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03151408194993 nn.Linear: 0.052967264549807] nn.Sequential: [nn.Linear: 0.031462107786006 nn.Linear: 0.035761311000683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50961011648178 nn.Linear: 0.2427674382925 nn.Linear: 0.18285623192787 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24239848554134 nn.Linear: 0.45259600877762] nn.Sequential: [nn.Linear: 0.12740728259087 nn.Linear: 0.229547560215]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085969066397287 nn.Linear: 0.00047866266343164 nn.Linear: 0.00029830501230067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001474560874996 nn.Linear: 0.002173526547925] nn.Sequential: [nn.Linear: 0.00013794665421751 nn.Linear: 0.0010917244188107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056223487481475 nn.Linear: 0.0084335282444954 nn.Linear: 0.0082994699478149 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062628570012748 nn.Linear: 0.017155829817057] nn.Sequential: [nn.Linear: 0.0049665728583932 nn.Linear: 0.011920562013984]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062714341680232 nn.Linear: 0.065192863035321 nn.Linear: 0.045294056555814 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031514349536371 nn.Linear: 0.052976539504028] nn.Sequential: [nn.Linear: 0.031462216375722 nn.Linear: 0.035772172630714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50952816009521 nn.Linear: 0.24275965988636 nn.Linear: 0.18394848704338 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24341800808907 nn.Linear: 0.45312908291817] nn.Sequential: [nn.Linear: 0.12766487896442 nn.Linear: 0.22935900092125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0036166328026076 nn.Linear: 0.0021079946972533 nn.Linear: 0.0010503609774336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00038846094406024 nn.Linear: 0.0044065017799125] nn.Sequential: [nn.Linear: 0.00035639500703385 nn.Linear: 0.0023074984212904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022085698321462 nn.Linear: 0.026518151164055 nn.Linear: 0.024983996525407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013850264251232 nn.Linear: 0.029351176694036] nn.Sequential: [nn.Linear: 0.009345943108201 nn.Linear: 0.023770108819008]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062705721589038 nn.Linear: 0.065191654685266 nn.Linear: 0.045294797925499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031514647918932 nn.Linear: 0.053010819913002] nn.Sequential: [nn.Linear: 0.031462221174905 nn.Linear: 0.035775315873927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.50975281000137 nn.Linear: 0.24277339875698 nn.Linear: 0.18314787745476 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24416401982307 nn.Linear: 0.45442676544189] nn.Sequential: [nn.Linear: 0.12789544463158 nn.Linear: 0.22972013056278]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098411416695414 nn.Linear: 0.00060184254011744 nn.Linear: 0.00033119584215729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016110507356818 nn.Linear: 0.0022256185961468] nn.Sequential: [nn.Linear: 0.00011999944948935 nn.Linear: 0.00081641531020882]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064827767200768 nn.Linear: 0.011145158670843 nn.Linear: 0.0095717636868358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084529193118215 nn.Linear: 0.020356247201562] nn.Sequential: [nn.Linear: 0.0046105147339404 nn.Linear: 0.0079096769914031]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062699553289814 nn.Linear: 0.065194820024593 nn.Linear: 0.045295589005679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031514583869637 nn.Linear: 0.052961485979694] nn.Sequential: [nn.Linear: 0.031462441600136 nn.Linear: 0.035770487401804]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51024013757706 nn.Linear: 0.24282403290272 nn.Linear: 0.18449635803699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24522086977959 nn.Linear: 0.45470407605171] nn.Sequential: [nn.Linear: 0.12829910218716 nn.Linear: 0.22987341880798]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012249016576776 nn.Linear: 0.0007199686043282 nn.Linear: 0.00034118234724041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012433411126516 nn.Linear: 0.0013616786322339] nn.Sequential: [nn.Linear: 0.00015606163460125 nn.Linear: 0.0012307660522706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007373858243227 nn.Linear: 0.0081322221085429 nn.Linear: 0.0090757105499506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072073191404343 nn.Linear: 0.010661999695003] nn.Sequential: [nn.Linear: 0.0074763284064829 nn.Linear: 0.013230447657406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062700617429077 nn.Linear: 0.065199200671545 nn.Linear: 0.045297722256027 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031515059896723 nn.Linear: 0.053023419616096] nn.Sequential: [nn.Linear: 0.03146251990256 nn.Linear: 0.035791257352322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51070541143417 nn.Linear: 0.24378561973572 nn.Linear: 0.18402804434299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24632593989372 nn.Linear: 0.45577418804169] nn.Sequential: [nn.Linear: 0.12844888865948 nn.Linear: 0.23033782839775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030038401833139 nn.Linear: 0.00184431527214 nn.Linear: 0.00096269989957569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00038599073047538 nn.Linear: 0.0046723032569682] nn.Sequential: [nn.Linear: 0.00034368728094112 nn.Linear: 0.0022275183164309]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017878040671349 nn.Linear: 0.02598399668932 nn.Linear: 0.019401457160711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013980741612613 nn.Linear: 0.02707201987505] nn.Sequential: [nn.Linear: 0.010885840281844 nn.Linear: 0.024377558380365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062690822074275 nn.Linear: 0.065197996902764 nn.Linear: 0.045296637411792 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031515012467519 nn.Linear: 0.05301698740098] nn.Sequential: [nn.Linear: 0.031462394760394 nn.Linear: 0.035788759298372]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51169562339783 nn.Linear: 0.24358779191971 nn.Linear: 0.1854453086853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2472630739212 nn.Linear: 0.45627945661545] nn.Sequential: [nn.Linear: 0.12862592935562 nn.Linear: 0.23044671118259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015579820384541 nn.Linear: 0.00098374214785952 nn.Linear: 0.00049691873756063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023069565311547 nn.Linear: 0.002925830245846] nn.Sequential: [nn.Linear: 0.00019152668679306 nn.Linear: 0.0014107035016817]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085949162021279 nn.Linear: 0.022319292649627 nn.Linear: 0.015028076246381 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084041254594922 nn.Linear: 0.026046922430396] nn.Sequential: [nn.Linear: 0.0049783326685429 nn.Linear: 0.015993157401681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062688898251433 nn.Linear: 0.065203345996868 nn.Linear: 0.045298510989679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031515225147567 nn.Linear: 0.05301847821238] nn.Sequential: [nn.Linear: 0.031462631150692 nn.Linear: 0.035793555854822]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5118744969368 nn.Linear: 0.24422726035118 nn.Linear: 0.18489691615105 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24780239164829 nn.Linear: 0.45750543475151] nn.Sequential: [nn.Linear: 0.1288587898016 nn.Linear: 0.23084868490696]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0070758362222893 nn.Linear: 0.0030496157845931 nn.Linear: 0.0010027620575051 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034290568342766 nn.Linear: 0.0037487832022245] nn.Sequential: [nn.Linear: 0.00027564711961577 nn.Linear: 0.0018393143033019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.045321315526962 nn.Linear: 0.057082790881395 nn.Linear: 0.057487312704325 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014994846656919 nn.Linear: 0.038360361009836] nn.Sequential: [nn.Linear: 0.018729243427515 nn.Linear: 0.015946682542562]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684740809771 nn.Linear: 0.065208644094469 nn.Linear: 0.045300075945977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031515755233513 nn.Linear: 0.05306717939202] nn.Sequential: [nn.Linear: 0.031462722604684 nn.Linear: 0.035808374583597]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51171761751175 nn.Linear: 0.24424788355827 nn.Linear: 0.18442830443382 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24756902456284 nn.Linear: 0.45789223909378] nn.Sequential: [nn.Linear: 0.12917324900627 nn.Linear: 0.23123195767403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013706501491609 nn.Linear: 0.00086722902120339 nn.Linear: 0.00044581478013496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018780074861724 nn.Linear: 0.0022995507496456] nn.Sequential: [nn.Linear: 0.00017235383740077 nn.Linear: 0.0013220993194529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007941366173327 nn.Linear: 0.014560174196959 nn.Linear: 0.018537875264883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01295761950314 nn.Linear: 0.018771940842271] nn.Sequential: [nn.Linear: 0.0074430909007788 nn.Linear: 0.014559516683221]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062694701158079 nn.Linear: 0.065215477513149 nn.Linear: 0.045303525857896 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031516068428715 nn.Linear: 0.053117223207494] nn.Sequential: [nn.Linear: 0.031463353409053 nn.Linear: 0.035839080494448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51255720853806 nn.Linear: 0.24417893588543 nn.Linear: 0.1845006197691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24878437817097 nn.Linear: 0.45951870083809] nn.Sequential: [nn.Linear: 0.12939500808716 nn.Linear: 0.23163104057312]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011225640526483 nn.Linear: 0.00071585607893827 nn.Linear: 0.00039002480520592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017377083972037 nn.Linear: 0.0021652575758367] nn.Sequential: [nn.Linear: 0.0001631498132413 nn.Linear: 0.001107239717904]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085370941087604 nn.Linear: 0.011833584867418 nn.Linear: 0.0082372482866049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051809926517308 nn.Linear: 0.013906492851675] nn.Sequential: [nn.Linear: 0.0043162778019905 nn.Linear: 0.010403937660158]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062702112495795 nn.Linear: 0.065222733463824 nn.Linear: 0.045306176994773 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031516427339094 nn.Linear: 0.05314276725818] nn.Sequential: [nn.Linear: 0.031463742641309 nn.Linear: 0.035859344110197]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51315528154373 nn.Linear: 0.24436999857426 nn.Linear: 0.18499155342579 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.24942640960217 nn.Linear: 0.46048885583878] nn.Sequential: [nn.Linear: 0.12986285984516 nn.Linear: 0.23196163773537]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089996897359274 nn.Linear: 0.00058532880330226 nn.Linear: 0.0002947807343262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011365814636153 nn.Linear: 0.0012879243876608] nn.Sequential: [nn.Linear: 0.00012384645001946 nn.Linear: 0.00089682238180394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076970625668764 nn.Linear: 0.0091072954237461 nn.Linear: 0.0069307629019022 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055757672525942 nn.Linear: 0.0079483957961202] nn.Sequential: [nn.Linear: 0.0040460550226271 nn.Linear: 0.0079808467999101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062702978859307 nn.Linear: 0.065224065264353 nn.Linear: 0.045307063820775 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031516664675592 nn.Linear: 0.053147121118513] nn.Sequential: [nn.Linear: 0.031463930459268 nn.Linear: 0.035866365310294]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51291543245316 nn.Linear: 0.24460631608963 nn.Linear: 0.18422362208366 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25043317675591 nn.Linear: 0.46182808279991] nn.Sequential: [nn.Linear: 0.13009509444237 nn.Linear: 0.23258404433727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025456090852698 nn.Linear: 0.0012456626725587 nn.Linear: 0.00054423354419612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013856074485989 nn.Linear: 0.0012025390643489] nn.Sequential: [nn.Linear: 0.00019146099972873 nn.Linear: 0.0015671665875878]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017200004309416 nn.Linear: 0.030203517526388 nn.Linear: 0.025339622050524 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011338109150529 nn.Linear: 0.0080130770802498] nn.Sequential: [nn.Linear: 0.0058287777937949 nn.Linear: 0.018129462376237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718059864761 nn.Linear: 0.065236381779928 nn.Linear: 0.045310990588635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031517406986938 nn.Linear: 0.053230889926716] nn.Sequential: [nn.Linear: 0.031464387717331 nn.Linear: 0.035886015303414]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51256120204926 nn.Linear: 0.24392186105251 nn.Linear: 0.18467709422112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25193303823471 nn.Linear: 0.4641527235508] nn.Sequential: [nn.Linear: 0.13065692782402 nn.Linear: 0.23358190059662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016902989427916 nn.Linear: 0.0010558852652589 nn.Linear: 0.00056831855712367 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019908652975849 nn.Linear: 0.0020031487248502] nn.Sequential: [nn.Linear: 0.00017115513456814 nn.Linear: 0.0012051310283042]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011818425729871 nn.Linear: 0.016968371346593 nn.Linear: 0.014632845297456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0130411433056 nn.Linear: 0.015610229223967] nn.Sequential: [nn.Linear: 0.0042231827974319 nn.Linear: 0.011787300929427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06271722917673 nn.Linear: 0.065242104647446 nn.Linear: 0.045312325196746 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031517625807665 nn.Linear: 0.053252583306744] nn.Sequential: [nn.Linear: 0.031464381721217 nn.Linear: 0.035886969051369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51345348358154 nn.Linear: 0.2444399446249 nn.Linear: 0.1856043189764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25301173329353 nn.Linear: 0.46529069542885] nn.Sequential: [nn.Linear: 0.13097785413265 nn.Linear: 0.23373238742352]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010593233213177 nn.Linear: 0.00063682726976055 nn.Linear: 0.00031793985256227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014132581433926 nn.Linear: 0.0015377696940897] nn.Sequential: [nn.Linear: 0.00012262839603232 nn.Linear: 0.00079240206724234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066378121264279 nn.Linear: 0.0094655556604266 nn.Linear: 0.0070534902624786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055837719701231 nn.Linear: 0.011066043749452] nn.Sequential: [nn.Linear: 0.0030697365291417 nn.Linear: 0.0062614851631224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062710703452444 nn.Linear: 0.065248290509991 nn.Linear: 0.045313471993581 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03151815103866 nn.Linear: 0.053303571484875] nn.Sequential: [nn.Linear: 0.031464464499454 nn.Linear: 0.035884517404392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51360845565796 nn.Linear: 0.24483507871628 nn.Linear: 0.18653006851673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25329723954201 nn.Linear: 0.46616226434708] nn.Sequential: [nn.Linear: 0.13130456209183 nn.Linear: 0.23398850858212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011638194425325 nn.Linear: 0.00074542093159785 nn.Linear: 0.00043774032237501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002634408131184 nn.Linear: 0.0038734134566414] nn.Sequential: [nn.Linear: 0.00018203271430687 nn.Linear: 0.0014972346064492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070803705602884 nn.Linear: 0.013097183778882 nn.Linear: 0.012092566117644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079389484599233 nn.Linear: 0.021097684279084] nn.Sequential: [nn.Linear: 0.0056136050261557 nn.Linear: 0.021231865510345]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062709801710386 nn.Linear: 0.065252502669107 nn.Linear: 0.045316138292927 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031518378311938 nn.Linear: 0.053353490958074] nn.Sequential: [nn.Linear: 0.031464815458498 nn.Linear: 0.035905048718524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51471650600433 nn.Linear: 0.24516069889069 nn.Linear: 0.186637327075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25482475757599 nn.Linear: 0.46765622496605] nn.Sequential: [nn.Linear: 0.13152578473091 nn.Linear: 0.23459504544735]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015653439874473 nn.Linear: 0.001120510784039 nn.Linear: 0.00056773265145653 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022412117466812 nn.Linear: 0.0032942189989221] nn.Sequential: [nn.Linear: 0.00018821897703967 nn.Linear: 0.0013743561077729]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017191387712955 nn.Linear: 0.026645790785551 nn.Linear: 0.015878459438682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010396894998848 nn.Linear: 0.023017125204206] nn.Sequential: [nn.Linear: 0.0064621367491782 nn.Linear: 0.01684463955462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.09728922586143	TD error	0.018953024789691	Qmax	1	

Steps: 8250000 (frames: 33000000), score: 2057.35, higheset score: 6804, epsilon: 0.05, lr: 0.0005, training time: 542s, training rate: 1842fps, testing time: 88s, testing rate: 5641fps,  num. ep.: 371,  num. rewards: 18457	
   2    4    8    2
   4   16  256    4
   8  128   64  512
   4   16    4    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06270765547985 nn.Linear: 0.065253063806078 nn.Linear: 0.045315675585459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031518498246425 nn.Linear: 0.053336812549119] nn.Sequential: [nn.Linear: 0.031464616258656 nn.Linear: 0.035891059823124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51510953903198 nn.Linear: 0.2452740073204 nn.Linear: 0.18677493929863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25577610731125 nn.Linear: 0.46810671687126] nn.Sequential: [nn.Linear: 0.1317989975214 nn.Linear: 0.23448459804058]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098930274548544 nn.Linear: 0.00065208419887597 nn.Linear: 0.0003852440031356 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018465546620652 nn.Linear: 0.0027692247454634] nn.Sequential: [nn.Linear: 0.00017465831395547 nn.Linear: 0.0014499207075729]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065670921467245 nn.Linear: 0.011831430718303 nn.Linear: 0.0094148144125938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0095004681497812 nn.Linear: 0.016116691753268] nn.Sequential: [nn.Linear: 0.0053276550024748 nn.Linear: 0.012081739492714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062706690919927 nn.Linear: 0.065254511333127 nn.Linear: 0.045316949575525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03151895341454 nn.Linear: 0.053358072690912] nn.Sequential: [nn.Linear: 0.031464591975119 nn.Linear: 0.035890451077986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51558083295822 nn.Linear: 0.24534544348717 nn.Linear: 0.18681199848652 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25692489743233 nn.Linear: 0.46956220269203] nn.Sequential: [nn.Linear: 0.13215732574463 nn.Linear: 0.2348156273365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020596143944076 nn.Linear: 0.0011640672204321 nn.Linear: 0.00055593708120446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023857956969241 nn.Linear: 0.002566328713486] nn.Sequential: [nn.Linear: 0.00018960373673467 nn.Linear: 0.0012720311518424]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013208717107773 nn.Linear: 0.015441338531673 nn.Linear: 0.014314132742584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085763288661838 nn.Linear: 0.018071796745062] nn.Sequential: [nn.Linear: 0.0058656688779593 nn.Linear: 0.011350809596479]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062699934482158 nn.Linear: 0.065252629271944 nn.Linear: 0.045316722913623 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031518976276189 nn.Linear: 0.053323383062065] nn.Sequential: [nn.Linear: 0.031464349505458 nn.Linear: 0.035895598924072]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51574373245239 nn.Linear: 0.24488620460033 nn.Linear: 0.18666945397854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25738251209259 nn.Linear: 0.47015881538391] nn.Sequential: [nn.Linear: 0.13239800930023 nn.Linear: 0.23504915833473]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0037147165909663 nn.Linear: 0.0017078091511101 nn.Linear: 0.0006651426665065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028550968851748 nn.Linear: 0.004250716921508] nn.Sequential: [nn.Linear: 0.00019940094968288 nn.Linear: 0.0014598499018479]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.02616380341351 nn.Linear: 0.024399178102612 nn.Linear: 0.043872069567442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019071584567428 nn.Linear: 0.036478769034147] nn.Sequential: [nn.Linear: 0.0062316288240254 nn.Linear: 0.012934533879161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06269894958154 nn.Linear: 0.065257031698878 nn.Linear: 0.045317219058506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031518920261871 nn.Linear: 0.053316835603269] nn.Sequential: [nn.Linear: 0.031464701323554 nn.Linear: 0.035907725689254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51550954580307 nn.Linear: 0.24533516168594 nn.Linear: 0.18651376664639 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25825023651123 nn.Linear: 0.47210496664047] nn.Sequential: [nn.Linear: 0.13261014223099 nn.Linear: 0.23562796413898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00055422216365337 nn.Linear: 0.00034832786526422 nn.Linear: 0.00022654810434714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.512391813286e-05 nn.Linear: 0.0010719978608857] nn.Sequential: [nn.Linear: 8.4266851024167e-05 nn.Linear: 0.00065036453074147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0037738236133009 nn.Linear: 0.0053873308934271 nn.Linear: 0.0045312605798244 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0038015516474843 nn.Linear: 0.0063812145963311] nn.Sequential: [nn.Linear: 0.0020463122054935 nn.Linear: 0.0064217685721815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062706325460068 nn.Linear: 0.065266219138167 nn.Linear: 0.045318242036306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031519260255261 nn.Linear: 0.053298579700481] nn.Sequential: [nn.Linear: 0.031465108812782 nn.Linear: 0.035901130969421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51530259847641 nn.Linear: 0.24514882266521 nn.Linear: 0.18710592389107 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.25959932804108 nn.Linear: 0.4734895825386] nn.Sequential: [nn.Linear: 0.13321036100388 nn.Linear: 0.23610818386078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014357196568765 nn.Linear: 0.00095838877456264 nn.Linear: 0.00041680328068553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018606125461751 nn.Linear: 0.0025172118653498] nn.Sequential: [nn.Linear: 0.00015661546132477 nn.Linear: 0.0010993431834678]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094216438010335 nn.Linear: 0.012624362483621 nn.Linear: 0.008704911917448 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081780422478914 nn.Linear: 0.01907255500555] nn.Sequential: [nn.Linear: 0.0053132325410843 nn.Linear: 0.010661792941391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698619171599 nn.Linear: 0.065266908539032 nn.Linear: 0.045318803441315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031519480168612 nn.Linear: 0.053330877743804] nn.Sequential: [nn.Linear: 0.031464873968377 nn.Linear: 0.035909346065001]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51579761505127 nn.Linear: 0.24525468051434 nn.Linear: 0.18747454881668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26065948605537 nn.Linear: 0.47401538491249] nn.Sequential: [nn.Linear: 0.13331805169582 nn.Linear: 0.23601870238781]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016348238981323 nn.Linear: 0.0011074507827341 nn.Linear: 0.00057946894351088 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022797734981567 nn.Linear: 0.0024981038129557] nn.Sequential: [nn.Linear: 0.00021330004706715 nn.Linear: 0.0019448077566094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011868072673678 nn.Linear: 0.014445640146732 nn.Linear: 0.010715814307332 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090130725875497 nn.Linear: 0.014211977832019] nn.Sequential: [nn.Linear: 0.006376557983458 nn.Linear: 0.02044845931232]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062695627953361 nn.Linear: 0.065269684323385 nn.Linear: 0.045319509115483 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031519577001781 nn.Linear: 0.05333503580281] nn.Sequential: [nn.Linear: 0.031464824298736 nn.Linear: 0.035913251780764]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51605403423309 nn.Linear: 0.2451243698597 nn.Linear: 0.18764038383961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26089945435524 nn.Linear: 0.47516405582428] nn.Sequential: [nn.Linear: 0.1333292722702 nn.Linear: 0.236357614398]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027671322319665 nn.Linear: 0.0014790594071494 nn.Linear: 0.00063196571376614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022609189193453 nn.Linear: 0.0027003949826159] nn.Sequential: [nn.Linear: 0.00022420641588739 nn.Linear: 0.0017723773396072]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025471085682511 nn.Linear: 0.034223567694426 nn.Linear: 0.016637686640024 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011304147541523 nn.Linear: 0.020714381709695] nn.Sequential: [nn.Linear: 0.0073076891712844 nn.Linear: 0.015801303088665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062690521606451 nn.Linear: 0.065269997529206 nn.Linear: 0.045320595866346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031519811246613 nn.Linear: 0.053358176897348] nn.Sequential: [nn.Linear: 0.031464679503862 nn.Linear: 0.035915128315646]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51639604568481 nn.Linear: 0.24565857648849 nn.Linear: 0.18706005811691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2616870701313 nn.Linear: 0.47648245096207] nn.Sequential: [nn.Linear: 0.13340948522091 nn.Linear: 0.2367737442255]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016957793390165 nn.Linear: 0.0009088691246424 nn.Linear: 0.00045113134641247 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001246564485965 nn.Linear: 0.0011248457220678] nn.Sequential: [nn.Linear: 0.00017144767841176 nn.Linear: 0.0013022506817173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013232138939202 nn.Linear: 0.019186299294233 nn.Linear: 0.026421068236232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01318184658885 nn.Linear: 0.0084510101005435] nn.Sequential: [nn.Linear: 0.0060462071560323 nn.Linear: 0.017152182757854]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062685020172987 nn.Linear: 0.065270210676892 nn.Linear: 0.045322117779991 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031520181728811 nn.Linear: 0.053355599762767] nn.Sequential: [nn.Linear: 0.031464859612764 nn.Linear: 0.035909283662665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51623922586441 nn.Linear: 0.24595314264297 nn.Linear: 0.18822349607944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2626146376133 nn.Linear: 0.47790053486824] nn.Sequential: [nn.Linear: 0.13397963345051 nn.Linear: 0.23699904978275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012650675729652 nn.Linear: 0.0007032078911695 nn.Linear: 0.00037114984181441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015063897177055 nn.Linear: 0.001872415021839] nn.Sequential: [nn.Linear: 0.00013383822829635 nn.Linear: 0.00099705664396716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008074002340436 nn.Linear: 0.010979749262333 nn.Linear: 0.012459486722946 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005656111985445 nn.Linear: 0.018090510740876] nn.Sequential: [nn.Linear: 0.0038134756032377 nn.Linear: 0.010534457862377]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062688628431675 nn.Linear: 0.065272529982632 nn.Linear: 0.045322636468516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031520300229936 nn.Linear: 0.053325222357062] nn.Sequential: [nn.Linear: 0.031464880262331 nn.Linear: 0.035917770390173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51635158061981 nn.Linear: 0.24633093178272 nn.Linear: 0.18825761973858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26344588398933 nn.Linear: 0.47831451892853] nn.Sequential: [nn.Linear: 0.13405129313469 nn.Linear: 0.23703327775002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012634406371496 nn.Linear: 0.00073964399242472 nn.Linear: 0.00039498212192371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013425780050478 nn.Linear: 0.0013407154501854] nn.Sequential: [nn.Linear: 0.00019529006998014 nn.Linear: 0.0016042569176033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009913737885654 nn.Linear: 0.010969819501042 nn.Linear: 0.0077492953278124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050240326672792 nn.Linear: 0.0092497328296304] nn.Sequential: [nn.Linear: 0.0070697269402444 nn.Linear: 0.020638598129153]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684795114308 nn.Linear: 0.065273410688746 nn.Linear: 0.045323638926738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031520489832245 nn.Linear: 0.053341692280355] nn.Sequential: [nn.Linear: 0.031465112216985 nn.Linear: 0.035915797454771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51556807756424 nn.Linear: 0.2463746368885 nn.Linear: 0.18746273219585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26414075493813 nn.Linear: 0.47927594184875] nn.Sequential: [nn.Linear: 0.134182497859 nn.Linear: 0.23743499815464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026323598002851 nn.Linear: 0.0017248831193037 nn.Linear: 0.00096322010830454 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00035208112373154 nn.Linear: 0.0046675864319732] nn.Sequential: [nn.Linear: 0.00032725437535206 nn.Linear: 0.0026389418548784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021752692759037 nn.Linear: 0.036361020058393 nn.Linear: 0.032167293131351 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019788846373558 nn.Linear: 0.046356976032257] nn.Sequential: [nn.Linear: 0.020936487242579 nn.Linear: 0.024378467351198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062674613645155 nn.Linear: 0.065272478350162 nn.Linear: 0.045323543625545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031520606976757 nn.Linear: 0.053335414678941] nn.Sequential: [nn.Linear: 0.031464960083548 nn.Linear: 0.035915207597263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51537144184113 nn.Linear: 0.24663147330284 nn.Linear: 0.18719628453255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26515007019043 nn.Linear: 0.4799847304821] nn.Sequential: [nn.Linear: 0.13436555862427 nn.Linear: 0.23725211620331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0048331448512198 nn.Linear: 0.0020129687502619 nn.Linear: 0.0007182694436978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018559307352535 nn.Linear: 0.0022843935608417] nn.Sequential: [nn.Linear: 0.00016408259416071 nn.Linear: 0.0010914262685886]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025592740625143 nn.Linear: 0.030018344521523 nn.Linear: 0.037785079330206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01132316980511 nn.Linear: 0.012415248900652] nn.Sequential: [nn.Linear: 0.011013409122825 nn.Linear: 0.014824919402599]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06267359938798 nn.Linear: 0.065277094069847 nn.Linear: 0.045324416522396 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031520909555417 nn.Linear: 0.0533198254453] nn.Sequential: [nn.Linear: 0.031465122835915 nn.Linear: 0.035912749438792]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5156512260437 nn.Linear: 0.24685031175613 nn.Linear: 0.188067689538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26613560318947 nn.Linear: 0.48121151328087] nn.Sequential: [nn.Linear: 0.13465540111065 nn.Linear: 0.23776030540466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00071678309710763 nn.Linear: 0.00050111165941911 nn.Linear: 0.00026036750051848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001017590949124 nn.Linear: 0.0010701668701744] nn.Sequential: [nn.Linear: 0.00010134883341705 nn.Linear: 0.00083554538346396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056719365529716 nn.Linear: 0.0074009229429066 nn.Linear: 0.0042727119289339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047691748477519 nn.Linear: 0.0071106306277215] nn.Sequential: [nn.Linear: 0.0037180238869041 nn.Linear: 0.008770857937634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678927091465 nn.Linear: 0.065282581944207 nn.Linear: 0.045325196363872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03152104326837 nn.Linear: 0.053338802811993] nn.Sequential: [nn.Linear: 0.031465265644126 nn.Linear: 0.035925164220039]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51608610153198 nn.Linear: 0.24641606211662 nn.Linear: 0.18732975423336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2667578458786 nn.Linear: 0.48201438784599] nn.Sequential: [nn.Linear: 0.13480734825134 nn.Linear: 0.23789472877979]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010050005905154 nn.Linear: 0.00052265360782427 nn.Linear: 0.00023488110995933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.6356654507536e-05 nn.Linear: 0.0011925363328964] nn.Sequential: [nn.Linear: 8.041778812584e-05 nn.Linear: 0.0005155356083154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076153981499374 nn.Linear: 0.0077322372235358 nn.Linear: 0.0071904323995113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0034834044054151 nn.Linear: 0.0092185884714127] nn.Sequential: [nn.Linear: 0.0022886351216584 nn.Linear: 0.0052407965995371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062666806517443 nn.Linear: 0.065283717120812 nn.Linear: 0.045325819829574 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031521006120392 nn.Linear: 0.053360920891862] nn.Sequential: [nn.Linear: 0.031465277836627 nn.Linear: 0.035925765034163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51652306318283 nn.Linear: 0.24670547246933 nn.Linear: 0.1875624358654 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26756536960602 nn.Linear: 0.48257929086685] nn.Sequential: [nn.Linear: 0.13499486446381 nn.Linear: 0.23800849914551]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015605739824456 nn.Linear: 0.00084728736701811 nn.Linear: 0.00043298599719747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015576296057767 nn.Linear: 0.001667086162163] nn.Sequential: [nn.Linear: 0.00016222747413711 nn.Linear: 0.0013515165256175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094391796737909 nn.Linear: 0.0097178323194385 nn.Linear: 0.0090814204886556 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088789295405149 nn.Linear: 0.01369190774858] nn.Sequential: [nn.Linear: 0.0064673749729991 nn.Linear: 0.016405519098043]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062664174467448 nn.Linear: 0.065286156142949 nn.Linear: 0.045326178458789 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031521368968568 nn.Linear: 0.053390291565165] nn.Sequential: [nn.Linear: 0.031465356761412 nn.Linear: 0.035931326495135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51634800434113 nn.Linear: 0.24663366377354 nn.Linear: 0.18798641860485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2681593298912 nn.Linear: 0.48352032899857] nn.Sequential: [nn.Linear: 0.13571372628212 nn.Linear: 0.23826560378075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001076166956002 nn.Linear: 0.00070632471172849 nn.Linear: 0.00042039058591672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020873176979523 nn.Linear: 0.0028909789948028] nn.Sequential: [nn.Linear: 0.00014506661969459 nn.Linear: 0.001037257765278]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084789302200079 nn.Linear: 0.011135469190776 nn.Linear: 0.0099456068128347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00806940253824 nn.Linear: 0.019196504727006] nn.Sequential: [nn.Linear: 0.0037914847489446 nn.Linear: 0.0087746204808354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672675316928 nn.Linear: 0.06528970605743 nn.Linear: 0.045326599869393 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031521693241189 nn.Linear: 0.053403315322328] nn.Sequential: [nn.Linear: 0.03146540586007 nn.Linear: 0.035949975924932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51652127504349 nn.Linear: 0.24650517106056 nn.Linear: 0.18781913816929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26903876662254 nn.Linear: 0.48414880037308] nn.Sequential: [nn.Linear: 0.13591861724854 nn.Linear: 0.2378396987915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024812905040494 nn.Linear: 0.0015359121928649 nn.Linear: 0.0010486688404305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00044267482039119 nn.Linear: 0.0056555052795162] nn.Sequential: [nn.Linear: 0.00046690923177322 nn.Linear: 0.0043715884760879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019746538251638 nn.Linear: 0.02428943105042 nn.Linear: 0.031889885663986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.023001104593277 nn.Linear: 0.047727040946484] nn.Sequential: [nn.Linear: 0.031154371798038 nn.Linear: 0.053590584546328]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678017953207 nn.Linear: 0.065298663234255 nn.Linear: 0.045328830425209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031522153904373 nn.Linear: 0.053412996736469] nn.Sequential: [nn.Linear: 0.031465909643759 nn.Linear: 0.035962579620405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51688688993454 nn.Linear: 0.24664525687695 nn.Linear: 0.18874345719814 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.26953613758087 nn.Linear: 0.48483696579933] nn.Sequential: [nn.Linear: 0.13611868023872 nn.Linear: 0.23798209428787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013817177849125 nn.Linear: 0.00077576921279161 nn.Linear: 0.00032767389774761 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010144365074221 nn.Linear: 0.00092172896649911] nn.Sequential: [nn.Linear: 0.00013061936823812 nn.Linear: 0.0011671094271301]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008824379183352 nn.Linear: 0.010329810902476 nn.Linear: 0.0080799357965589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057232868857682 nn.Linear: 0.0072453692555428] nn.Sequential: [nn.Linear: 0.0042175510898232 nn.Linear: 0.013597236946225]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062679688097513 nn.Linear: 0.065305382511937 nn.Linear: 0.045331929764941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031522520797441 nn.Linear: 0.053446813247312] nn.Sequential: [nn.Linear: 0.031466268772595 nn.Linear: 0.035969386558742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51761215925217 nn.Linear: 0.24721412360668 nn.Linear: 0.18912129104137 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27050825953484 nn.Linear: 0.48590877652168] nn.Sequential: [nn.Linear: 0.13622623682022 nn.Linear: 0.23826944828033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085724351910631 nn.Linear: 0.00058066403858767 nn.Linear: 0.00029765809612659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010493238413389 nn.Linear: 0.00099239676729969] nn.Sequential: [nn.Linear: 0.00012386222345505 nn.Linear: 0.0008933203845322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064676296897233 nn.Linear: 0.0081419590860605 nn.Linear: 0.0095867970958352 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006684445310384 nn.Linear: 0.0075923595577478] nn.Sequential: [nn.Linear: 0.0046990429982543 nn.Linear: 0.0082539962604642]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678212592966 nn.Linear: 0.065305990084525 nn.Linear: 0.045332599663388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03152277065297 nn.Linear: 0.053472032991749] nn.Sequential: [nn.Linear: 0.031466144666341 nn.Linear: 0.035968897812111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51834106445312 nn.Linear: 0.24720595777035 nn.Linear: 0.18943357467651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27118623256683 nn.Linear: 0.48674118518829] nn.Sequential: [nn.Linear: 0.13628631830215 nn.Linear: 0.23858578503132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00066740514347257 nn.Linear: 0.00040936945204061 nn.Linear: 0.00020267313870374 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.902073260709e-05 nn.Linear: 0.00095455239546624] nn.Sequential: [nn.Linear: 7.3122126148075e-05 nn.Linear: 0.00045708281384772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0038349190726876 nn.Linear: 0.0051843919791281 nn.Linear: 0.0038976720534265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044723749160767 nn.Linear: 0.0075232125818729] nn.Sequential: [nn.Linear: 0.0036081308498979 nn.Linear: 0.0047429809346795]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062681375105121 nn.Linear: 0.065307060464361 nn.Linear: 0.045333261046749 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031522941245889 nn.Linear: 0.053481297804467] nn.Sequential: [nn.Linear: 0.031466521080456 nn.Linear: 0.035993927873939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51855373382568 nn.Linear: 0.24735204875469 nn.Linear: 0.1894905269146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27163392305374 nn.Linear: 0.48780688643456] nn.Sequential: [nn.Linear: 0.13659350574017 nn.Linear: 0.23906780779362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010299965877328 nn.Linear: 0.00056110342061929 nn.Linear: 0.00031104758235834 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012853265482838 nn.Linear: 0.0016453385929192] nn.Sequential: [nn.Linear: 0.000117909479079 nn.Linear: 0.0009752972145055]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065427455119789 nn.Linear: 0.010047908872366 nn.Linear: 0.0057602790184319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005339752882719 nn.Linear: 0.0088997520506382] nn.Sequential: [nn.Linear: 0.0039603495970368 nn.Linear: 0.0089025450870395]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062676711888574 nn.Linear: 0.065310002551918 nn.Linear: 0.045334276909432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031523147741743 nn.Linear: 0.053498341683255] nn.Sequential: [nn.Linear: 0.031466449878381 nn.Linear: 0.035985951313179]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51919937133789 nn.Linear: 0.24688726663589 nn.Linear: 0.18999935686588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2724404335022 nn.Linear: 0.48830807209015] nn.Sequential: [nn.Linear: 0.13686515390873 nn.Linear: 0.23908343911171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010370906576403 nn.Linear: 0.00049329804607908 nn.Linear: 0.00027866577481862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011808771070223 nn.Linear: 0.0014401972319722] nn.Sequential: [nn.Linear: 0.00011311426585769 nn.Linear: 0.00088483788338672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0069857412017882 nn.Linear: 0.0098567986860871 nn.Linear: 0.0073762135580182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0049795531667769 nn.Linear: 0.01162348780781] nn.Sequential: [nn.Linear: 0.0036574373953044 nn.Linear: 0.0092423669993877]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062675018523628 nn.Linear: 0.065309115862602 nn.Linear: 0.04533451919937 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031523170858354 nn.Linear: 0.053499701447862] nn.Sequential: [nn.Linear: 0.031466492543048 nn.Linear: 0.03598796327489]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51901084184647 nn.Linear: 0.24693840742111 nn.Linear: 0.18944706022739 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27317813038826 nn.Linear: 0.48888769745827] nn.Sequential: [nn.Linear: 0.13707587122917 nn.Linear: 0.23910950124264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00062388168086002 nn.Linear: 0.00048012685610803 nn.Linear: 0.00029780066933635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012712255075316 nn.Linear: 0.0016011374630933] nn.Sequential: [nn.Linear: 0.0001303449964415 nn.Linear: 0.0011041838196495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057896953076124 nn.Linear: 0.0092133991420269 nn.Linear: 0.0051324819214642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0041759223677218 nn.Linear: 0.010327197611332] nn.Sequential: [nn.Linear: 0.0049427654594183 nn.Linear: 0.0095108626410365]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062679949031081 nn.Linear: 0.065314661492744 nn.Linear: 0.045337406767575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031523470155069 nn.Linear: 0.053510559571919] nn.Sequential: [nn.Linear: 0.031466805440275 nn.Linear: 0.035999450370795]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51893973350525 nn.Linear: 0.24715067446232 nn.Linear: 0.19018888473511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27407932281494 nn.Linear: 0.48957926034927] nn.Sequential: [nn.Linear: 0.13715048134327 nn.Linear: 0.23925505578518]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094086431130503 nn.Linear: 0.00053231751421859 nn.Linear: 0.00027317066138625 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011832901180764 nn.Linear: 0.0015364101140523] nn.Sequential: [nn.Linear: 0.00010537938613058 nn.Linear: 0.00070981403056129]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0056556300260127 nn.Linear: 0.0069476114585996 nn.Linear: 0.0073118563741446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062174987979233 nn.Linear: 0.014212010428309] nn.Sequential: [nn.Linear: 0.0034426066558808 nn.Linear: 0.0064178132452071]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062680382800171 nn.Linear: 0.065316008570515 nn.Linear: 0.045337314211861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031523539882037 nn.Linear: 0.053518455881033] nn.Sequential: [nn.Linear: 0.031466899265056 nn.Linear: 0.036018636536748]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.518734395504 nn.Linear: 0.24716234207153 nn.Linear: 0.18985788524151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27428558468819 nn.Linear: 0.49031743407249] nn.Sequential: [nn.Linear: 0.13735389709473 nn.Linear: 0.23931838572025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091447915497155 nn.Linear: 0.00055757784521986 nn.Linear: 0.00033737072261184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018117710926906 nn.Linear: 0.0024541758952623] nn.Sequential: [nn.Linear: 0.00012845560604031 nn.Linear: 0.00091200478230935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060172802768648 nn.Linear: 0.0097487801685929 nn.Linear: 0.015093919821084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076314504258335 nn.Linear: 0.018670815974474] nn.Sequential: [nn.Linear: 0.0034863159526139 nn.Linear: 0.0099338442087173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.082388330049813	TD error	0.017817586954683	Qmax	1	

Steps: 8500000 (frames: 34000000), score: 2058.03, higheset score: 6820, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1840fps, testing time: 88s, testing rate: 5657fps,  num. ep.: 270,  num. rewards: 15232	
   2    4    8    4
   4    8   32    2
   8  256  128    4
   4   64    4  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062691967112142 nn.Linear: 0.065320069669029 nn.Linear: 0.045338541407596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031523864726399 nn.Linear: 0.053565422086137] nn.Sequential: [nn.Linear: 0.031467168575752 nn.Linear: 0.036031528221992]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51896160840988 nn.Linear: 0.24745406210423 nn.Linear: 0.19103725254536 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27545258402824 nn.Linear: 0.49100837111473] nn.Sequential: [nn.Linear: 0.13792152702808 nn.Linear: 0.23934692144394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015177353687709 nn.Linear: 0.00092612800270584 nn.Linear: 0.00051924857953234 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002440931079249 nn.Linear: 0.0027839945477677] nn.Sequential: [nn.Linear: 0.00019354636172261 nn.Linear: 0.0013428892300806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011686681769788 nn.Linear: 0.01520914118737 nn.Linear: 0.010539395734668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079364748671651 nn.Linear: 0.017580699175596] nn.Sequential: [nn.Linear: 0.0055783996358514 nn.Linear: 0.011870854534209]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062680284119161 nn.Linear: 0.065326045563518 nn.Linear: 0.045340594550191 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031524333171474 nn.Linear: 0.053586688846764] nn.Sequential: [nn.Linear: 0.031467318628468 nn.Linear: 0.036024527631748]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51927959918976 nn.Linear: 0.24841374158859 nn.Linear: 0.19087734818459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27535793185234 nn.Linear: 0.49205747246742] nn.Sequential: [nn.Linear: 0.13827331364155 nn.Linear: 0.2395850867033]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001487983541593 nn.Linear: 0.00086268738838731 nn.Linear: 0.00039679638168049 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015529188124442 nn.Linear: 0.0018349602374985] nn.Sequential: [nn.Linear: 0.00013704574959147 nn.Linear: 0.0010157441592978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015608779154718 nn.Linear: 0.013800139538944 nn.Linear: 0.013259106315672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059317192062736 nn.Linear: 0.014550515450537] nn.Sequential: [nn.Linear: 0.0055520553141832 nn.Linear: 0.0088832126930356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062671287299052 nn.Linear: 0.065330366225025 nn.Linear: 0.045342045661119 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031524690692694 nn.Linear: 0.05363801175713] nn.Sequential: [nn.Linear: 0.031467462461327 nn.Linear: 0.036034456827275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51922398805618 nn.Linear: 0.24846735596657 nn.Linear: 0.19083520770073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27617451548576 nn.Linear: 0.4930684864521] nn.Sequential: [nn.Linear: 0.13834244012833 nn.Linear: 0.23997028172016]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002105110045871 nn.Linear: 0.0013056704400342 nn.Linear: 0.00062401469665242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021272554114732 nn.Linear: 0.0024660086780643] nn.Sequential: [nn.Linear: 0.00026539544521922 nn.Linear: 0.0021470507952007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014609861187637 nn.Linear: 0.017363872379065 nn.Linear: 0.011886829510331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010476001538336 nn.Linear: 0.014737972989678] nn.Sequential: [nn.Linear: 0.010013681836426 nn.Linear: 0.031161949038506]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062669464267746 nn.Linear: 0.065333469011029 nn.Linear: 0.045343549401855 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031525027238178 nn.Linear: 0.053669464987195] nn.Sequential: [nn.Linear: 0.031467547991861 nn.Linear: 0.036061210755436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52014017105103 nn.Linear: 0.24852760136127 nn.Linear: 0.19056467711926 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27693721652031 nn.Linear: 0.49372306466103] nn.Sequential: [nn.Linear: 0.13883711397648 nn.Linear: 0.24021700024605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010674831767011 nn.Linear: 0.00058032737187765 nn.Linear: 0.00033141683101843 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014700929696031 nn.Linear: 0.0018229475414659] nn.Sequential: [nn.Linear: 0.00011751026315339 nn.Linear: 0.00078792192314234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071110087446868 nn.Linear: 0.009119039401412 nn.Linear: 0.0092011289671063 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047645517624915 nn.Linear: 0.01411459222436] nn.Sequential: [nn.Linear: 0.0050643365830183 nn.Linear: 0.005698402877897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062672700100162 nn.Linear: 0.065337103606685 nn.Linear: 0.045344907353661 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03152532563353 nn.Linear: 0.053684805892132] nn.Sequential: [nn.Linear: 0.031467579722886 nn.Linear: 0.036074305825632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51986885070801 nn.Linear: 0.24866743385792 nn.Linear: 0.19115023314953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27733689546585 nn.Linear: 0.49489840865135] nn.Sequential: [nn.Linear: 0.13908743858337 nn.Linear: 0.24067234992981]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0032052093284551 nn.Linear: 0.0016983077866513 nn.Linear: 0.00068052476682395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023026871929314 nn.Linear: 0.0026418766449199] nn.Sequential: [nn.Linear: 0.00023402661751917 nn.Linear: 0.0015743417767519]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019357644021511 nn.Linear: 0.024042677134275 nn.Linear: 0.019053280353546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012465158477426 nn.Linear: 0.020019937306643] nn.Sequential: [nn.Linear: 0.019054688513279 nn.Linear: 0.019226497039199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062674653122368 nn.Linear: 0.065340343613777 nn.Linear: 0.045346109302578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031525765532653 nn.Linear: 0.053690751119305] nn.Sequential: [nn.Linear: 0.031467581724887 nn.Linear: 0.036060499779007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.51978069543839 nn.Linear: 0.24897177517414 nn.Linear: 0.19101855158806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27829170227051 nn.Linear: 0.49593958258629] nn.Sequential: [nn.Linear: 0.13958199322224 nn.Linear: 0.24056895077229]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009445041420941 nn.Linear: 0.00056590937555295 nn.Linear: 0.00034990591258983 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016436947728128 nn.Linear: 0.0020885302866915] nn.Sequential: [nn.Linear: 0.00013342988937288 nn.Linear: 0.00089477149370291]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067200339399278 nn.Linear: 0.0085317362099886 nn.Linear: 0.005908478051424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054792580194771 nn.Linear: 0.015572779811919] nn.Sequential: [nn.Linear: 0.0049745100550354 nn.Linear: 0.0072427117265761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06267507848061 nn.Linear: 0.065345370129622 nn.Linear: 0.045346976262866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031525677295786 nn.Linear: 0.053679496325824] nn.Sequential: [nn.Linear: 0.031467879039138 nn.Linear: 0.036068436399693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52003526687622 nn.Linear: 0.24893595278263 nn.Linear: 0.19125208258629 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27862700819969 nn.Linear: 0.49688598513603] nn.Sequential: [nn.Linear: 0.13982024788857 nn.Linear: 0.24092096090317]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0006518140901503 nn.Linear: 0.00043568108679247 nn.Linear: 0.00027113025596756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011171468441588 nn.Linear: 0.0012856997711581] nn.Sequential: [nn.Linear: 0.00011979892644295 nn.Linear: 0.00094112640463617]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049674771726131 nn.Linear: 0.0063028782606125 nn.Linear: 0.0057503995485604 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061275120824575 nn.Linear: 0.0085495756939054] nn.Sequential: [nn.Linear: 0.0050676860846579 nn.Linear: 0.0087189003825188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06268450524845 nn.Linear: 0.065346129105057 nn.Linear: 0.045348251465473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031525984595636 nn.Linear: 0.053729926752887] nn.Sequential: [nn.Linear: 0.031468002409574 nn.Linear: 0.036086724072421]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52044928073883 nn.Linear: 0.24894948303699 nn.Linear: 0.19106757640839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.27976217865944 nn.Linear: 0.49789246916771] nn.Sequential: [nn.Linear: 0.14025940001011 nn.Linear: 0.24102781713009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015543951308526 nn.Linear: 0.00096683270726757 nn.Linear: 0.00045629598732888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016055718584452 nn.Linear: 0.001680932275545] nn.Sequential: [nn.Linear: 0.00016318921420975 nn.Linear: 0.0010696310198574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012936670333147 nn.Linear: 0.015517575666308 nn.Linear: 0.010477818548679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058893775567412 nn.Linear: 0.015219766646624] nn.Sequential: [nn.Linear: 0.006703669205308 nn.Linear: 0.010759489610791]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062686890330065 nn.Linear: 0.065350009759142 nn.Linear: 0.045350360480308 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031526416795687 nn.Linear: 0.05375899800184] nn.Sequential: [nn.Linear: 0.031468295388559 nn.Linear: 0.036105583027694]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5203076004982 nn.Linear: 0.24894519150257 nn.Linear: 0.19119819998741 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28090512752533 nn.Linear: 0.49884217977524] nn.Sequential: [nn.Linear: 0.14065293967724 nn.Linear: 0.2413974404335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00062708382338199 nn.Linear: 0.00042359478690871 nn.Linear: 0.00024856845355142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011711263869656 nn.Linear: 0.0013727791819028] nn.Sequential: [nn.Linear: 0.00010893840323865 nn.Linear: 0.00075032367937438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046837609261274 nn.Linear: 0.0057581700384617 nn.Linear: 0.0061460533179343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046634408645332 nn.Linear: 0.0096199130639434] nn.Sequential: [nn.Linear: 0.0028344502206892 nn.Linear: 0.0087204948067665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062682187859695 nn.Linear: 0.065350961641233 nn.Linear: 0.045351355429771 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03152655348628 nn.Linear: 0.05378907874902] nn.Sequential: [nn.Linear: 0.031468603313413 nn.Linear: 0.036110583692504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52061933279037 nn.Linear: 0.24907910823822 nn.Linear: 0.19225345551968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28144344687462 nn.Linear: 0.49995613098145] nn.Sequential: [nn.Linear: 0.1411077529192 nn.Linear: 0.24178767204285]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001565030446217 nn.Linear: 0.0010644875917282 nn.Linear: 0.00045540596028931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018170022696897 nn.Linear: 0.0022504725198065] nn.Sequential: [nn.Linear: 0.0001595776493901 nn.Linear: 0.0012338361103275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017625570297241 nn.Linear: 0.018952913582325 nn.Linear: 0.01605511084199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081677651032805 nn.Linear: 0.016659408807755] nn.Sequential: [nn.Linear: 0.0077214455232024 nn.Linear: 0.013736850582063]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062683737699333 nn.Linear: 0.065355350723401 nn.Linear: 0.045352261291573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031526845853973 nn.Linear: 0.053796074235095] nn.Sequential: [nn.Linear: 0.031468750139598 nn.Linear: 0.036126980980019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52150523662567 nn.Linear: 0.24966378509998 nn.Linear: 0.19219675660133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28198933601379 nn.Linear: 0.50129103660583] nn.Sequential: [nn.Linear: 0.14131516218185 nn.Linear: 0.24233509600163]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016494519929742 nn.Linear: 0.00089121309719344 nn.Linear: 0.00041608410936682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017058500210347 nn.Linear: 0.0016671511910716] nn.Sequential: [nn.Linear: 0.00016929450593084 nn.Linear: 0.0010634338229496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010185153223574 nn.Linear: 0.01521360874176 nn.Linear: 0.013642655685544 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0067320056259632 nn.Linear: 0.0092890355736017] nn.Sequential: [nn.Linear: 0.0045358715578914 nn.Linear: 0.0092444894835353]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684846445218 nn.Linear: 0.065357211035522 nn.Linear: 0.045352492821175 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031527072572657 nn.Linear: 0.053813684628778] nn.Sequential: [nn.Linear: 0.031468720279558 nn.Linear: 0.036120224824854]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52170264720917 nn.Linear: 0.2491258084774 nn.Linear: 0.19393219053745 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28317615389824 nn.Linear: 0.50151461362839] nn.Sequential: [nn.Linear: 0.14188818633556 nn.Linear: 0.24224445223808]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013796011268897 nn.Linear: 0.00084353124253586 nn.Linear: 0.00042784927639945 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018858238503891 nn.Linear: 0.0023816689031957] nn.Sequential: [nn.Linear: 0.0001410345834255 nn.Linear: 0.001072401851062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010147653520107 nn.Linear: 0.014774973504245 nn.Linear: 0.012150272727013 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010168583132327 nn.Linear: 0.016239309683442] nn.Sequential: [nn.Linear: 0.0056673702783883 nn.Linear: 0.013464511372149]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062686870070537 nn.Linear: 0.065359636014353 nn.Linear: 0.045354774806701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031527451065381 nn.Linear: 0.05384451332668] nn.Sequential: [nn.Linear: 0.031468924656485 nn.Linear: 0.036136774759276]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52175563573837 nn.Linear: 0.24941688776016 nn.Linear: 0.19477133452892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28430476784706 nn.Linear: 0.50225299596786] nn.Sequential: [nn.Linear: 0.14233729243279 nn.Linear: 0.24261659383774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018650117361776 nn.Linear: 0.0010146439875297 nn.Linear: 0.00050480665586527 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019068600578649 nn.Linear: 0.0021517997466707] nn.Sequential: [nn.Linear: 0.00017701878192897 nn.Linear: 0.0011807423435132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01530934497714 nn.Linear: 0.015983231365681 nn.Linear: 0.012253156863153 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062514059245586 nn.Linear: 0.012304654344916] nn.Sequential: [nn.Linear: 0.0052445097826421 nn.Linear: 0.01048020273447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06268384208954 nn.Linear: 0.065365889654947 nn.Linear: 0.045356127347118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031527531137715 nn.Linear: 0.053849957207774] nn.Sequential: [nn.Linear: 0.031469055340047 nn.Linear: 0.036134443555051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52198940515518 nn.Linear: 0.24940374493599 nn.Linear: 0.19481700658798 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28478741645813 nn.Linear: 0.50330197811127] nn.Sequential: [nn.Linear: 0.14276020228863 nn.Linear: 0.24265713989735]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017097379627939 nn.Linear: 0.0008579082147067 nn.Linear: 0.0004459024243742 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002543890805721 nn.Linear: 0.0034142524740444] nn.Sequential: [nn.Linear: 0.00014721531185601 nn.Linear: 0.0010027119917089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011646549217403 nn.Linear: 0.013269709423184 nn.Linear: 0.011104202829301 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012738681398332 nn.Linear: 0.033380798995495] nn.Sequential: [nn.Linear: 0.0047253193333745 nn.Linear: 0.0077714030630887]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062678105379932 nn.Linear: 0.065370075127114 nn.Linear: 0.04535798609158 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031527598798713 nn.Linear: 0.053857462367571] nn.Sequential: [nn.Linear: 0.031469303816583 nn.Linear: 0.036143730494364]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5226001739502 nn.Linear: 0.24987806379795 nn.Linear: 0.19539864361286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28535655140877 nn.Linear: 0.50438433885574] nn.Sequential: [nn.Linear: 0.14293570816517 nn.Linear: 0.24339063465595]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022446988622116 nn.Linear: 0.0016779862898887 nn.Linear: 0.00075901496595553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00031302107516862 nn.Linear: 0.0045420608709934] nn.Sequential: [nn.Linear: 0.00023725106290326 nn.Linear: 0.0018341622818164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016048895195127 nn.Linear: 0.024624669924378 nn.Linear: 0.018485683947802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011030375026166 nn.Linear: 0.02932046353817] nn.Sequential: [nn.Linear: 0.0092367492616177 nn.Linear: 0.020313220098615]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062684425674081 nn.Linear: 0.065374060375389 nn.Linear: 0.045360166570584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031527880188544 nn.Linear: 0.05387137328313] nn.Sequential: [nn.Linear: 0.031469655906347 nn.Linear: 0.036164452957669]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52312725782394 nn.Linear: 0.24997493624687 nn.Linear: 0.19507645070553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28612011671066 nn.Linear: 0.50563043355942] nn.Sequential: [nn.Linear: 0.14293579757214 nn.Linear: 0.24372735619545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011815746064689 nn.Linear: 0.00068930532215018 nn.Linear: 0.00036549770654453 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013454553875134 nn.Linear: 0.0014222260963714] nn.Sequential: [nn.Linear: 0.00012490054614795 nn.Linear: 0.00097229757680159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063845394179225 nn.Linear: 0.012042982503772 nn.Linear: 0.0082180257886648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089809484779835 nn.Linear: 0.011424495838583] nn.Sequential: [nn.Linear: 0.0067114811390638 nn.Linear: 0.011258824728429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062693233184207 nn.Linear: 0.065378955857573 nn.Linear: 0.045362214029857 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031528168294395 nn.Linear: 0.053896234694449] nn.Sequential: [nn.Linear: 0.031469585604821 nn.Linear: 0.036161186608461]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52344685792923 nn.Linear: 0.25025305151939 nn.Linear: 0.19457004964352 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28682881593704 nn.Linear: 0.50685375928879] nn.Sequential: [nn.Linear: 0.14305587112904 nn.Linear: 0.24394185841084]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030503345579561 nn.Linear: 0.0013948250666654 nn.Linear: 0.00061323781976416 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025031190956191 nn.Linear: 0.0034990839634973] nn.Sequential: [nn.Linear: 0.00019890827219331 nn.Linear: 0.0016613248101147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020024888217449 nn.Linear: 0.026557840406895 nn.Linear: 0.016554223373532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018272722139955 nn.Linear: 0.029386844485998] nn.Sequential: [nn.Linear: 0.0083638140931726 nn.Linear: 0.024409472942352]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062688820652372 nn.Linear: 0.065382122402946 nn.Linear: 0.045362253245298 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031528423965447 nn.Linear: 0.053898130937867] nn.Sequential: [nn.Linear: 0.031469560099079 nn.Linear: 0.036177948185424]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52368438243866 nn.Linear: 0.25049790740013 nn.Linear: 0.19477705657482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28780701756477 nn.Linear: 0.50788372755051] nn.Sequential: [nn.Linear: 0.14335058629513 nn.Linear: 0.24423538148403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026578027860662 nn.Linear: 0.0012689191121492 nn.Linear: 0.00055098735676614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020045647801551 nn.Linear: 0.0022691456628383] nn.Sequential: [nn.Linear: 0.00015552324533133 nn.Linear: 0.00099894377203288]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015441535040736 nn.Linear: 0.018865644931793 nn.Linear: 0.025836136192083 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012450223788619 nn.Linear: 0.017471924424171] nn.Sequential: [nn.Linear: 0.0066930120810866 nn.Linear: 0.011013980023563]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698359887208 nn.Linear: 0.065382230494195 nn.Linear: 0.045363195313676 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031528543023903 nn.Linear: 0.05390672836613] nn.Sequential: [nn.Linear: 0.031469871665584 nn.Linear: 0.03619469866783]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52335435152054 nn.Linear: 0.25161352753639 nn.Linear: 0.19409024715424 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28830471634865 nn.Linear: 0.50851142406464] nn.Sequential: [nn.Linear: 0.14363519847393 nn.Linear: 0.24445956945419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001240376572866 nn.Linear: 0.00054970384989023 nn.Linear: 0.00026848406236202 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010524617415253 nn.Linear: 0.0011157039797225] nn.Sequential: [nn.Linear: 9.3066760718347e-05 nn.Linear: 0.0006678000958612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095717580989003 nn.Linear: 0.0084317084401846 nn.Linear: 0.0093027232214808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0042670355178416 nn.Linear: 0.0073868106119335] nn.Sequential: [nn.Linear: 0.0034215443301946 nn.Linear: 0.0061680776998401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698325249115 nn.Linear: 0.065385138980382 nn.Linear: 0.045365276392809 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031528762854179 nn.Linear: 0.053896084486084] nn.Sequential: [nn.Linear: 0.031470189387097 nn.Linear: 0.036198234645732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52381587028503 nn.Linear: 0.2517001926899 nn.Linear: 0.19417051970959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28895190358162 nn.Linear: 0.50923681259155] nn.Sequential: [nn.Linear: 0.14372856914997 nn.Linear: 0.24462841451168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010043433042534 nn.Linear: 0.00071059875311414 nn.Linear: 0.00039815023131336 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002108354675789 nn.Linear: 0.0031032119368246] nn.Sequential: [nn.Linear: 0.0001397924429277 nn.Linear: 0.000992892559597]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.006167899351567 nn.Linear: 0.010481685400009 nn.Linear: 0.0060367453843355 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065192542970181 nn.Linear: 0.016418494284153] nn.Sequential: [nn.Linear: 0.0069147213362157 nn.Linear: 0.011365162208676]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062706235738102 nn.Linear: 0.065386451291402 nn.Linear: 0.045366061773837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031528819127884 nn.Linear: 0.053887732352138] nn.Sequential: [nn.Linear: 0.031470368777063 nn.Linear: 0.036201183642441]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52359282970428 nn.Linear: 0.25198778510094 nn.Linear: 0.194196164608 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.28936824202538 nn.Linear: 0.51006710529327] nn.Sequential: [nn.Linear: 0.14387845993042 nn.Linear: 0.24469819664955]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0062199027020598 nn.Linear: 0.0028155347690231 nn.Linear: 0.00091697489324457 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020609470785402 nn.Linear: 0.002235980903102] nn.Sequential: [nn.Linear: 0.00022194408488862 nn.Linear: 0.001846088449616]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.045569848269224 nn.Linear: 0.042308729141951 nn.Linear: 0.055819202214479 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.027187449857593 nn.Linear: 0.018022559583187] nn.Sequential: [nn.Linear: 0.0073782792314887 nn.Linear: 0.023160943761468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062709162968307 nn.Linear: 0.065393638973888 nn.Linear: 0.045368904188641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031529425370645 nn.Linear: 0.053950270605583] nn.Sequential: [nn.Linear: 0.031470647414679 nn.Linear: 0.036212173918978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52334994077682 nn.Linear: 0.25225508213043 nn.Linear: 0.19473980367184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29013761878014 nn.Linear: 0.51085501909256] nn.Sequential: [nn.Linear: 0.14397870004177 nn.Linear: 0.24502976238728]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014641337098883 nn.Linear: 0.00086466116822585 nn.Linear: 0.00051613360520224 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026605589886013 nn.Linear: 0.0039218614659382] nn.Sequential: [nn.Linear: 0.00024522988500539 nn.Linear: 0.0022752795136824]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01064030919224 nn.Linear: 0.010085068643093 nn.Linear: 0.009505276568234 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011575386859477 nn.Linear: 0.02263487316668] nn.Sequential: [nn.Linear: 0.007530122064054 nn.Linear: 0.027170294895768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062708812166149 nn.Linear: 0.065394404059266 nn.Linear: 0.045370573234264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031529822509425 nn.Linear: 0.05399332051195] nn.Sequential: [nn.Linear: 0.031470704895669 nn.Linear: 0.036217562784826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52374744415283 nn.Linear: 0.25289940834045 nn.Linear: 0.19489489495754 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29097443819046 nn.Linear: 0.51186603307724] nn.Sequential: [nn.Linear: 0.14420349895954 nn.Linear: 0.24528510868549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012848753418135 nn.Linear: 0.0007617485907673 nn.Linear: 0.00041135769191268 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016132258994757 nn.Linear: 0.00179230988159] nn.Sequential: [nn.Linear: 0.00015399485305584 nn.Linear: 0.0013586595290682]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077585764229298 nn.Linear: 0.012057324871421 nn.Linear: 0.010447515174747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012365025468171 nn.Linear: 0.013542726635933] nn.Sequential: [nn.Linear: 0.0082788374274969 nn.Linear: 0.017065053805709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062704289035971 nn.Linear: 0.065395946753943 nn.Linear: 0.045370242483785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031529795492537 nn.Linear: 0.053975254704] nn.Sequential: [nn.Linear: 0.031470577593273 nn.Linear: 0.036214794395675]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52419751882553 nn.Linear: 0.25303709506989 nn.Linear: 0.19492557644844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29129222035408 nn.Linear: 0.51259976625443] nn.Sequential: [nn.Linear: 0.14432461559772 nn.Linear: 0.24513214826584]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016561632454653 nn.Linear: 0.001022661857817 nn.Linear: 0.00047274783101546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018251972556885 nn.Linear: 0.002134249976422] nn.Sequential: [nn.Linear: 0.00017365199014499 nn.Linear: 0.001540846140188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013895558193326 nn.Linear: 0.0165935177356 nn.Linear: 0.012664856389165 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068303127773106 nn.Linear: 0.014954281039536] nn.Sequential: [nn.Linear: 0.0044698161073029 nn.Linear: 0.012107374146581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062715656194886 nn.Linear: 0.065401796952772 nn.Linear: 0.045372517577427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031530371085199 nn.Linear: 0.053990771649893] nn.Sequential: [nn.Linear: 0.031470902760933 nn.Linear: 0.03622716549737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52406269311905 nn.Linear: 0.2526743710041 nn.Linear: 0.19597898423672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29222220182419 nn.Linear: 0.51427155733109] nn.Sequential: [nn.Linear: 0.14444503188133 nn.Linear: 0.24575415253639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015344976249538 nn.Linear: 0.00095876425657821 nn.Linear: 0.00052208213365805 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019151045124242 nn.Linear: 0.0020260071291729] nn.Sequential: [nn.Linear: 0.00021551302711718 nn.Linear: 0.0016300300720156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011496878229082 nn.Linear: 0.010989451780915 nn.Linear: 0.0099568925797939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097531927749515 nn.Linear: 0.015219379216433] nn.Sequential: [nn.Linear: 0.0058743916451931 nn.Linear: 0.021427212283015]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.08464310862869	TD error	0.01837547314167	Qmax	1	

Steps: 8750000 (frames: 35000000), score: 1835.48, higheset score: 6572, epsilon: 0.05, lr: 0.0005, training time: 542s, training rate: 1841fps, testing time: 88s, testing rate: 5646fps,  num. ep.: 416,  num. rewards: 17604	
   2    4   32    2
   4    8   64  256
   8   16   32    4
   2   64   16  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718454236093 nn.Linear: 0.065409158018286 nn.Linear: 0.045375762279952 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031530647850975 nn.Linear: 0.054031835871555] nn.Sequential: [nn.Linear: 0.031471408634511 nn.Linear: 0.03625816798613]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52452385425568 nn.Linear: 0.25273808836937 nn.Linear: 0.19585517048836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.2934829890728 nn.Linear: 0.51498782634735] nn.Sequential: [nn.Linear: 0.1446575075388 nn.Linear: 0.2459160387516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016582547247277 nn.Linear: 0.00091827086116542 nn.Linear: 0.00042964459951645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019708544049099 nn.Linear: 0.0022238710062976] nn.Sequential: [nn.Linear: 0.00015537562793097 nn.Linear: 0.0012920557956942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098192254081368 nn.Linear: 0.014302373863757 nn.Linear: 0.0088143022730947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096543440595269 nn.Linear: 0.018563762307167] nn.Sequential: [nn.Linear: 0.0041196052916348 nn.Linear: 0.012818134389818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718137143968 nn.Linear: 0.065411886518163 nn.Linear: 0.045377042280384 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031530851708835 nn.Linear: 0.054038568604312] nn.Sequential: [nn.Linear: 0.031471489896775 nn.Linear: 0.036264803921779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52481633424759 nn.Linear: 0.25279307365417 nn.Linear: 0.19586600363255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29413515329361 nn.Linear: 0.51549082994461] nn.Sequential: [nn.Linear: 0.14504933357239 nn.Linear: 0.2461004704237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0009005285322163 nn.Linear: 0.00051719141666329 nn.Linear: 0.00027979029090829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014092480839282 nn.Linear: 0.001754092914653] nn.Sequential: [nn.Linear: 9.6198726162043e-05 nn.Linear: 0.00069293386348223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054721138440073 nn.Linear: 0.0075924843549728 nn.Linear: 0.0052029965445399 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063531901687384 nn.Linear: 0.012755546718836] nn.Sequential: [nn.Linear: 0.0029703699983656 nn.Linear: 0.0059501752257347]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.0627197585393 nn.Linear: 0.065416931041675 nn.Linear: 0.045377223647179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031531059413607 nn.Linear: 0.054067964031702] nn.Sequential: [nn.Linear: 0.031471557795138 nn.Linear: 0.036274761824881]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52462255954742 nn.Linear: 0.25263464450836 nn.Linear: 0.19652265310287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29475057125092 nn.Linear: 0.51579284667969] nn.Sequential: [nn.Linear: 0.14518591761589 nn.Linear: 0.24627266824245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011573385920197 nn.Linear: 0.00079422989477031 nn.Linear: 0.00041218989379854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000158050962622 nn.Linear: 0.001870270833736] nn.Sequential: [nn.Linear: 0.00012544950673267 nn.Linear: 0.00080572217020378]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095328884199262 nn.Linear: 0.012319173663855 nn.Linear: 0.0096325175836682 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012542635202408 nn.Linear: 0.020472228527069] nn.Sequential: [nn.Linear: 0.0060959411785007 nn.Linear: 0.0077336407266557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062728431868449 nn.Linear: 0.065423692460918 nn.Linear: 0.045379368736827 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031531464088653 nn.Linear: 0.054114100521019] nn.Sequential: [nn.Linear: 0.031471907663588 nn.Linear: 0.036283330027715]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52478408813477 nn.Linear: 0.25282916426659 nn.Linear: 0.19640776515007 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29552245140076 nn.Linear: 0.51675367355347] nn.Sequential: [nn.Linear: 0.14542865753174 nn.Linear: 0.24643971025944]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0008575210909102 nn.Linear: 0.00058783848353809 nn.Linear: 0.00030222825749574 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015157512420054 nn.Linear: 0.0020705058784894] nn.Sequential: [nn.Linear: 0.00012861343563022 nn.Linear: 0.0010462984361116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071913627907634 nn.Linear: 0.010358761064708 nn.Linear: 0.0057762959040701 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069249481894076 nn.Linear: 0.013807433657348] nn.Sequential: [nn.Linear: 0.0040108496323228 nn.Linear: 0.0097418846562505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732013172165 nn.Linear: 0.065428368275749 nn.Linear: 0.045380294880528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031531681618499 nn.Linear: 0.05414407741543] nn.Sequential: [nn.Linear: 0.03147204698582 nn.Linear: 0.036300146939242]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52495968341827 nn.Linear: 0.25256881117821 nn.Linear: 0.19693404436111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29637718200684 nn.Linear: 0.51744973659515] nn.Sequential: [nn.Linear: 0.14566572010517 nn.Linear: 0.2465980052948]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0037702195698314 nn.Linear: 0.0024093011608189 nn.Linear: 0.0011643753070698 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00045333558294878 nn.Linear: 0.0055825082449764] nn.Sequential: [nn.Linear: 0.00038832567487377 nn.Linear: 0.002934415331969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.032649099826813 nn.Linear: 0.045811366289854 nn.Linear: 0.025698592886329 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024847770109773 nn.Linear: 0.034279882907867] nn.Sequential: [nn.Linear: 0.011710803955793 nn.Linear: 0.031043510884047]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062724748387411 nn.Linear: 0.065432850920061 nn.Linear: 0.045383052447378 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03153232308434 nn.Linear: 0.054190797098215] nn.Sequential: [nn.Linear: 0.031472222106115 nn.Linear: 0.036290330185585]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52428352832794 nn.Linear: 0.25340393185616 nn.Linear: 0.19761273264885 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29717841744423 nn.Linear: 0.51831650733948] nn.Sequential: [nn.Linear: 0.1457601338625 nn.Linear: 0.24696896970272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083084729700887 nn.Linear: 0.00049022060268976 nn.Linear: 0.00029713654817274 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013033746678902 nn.Linear: 0.0013485029727335] nn.Sequential: [nn.Linear: 0.00013195387010142 nn.Linear: 0.00095130756407905]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054130591452122 nn.Linear: 0.00951022002846 nn.Linear: 0.0049784784205258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01109445374459 nn.Linear: 0.0099529959261417] nn.Sequential: [nn.Linear: 0.0031149687711149 nn.Linear: 0.0081543195992708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062725744834037 nn.Linear: 0.065436486491849 nn.Linear: 0.045384966167013 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031532612656711 nn.Linear: 0.054182835884887] nn.Sequential: [nn.Linear: 0.031472446896637 nn.Linear: 0.036286089683419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52536356449127 nn.Linear: 0.25324541330338 nn.Linear: 0.19781751930714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29839873313904 nn.Linear: 0.51915681362152] nn.Sequential: [nn.Linear: 0.14589039981365 nn.Linear: 0.24716831743717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011885512354481 nn.Linear: 0.00076784472250937 nn.Linear: 0.0003957012373121 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015217392298017 nn.Linear: 0.0016683917408016] nn.Sequential: [nn.Linear: 0.00017051188377317 nn.Linear: 0.0011157955476521]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079525355249643 nn.Linear: 0.011528146453202 nn.Linear: 0.0086763706058264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057129031047225 nn.Linear: 0.0084500210359693] nn.Sequential: [nn.Linear: 0.0047453125007451 nn.Linear: 0.010481181554496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062726232569152 nn.Linear: 0.06544005282408 nn.Linear: 0.045386219342251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031532942885058 nn.Linear: 0.05420871658157] nn.Sequential: [nn.Linear: 0.031472758090714 nn.Linear: 0.036310238554272]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52545243501663 nn.Linear: 0.25371110439301 nn.Linear: 0.19709891080856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29868945479393 nn.Linear: 0.51974993944168] nn.Sequential: [nn.Linear: 0.14576651155949 nn.Linear: 0.24738200008869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096320436589592 nn.Linear: 0.00055494923841098 nn.Linear: 0.00032823148565825 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011779327463172 nn.Linear: 0.0014343169532838] nn.Sequential: [nn.Linear: 0.00014881178329529 nn.Linear: 0.0011662199474963]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079794777557254 nn.Linear: 0.0085140829905868 nn.Linear: 0.0066344542428851 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0053110709413886 nn.Linear: 0.0076547190546989] nn.Sequential: [nn.Linear: 0.0062852948904037 nn.Linear: 0.013323429040611]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062736457447145 nn.Linear: 0.065445145474712 nn.Linear: 0.045387946028534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031533104113825 nn.Linear: 0.054262537446107] nn.Sequential: [nn.Linear: 0.031472813274039 nn.Linear: 0.036312462429137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52553236484528 nn.Linear: 0.25314897298813 nn.Linear: 0.19776530563831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.29946714639664 nn.Linear: 0.52072966098785] nn.Sequential: [nn.Linear: 0.14604249596596 nn.Linear: 0.247618034482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017775724841775 nn.Linear: 0.00089030100434448 nn.Linear: 0.00045224035423645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018143037566423 nn.Linear: 0.0020930543137374] nn.Sequential: [nn.Linear: 0.00018691975797686 nn.Linear: 0.0015658721667148]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015273550525308 nn.Linear: 0.012811141088605 nn.Linear: 0.0089551340788603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073252813890576 nn.Linear: 0.016324903815985] nn.Sequential: [nn.Linear: 0.0065886029042304 nn.Linear: 0.016757011413574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062739536908499 nn.Linear: 0.065445879710443 nn.Linear: 0.045388436687845 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031533580834507 nn.Linear: 0.054335478155508] nn.Sequential: [nn.Linear: 0.031472831796336 nn.Linear: 0.03632849488432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52580583095551 nn.Linear: 0.25364834070206 nn.Linear: 0.19740569591522 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30079936981201 nn.Linear: 0.52180671691895] nn.Sequential: [nn.Linear: 0.1462407708168 nn.Linear: 0.24779270589352]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023073685816461 nn.Linear: 0.0016799043635516 nn.Linear: 0.00088426016834227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00031524848757244 nn.Linear: 0.0039393553703218] nn.Sequential: [nn.Linear: 0.00025111392131989 nn.Linear: 0.0022630311242794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022791648283601 nn.Linear: 0.033963039517403 nn.Linear: 0.026681710034609 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.039417069405317 nn.Linear: 0.040047809481621] nn.Sequential: [nn.Linear: 0.012321329675615 nn.Linear: 0.025927640497684]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06274314975783 nn.Linear: 0.065450710640907 nn.Linear: 0.045390593190265 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031533775296426 nn.Linear: 0.05433384487884] nn.Sequential: [nn.Linear: 0.031472968619944 nn.Linear: 0.03631598462402]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52512907981873 nn.Linear: 0.25349122285843 nn.Linear: 0.19761072099209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30143189430237 nn.Linear: 0.52283835411072] nn.Sequential: [nn.Linear: 0.14635445177555 nn.Linear: 0.24802674353123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018368501001829 nn.Linear: 0.0010954969954365 nn.Linear: 0.00057169128040707 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028787582691818 nn.Linear: 0.0035421245820826] nn.Sequential: [nn.Linear: 0.00020877698619795 nn.Linear: 0.0014602871432744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012663498520851 nn.Linear: 0.015756901353598 nn.Linear: 0.011503505520523 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011917433701456 nn.Linear: 0.026583826169372] nn.Sequential: [nn.Linear: 0.0065930695272982 nn.Linear: 0.013076834380627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062746983901393 nn.Linear: 0.06545512546106 nn.Linear: 0.045391933932764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031534047051504 nn.Linear: 0.054366484261948] nn.Sequential: [nn.Linear: 0.031473013768657 nn.Linear: 0.036325775418763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52514153718948 nn.Linear: 0.25372520089149 nn.Linear: 0.1977780610323 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30240160226822 nn.Linear: 0.52353185415268] nn.Sequential: [nn.Linear: 0.146594196558 nn.Linear: 0.24819724261761]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0035131382080967 nn.Linear: 0.0018512403633757 nn.Linear: 0.00071205324049144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027853656411059 nn.Linear: 0.0036088658967919] nn.Sequential: [nn.Linear: 0.00023189654865581 nn.Linear: 0.0018132583611988]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022800356149673 nn.Linear: 0.026560701429844 nn.Linear: 0.032494716346264 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010613342747092 nn.Linear: 0.025279959663749] nn.Sequential: [nn.Linear: 0.0071979039348662 nn.Linear: 0.016158420592546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	8880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062748663644371 nn.Linear: 0.065458849991689 nn.Linear: 0.045393521296058 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031534202732138 nn.Linear: 0.054391998621213] nn.Sequential: [nn.Linear: 0.031473379124406 nn.Linear: 0.036337388294804]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52562069892883 nn.Linear: 0.2540562748909 nn.Linear: 0.19762270152569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30294901132584 nn.Linear: 0.52400588989258] nn.Sequential: [nn.Linear: 0.14668053388596 nn.Linear: 0.2486610263586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015431794860099 nn.Linear: 0.00074419191996538 nn.Linear: 0.00031898879876155 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001328235100763 nn.Linear: 0.0014675526280366] nn.Sequential: [nn.Linear: 0.00012367079800163 nn.Linear: 0.0010090855307695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098342839628458 nn.Linear: 0.011175909079611 nn.Linear: 0.013049592263997 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075226766057312 nn.Linear: 0.0091190235689282] nn.Sequential: [nn.Linear: 0.0070911296643317 nn.Linear: 0.011799058876932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062744384390607 nn.Linear: 0.065462754278651 nn.Linear: 0.045394135689322 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031534363993713 nn.Linear: 0.0543673870337] nn.Sequential: [nn.Linear: 0.031473235121436 nn.Linear: 0.036340075531658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52572011947632 nn.Linear: 0.25385516881943 nn.Linear: 0.19776736199856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30348047614098 nn.Linear: 0.5247095823288] nn.Sequential: [nn.Linear: 0.14698879420757 nn.Linear: 0.24878773093224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021512163939419 nn.Linear: 0.0013689008749041 nn.Linear: 0.00069162059658302 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030699388176577 nn.Linear: 0.0043652914741894] nn.Sequential: [nn.Linear: 0.00023448015069622 nn.Linear: 0.0017722259517303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022749405354261 nn.Linear: 0.02228020504117 nn.Linear: 0.016410434618592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014462428167462 nn.Linear: 0.032421816140413] nn.Sequential: [nn.Linear: 0.0082903187721968 nn.Linear: 0.012307990342379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062748124654966 nn.Linear: 0.06546526932438 nn.Linear: 0.045395564454457 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031534644827507 nn.Linear: 0.054399612766865] nn.Sequential: [nn.Linear: 0.031473415084673 nn.Linear: 0.036343864270857]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52539187669754 nn.Linear: 0.25428423285484 nn.Linear: 0.19744899868965 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30392268300056 nn.Linear: 0.52577531337738] nn.Sequential: [nn.Linear: 0.14728179574013 nn.Linear: 0.24905163049698]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0069407924976254 nn.Linear: 0.0032260099133386 nn.Linear: 0.0010226224923197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030159227175514 nn.Linear: 0.0032333936834785] nn.Sequential: [nn.Linear: 0.00022420917286451 nn.Linear: 0.0019552885569629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.046692531555891 nn.Linear: 0.064827971160412 nn.Linear: 0.057055849581957 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.044271484017372 nn.Linear: 0.030433069914579] nn.Sequential: [nn.Linear: 0.016142012551427 nn.Linear: 0.02842765301466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062761350667674 nn.Linear: 0.065471321498924 nn.Linear: 0.045397038222908 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031534912293499 nn.Linear: 0.054427639995083] nn.Sequential: [nn.Linear: 0.031473875509757 nn.Linear: 0.036362924851713]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52619844675064 nn.Linear: 0.25428327918053 nn.Linear: 0.19788283109665 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30438029766083 nn.Linear: 0.52668350934982] nn.Sequential: [nn.Linear: 0.14749233424664 nn.Linear: 0.24927029013634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0048866958715854 nn.Linear: 0.0030100294992592 nn.Linear: 0.0014439657977713 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00044558398832695 nn.Linear: 0.0043144938498898] nn.Sequential: [nn.Linear: 0.00050110407024779 nn.Linear: 0.0043579940930611]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.031240338459611 nn.Linear: 0.056044273078442 nn.Linear: 0.057958282530308 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.052846524864435 nn.Linear: 0.037283785641193] nn.Sequential: [nn.Linear: 0.023929690942168 nn.Linear: 0.046559274196625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062754406265275 nn.Linear: 0.065472795185002 nn.Linear: 0.045397615694353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031535319372305 nn.Linear: 0.054437710413708] nn.Sequential: [nn.Linear: 0.031473999650235 nn.Linear: 0.03636905813078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52677381038666 nn.Linear: 0.25403499603271 nn.Linear: 0.19826033711433 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30462405085564 nn.Linear: 0.52675241231918] nn.Sequential: [nn.Linear: 0.1476181447506 nn.Linear: 0.24946838617325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080497673981886 nn.Linear: 0.0005189413680644 nn.Linear: 0.0003031274151182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016139324223149 nn.Linear: 0.0023291369801912] nn.Sequential: [nn.Linear: 0.0001075293858308 nn.Linear: 0.00090177591076278]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0055916733108461 nn.Linear: 0.0081479297950864 nn.Linear: 0.0073888907209039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068253912031651 nn.Linear: 0.014677571132779] nn.Sequential: [nn.Linear: 0.0037755188532174 nn.Linear: 0.0097664399072528]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062752956711241 nn.Linear: 0.065477206243566 nn.Linear: 0.045399177748035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031535404296619 nn.Linear: 0.054463001751969] nn.Sequential: [nn.Linear: 0.031474155091773 nn.Linear: 0.036368013793708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52698248624802 nn.Linear: 0.25443452596664 nn.Linear: 0.19868093729019 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30555590987206 nn.Linear: 0.52746069431305] nn.Sequential: [nn.Linear: 0.14777199923992 nn.Linear: 0.24968680739403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011903845748963 nn.Linear: 0.00072872937857216 nn.Linear: 0.00036149283781664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012684569223104 nn.Linear: 0.0011739116274478] nn.Sequential: [nn.Linear: 0.00013931937605191 nn.Linear: 0.00087655986656919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010790360160172 nn.Linear: 0.011548788286746 nn.Linear: 0.0076235039159656 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056440914049745 nn.Linear: 0.0092806741595268] nn.Sequential: [nn.Linear: 0.0046216882765293 nn.Linear: 0.0095851495862007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062754512402766 nn.Linear: 0.065484038074294 nn.Linear: 0.045401496310125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031536129505195 nn.Linear: 0.054536714758115] nn.Sequential: [nn.Linear: 0.03147442872189 nn.Linear: 0.036391393959351]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52793920040131 nn.Linear: 0.25499552488327 nn.Linear: 0.20017026364803 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30645698308945 nn.Linear: 0.52861458063126] nn.Sequential: [nn.Linear: 0.14793561398983 nn.Linear: 0.24978186190128]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00084979245531021 nn.Linear: 0.00046062401469461 nn.Linear: 0.00021279537004532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.8841949149757e-05 nn.Linear: 0.001006126529608] nn.Sequential: [nn.Linear: 7.5906104870706e-05 nn.Linear: 0.00045511954853868]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046108178794384 nn.Linear: 0.0057364758104086 nn.Linear: 0.004774353466928 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044806753285229 nn.Linear: 0.0080647226423025] nn.Sequential: [nn.Linear: 0.0024228873662651 nn.Linear: 0.005578491371125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757164493648 nn.Linear: 0.06548951472187 nn.Linear: 0.045402278178398 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031536333338731 nn.Linear: 0.054582743922197] nn.Sequential: [nn.Linear: 0.031474381558615 nn.Linear: 0.036381464703569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52846711874008 nn.Linear: 0.25494650006294 nn.Linear: 0.20015229284763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30640596151352 nn.Linear: 0.52946525812149] nn.Sequential: [nn.Linear: 0.14840605854988 nn.Linear: 0.25011858344078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015414417672396 nn.Linear: 0.00082858370669456 nn.Linear: 0.00040831339412359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019451910143035 nn.Linear: 0.0027549972122112] nn.Sequential: [nn.Linear: 0.00011011444671949 nn.Linear: 0.00086762038738099]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011583789251745 nn.Linear: 0.010837733745575 nn.Linear: 0.0081507954746485 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014353320933878 nn.Linear: 0.022855222225189] nn.Sequential: [nn.Linear: 0.0041308966465294 nn.Linear: 0.0094181932508945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062750179577637 nn.Linear: 0.065487769792351 nn.Linear: 0.045401145150663 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031536507111075 nn.Linear: 0.054575149426569] nn.Sequential: [nn.Linear: 0.031474342800134 nn.Linear: 0.036383560683052]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52863585948944 nn.Linear: 0.25498420000076 nn.Linear: 0.20032268762589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30689215660095 nn.Linear: 0.52984130382538] nn.Sequential: [nn.Linear: 0.14867301285267 nn.Linear: 0.25038433074951]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0038192168931438 nn.Linear: 0.0021702954278805 nn.Linear: 0.00094570368983593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00042074854102085 nn.Linear: 0.0054632100230751] nn.Sequential: [nn.Linear: 0.00035954472336338 nn.Linear: 0.0028080579272065]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020718563348055 nn.Linear: 0.068982198834419 nn.Linear: 0.039030697196722 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022331109270453 nn.Linear: 0.047199685126543] nn.Sequential: [nn.Linear: 0.011710211634636 nn.Linear: 0.033411540091038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062759996356653 nn.Linear: 0.065493613780411 nn.Linear: 0.045403517564047 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031536504916224 nn.Linear: 0.054585132906482] nn.Sequential: [nn.Linear: 0.031474707316177 nn.Linear: 0.036383175436992]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52902537584305 nn.Linear: 0.25520360469818 nn.Linear: 0.2001411318779 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3076414167881 nn.Linear: 0.53075414896011] nn.Sequential: [nn.Linear: 0.14880849421024 nn.Linear: 0.25067174434662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090908867108709 nn.Linear: 0.00053175640366921 nn.Linear: 0.00031038706332362 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017470494894319 nn.Linear: 0.0024991818287987] nn.Sequential: [nn.Linear: 9.7584845238789e-05 nn.Linear: 0.00067309896138469]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0055051422677934 nn.Linear: 0.0073610795661807 nn.Linear: 0.0074928253889084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077148145064712 nn.Linear: 0.023957416415215] nn.Sequential: [nn.Linear: 0.003283912781626 nn.Linear: 0.0064007332548499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062753186930452 nn.Linear: 0.06549167302346 nn.Linear: 0.045402337848338 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031536693051745 nn.Linear: 0.054619693944346] nn.Sequential: [nn.Linear: 0.031474561357689 nn.Linear: 0.036396500093102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52897638082504 nn.Linear: 0.25602462887764 nn.Linear: 0.20104077458382 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30817505717278 nn.Linear: 0.53166365623474] nn.Sequential: [nn.Linear: 0.14887648820877 nn.Linear: 0.25094920396805]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014236581570771 nn.Linear: 0.00086633136144215 nn.Linear: 0.00048741787033235 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020791928820167 nn.Linear: 0.0025026353001338] nn.Sequential: [nn.Linear: 0.00020084727822479 nn.Linear: 0.0015527400740244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01062938850373 nn.Linear: 0.010795097798109 nn.Linear: 0.010761940851808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077215703204274 nn.Linear: 0.016991659998894] nn.Sequential: [nn.Linear: 0.0049139643087983 nn.Linear: 0.012907451018691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	8990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757817807853 nn.Linear: 0.06549832712718 nn.Linear: 0.045405709003188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031537117957889 nn.Linear: 0.054644875817303] nn.Sequential: [nn.Linear: 0.03147489863615 nn.Linear: 0.036400494567488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52918571233749 nn.Linear: 0.25618755817413 nn.Linear: 0.20099809765816 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30841237306595 nn.Linear: 0.5324615240097] nn.Sequential: [nn.Linear: 0.14906352758408 nn.Linear: 0.25140565633774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010363182864773 nn.Linear: 0.00065753242079882 nn.Linear: 0.00042229447036518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014575036062614 nn.Linear: 0.0015343519805271] nn.Sequential: [nn.Linear: 0.00020530442644309 nn.Linear: 0.0018252843273617]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074559571221471 nn.Linear: 0.009735724888742 nn.Linear: 0.010967739857733 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0048418012447655 nn.Linear: 0.0097553692758083] nn.Sequential: [nn.Linear: 0.0063675935380161 nn.Linear: 0.017732635140419]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062756068244452 nn.Linear: 0.065497369166523 nn.Linear: 0.045405370850612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03153728453882 nn.Linear: 0.054640921442569] nn.Sequential: [nn.Linear: 0.031474790004752 nn.Linear: 0.036403173459133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52834784984589 nn.Linear: 0.25591215491295 nn.Linear: 0.20132380723953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30866941809654 nn.Linear: 0.53326952457428] nn.Sequential: [nn.Linear: 0.14955307543278 nn.Linear: 0.2515851855278]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022803377642971 nn.Linear: 0.0013880895424487 nn.Linear: 0.0005804750277977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016126185055343 nn.Linear: 0.0020436312850712] nn.Sequential: [nn.Linear: 0.00011326102402458 nn.Linear: 0.00076831627027914]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014118183404207 nn.Linear: 0.025238979607821 nn.Linear: 0.017137747257948 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015624368563294 nn.Linear: 0.018585538491607] nn.Sequential: [nn.Linear: 0.0070544718764722 nn.Linear: 0.010864443145692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.083079145923257	TD error	0.017385396808386	Qmax	1	

Steps: 9000000 (frames: 36000000), score: 2021.23, higheset score: 5880, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1840fps, testing time: 88s, testing rate: 5648fps,  num. ep.: 324,  num. rewards: 17013	
   4   16    2    4
   8    4   32    2
   4    8   16  256
   2   16    4  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062759656799761 nn.Linear: 0.065499736345656 nn.Linear: 0.045406681191459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031537579391237 nn.Linear: 0.054650532597407] nn.Sequential: [nn.Linear: 0.031474877535904 nn.Linear: 0.036404263033676]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52837783098221 nn.Linear: 0.25610208511353 nn.Linear: 0.20147779583931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.30949425697327 nn.Linear: 0.53360259532928] nn.Sequential: [nn.Linear: 0.1497583091259 nn.Linear: 0.25187680125237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012607353983348 nn.Linear: 0.00068527370548391 nn.Linear: 0.00029341668604753 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010056322710526 nn.Linear: 0.0010805163343673] nn.Sequential: [nn.Linear: 8.9650244720686e-05 nn.Linear: 0.00052680346672408]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098850978538394 nn.Linear: 0.0120162460953 nn.Linear: 0.011357118375599 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085562644526362 nn.Linear: 0.0088454186916351] nn.Sequential: [nn.Linear: 0.0022195046767592 nn.Linear: 0.0051305955275893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062749004393219 nn.Linear: 0.065503402202393 nn.Linear: 0.045408108553469 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031537931381025 nn.Linear: 0.054683680272888] nn.Sequential: [nn.Linear: 0.031474908924394 nn.Linear: 0.036406078104354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52768641710281 nn.Linear: 0.25598096847534 nn.Linear: 0.20267029106617 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3104165494442 nn.Linear: 0.53436160087585] nn.Sequential: [nn.Linear: 0.15012568235397 nn.Linear: 0.25200748443604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022654543987255 nn.Linear: 0.001332407310011 nn.Linear: 0.00064872918350999 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033856667627365 nn.Linear: 0.0050060306370865] nn.Sequential: [nn.Linear: 0.00023236458632165 nn.Linear: 0.0015939287970378]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01476345770061 nn.Linear: 0.018543306738138 nn.Linear: 0.020328352227807 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.021951157599688 nn.Linear: 0.049599882215261] nn.Sequential: [nn.Linear: 0.019239023327827 nn.Linear: 0.016744092106819]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062754446191735 nn.Linear: 0.065507427883746 nn.Linear: 0.045409867090287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03153794884665 nn.Linear: 0.054712326515983] nn.Sequential: [nn.Linear: 0.031475025151492 nn.Linear: 0.036402788581125]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52837777137756 nn.Linear: 0.25668698549271 nn.Linear: 0.20204076170921 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31144139170647 nn.Linear: 0.53485590219498] nn.Sequential: [nn.Linear: 0.15032374858856 nn.Linear: 0.25230914354324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025503819557966 nn.Linear: 0.0015145602933218 nn.Linear: 0.00064106505151985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002275942371783 nn.Linear: 0.0027018921523085] nn.Sequential: [nn.Linear: 0.00025605191850833 nn.Linear: 0.0019386130940317]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016447013244033 nn.Linear: 0.021374426782131 nn.Linear: 0.017134817317128 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088403094559908 nn.Linear: 0.023191221058369] nn.Sequential: [nn.Linear: 0.008683817461133 nn.Linear: 0.020783273503184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062747662263601 nn.Linear: 0.065509143999582 nn.Linear: 0.045410811128254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031538497429093 nn.Linear: 0.054755462067078] nn.Sequential: [nn.Linear: 0.031474913913952 nn.Linear: 0.036405142822242]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52857822179794 nn.Linear: 0.25694531202316 nn.Linear: 0.20118877291679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31197023391724 nn.Linear: 0.53539782762527] nn.Sequential: [nn.Linear: 0.1504303663969 nn.Linear: 0.25244030356407]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.005535987847796 nn.Linear: 0.0021757262031631 nn.Linear: 0.00076504571868811 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026039344135534 nn.Linear: 0.0031545764194996] nn.Sequential: [nn.Linear: 0.00019591466794166 nn.Linear: 0.00139314086618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.049286533147097 nn.Linear: 0.045068811625242 nn.Linear: 0.055742636322975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016089109703898 nn.Linear: 0.024431148543954] nn.Sequential: [nn.Linear: 0.013974989764392 nn.Linear: 0.016170622780919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757440768763 nn.Linear: 0.06551480267129 nn.Linear: 0.045413065938076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031538980479103 nn.Linear: 0.054742098444876] nn.Sequential: [nn.Linear: 0.031474900379033 nn.Linear: 0.036400373468076]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52893042564392 nn.Linear: 0.25731772184372 nn.Linear: 0.20101627707481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31235313415527 nn.Linear: 0.53589725494385] nn.Sequential: [nn.Linear: 0.15080603957176 nn.Linear: 0.25249588489532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085987546956473 nn.Linear: 0.00057381862714154 nn.Linear: 0.00031783623196473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012460426458196 nn.Linear: 0.0012425765007109] nn.Sequential: [nn.Linear: 0.00016759716587586 nn.Linear: 0.0012037486930178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065353740938008 nn.Linear: 0.0080167055130005 nn.Linear: 0.007053610868752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052042594179511 nn.Linear: 0.0089995888993144] nn.Sequential: [nn.Linear: 0.0085668666288257 nn.Linear: 0.013478979468346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757689484917 nn.Linear: 0.065520392590245 nn.Linear: 0.045414371701455 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539177330104 nn.Linear: 0.054750967820155] nn.Sequential: [nn.Linear: 0.031475125340005 nn.Linear: 0.036427299663448]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52948790788651 nn.Linear: 0.25708612799644 nn.Linear: 0.20148503780365 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31260147690773 nn.Linear: 0.53715431690216] nn.Sequential: [nn.Linear: 0.151053622365 nn.Linear: 0.25249153375626]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092551342154021 nn.Linear: 0.00053432259130933 nn.Linear: 0.0002776800755519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014829825254757 nn.Linear: 0.0019034449583111] nn.Sequential: [nn.Linear: 0.00011023410760712 nn.Linear: 0.00087464974194003]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060383304953575 nn.Linear: 0.0073426775634289 nn.Linear: 0.0056696641258895 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068745501339436 nn.Linear: 0.016162235289812] nn.Sequential: [nn.Linear: 0.003745781024918 nn.Linear: 0.012396397069097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062758581048794 nn.Linear: 0.065527307532936 nn.Linear: 0.045416310723076 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539458355542 nn.Linear: 0.054768606667039] nn.Sequential: [nn.Linear: 0.031475228352407 nn.Linear: 0.036425441027545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52967619895935 nn.Linear: 0.25738203525543 nn.Linear: 0.20210558176041 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31328123807907 nn.Linear: 0.5380734205246] nn.Sequential: [nn.Linear: 0.15141572058201 nn.Linear: 0.25273108482361]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080078616415247 nn.Linear: 0.000513213962338 nn.Linear: 0.00030101244249371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015322699977831 nn.Linear: 0.0021040288754705] nn.Sequential: [nn.Linear: 0.00014610370050863 nn.Linear: 0.0011830745438405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0061305174604058 nn.Linear: 0.0078713148832321 nn.Linear: 0.0079987170174718 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054417690262198 nn.Linear: 0.016377566382289] nn.Sequential: [nn.Linear: 0.0035919758956879 nn.Linear: 0.013197043910623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062760376413808 nn.Linear: 0.0655274642213 nn.Linear: 0.045417378536686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539489334535 nn.Linear: 0.054774579376954] nn.Sequential: [nn.Linear: 0.031475360579367 nn.Linear: 0.036429869303062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52991956472397 nn.Linear: 0.25774309039116 nn.Linear: 0.20246641337872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31375861167908 nn.Linear: 0.53914248943329] nn.Sequential: [nn.Linear: 0.15136730670929 nn.Linear: 0.25317633152008]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0007692966785918 nn.Linear: 0.00051217635224378 nn.Linear: 0.00028923418368298 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001272125649783 nn.Linear: 0.0014453129762779] nn.Sequential: [nn.Linear: 0.00013579395860006 nn.Linear: 0.0011507041682577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082787368446589 nn.Linear: 0.0086538000032306 nn.Linear: 0.0077603291720152 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058328732848167 nn.Linear: 0.0069879437796772] nn.Sequential: [nn.Linear: 0.0057292548008263 nn.Linear: 0.011382093653083]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062761165157584 nn.Linear: 0.06552766091917 nn.Linear: 0.045417007673318 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539548590247 nn.Linear: 0.054767907374639] nn.Sequential: [nn.Linear: 0.031475356407475 nn.Linear: 0.03644410830372]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52989375591278 nn.Linear: 0.25733342766762 nn.Linear: 0.20229117572308 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31407627463341 nn.Linear: 0.53998029232025] nn.Sequential: [nn.Linear: 0.15151377022266 nn.Linear: 0.25356873869896]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021212704562842 nn.Linear: 0.0012712189828792 nn.Linear: 0.00054767214498473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025286050593651 nn.Linear: 0.00315649172419] nn.Sequential: [nn.Linear: 0.00023138090029202 nn.Linear: 0.0018085086693191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015953175723553 nn.Linear: 0.018512666225433 nn.Linear: 0.01531711127609 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089958449825644 nn.Linear: 0.022788617759943] nn.Sequential: [nn.Linear: 0.0058230371214449 nn.Linear: 0.020125711336732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062763780199496 nn.Linear: 0.065531310326885 nn.Linear: 0.04541807437971 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539561236789 nn.Linear: 0.054767033838289] nn.Sequential: [nn.Linear: 0.031475577056978 nn.Linear: 0.036443785645662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53011924028397 nn.Linear: 0.25726932287216 nn.Linear: 0.20285719633102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31459313631058 nn.Linear: 0.54026019573212] nn.Sequential: [nn.Linear: 0.15167888998985 nn.Linear: 0.25372824072838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011680132336458 nn.Linear: 0.00078468650654524 nn.Linear: 0.00048948165163057 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021529642504205 nn.Linear: 0.002318287853221] nn.Sequential: [nn.Linear: 0.00023098484680244 nn.Linear: 0.0018752890795803]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092324819415808 nn.Linear: 0.010718947276473 nn.Linear: 0.018958631902933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090615563094616 nn.Linear: 0.018403075635433] nn.Sequential: [nn.Linear: 0.011615453287959 nn.Linear: 0.025034230202436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062764796039188 nn.Linear: 0.06553269200711 nn.Linear: 0.045418891556103 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539751086032 nn.Linear: 0.054784559475365] nn.Sequential: [nn.Linear: 0.031475593228973 nn.Linear: 0.036453772662586]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53048062324524 nn.Linear: 0.25701469182968 nn.Linear: 0.20245413482189 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.315181016922 nn.Linear: 0.54084700345993] nn.Sequential: [nn.Linear: 0.15184409916401 nn.Linear: 0.2539758682251]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0042154536607742 nn.Linear: 0.0016665793388593 nn.Linear: 0.00067086084238952 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00031958550131818 nn.Linear: 0.0047401568636012] nn.Sequential: [nn.Linear: 0.00026437383730441 nn.Linear: 0.0022066054526267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.038448967039585 nn.Linear: 0.034995034337044 nn.Linear: 0.039592865854502 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.021565265953541 nn.Linear: 0.042209558188915] nn.Sequential: [nn.Linear: 0.02154036052525 nn.Linear: 0.033312577754259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062772010800244 nn.Linear: 0.065537470010516 nn.Linear: 0.045421364519986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031539993842411 nn.Linear: 0.054781432568177] nn.Sequential: [nn.Linear: 0.031475980466379 nn.Linear: 0.036481293563011]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52954876422882 nn.Linear: 0.25764280557632 nn.Linear: 0.20251472294331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31567019224167 nn.Linear: 0.54157638549805] nn.Sequential: [nn.Linear: 0.15226927399635 nn.Linear: 0.25421965122223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00066487648774759 nn.Linear: 0.00044286848434321 nn.Linear: 0.00026264940731671 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012411811566718 nn.Linear: 0.0014863426690327] nn.Sequential: [nn.Linear: 9.3701479671326e-05 nn.Linear: 0.00060966375423893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0047516054473817 nn.Linear: 0.0056254575029016 nn.Linear: 0.0045496919192374 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047063939273357 nn.Linear: 0.0088631613180041] nn.Sequential: [nn.Linear: 0.0029641920700669 nn.Linear: 0.0043463190086186]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062771539548333 nn.Linear: 0.065545280323244 nn.Linear: 0.045423483967918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031540153402376 nn.Linear: 0.054800064164169] nn.Sequential: [nn.Linear: 0.03147644409406 nn.Linear: 0.036490402665271]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52940958738327 nn.Linear: 0.25778910517693 nn.Linear: 0.20340302586555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3160699903965 nn.Linear: 0.54268741607666] nn.Sequential: [nn.Linear: 0.15270504355431 nn.Linear: 0.25457733869553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012081581754599 nn.Linear: 0.00078478912957169 nn.Linear: 0.00042287132812941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016648345165052 nn.Linear: 0.0015466831517332] nn.Sequential: [nn.Linear: 0.00021099261963609 nn.Linear: 0.0018087421934459]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090948473662138 nn.Linear: 0.0089147305116057 nn.Linear: 0.0081786969676614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081357778981328 nn.Linear: 0.010431262664497] nn.Sequential: [nn.Linear: 0.0066532571800053 nn.Linear: 0.02014010772109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062777567501015 nn.Linear: 0.065547850401289 nn.Linear: 0.045426221827081 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031540448797048 nn.Linear: 0.054829916646554] nn.Sequential: [nn.Linear: 0.031476795780085 nn.Linear: 0.036507607979248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52963531017303 nn.Linear: 0.25847429037094 nn.Linear: 0.20256118476391 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31650093197823 nn.Linear: 0.54305821657181] nn.Sequential: [nn.Linear: 0.15273334085941 nn.Linear: 0.25464698672295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00150656850152 nn.Linear: 0.00093390652938556 nn.Linear: 0.0004854799211934 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029343137816078 nn.Linear: 0.0045208485438777] nn.Sequential: [nn.Linear: 0.00019229939894055 nn.Linear: 0.0013703126560198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009086187928915 nn.Linear: 0.012628247961402 nn.Linear: 0.011728352867067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015757989138365 nn.Linear: 0.026279740035534] nn.Sequential: [nn.Linear: 0.0058816685341299 nn.Linear: 0.01132704038173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062775901417258 nn.Linear: 0.065548177313642 nn.Linear: 0.045427042415219 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031540636807983 nn.Linear: 0.054841151832079] nn.Sequential: [nn.Linear: 0.031476710540197 nn.Linear: 0.036515888695714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52981686592102 nn.Linear: 0.25827252864838 nn.Linear: 0.20218713581562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31698819994926 nn.Linear: 0.54372906684875] nn.Sequential: [nn.Linear: 0.15283001959324 nn.Linear: 0.25493782758713]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012329387285837 nn.Linear: 0.00080004372857706 nn.Linear: 0.00044911226451115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025487157866664 nn.Linear: 0.0037714301796057] nn.Sequential: [nn.Linear: 0.00015824507372282 nn.Linear: 0.0013026124221838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007630692794919 nn.Linear: 0.0094281015917659 nn.Linear: 0.0068999170325696 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096893236041069 nn.Linear: 0.025485780090094] nn.Sequential: [nn.Linear: 0.004075794480741 nn.Linear: 0.012084999121726]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062775786544219 nn.Linear: 0.06555256958642 nn.Linear: 0.045427391585429 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154090855635 nn.Linear: 0.054847408327703] nn.Sequential: [nn.Linear: 0.031476917318748 nn.Linear: 0.036519124457389]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.52938461303711 nn.Linear: 0.25729075074196 nn.Linear: 0.20281252264977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3174743950367 nn.Linear: 0.54409056901932] nn.Sequential: [nn.Linear: 0.15290220081806 nn.Linear: 0.25529319047928]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011594301955486 nn.Linear: 0.00070689148097153 nn.Linear: 0.00041390443096182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018071136251567 nn.Linear: 0.0020000581689145] nn.Sequential: [nn.Linear: 0.00019809742307924 nn.Linear: 0.0020216365487601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098717585206032 nn.Linear: 0.0084608569741249 nn.Linear: 0.0061101852916181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057835914194584 nn.Linear: 0.012648495845497] nn.Sequential: [nn.Linear: 0.0059460056945682 nn.Linear: 0.016192089766264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062775003177854 nn.Linear: 0.06555281508999 nn.Linear: 0.045427887703294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031540796401368 nn.Linear: 0.054838604077077] nn.Sequential: [nn.Linear: 0.031476979467398 nn.Linear: 0.036520375929663]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53000158071518 nn.Linear: 0.25713995099068 nn.Linear: 0.2035994976759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31832966208458 nn.Linear: 0.54377740621567] nn.Sequential: [nn.Linear: 0.1532529592514 nn.Linear: 0.25538438558578]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00073378462841484 nn.Linear: 0.00046603606189388 nn.Linear: 0.00027602195562652 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012899684796766 nn.Linear: 0.001567081509017] nn.Sequential: [nn.Linear: 0.00013047854025954 nn.Linear: 0.00095859342313417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058875824324787 nn.Linear: 0.0075112017802894 nn.Linear: 0.0050689349882305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057005253620446 nn.Linear: 0.011366784572601] nn.Sequential: [nn.Linear: 0.0047149551101029 nn.Linear: 0.0082579096779227]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062771097732849 nn.Linear: 0.065558734918963 nn.Linear: 0.045429436282514 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031541025769344 nn.Linear: 0.054838685322238] nn.Sequential: [nn.Linear: 0.031477404905369 nn.Linear: 0.036543168313089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53020846843719 nn.Linear: 0.25766879320145 nn.Linear: 0.20399516820908 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31892919540405 nn.Linear: 0.54389953613281] nn.Sequential: [nn.Linear: 0.1534365862608 nn.Linear: 0.25544446706772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013767826551251 nn.Linear: 0.00073508780347624 nn.Linear: 0.00040968776490176 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017371611515549 nn.Linear: 0.0020485609157364] nn.Sequential: [nn.Linear: 0.00021380990987722 nn.Linear: 0.0018331533566719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010784909129143 nn.Linear: 0.011555871926248 nn.Linear: 0.0095432316884398 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085287028923631 nn.Linear: 0.015778928995132] nn.Sequential: [nn.Linear: 0.0072490908205509 nn.Linear: 0.021916916593909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062772067253851 nn.Linear: 0.065563853945185 nn.Linear: 0.045430813119874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031541454775438 nn.Linear: 0.054843235854264] nn.Sequential: [nn.Linear: 0.031477420312565 nn.Linear: 0.036535935992396]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53028219938278 nn.Linear: 0.25788313150406 nn.Linear: 0.20343445241451 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31916284561157 nn.Linear: 0.54479020833969] nn.Sequential: [nn.Linear: 0.15349300205708 nn.Linear: 0.25580537319183]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001377599352156 nn.Linear: 0.0007958044622057 nn.Linear: 0.00045843036558853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021953509414268 nn.Linear: 0.0028844599230865] nn.Sequential: [nn.Linear: 0.00018247218413986 nn.Linear: 0.0013499995630246]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010635156184435 nn.Linear: 0.014466333203018 nn.Linear: 0.0099733350798488 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084121804684401 nn.Linear: 0.017792884260416] nn.Sequential: [nn.Linear: 0.0054581561125815 nn.Linear: 0.013026577420533]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062772850097906 nn.Linear: 0.065564071781298 nn.Linear: 0.045432510143594 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031541725280747 nn.Linear: 0.054886392956064] nn.Sequential: [nn.Linear: 0.031477694525808 nn.Linear: 0.036552875049696]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53098917007446 nn.Linear: 0.25841084122658 nn.Linear: 0.20315389335155 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.31972631812096 nn.Linear: 0.54569190740585] nn.Sequential: [nn.Linear: 0.1537092924118 nn.Linear: 0.2559794485569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024542039606968 nn.Linear: 0.0013514047036916 nn.Linear: 0.000754939260035 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032868448065178 nn.Linear: 0.0042075770701341] nn.Sequential: [nn.Linear: 0.00035204306468891 nn.Linear: 0.0029832481457859]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019941741600633 nn.Linear: 0.028135366737843 nn.Linear: 0.015243052504957 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012779748998582 nn.Linear: 0.029188975691795] nn.Sequential: [nn.Linear: 0.01031397935003 nn.Linear: 0.032678205519915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06277889678379 nn.Linear: 0.065565109190636 nn.Linear: 0.045433952731513 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031541757858895 nn.Linear: 0.054903253857901] nn.Sequential: [nn.Linear: 0.0314777998288 nn.Linear: 0.03656250076809]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53050655126572 nn.Linear: 0.25869762897491 nn.Linear: 0.20331326127052 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3202753663063 nn.Linear: 0.54682606458664] nn.Sequential: [nn.Linear: 0.15395528078079 nn.Linear: 0.25652271509171]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0058904798550409 nn.Linear: 0.0023918866549401 nn.Linear: 0.00082727027430177 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023638536847484 nn.Linear: 0.0028100703020985] nn.Sequential: [nn.Linear: 0.00021281149733609 nn.Linear: 0.0016078972418136]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.035564187914133 nn.Linear: 0.032108098268509 nn.Linear: 0.05187076702714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013838144019246 nn.Linear: 0.026190500706434] nn.Sequential: [nn.Linear: 0.0073450403288007 nn.Linear: 0.015092249028385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062782410946097 nn.Linear: 0.065573527701696 nn.Linear: 0.045436158971622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031542161703114 nn.Linear: 0.054933317701398] nn.Sequential: [nn.Linear: 0.031478265431431 nn.Linear: 0.036577325820223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53073459863663 nn.Linear: 0.25854820013046 nn.Linear: 0.20359274744987 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32082185149193 nn.Linear: 0.54831391572952] nn.Sequential: [nn.Linear: 0.15418308973312 nn.Linear: 0.25715261697769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018314554365205 nn.Linear: 0.00094864261219846 nn.Linear: 0.00044408153181132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022349089382751 nn.Linear: 0.0028192224690868] nn.Sequential: [nn.Linear: 0.00014886948792906 nn.Linear: 0.0010627525578751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014074646867812 nn.Linear: 0.016819342970848 nn.Linear: 0.014352143742144 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01202089432627 nn.Linear: 0.029530229046941] nn.Sequential: [nn.Linear: 0.0044092857278883 nn.Linear: 0.0089763635769486]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062784277148738 nn.Linear: 0.065579370981465 nn.Linear: 0.045438795013511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031542533949184 nn.Linear: 0.054975676186245] nn.Sequential: [nn.Linear: 0.031478671839046 nn.Linear: 0.036590870987941]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53066396713257 nn.Linear: 0.25864827632904 nn.Linear: 0.20404998958111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32132604718208 nn.Linear: 0.54890704154968] nn.Sequential: [nn.Linear: 0.15423865616322 nn.Linear: 0.2574414908886]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011081127325575 nn.Linear: 0.00055351903980921 nn.Linear: 0.00028244811838099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011458638008173 nn.Linear: 0.001233359468004] nn.Sequential: [nn.Linear: 0.00011620786698606 nn.Linear: 0.00087507570376737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070074717514217 nn.Linear: 0.0095310434699059 nn.Linear: 0.0070841093547642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064942636527121 nn.Linear: 0.0093844197690487] nn.Sequential: [nn.Linear: 0.0032297119032592 nn.Linear: 0.0089510083198547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062780187366865 nn.Linear: 0.06558127585675 nn.Linear: 0.045439872374918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031542844058573 nn.Linear: 0.054986722150772] nn.Sequential: [nn.Linear: 0.031478830575932 nn.Linear: 0.036603744823749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53101450204849 nn.Linear: 0.25930905342102 nn.Linear: 0.20428617298603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32184308767319 nn.Linear: 0.54980450868607] nn.Sequential: [nn.Linear: 0.15466737747192 nn.Linear: 0.25764310359955]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016998860414276 nn.Linear: 0.0008633860302982 nn.Linear: 0.00046167414862644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013567773050404 nn.Linear: 0.0013120022783256] nn.Sequential: [nn.Linear: 0.00019503248154836 nn.Linear: 0.0014396724176834]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013490231707692 nn.Linear: 0.019052619114518 nn.Linear: 0.017135923728347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083015887066722 nn.Linear: 0.011789660900831] nn.Sequential: [nn.Linear: 0.012433801777661 nn.Linear: 0.021789973601699]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062783354394617 nn.Linear: 0.065584544055955 nn.Linear: 0.04544088810112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543302666644 nn.Linear: 0.055019922390557] nn.Sequential: [nn.Linear: 0.031478952519896 nn.Linear: 0.036616448322645]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53098523616791 nn.Linear: 0.25904271006584 nn.Linear: 0.20467305183411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32241675257683 nn.Linear: 0.55053097009659] nn.Sequential: [nn.Linear: 0.15486592054367 nn.Linear: 0.25799551606178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012374174577764 nn.Linear: 0.00073429112546136 nn.Linear: 0.00041587054295801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019435741955424 nn.Linear: 0.0026136877853494] nn.Sequential: [nn.Linear: 0.00016759777990885 nn.Linear: 0.0015156785650356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007689340505749 nn.Linear: 0.0099939191713929 nn.Linear: 0.0099756326526403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090703936293721 nn.Linear: 0.017056316137314] nn.Sequential: [nn.Linear: 0.0067734979093075 nn.Linear: 0.013383279554546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.086257054798305	TD error	0.018167095504701	Qmax	1	

Steps: 9250000 (frames: 37000000), score: 2070.37, higheset score: 6548, epsilon: 0.05, lr: 0.0005, training time: 541s, training rate: 1846fps, testing time: 86s, testing rate: 5757fps,  num. ep.: 316,  num. rewards: 16103	
   2    4    8    2
   8  256   16    4
   2    8   32    8
   4  512    8  128
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062788510144278 nn.Linear: 0.065589858006059 nn.Linear: 0.045442834101145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543308933176 nn.Linear: 0.05500343279175] nn.Sequential: [nn.Linear: 0.03147907437963 nn.Linear: 0.036608856032086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53093338012695 nn.Linear: 0.25999596714973 nn.Linear: 0.20405720174313 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32274854183197 nn.Linear: 0.55098086595535] nn.Sequential: [nn.Linear: 0.15531718730927 nn.Linear: 0.25828790664673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019605493932413 nn.Linear: 0.0011496171768797 nn.Linear: 0.00059981160803432 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025758606455739 nn.Linear: 0.0028848309806933] nn.Sequential: [nn.Linear: 0.0002106441909897 nn.Linear: 0.0014705761979343]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012572815641761 nn.Linear: 0.014483097009361 nn.Linear: 0.017767582088709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01491909660399 nn.Linear: 0.021378211677074] nn.Sequential: [nn.Linear: 0.006361129693687 nn.Linear: 0.015899803489447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062787977042546 nn.Linear: 0.065590641043462 nn.Linear: 0.045442739704082 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543538928228 nn.Linear: 0.054979186894002] nn.Sequential: [nn.Linear: 0.031478865115888 nn.Linear: 0.036605939020399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53096669912338 nn.Linear: 0.25966706871986 nn.Linear: 0.20435187220573 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32295483350754 nn.Linear: 0.55159962177277] nn.Sequential: [nn.Linear: 0.15548259019852 nn.Linear: 0.25843524932861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016863158088711 nn.Linear: 0.00097862436790881 nn.Linear: 0.00040388655507161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014259640090397 nn.Linear: 0.0015056629656125] nn.Sequential: [nn.Linear: 0.00011955081892759 nn.Linear: 0.00082528133251741]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010973982512951 nn.Linear: 0.013294227421284 nn.Linear: 0.006797818467021 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083144856616855 nn.Linear: 0.012076677754521] nn.Sequential: [nn.Linear: 0.0059775840491056 nn.Linear: 0.0073185604996979]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062777946372903 nn.Linear: 0.065590522351674 nn.Linear: 0.045442341140726 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543556793852 nn.Linear: 0.054973849473754] nn.Sequential: [nn.Linear: 0.03147873124252 nn.Linear: 0.036598869889147]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53109437227249 nn.Linear: 0.26017662882805 nn.Linear: 0.20435144007206 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32350847125053 nn.Linear: 0.55203104019165] nn.Sequential: [nn.Linear: 0.15552651882172 nn.Linear: 0.25853937864304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020767300162292 nn.Linear: 0.0011223158835151 nn.Linear: 0.00053588905990792 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022247149940203 nn.Linear: 0.0027495066353164] nn.Sequential: [nn.Linear: 0.00021637001633754 nn.Linear: 0.0016089334546708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017492033541203 nn.Linear: 0.018742484971881 nn.Linear: 0.014487748034298 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010907410643995 nn.Linear: 0.028061943128705] nn.Sequential: [nn.Linear: 0.0092001371085644 nn.Linear: 0.020114466547966]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062782568911242 nn.Linear: 0.065595959423415 nn.Linear: 0.045443544659475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543737962699 nn.Linear: 0.054952104395852] nn.Sequential: [nn.Linear: 0.031479048964826 nn.Linear: 0.036610192667624]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53073084354401 nn.Linear: 0.25993463397026 nn.Linear: 0.20429965853691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32439461350441 nn.Linear: 0.55254584550858] nn.Sequential: [nn.Linear: 0.15578858554363 nn.Linear: 0.25875070691109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00083094701318115 nn.Linear: 0.00043279302729194 nn.Linear: 0.0002248703272697 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.514455230934e-05 nn.Linear: 0.0010682193679863] nn.Sequential: [nn.Linear: 8.5938762583628e-05 nn.Linear: 0.00070015204609309]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072080008685589 nn.Linear: 0.010705268010497 nn.Linear: 0.0047378935851157 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055887857452035 nn.Linear: 0.010015301406384] nn.Sequential: [nn.Linear: 0.0035402588546276 nn.Linear: 0.0065498277544975]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062780575230184 nn.Linear: 0.065595611863836 nn.Linear: 0.045444885882209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543694182096 nn.Linear: 0.054978766648276] nn.Sequential: [nn.Linear: 0.031479096482676 nn.Linear: 0.036618813621522]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5312614440918 nn.Linear: 0.26052084565163 nn.Linear: 0.20386992394924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32482531666756 nn.Linear: 0.55299282073975] nn.Sequential: [nn.Linear: 0.15593977272511 nn.Linear: 0.25899797677994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016469330571867 nn.Linear: 0.00085170301160302 nn.Linear: 0.00037879378175719 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016500008098403 nn.Linear: 0.0019703936031885] nn.Sequential: [nn.Linear: 0.00012204453579016 nn.Linear: 0.00079071404793067]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088684037327766 nn.Linear: 0.012022501789033 nn.Linear: 0.013754141516984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012185710482299 nn.Linear: 0.017869088798761] nn.Sequential: [nn.Linear: 0.0047965543344617 nn.Linear: 0.0094996970146894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062777084571038 nn.Linear: 0.065598962737127 nn.Linear: 0.04544564062754 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154357629738 nn.Linear: 0.054982118929388] nn.Sequential: [nn.Linear: 0.031479150314789 nn.Linear: 0.03660881294442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53104907274246 nn.Linear: 0.26048195362091 nn.Linear: 0.20457321405411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32508507370949 nn.Linear: 0.55362647771835] nn.Sequential: [nn.Linear: 0.1559274494648 nn.Linear: 0.25922435522079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010999994316659 nn.Linear: 0.0006361359017303 nn.Linear: 0.00035594099952752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016590535995546 nn.Linear: 0.0021933525956093] nn.Sequential: [nn.Linear: 0.00012134999096244 nn.Linear: 0.00082180652754921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085304034873843 nn.Linear: 0.0093484278768301 nn.Linear: 0.0089297220110893 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061237793415785 nn.Linear: 0.013369959779084] nn.Sequential: [nn.Linear: 0.0059027601964772 nn.Linear: 0.0075012729503214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062769991415925 nn.Linear: 0.065599711319848 nn.Linear: 0.045445981317736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543992916447 nn.Linear: 0.055006789942468] nn.Sequential: [nn.Linear: 0.031479066476925 nn.Linear: 0.036617287452407]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53086507320404 nn.Linear: 0.26089105010033 nn.Linear: 0.20429742336273 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32590055465698 nn.Linear: 0.55453687906265] nn.Sequential: [nn.Linear: 0.15597711503506 nn.Linear: 0.25967425107956]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014296570365643 nn.Linear: 0.00081476288381276 nn.Linear: 0.00034132587652588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012381595873048 nn.Linear: 0.0012842736936159] nn.Sequential: [nn.Linear: 0.00013204907924998 nn.Linear: 0.0010959499661258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090303737670183 nn.Linear: 0.011999510228634 nn.Linear: 0.0066207703202963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046616489998996 nn.Linear: 0.012984975241125] nn.Sequential: [nn.Linear: 0.0038845832459629 nn.Linear: 0.0086481655016541]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06276998533071 nn.Linear: 0.06560415106062 nn.Linear: 0.045446898910581 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031543967975247 nn.Linear: 0.055018539676439] nn.Sequential: [nn.Linear: 0.031479205978442 nn.Linear: 0.036613383857693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53099501132965 nn.Linear: 0.26064348220825 nn.Linear: 0.2046156078577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3266142308712 nn.Linear: 0.55487138032913] nn.Sequential: [nn.Linear: 0.15643620491028 nn.Linear: 0.25962653756142]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097162382207613 nn.Linear: 0.0006279137667288 nn.Linear: 0.00027723320819929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011527899420063 nn.Linear: 0.0013099802950979] nn.Sequential: [nn.Linear: 0.00011948329849732 nn.Linear: 0.00089954602196837]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065279342234135 nn.Linear: 0.0075691901147366 nn.Linear: 0.0050616743974388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058313431218266 nn.Linear: 0.010000430978835] nn.Sequential: [nn.Linear: 0.0040811393409967 nn.Linear: 0.010149447247386]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062776514800333 nn.Linear: 0.065607295256177 nn.Linear: 0.045448475617977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031544277863676 nn.Linear: 0.05503444926137] nn.Sequential: [nn.Linear: 0.031479126074559 nn.Linear: 0.036618853621001]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53116720914841 nn.Linear: 0.26019275188446 nn.Linear: 0.20470474660397 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32693135738373 nn.Linear: 0.55516427755356] nn.Sequential: [nn.Linear: 0.1562961935997 nn.Linear: 0.25986221432686]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012976529005632 nn.Linear: 0.000811156502806 nn.Linear: 0.00040863961616769 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012884428383065 nn.Linear: 0.0012698048297708] nn.Sequential: [nn.Linear: 0.00019211765067539 nn.Linear: 0.001473730664467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088015263900161 nn.Linear: 0.014802108518779 nn.Linear: 0.0063065811991692 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093278773128986 nn.Linear: 0.0088321072980762] nn.Sequential: [nn.Linear: 0.0068081319332123 nn.Linear: 0.015260114334524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062777979984854 nn.Linear: 0.0656139092213 nn.Linear: 0.045450834876716 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031544688469401 nn.Linear: 0.055107250041488] nn.Sequential: [nn.Linear: 0.031479656029154 nn.Linear: 0.036634910840969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53136456012726 nn.Linear: 0.26133200526237 nn.Linear: 0.20478984713554 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32740417122841 nn.Linear: 0.55595654249191] nn.Sequential: [nn.Linear: 0.15651133656502 nn.Linear: 0.2602570950985]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00061924181571876 nn.Linear: 0.00037373388651634 nn.Linear: 0.00019798979883258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001069731632454 nn.Linear: 0.0014385825425804] nn.Sequential: [nn.Linear: 9.4492600992393e-05 nn.Linear: 0.00067445380885703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0044833892025054 nn.Linear: 0.006127655506134 nn.Linear: 0.0045011341571808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060861073434353 nn.Linear: 0.011263740248978] nn.Sequential: [nn.Linear: 0.0040834061801434 nn.Linear: 0.009495971724391]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062775420057887 nn.Linear: 0.065612068753619 nn.Linear: 0.045449600506702 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031544816997492 nn.Linear: 0.055082570554532] nn.Sequential: [nn.Linear: 0.031479551780189 nn.Linear: 0.036638959757071]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53190153837204 nn.Linear: 0.26117065548897 nn.Linear: 0.20467048883438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32779601216316 nn.Linear: 0.55671328306198] nn.Sequential: [nn.Linear: 0.15652973949909 nn.Linear: 0.26052278280258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018787267662801 nn.Linear: 0.0010294212627737 nn.Linear: 0.00046544722671346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017228502964422 nn.Linear: 0.0017646428307179] nn.Sequential: [nn.Linear: 0.00015865455227156 nn.Linear: 0.0010730469979972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014313952066004 nn.Linear: 0.016451245173812 nn.Linear: 0.014879719354212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005348083563149 nn.Linear: 0.011980359442532] nn.Sequential: [nn.Linear: 0.0040819123387337 nn.Linear: 0.012942308560014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062770456424177 nn.Linear: 0.065612752334353 nn.Linear: 0.045450524206215 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154480235512 nn.Linear: 0.055070518912885] nn.Sequential: [nn.Linear: 0.031479638338382 nn.Linear: 0.036624246279722]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53120255470276 nn.Linear: 0.2613999247551 nn.Linear: 0.20503561198711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32835504412651 nn.Linear: 0.55718237161636] nn.Sequential: [nn.Linear: 0.15670642256737 nn.Linear: 0.26084074378014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013419037313141 nn.Linear: 0.00093591056403437 nn.Linear: 0.00049257111329928 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025686336393554 nn.Linear: 0.0032990014415749] nn.Sequential: [nn.Linear: 0.00019722444931255 nn.Linear: 0.0013122695346641]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096457116305828 nn.Linear: 0.017533937469125 nn.Linear: 0.012721951119602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011519090272486 nn.Linear: 0.020532568916678] nn.Sequential: [nn.Linear: 0.0055040349252522 nn.Linear: 0.013791003264487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06277182737217 nn.Linear: 0.065616486420564 nn.Linear: 0.0454524293612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031545171842236 nn.Linear: 0.055095990158719] nn.Sequential: [nn.Linear: 0.031479779692632 nn.Linear: 0.036631585158672]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53132200241089 nn.Linear: 0.26158767938614 nn.Linear: 0.20513233542442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32917174696922 nn.Linear: 0.55770003795624] nn.Sequential: [nn.Linear: 0.15704369544983 nn.Linear: 0.26110139489174]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012859995645286 nn.Linear: 0.00074454724908056 nn.Linear: 0.00037693115062469 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015960173988649 nn.Linear: 0.0017491815923784] nn.Sequential: [nn.Linear: 0.00015474394162841 nn.Linear: 0.0010485335635816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076755355112255 nn.Linear: 0.0088045084849 nn.Linear: 0.0087052593007684 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066021252423525 nn.Linear: 0.01331065967679] nn.Sequential: [nn.Linear: 0.0054964814335108 nn.Linear: 0.010933734476566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062770868176947 nn.Linear: 0.065619796470198 nn.Linear: 0.045452969763437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031545236959485 nn.Linear: 0.055094373151206] nn.Sequential: [nn.Linear: 0.031479791146151 nn.Linear: 0.03662739485527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53105890750885 nn.Linear: 0.26181057095528 nn.Linear: 0.20480847358704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.32969084382057 nn.Linear: 0.55867326259613] nn.Sequential: [nn.Linear: 0.15707185864449 nn.Linear: 0.26138365268707]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00076965457400002 nn.Linear: 0.000540199804417 nn.Linear: 0.00033483571046699 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013763694042594 nn.Linear: 0.0014673351533696] nn.Sequential: [nn.Linear: 0.00017030299571878 nn.Linear: 0.0014760254270436]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058260839432478 nn.Linear: 0.0088088139891624 nn.Linear: 0.0077058607712388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0046327812597156 nn.Linear: 0.01158700324595] nn.Sequential: [nn.Linear: 0.0051696449518204 nn.Linear: 0.012169362045825]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062774818418387 nn.Linear: 0.065622085800411 nn.Linear: 0.04545357552836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031545612138387 nn.Linear: 0.055116453070866] nn.Sequential: [nn.Linear: 0.031479857056523 nn.Linear: 0.036629321428023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53096050024033 nn.Linear: 0.26229485869408 nn.Linear: 0.20513692498207 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33017551898956 nn.Linear: 0.55904567241669] nn.Sequential: [nn.Linear: 0.1573737859726 nn.Linear: 0.26149398088455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025333540876079 nn.Linear: 0.0015582846960337 nn.Linear: 0.00074036968058408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032508152750303 nn.Linear: 0.0043480208948959] nn.Sequential: [nn.Linear: 0.00030133698719746 nn.Linear: 0.0021901401223221]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021728446707129 nn.Linear: 0.022759612649679 nn.Linear: 0.018401220440865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024472933262587 nn.Linear: 0.029944680631161] nn.Sequential: [nn.Linear: 0.010313036851585 nn.Linear: 0.022559501230717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06277379843743 nn.Linear: 0.065624148016097 nn.Linear: 0.045454815560729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031545865178423 nn.Linear: 0.055134681463386] nn.Sequential: [nn.Linear: 0.03147987495214 nn.Linear: 0.036634868500838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53128468990326 nn.Linear: 0.26276540756226 nn.Linear: 0.20570772886276 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33125817775726 nn.Linear: 0.55983883142471] nn.Sequential: [nn.Linear: 0.15763503313065 nn.Linear: 0.26161453127861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001096840897867 nn.Linear: 0.00069110359374521 nn.Linear: 0.0004397669423098 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018967333152552 nn.Linear: 0.0022974667089345] nn.Sequential: [nn.Linear: 0.00019317814642928 nn.Linear: 0.0014476778019938]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067895180545747 nn.Linear: 0.011304084211588 nn.Linear: 0.0092247314751148 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087919356301427 nn.Linear: 0.016417354345322] nn.Sequential: [nn.Linear: 0.0064584058709443 nn.Linear: 0.012520764023066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062766230222512 nn.Linear: 0.065626356273853 nn.Linear: 0.045454800270923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031546098846851 nn.Linear: 0.055140677321191] nn.Sequential: [nn.Linear: 0.031480126961045 nn.Linear: 0.03664930556429]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5313276052475 nn.Linear: 0.26226365566254 nn.Linear: 0.20623105764389 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33194562792778 nn.Linear: 0.56075179576874] nn.Sequential: [nn.Linear: 0.15776202082634 nn.Linear: 0.26191484928131]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010481583567958 nn.Linear: 0.00071719873072394 nn.Linear: 0.00037314958811857 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016656915069002 nn.Linear: 0.0018894699247492] nn.Sequential: [nn.Linear: 0.00015903948635867 nn.Linear: 0.0011727619257949]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082531655207276 nn.Linear: 0.012033744715154 nn.Linear: 0.0081759691238403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073522161692381 nn.Linear: 0.011828677728772] nn.Sequential: [nn.Linear: 0.005774094723165 nn.Linear: 0.015622624196112]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062767773489067 nn.Linear: 0.065627555377406 nn.Linear: 0.045454926230346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031546230754008 nn.Linear: 0.055130849857093] nn.Sequential: [nn.Linear: 0.031480048344803 nn.Linear: 0.036648187394733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53139579296112 nn.Linear: 0.26230984926224 nn.Linear: 0.20594857633114 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33223500847816 nn.Linear: 0.5609535574913] nn.Sequential: [nn.Linear: 0.15764665603638 nn.Linear: 0.26213729381561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015583895527976 nn.Linear: 0.00084896509800086 nn.Linear: 0.00046121123117299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021487309371868 nn.Linear: 0.0026617817755212] nn.Sequential: [nn.Linear: 0.00022976841179183 nn.Linear: 0.0017502677097836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01008366048336 nn.Linear: 0.015445905737579 nn.Linear: 0.014161869883537 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012970781885087 nn.Linear: 0.029594454914331] nn.Sequential: [nn.Linear: 0.011057071387768 nn.Linear: 0.017224648967385]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062763500021844 nn.Linear: 0.065628921655111 nn.Linear: 0.045456648354369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0315463499485 nn.Linear: 0.05511850280643] nn.Sequential: [nn.Linear: 0.031480374213432 nn.Linear: 0.03665387912067]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5314901471138 nn.Linear: 0.26240754127502 nn.Linear: 0.20647025108337 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33258908987045 nn.Linear: 0.56148791313171] nn.Sequential: [nn.Linear: 0.15784305334091 nn.Linear: 0.26222276687622]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017633529602271 nn.Linear: 0.0010337431288284 nn.Linear: 0.0004807912568591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025037672937083 nn.Linear: 0.0033756715813704] nn.Sequential: [nn.Linear: 0.00014968250283002 nn.Linear: 0.00097512683063198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0089767463505268 nn.Linear: 0.013433943502605 nn.Linear: 0.0085194921121001 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086317621171474 nn.Linear: 0.019445862621069] nn.Sequential: [nn.Linear: 0.0040268660522997 nn.Linear: 0.0092847160995007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757735740124 nn.Linear: 0.065632769905041 nn.Linear: 0.045457632516447 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031546524002009 nn.Linear: 0.055141289868658] nn.Sequential: [nn.Linear: 0.031480278789879 nn.Linear: 0.036647971288489]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53158158063889 nn.Linear: 0.2626965045929 nn.Linear: 0.20684409141541 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33348616957664 nn.Linear: 0.56178176403046] nn.Sequential: [nn.Linear: 0.15796732902527 nn.Linear: 0.26228058338165]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023381928751345 nn.Linear: 0.0012393045222789 nn.Linear: 0.00052477324634037 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023121398471133 nn.Linear: 0.0026189443064657] nn.Sequential: [nn.Linear: 0.00020168391912254 nn.Linear: 0.0016219053845437]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024187298491597 nn.Linear: 0.017673479393125 nn.Linear: 0.028108790516853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011970003135502 nn.Linear: 0.022173281759024] nn.Sequential: [nn.Linear: 0.0080042574554682 nn.Linear: 0.017506947740912]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062753643499154 nn.Linear: 0.065631736748346 nn.Linear: 0.045457408972211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031546961191384 nn.Linear: 0.055185197159801] nn.Sequential: [nn.Linear: 0.031479961703457 nn.Linear: 0.036661087313138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53113055229187 nn.Linear: 0.26286846399307 nn.Linear: 0.20671658217907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33381187915802 nn.Linear: 0.56250607967377] nn.Sequential: [nn.Linear: 0.15797750651836 nn.Linear: 0.26265585422516]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010455802000858 nn.Linear: 0.0005978377544853 nn.Linear: 0.00033387450062116 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017223268994551 nn.Linear: 0.0023559768923098] nn.Sequential: [nn.Linear: 0.0001133308041059 nn.Linear: 0.00074823405827262]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064630163833499 nn.Linear: 0.0089417025446892 nn.Linear: 0.0072843260131776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099913058802485 nn.Linear: 0.014197172597051] nn.Sequential: [nn.Linear: 0.0038131347391754 nn.Linear: 0.0077134342864156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062759495044974 nn.Linear: 0.065636244001171 nn.Linear: 0.045458317744299 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154709482532 nn.Linear: 0.055184436522495] nn.Sequential: [nn.Linear: 0.031480342024188 nn.Linear: 0.036658788342733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53189319372177 nn.Linear: 0.26274839043617 nn.Linear: 0.20631638169289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33472481369972 nn.Linear: 0.56307804584503] nn.Sequential: [nn.Linear: 0.15823961794376 nn.Linear: 0.26300176978111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013608672968128 nn.Linear: 0.00089432534934505 nn.Linear: 0.00046741652811865 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019244201284393 nn.Linear: 0.002393483466357] nn.Sequential: [nn.Linear: 0.00020664003889946 nn.Linear: 0.0016133013669198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099535826593637 nn.Linear: 0.01091084908694 nn.Linear: 0.012473119422793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017805280163884 nn.Linear: 0.028580665588379] nn.Sequential: [nn.Linear: 0.0087133422493935 nn.Linear: 0.018400711938739]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062757388375498 nn.Linear: 0.065639307574551 nn.Linear: 0.045459444565387 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031547491238392 nn.Linear: 0.055188550787193] nn.Sequential: [nn.Linear: 0.031480265614792 nn.Linear: 0.036661033346388]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53195261955261 nn.Linear: 0.26277270913124 nn.Linear: 0.20684632658958 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33501043915749 nn.Linear: 0.56378954648972] nn.Sequential: [nn.Linear: 0.15824550390244 nn.Linear: 0.26330265402794]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020961908332195 nn.Linear: 0.001137009653173 nn.Linear: 0.00062113118660733 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002503095725879 nn.Linear: 0.0031578119458429] nn.Sequential: [nn.Linear: 0.00022784435362508 nn.Linear: 0.0019650568058857]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014360148459673 nn.Linear: 0.016204072162509 nn.Linear: 0.012238695286214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014366589486599 nn.Linear: 0.029265122488141] nn.Sequential: [nn.Linear: 0.0064489771611989 nn.Linear: 0.018650406971574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062759953958617 nn.Linear: 0.065638882716852 nn.Linear: 0.045460083686975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031547579968524 nn.Linear: 0.05519237712889] nn.Sequential: [nn.Linear: 0.031480644056219 nn.Linear: 0.036672132140013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53224766254425 nn.Linear: 0.2636122405529 nn.Linear: 0.20595186948776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33522894978523 nn.Linear: 0.5638764500618] nn.Sequential: [nn.Linear: 0.15862102806568 nn.Linear: 0.26338276267052]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00087189936753093 nn.Linear: 0.00043278663412475 nn.Linear: 0.00025759725990546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001081613265499 nn.Linear: 0.0011271684409477] nn.Sequential: [nn.Linear: 9.5071495149616e-05 nn.Linear: 0.000774386703069]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073580774478614 nn.Linear: 0.0077423523180187 nn.Linear: 0.0051537705585361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056045171804726 nn.Linear: 0.0088894106447697] nn.Sequential: [nn.Linear: 0.00231464789249 nn.Linear: 0.0071492735296488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062755617939706 nn.Linear: 0.065641187282491 nn.Linear: 0.045460472282222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031547550364376 nn.Linear: 0.055199629042079] nn.Sequential: [nn.Linear: 0.031480499745324 nn.Linear: 0.036666462116123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53300553560257 nn.Linear: 0.26328521966934 nn.Linear: 0.20668067038059 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33578598499298 nn.Linear: 0.56471586227417] nn.Sequential: [nn.Linear: 0.1591265052557 nn.Linear: 0.26384690403938]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080727376757049 nn.Linear: 0.00061456365842767 nn.Linear: 0.00038623456657357 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022892413435943 nn.Linear: 0.0031259090126374] nn.Sequential: [nn.Linear: 0.00014470802206147 nn.Linear: 0.001060385917774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0071672983467579 nn.Linear: 0.0094127943739295 nn.Linear: 0.0082447687163949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006908172275871 nn.Linear: 0.018625939264894] nn.Sequential: [nn.Linear: 0.0040288669988513 nn.Linear: 0.010219268500805]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.084217051409185	TD error	0.017189731962979	Qmax	1	

Steps: 9500000 (frames: 38000000), score: 1634.25, higheset score: 6792, epsilon: 0.05, lr: 0.0005, training time: 541s, training rate: 1846fps, testing time: 88s, testing rate: 5640fps,  num. ep.: 494,  num. rewards: 19019	
   2    4    2   16
   8   32   16  512
  16  128  256    4
   2    4   32    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062756599449005 nn.Linear: 0.065643321084465 nn.Linear: 0.045461808753009 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031547913526647 nn.Linear: 0.055222110528803] nn.Sequential: [nn.Linear: 0.031480642701237 nn.Linear: 0.036661355392952]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53285318613052 nn.Linear: 0.26368474960327 nn.Linear: 0.20618025958538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33626765012741 nn.Linear: 0.56544494628906] nn.Sequential: [nn.Linear: 0.15919035673141 nn.Linear: 0.26412805914879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095141774897646 nn.Linear: 0.00049999654481517 nn.Linear: 0.00028070778966559 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015244809862925 nn.Linear: 0.0017958814718181] nn.Sequential: [nn.Linear: 0.00011204936412648 nn.Linear: 0.0007023151685199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060512972995639 nn.Linear: 0.0082124406471848 nn.Linear: 0.005328185390681 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006151900626719 nn.Linear: 0.011524305678904] nn.Sequential: [nn.Linear: 0.0036550930235535 nn.Linear: 0.0058574443683028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062759218019766 nn.Linear: 0.065645338341038 nn.Linear: 0.045462904878047 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031548412835956 nn.Linear: 0.05525159923161] nn.Sequential: [nn.Linear: 0.031480793906707 nn.Linear: 0.036662406066782]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53324973583221 nn.Linear: 0.26378434896469 nn.Linear: 0.20617744326591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3365620970726 nn.Linear: 0.56594836711884] nn.Sequential: [nn.Linear: 0.15932083129883 nn.Linear: 0.26451683044434]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011230770488599 nn.Linear: 0.00071891659537664 nn.Linear: 0.00046321800611357 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019904156094831 nn.Linear: 0.0028976308085376] nn.Sequential: [nn.Linear: 0.0002445529471437 nn.Linear: 0.0019927634126053]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063903122209013 nn.Linear: 0.010433319956064 nn.Linear: 0.0087665216997266 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085712820291519 nn.Linear: 0.016735762357712] nn.Sequential: [nn.Linear: 0.0091279055923223 nn.Linear: 0.019348535686731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062747255768162 nn.Linear: 0.065647697365533 nn.Linear: 0.045463687724547 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031548674103769 nn.Linear: 0.055308221691007] nn.Sequential: [nn.Linear: 0.031480912367622 nn.Linear: 0.036682141319196]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53354859352112 nn.Linear: 0.26429244875908 nn.Linear: 0.2059406042099 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33688727021217 nn.Linear: 0.5670000910759] nn.Sequential: [nn.Linear: 0.1596814841032 nn.Linear: 0.26469796895981]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016303812627299 nn.Linear: 0.00094666386605442 nn.Linear: 0.00045119220746004 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021977169439842 nn.Linear: 0.0029189945556106] nn.Sequential: [nn.Linear: 0.00016255241341856 nn.Linear: 0.0013037144796846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014360069297254 nn.Linear: 0.011854101903737 nn.Linear: 0.0078733945265412 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014117906801403 nn.Linear: 0.020349683240056] nn.Sequential: [nn.Linear: 0.0058299722149968 nn.Linear: 0.010818282142282]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062753838915206 nn.Linear: 0.065653911739567 nn.Linear: 0.045464757021732 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154887689398 nn.Linear: 0.055278574117494] nn.Sequential: [nn.Linear: 0.03148114259538 nn.Linear: 0.036671783675583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53324693441391 nn.Linear: 0.26454496383667 nn.Linear: 0.20609775185585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33724170923233 nn.Linear: 0.567253947258] nn.Sequential: [nn.Linear: 0.15995611250401 nn.Linear: 0.26505234837532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013728452365282 nn.Linear: 0.00091262474492578 nn.Linear: 0.00050451101659522 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026328985370221 nn.Linear: 0.0033124488897643] nn.Sequential: [nn.Linear: 0.00019815229678331 nn.Linear: 0.0014320850465666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011638607829809 nn.Linear: 0.012930786237121 nn.Linear: 0.0101283704862 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0090336427092552 nn.Linear: 0.020169485360384] nn.Sequential: [nn.Linear: 0.0055755898356438 nn.Linear: 0.010758630000055]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062752483535511 nn.Linear: 0.065653338684063 nn.Linear: 0.045465866702195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031548950753871 nn.Linear: 0.05526890263441] nn.Sequential: [nn.Linear: 0.03148125639029 nn.Linear: 0.036690425514184]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53338694572449 nn.Linear: 0.26433256268501 nn.Linear: 0.20680119097233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33797374367714 nn.Linear: 0.56810200214386] nn.Sequential: [nn.Linear: 0.16014859080315 nn.Linear: 0.26549541950226]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00069182044456803 nn.Linear: 0.00054754161783573 nn.Linear: 0.00035192875061551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015634452769946 nn.Linear: 0.001522333168208] nn.Sequential: [nn.Linear: 0.00019829034917893 nn.Linear: 0.0016826088340028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0044150701723993 nn.Linear: 0.0071285688318312 nn.Linear: 0.0059179808013141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057912897318602 nn.Linear: 0.010152359493077] nn.Sequential: [nn.Linear: 0.006742253433913 nn.Linear: 0.019918629899621]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062746788457082 nn.Linear: 0.065651495670076 nn.Linear: 0.0454656859859 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031548680220339 nn.Linear: 0.055253309028899] nn.Sequential: [nn.Linear: 0.031481262116569 nn.Linear: 0.03670813926061]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53366488218307 nn.Linear: 0.26422119140625 nn.Linear: 0.20696802437305 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33874067664146 nn.Linear: 0.56852412223816] nn.Sequential: [nn.Linear: 0.16010671854019 nn.Linear: 0.26572182774544]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014041442578943 nn.Linear: 0.00087237986976034 nn.Linear: 0.00041546459932093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001370054491079 nn.Linear: 0.0016093768470603] nn.Sequential: [nn.Linear: 0.00020181681061941 nn.Linear: 0.0015474119577762]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085767013952136 nn.Linear: 0.012066057883203 nn.Linear: 0.010088575072587 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076414905488491 nn.Linear: 0.013877819292247] nn.Sequential: [nn.Linear: 0.0085153486579657 nn.Linear: 0.017325676977634]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062743438220322 nn.Linear: 0.065657341446993 nn.Linear: 0.045467664488954 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549084638103 nn.Linear: 0.055287978758827] nn.Sequential: [nn.Linear: 0.031481720211439 nn.Linear: 0.036715911246388]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53412413597107 nn.Linear: 0.26433455944061 nn.Linear: 0.20758068561554 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.33921390771866 nn.Linear: 0.56883668899536] nn.Sequential: [nn.Linear: 0.16011546552181 nn.Linear: 0.26591050624847]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010707759369067 nn.Linear: 0.00060334765488769 nn.Linear: 0.00031045349914511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014793013508791 nn.Linear: 0.0020158246906274] nn.Sequential: [nn.Linear: 0.00014913519803985 nn.Linear: 0.0012880569116178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073088938370347 nn.Linear: 0.0084384605288506 nn.Linear: 0.0066835656762123 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0095823239535093 nn.Linear: 0.015687445178628] nn.Sequential: [nn.Linear: 0.010084158740938 nn.Linear: 0.019671574234962]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062744280134042 nn.Linear: 0.065659834880194 nn.Linear: 0.045469401409596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549120652817 nn.Linear: 0.055309077319407] nn.Sequential: [nn.Linear: 0.03148173934828 nn.Linear: 0.036721573608028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53457498550415 nn.Linear: 0.2644170820713 nn.Linear: 0.20704385638237 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34012076258659 nn.Linear: 0.56894689798355] nn.Sequential: [nn.Linear: 0.16042755544186 nn.Linear: 0.26603832840919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014087296491173 nn.Linear: 0.00067395665415675 nn.Linear: 0.00033013271633519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012561172812196 nn.Linear: 0.001357235617522] nn.Sequential: [nn.Linear: 0.00012077226262773 nn.Linear: 0.00085243910812355]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094073852524161 nn.Linear: 0.012961907312274 nn.Linear: 0.010979541577399 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051655876450241 nn.Linear: 0.0094808582216501] nn.Sequential: [nn.Linear: 0.005451301112771 nn.Linear: 0.0091387713328004]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06274654990518 nn.Linear: 0.065661725239068 nn.Linear: 0.045469514771245 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549314085107 nn.Linear: 0.055294368607406] nn.Sequential: [nn.Linear: 0.031481698710706 nn.Linear: 0.036730482138974]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5342178940773 nn.Linear: 0.26436847448349 nn.Linear: 0.2072102278471 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34038496017456 nn.Linear: 0.56907898187637] nn.Sequential: [nn.Linear: 0.16083391010761 nn.Linear: 0.26620358228683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093380149404377 nn.Linear: 0.00064126971888756 nn.Linear: 0.00040788743017141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019508913575036 nn.Linear: 0.0018661139055192] nn.Sequential: [nn.Linear: 0.00016482894265775 nn.Linear: 0.00098008716311623]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0077093900181353 nn.Linear: 0.0091084316372871 nn.Linear: 0.0094125894829631 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074688163585961 nn.Linear: 0.014327798038721] nn.Sequential: [nn.Linear: 0.0052031530067325 nn.Linear: 0.011220389045775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062746236985268 nn.Linear: 0.06566469901398 nn.Linear: 0.045470418771792 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549580602534 nn.Linear: 0.055293974429503] nn.Sequential: [nn.Linear: 0.031481727439127 nn.Linear: 0.036741901477985]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53457313776016 nn.Linear: 0.26468825340271 nn.Linear: 0.20762722194195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34095951914787 nn.Linear: 0.5697049498558] nn.Sequential: [nn.Linear: 0.16113735735416 nn.Linear: 0.26638975739479]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00080994675695722 nn.Linear: 0.00049451516236246 nn.Linear: 0.00028174922908706 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014281664047185 nn.Linear: 0.0016212910915305] nn.Sequential: [nn.Linear: 0.00010906418537258 nn.Linear: 0.00074496359262254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085084559395909 nn.Linear: 0.0064256489276886 nn.Linear: 0.0046773739159107 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0044556576758623 nn.Linear: 0.010648605413735] nn.Sequential: [nn.Linear: 0.0029925219714642 nn.Linear: 0.0066518024541438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062750971606397 nn.Linear: 0.065665165309362 nn.Linear: 0.045471581953501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03154966053614 nn.Linear: 0.055297822822467] nn.Sequential: [nn.Linear: 0.03148176932702 nn.Linear: 0.036721645896217]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53477001190186 nn.Linear: 0.26452669501305 nn.Linear: 0.20777896046638 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34171399474144 nn.Linear: 0.57003372907639] nn.Sequential: [nn.Linear: 0.16150689125061 nn.Linear: 0.26660174131393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018058620365216 nn.Linear: 0.00092169415500649 nn.Linear: 0.00053722479824451 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027000572137151 nn.Linear: 0.0032722425779651] nn.Sequential: [nn.Linear: 0.000217761480262 nn.Linear: 0.00169677510111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01128133200109 nn.Linear: 0.015495534986258 nn.Linear: 0.024940771982074 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011098951101303 nn.Linear: 0.022104665637016] nn.Sequential: [nn.Linear: 0.008247097954154 nn.Linear: 0.022361341863871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062745370736824 nn.Linear: 0.065663804379124 nn.Linear: 0.045471382805555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549575619369 nn.Linear: 0.055299783606614] nn.Sequential: [nn.Linear: 0.031481710987668 nn.Linear: 0.036721378245134]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53505438566208 nn.Linear: 0.26495614647865 nn.Linear: 0.20812532305717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34218135476112 nn.Linear: 0.57036411762238] nn.Sequential: [nn.Linear: 0.16172349452972 nn.Linear: 0.26668494939804]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098168436549756 nn.Linear: 0.0005631282018441 nn.Linear: 0.0002970283436419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011169459343432 nn.Linear: 0.0011395107886328] nn.Sequential: [nn.Linear: 0.00010352209354132 nn.Linear: 0.00067017560882203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059417192824185 nn.Linear: 0.0094208214432001 nn.Linear: 0.0055576697923243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0069924988783896 nn.Linear: 0.0083749648183584] nn.Sequential: [nn.Linear: 0.0049516712315381 nn.Linear: 0.0076926969923079]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062746056173449 nn.Linear: 0.065668934053821 nn.Linear: 0.045472160301529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031549693450857 nn.Linear: 0.055293794769796] nn.Sequential: [nn.Linear: 0.031481814236754 nn.Linear: 0.036729036422501]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53590124845505 nn.Linear: 0.26475536823273 nn.Linear: 0.20834645628929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34230321645737 nn.Linear: 0.57082432508469] nn.Sequential: [nn.Linear: 0.16198217868805 nn.Linear: 0.26711958646774]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017779260484029 nn.Linear: 0.0011670763090562 nn.Linear: 0.00059917716111371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030547156507204 nn.Linear: 0.0041652317688703] nn.Sequential: [nn.Linear: 0.00021160773438436 nn.Linear: 0.0017521318750643]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010701354593039 nn.Linear: 0.018622998148203 nn.Linear: 0.011434126645327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01464363373816 nn.Linear: 0.036869846284389] nn.Sequential: [nn.Linear: 0.0092613911256194 nn.Linear: 0.013234539888799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062740781654782 nn.Linear: 0.065671687942805 nn.Linear: 0.045473316165426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550147056608 nn.Linear: 0.055319777750213] nn.Sequential: [nn.Linear: 0.031482067031181 nn.Linear: 0.036737063815006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53633141517639 nn.Linear: 0.26514345407486 nn.Linear: 0.20886053144932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34276175498962 nn.Linear: 0.57157462835312] nn.Sequential: [nn.Linear: 0.16234709322453 nn.Linear: 0.26738882064819]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026505558602047 nn.Linear: 0.0014142522520472 nn.Linear: 0.00066524449731895 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022481583922139 nn.Linear: 0.0026864735496877] nn.Sequential: [nn.Linear: 0.00022199248140918 nn.Linear: 0.0016630860781368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015777302905917 nn.Linear: 0.023613834753633 nn.Linear: 0.016303315758705 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.009734608232975 nn.Linear: 0.022050989791751] nn.Sequential: [nn.Linear: 0.007423919159919 nn.Linear: 0.01492034830153]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062742375589014 nn.Linear: 0.06567620418387 nn.Linear: 0.045474308076027 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550449701781 nn.Linear: 0.055347018738303] nn.Sequential: [nn.Linear: 0.031482120664679 nn.Linear: 0.036743138881826]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53685969114304 nn.Linear: 0.26549649238586 nn.Linear: 0.20938535034657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34297713637352 nn.Linear: 0.57195395231247] nn.Sequential: [nn.Linear: 0.1624401807785 nn.Linear: 0.26791322231293]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093679894835368 nn.Linear: 0.00062463683390726 nn.Linear: 0.00038488328620978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022945641603332 nn.Linear: 0.003240510137663] nn.Sequential: [nn.Linear: 0.00015191097729196 nn.Linear: 0.0010910012689756]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0078295869752765 nn.Linear: 0.0079969922080636 nn.Linear: 0.006528521887958 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010373359546065 nn.Linear: 0.018622187897563] nn.Sequential: [nn.Linear: 0.0046254796907306 nn.Linear: 0.012614201754332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062733716449669 nn.Linear: 0.065676700442067 nn.Linear: 0.045474146121108 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550413536681 nn.Linear: 0.055340451550705] nn.Sequential: [nn.Linear: 0.031481908676813 nn.Linear: 0.036742585226571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5367339849472 nn.Linear: 0.26546281576157 nn.Linear: 0.20961791276932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34330296516418 nn.Linear: 0.5722668170929] nn.Sequential: [nn.Linear: 0.16246294975281 nn.Linear: 0.26814961433411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0076947561480386 nn.Linear: 0.0046748358446058 nn.Linear: 0.0021170723839612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00067966685127165 nn.Linear: 0.0085137362936378] nn.Sequential: [nn.Linear: 0.00056537597334098 nn.Linear: 0.0047076182766968]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.058695752173662 nn.Linear: 0.062446102499962 nn.Linear: 0.077374406158924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.081579364836216 nn.Linear: 0.064609542489052] nn.Sequential: [nn.Linear: 0.026981016620994 nn.Linear: 0.056220527738333]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06273760637538 nn.Linear: 0.065684373537769 nn.Linear: 0.045477228647188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550564874431 nn.Linear: 0.055353901130985] nn.Sequential: [nn.Linear: 0.031482381415984 nn.Linear: 0.036754087482485]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53658759593964 nn.Linear: 0.26621103286743 nn.Linear: 0.20996879041195 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3437502682209 nn.Linear: 0.57294195890427] nn.Sequential: [nn.Linear: 0.16279274225235 nn.Linear: 0.26875644922256]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0037160104833066 nn.Linear: 0.0015110718144736 nn.Linear: 0.00066411929801725 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026634000020636 nn.Linear: 0.0036781510243804] nn.Sequential: [nn.Linear: 0.00018699406808429 nn.Linear: 0.0011919919965815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023798080161214 nn.Linear: 0.026367995887995 nn.Linear: 0.034585572779179 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016361301764846 nn.Linear: 0.037692692130804] nn.Sequential: [nn.Linear: 0.010688042268157 nn.Linear: 0.01252262853086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062736861072376 nn.Linear: 0.065680796459747 nn.Linear: 0.045476681996546 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550721626768 nn.Linear: 0.055364619121974] nn.Sequential: [nn.Linear: 0.031482192690657 nn.Linear: 0.036761669149279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53763008117676 nn.Linear: 0.26595443487167 nn.Linear: 0.21006542444229 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34409606456757 nn.Linear: 0.57350951433182] nn.Sequential: [nn.Linear: 0.16310824453831 nn.Linear: 0.26928660273552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011674354491122 nn.Linear: 0.00062551365095057 nn.Linear: 0.0003256875591501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001193966294508 nn.Linear: 0.0012788266094266] nn.Sequential: [nn.Linear: 0.000126095901105 nn.Linear: 0.00094639675575377]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079357847571373 nn.Linear: 0.0093207508325577 nn.Linear: 0.0064212139695883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074626174755394 nn.Linear: 0.010707695968449] nn.Sequential: [nn.Linear: 0.0072238072752953 nn.Linear: 0.0093949632719159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062731132339016 nn.Linear: 0.065685051037549 nn.Linear: 0.045477789062802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550721551957 nn.Linear: 0.055350077478693] nn.Sequential: [nn.Linear: 0.031482253713254 nn.Linear: 0.036760236280631]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53801649808884 nn.Linear: 0.26631900668144 nn.Linear: 0.21051560342312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34461799263954 nn.Linear: 0.57378309965134] nn.Sequential: [nn.Linear: 0.16342757642269 nn.Linear: 0.26947656273842]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0008812853792401 nn.Linear: 0.00048641031749413 nn.Linear: 0.00030716124986423 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016965166623208 nn.Linear: 0.0025682163372927] nn.Sequential: [nn.Linear: 0.0001194844431375 nn.Linear: 0.00085360936829532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057105128653347 nn.Linear: 0.0068885940127075 nn.Linear: 0.0066728056408465 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076808929443359 nn.Linear: 0.016502197831869] nn.Sequential: [nn.Linear: 0.0040789120830595 nn.Linear: 0.0067167282104492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062733319899949 nn.Linear: 0.065691016232256 nn.Linear: 0.045479765641409 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031550982304805 nn.Linear: 0.055386311691109] nn.Sequential: [nn.Linear: 0.031482585913002 nn.Linear: 0.036761060073248]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53764879703522 nn.Linear: 0.26613771915436 nn.Linear: 0.2104789018631 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34500980377197 nn.Linear: 0.57438957691193] nn.Sequential: [nn.Linear: 0.16344779729843 nn.Linear: 0.26980349421501]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090249981494017 nn.Linear: 0.00068402774715155 nn.Linear: 0.0003487492760053 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001406453429019 nn.Linear: 0.0014301814807061] nn.Sequential: [nn.Linear: 0.00015040804678584 nn.Linear: 0.0010429829234315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057951579801738 nn.Linear: 0.0073718326166272 nn.Linear: 0.0074419919401407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057580191642046 nn.Linear: 0.010836757719517] nn.Sequential: [nn.Linear: 0.0045473822392523 nn.Linear: 0.012476928532124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722027294948 nn.Linear: 0.065690234329292 nn.Linear: 0.045479017500938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551140486698 nn.Linear: 0.055395718670638] nn.Sequential: [nn.Linear: 0.031482150700825 nn.Linear: 0.03675978524485]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53803449869156 nn.Linear: 0.26640027761459 nn.Linear: 0.21066881716251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34575295448303 nn.Linear: 0.57561033964157] nn.Sequential: [nn.Linear: 0.16383661329746 nn.Linear: 0.27004665136337]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033547528933085 nn.Linear: 0.0018778623169737 nn.Linear: 0.00094016755329238 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034964231383357 nn.Linear: 0.0041402497818346] nn.Sequential: [nn.Linear: 0.00031971403996588 nn.Linear: 0.0023616883611732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.034582063555717 nn.Linear: 0.033402226865292 nn.Linear: 0.030676297843456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.038489200174809 nn.Linear: 0.045625928789377] nn.Sequential: [nn.Linear: 0.023201232776046 nn.Linear: 0.027967164292932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722913791594 nn.Linear: 0.065694056009491 nn.Linear: 0.045480169048405 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551021656265 nn.Linear: 0.055369605299092] nn.Sequential: [nn.Linear: 0.031482446878612 nn.Linear: 0.036763439535886]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53824961185455 nn.Linear: 0.26652452349663 nn.Linear: 0.21137984097004 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3464467227459 nn.Linear: 0.57600438594818] nn.Sequential: [nn.Linear: 0.16423581540585 nn.Linear: 0.27019107341766]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014540705922111 nn.Linear: 0.00085121594155123 nn.Linear: 0.00038426834589014 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016626824519169 nn.Linear: 0.001784284702824] nn.Sequential: [nn.Linear: 0.00015456420893739 nn.Linear: 0.00098006215881561]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090549932792783 nn.Linear: 0.0098921842873096 nn.Linear: 0.0089711528271437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0085965394973755 nn.Linear: 0.0092264590784907] nn.Sequential: [nn.Linear: 0.0044818045571446 nn.Linear: 0.0087872575968504]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062721533397752 nn.Linear: 0.065695499192324 nn.Linear: 0.045481345585358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551093531972 nn.Linear: 0.055360455881413] nn.Sequential: [nn.Linear: 0.031482603033408 nn.Linear: 0.036766832423706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53834092617035 nn.Linear: 0.26644054055214 nn.Linear: 0.21159766614437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34672901034355 nn.Linear: 0.57643884420395] nn.Sequential: [nn.Linear: 0.16424486041069 nn.Linear: 0.27051424980164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030586112463737 nn.Linear: 0.0016184257814511 nn.Linear: 0.00079364936765516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032049846547229 nn.Linear: 0.0034836183494994] nn.Sequential: [nn.Linear: 0.00033147247198429 nn.Linear: 0.0027014715089865]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020218519493937 nn.Linear: 0.028685925528407 nn.Linear: 0.023504603654146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019674181938171 nn.Linear: 0.031247304752469] nn.Sequential: [nn.Linear: 0.015008941292763 nn.Linear: 0.039657913148403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062726716032266 nn.Linear: 0.065698857000107 nn.Linear: 0.045482413753568 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551284266782 nn.Linear: 0.055394027429912] nn.Sequential: [nn.Linear: 0.03148272854152 nn.Linear: 0.036775424197842]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53936111927032 nn.Linear: 0.26679101586342 nn.Linear: 0.21152171492577 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34741681814194 nn.Linear: 0.57720202207565] nn.Sequential: [nn.Linear: 0.16466410458088 nn.Linear: 0.27066478133202]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002343130376391 nn.Linear: 0.0014566790772129 nn.Linear: 0.00074253775878756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002611006857466 nn.Linear: 0.0031851578669291] nn.Sequential: [nn.Linear: 0.00018123395945761 nn.Linear: 0.0012403041118833]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015027550980449 nn.Linear: 0.02552735619247 nn.Linear: 0.024511260911822 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.025475919246674 nn.Linear: 0.024337586015463] nn.Sequential: [nn.Linear: 0.011469455435872 nn.Linear: 0.014810936525464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062727777067385 nn.Linear: 0.065700404533024 nn.Linear: 0.045482721641511 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551319841125 nn.Linear: 0.055382013669941] nn.Sequential: [nn.Linear: 0.031482876263016 nn.Linear: 0.036764107517152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53850495815277 nn.Linear: 0.26640537381172 nn.Linear: 0.21177394688129 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34787109494209 nn.Linear: 0.57830452919006] nn.Sequential: [nn.Linear: 0.16496624052525 nn.Linear: 0.27101042866707]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002356658783075 nn.Linear: 0.0010993924870303 nn.Linear: 0.00049646389631597 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020483415026455 nn.Linear: 0.0020556851951915] nn.Sequential: [nn.Linear: 0.00017976381498354 nn.Linear: 0.0011711351490871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020212519913912 nn.Linear: 0.017974304035306 nn.Linear: 0.008069122210145 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0073430808261037 nn.Linear: 0.014199358411133] nn.Sequential: [nn.Linear: 0.0041780713945627 nn.Linear: 0.0093956980854273]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.086440138593316	TD error	0.017452021569014	Qmax	1	

Steps: 9750000 (frames: 39000000), score: 1797.46, higheset score: 6184, epsilon: 0.05, lr: 0.0005, training time: 542s, training rate: 1843fps, testing time: 88s, testing rate: 5630fps,  num. ep.: 421,  num. rewards: 17128	
   4   64   32   16
  16  256    2    4
   4    8    4    2
   2    4    8  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732643409675 nn.Linear: 0.065704950825392 nn.Linear: 0.045484240604303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551772142515 nn.Linear: 0.055419642510429] nn.Sequential: [nn.Linear: 0.031482952741257 nn.Linear: 0.036780956395028]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53875744342804 nn.Linear: 0.26624006032944 nn.Linear: 0.21176780760288 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3484562933445 nn.Linear: 0.57844310998917] nn.Sequential: [nn.Linear: 0.16523069143295 nn.Linear: 0.2711825966835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016833172968805 nn.Linear: 0.00090284585216007 nn.Linear: 0.00043885766571916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024361256576338 nn.Linear: 0.003520941235879] nn.Sequential: [nn.Linear: 0.00020141842105001 nn.Linear: 0.0016631307332601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011858406476676 nn.Linear: 0.018050946295261 nn.Linear: 0.0096084121614695 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097496844828129 nn.Linear: 0.023263555020094] nn.Sequential: [nn.Linear: 0.0073794680647552 nn.Linear: 0.016848940402269]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062731332811649 nn.Linear: 0.065707119059586 nn.Linear: 0.045484772765888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551956817533 nn.Linear: 0.055467763731485] nn.Sequential: [nn.Linear: 0.031482990669631 nn.Linear: 0.036769289020403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53873425722122 nn.Linear: 0.26620796322823 nn.Linear: 0.21147418022156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34925928711891 nn.Linear: 0.57888752222061] nn.Sequential: [nn.Linear: 0.1654235124588 nn.Linear: 0.27139738202095]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016675249597163 nn.Linear: 0.0011898663014439 nn.Linear: 0.00064709639967675 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030349511274755 nn.Linear: 0.0039960576743369] nn.Sequential: [nn.Linear: 0.00028763784450115 nn.Linear: 0.0024421531912156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015937188640237 nn.Linear: 0.020222263410687 nn.Linear: 0.016923012211919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.028974238783121 nn.Linear: 0.036248151212931] nn.Sequential: [nn.Linear: 0.024060575291514 nn.Linear: 0.032753068953753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732635639522 nn.Linear: 0.065709938841688 nn.Linear: 0.045485532033965 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031551971143567 nn.Linear: 0.055459088013777] nn.Sequential: [nn.Linear: 0.031483121584286 nn.Linear: 0.036773325449126]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53932881355286 nn.Linear: 0.26673537492752 nn.Linear: 0.21171940863132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34944114089012 nn.Linear: 0.57886797189713] nn.Sequential: [nn.Linear: 0.16555406153202 nn.Linear: 0.27159878611565]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001050508991364 nn.Linear: 0.00052894793844664 nn.Linear: 0.00028018526933954 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011971320861176 nn.Linear: 0.0012691257246322] nn.Sequential: [nn.Linear: 0.00012740217462667 nn.Linear: 0.0009753469267274]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066867270506918 nn.Linear: 0.0087832314893603 nn.Linear: 0.0052701137028635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089939394965768 nn.Linear: 0.011448930948973] nn.Sequential: [nn.Linear: 0.0060584805905819 nn.Linear: 0.0096029546111822]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062727798304909 nn.Linear: 0.065708765703655 nn.Linear: 0.045485632475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031552091388196 nn.Linear: 0.055447359158677] nn.Sequential: [nn.Linear: 0.031482950687628 nn.Linear: 0.03677245863593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53910201787949 nn.Linear: 0.26699152588844 nn.Linear: 0.21174213290215 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.34994176030159 nn.Linear: 0.57926607131958] nn.Sequential: [nn.Linear: 0.16525410115719 nn.Linear: 0.27184039354324]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002247292250987 nn.Linear: 0.0010776857388659 nn.Linear: 0.00051121809767422 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021543436336241 nn.Linear: 0.0024168888659162] nn.Sequential: [nn.Linear: 0.00019135547681251 nn.Linear: 0.0012592339317776]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016447361558676 nn.Linear: 0.017108360305429 nn.Linear: 0.011219006031752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02396828122437 nn.Linear: 0.02030024677515] nn.Sequential: [nn.Linear: 0.0083007058128715 nn.Linear: 0.012682374566793]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062723838112058 nn.Linear: 0.06570973019705 nn.Linear: 0.045486805783612 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031552217642481 nn.Linear: 0.05544434558044] nn.Sequential: [nn.Linear: 0.031483292830067 nn.Linear: 0.036796277405591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53946006298065 nn.Linear: 0.26745015382767 nn.Linear: 0.21209980547428 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35057184100151 nn.Linear: 0.57988035678864] nn.Sequential: [nn.Linear: 0.16554237902164 nn.Linear: 0.27205032110214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016196035655003 nn.Linear: 0.00092555569179898 nn.Linear: 0.00048633437599091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017370826396027 nn.Linear: 0.0018749626088144] nn.Sequential: [nn.Linear: 0.00019427669644802 nn.Linear: 0.0016054439192404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012675121426582 nn.Linear: 0.012323779985309 nn.Linear: 0.013564545661211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019822500646114 nn.Linear: 0.013688241131604] nn.Sequential: [nn.Linear: 0.0068743210285902 nn.Linear: 0.019818034023046]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062720587425558 nn.Linear: 0.065712935047144 nn.Linear: 0.04548608200384 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031552465999591 nn.Linear: 0.05545124838244] nn.Sequential: [nn.Linear: 0.031483242186251 nn.Linear: 0.036796435683239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53940171003342 nn.Linear: 0.26770555973053 nn.Linear: 0.2125578969717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3510334789753 nn.Linear: 0.58020329475403] nn.Sequential: [nn.Linear: 0.16569952666759 nn.Linear: 0.27199020981789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011326898170953 nn.Linear: 0.00062536008620406 nn.Linear: 0.00032961869900222 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001557097243404 nn.Linear: 0.0019940484094547] nn.Sequential: [nn.Linear: 0.0001308583429513 nn.Linear: 0.0010081435252447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008122967556119 nn.Linear: 0.0076249409466982 nn.Linear: 0.0070622386410832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007190611679107 nn.Linear: 0.014557505957782] nn.Sequential: [nn.Linear: 0.0071330475620925 nn.Linear: 0.013833999633789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716434130644 nn.Linear: 0.065715951581303 nn.Linear: 0.045486710970535 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031552597817632 nn.Linear: 0.055471043374112] nn.Sequential: [nn.Linear: 0.031483536624794 nn.Linear: 0.036796945547581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53938472270966 nn.Linear: 0.26728808879852 nn.Linear: 0.21259890496731 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35132992267609 nn.Linear: 0.58046513795853] nn.Sequential: [nn.Linear: 0.16573564708233 nn.Linear: 0.27205562591553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095203258388057 nn.Linear: 0.000537006237333 nn.Linear: 0.0003249283579874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016820286816673 nn.Linear: 0.0022908569521354] nn.Sequential: [nn.Linear: 0.00015564060373246 nn.Linear: 0.0011825763074729]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066495044156909 nn.Linear: 0.0064141117036343 nn.Linear: 0.0072047123685479 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01372385583818 nn.Linear: 0.027857488021255] nn.Sequential: [nn.Linear: 0.006118303630501 nn.Linear: 0.011433728039265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062713637430779 nn.Linear: 0.065720012672384 nn.Linear: 0.045488289998285 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03155282369475 nn.Linear: 0.055482419330261] nn.Sequential: [nn.Linear: 0.031483730625171 nn.Linear: 0.036800907808085]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.53959214687347 nn.Linear: 0.26700684428215 nn.Linear: 0.21281640231609 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35166537761688 nn.Linear: 0.58114981651306] nn.Sequential: [nn.Linear: 0.16599963605404 nn.Linear: 0.27255335450172]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00082365198266342 nn.Linear: 0.00047563350325819 nn.Linear: 0.00024321709958272 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011217241264096 nn.Linear: 0.0013072679239676] nn.Sequential: [nn.Linear: 8.5087407488352e-05 nn.Linear: 0.00053448948103456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0051740673370659 nn.Linear: 0.0067870919592679 nn.Linear: 0.0043491111136973 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0040219775401056 nn.Linear: 0.0092585235834122] nn.Sequential: [nn.Linear: 0.0029727770015597 nn.Linear: 0.0057221134193242]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062711268771615 nn.Linear: 0.065719054247943 nn.Linear: 0.045487550400552 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553055215325 nn.Linear: 0.055478712735407] nn.Sequential: [nn.Linear: 0.031483435176058 nn.Linear: 0.036809827769024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54014486074448 nn.Linear: 0.2670174241066 nn.Linear: 0.21299384534359 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35180577635765 nn.Linear: 0.58153980970383] nn.Sequential: [nn.Linear: 0.16618564724922 nn.Linear: 0.27278277277946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0035480075693367 nn.Linear: 0.001813187986291 nn.Linear: 0.00093788633200944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003952416830896 nn.Linear: 0.0043268723640981] nn.Sequential: [nn.Linear: 0.00031735492389677 nn.Linear: 0.0024272570263474]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021181423217058 nn.Linear: 0.043746992945671 nn.Linear: 0.03522265702486 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.023894071578979 nn.Linear: 0.039565190672874] nn.Sequential: [nn.Linear: 0.01741698384285 nn.Linear: 0.030792566016316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06272197730428 nn.Linear: 0.065722699997371 nn.Linear: 0.045489353805411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553374227757 nn.Linear: 0.05548939825303] nn.Sequential: [nn.Linear: 0.031483827624749 nn.Linear: 0.036805339996254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.540154337883 nn.Linear: 0.26687031984329 nn.Linear: 0.21349093317986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35242396593094 nn.Linear: 0.58207154273987] nn.Sequential: [nn.Linear: 0.16643802821636 nn.Linear: 0.27302733063698]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016875406135806 nn.Linear: 0.00080819789633336 nn.Linear: 0.00029204362181764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013068679954018 nn.Linear: 0.0018625285460031] nn.Sequential: [nn.Linear: 8.8276732781321e-05 nn.Linear: 0.00074188397291192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014139891602099 nn.Linear: 0.010893494822085 nn.Linear: 0.01304174400866 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076907002367079 nn.Linear: 0.015525978058577] nn.Sequential: [nn.Linear: 0.0028461934998631 nn.Linear: 0.0082608573138714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06271444160627 nn.Linear: 0.065725737717758 nn.Linear: 0.045489864314854 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553399378854 nn.Linear: 0.055486203226607] nn.Sequential: [nn.Linear: 0.031483895827924 nn.Linear: 0.03682557894966]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54056614637375 nn.Linear: 0.26755478978157 nn.Linear: 0.21356803178787 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35276499390602 nn.Linear: 0.58252555131912] nn.Sequential: [nn.Linear: 0.16662795841694 nn.Linear: 0.27322003245354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00089493665071372 nn.Linear: 0.0005459646599657 nn.Linear: 0.0003074045298257 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013818536831857 nn.Linear: 0.0017807623890028] nn.Sequential: [nn.Linear: 0.00013368036681363 nn.Linear: 0.00091589191013374]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0046403408050537 nn.Linear: 0.0063390377908945 nn.Linear: 0.0064387083984911 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063558425754309 nn.Linear: 0.013801702298224] nn.Sequential: [nn.Linear: 0.0037240632809699 nn.Linear: 0.0070949061773717]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062705127168933 nn.Linear: 0.065723767171863 nn.Linear: 0.045489959133832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553443195278 nn.Linear: 0.055465481501869] nn.Sequential: [nn.Linear: 0.031483924114266 nn.Linear: 0.03682963614413]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54054456949234 nn.Linear: 0.26746904850006 nn.Linear: 0.21373169124126 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35316267609596 nn.Linear: 0.58303755521774] nn.Sequential: [nn.Linear: 0.16695240139961 nn.Linear: 0.2734090089798]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012332217237181 nn.Linear: 0.00072859886300523 nn.Linear: 0.00041705107746319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017045806456311 nn.Linear: 0.002147236348896] nn.Sequential: [nn.Linear: 0.00016700716009957 nn.Linear: 0.0013568873807133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012670794501901 nn.Linear: 0.014221797697246 nn.Linear: 0.0078855520114303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012246132828295 nn.Linear: 0.029552776366472] nn.Sequential: [nn.Linear: 0.0064862906001508 nn.Linear: 0.015417949296534]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	9880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062710602629425 nn.Linear: 0.06572868221082 nn.Linear: 0.045492846637731 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553526456543 nn.Linear: 0.055465087859318] nn.Sequential: [nn.Linear: 0.031484130457324 nn.Linear: 0.036817418942967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54130655527115 nn.Linear: 0.26781687140465 nn.Linear: 0.21423178911209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35378262400627 nn.Linear: 0.58349788188934] nn.Sequential: [nn.Linear: 0.16746723651886 nn.Linear: 0.27365118265152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017051253338974 nn.Linear: 0.00093453048385111 nn.Linear: 0.00048504873792414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015134992320076 nn.Linear: 0.0016130117345672] nn.Sequential: [nn.Linear: 0.00017652059067145 nn.Linear: 0.0013299711208287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01474479213357 nn.Linear: 0.020208535715938 nn.Linear: 0.015275989659131 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017537709325552 nn.Linear: 0.014292902313173] nn.Sequential: [nn.Linear: 0.0080007845535874 nn.Linear: 0.016669040545821]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062711360794194 nn.Linear: 0.065733950181246 nn.Linear: 0.045493304366045 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031554060919767 nn.Linear: 0.055510913238834] nn.Sequential: [nn.Linear: 0.031484164772159 nn.Linear: 0.036832767242318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54105079174042 nn.Linear: 0.2681890130043 nn.Linear: 0.21427342295647 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3542445898056 nn.Linear: 0.58402353525162] nn.Sequential: [nn.Linear: 0.16708545386791 nn.Linear: 0.27393814921379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088812037179265 nn.Linear: 0.00041471833046037 nn.Linear: 0.00020274620869786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.7438265491269e-05 nn.Linear: 0.001109623748172] nn.Sequential: [nn.Linear: 7.0307681963292e-05 nn.Linear: 0.00054530009514283]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079370774328709 nn.Linear: 0.0056303609162569 nn.Linear: 0.0074034947901964 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0052759628742933 nn.Linear: 0.011143301613629] nn.Sequential: [nn.Linear: 0.002889382885769 nn.Linear: 0.0065185390412807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062703262623976 nn.Linear: 0.06573154919006 nn.Linear: 0.045493163090218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553991318205 nn.Linear: 0.055496963201506] nn.Sequential: [nn.Linear: 0.031484109255565 nn.Linear: 0.036831120564002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5410567522049 nn.Linear: 0.26873558759689 nn.Linear: 0.2144330739975 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35499566793442 nn.Linear: 0.5843368768692] nn.Sequential: [nn.Linear: 0.16745339334011 nn.Linear: 0.27429640293121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022877896951404 nn.Linear: 0.0012070287776897 nn.Linear: 0.00052380431424118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021158971249086 nn.Linear: 0.0026243557343011] nn.Sequential: [nn.Linear: 0.00018579723710686 nn.Linear: 0.0014072632978121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023785375058651 nn.Linear: 0.025227593258023 nn.Linear: 0.019516626372933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.009490504860878 nn.Linear: 0.025823468342423] nn.Sequential: [nn.Linear: 0.0070820660330355 nn.Linear: 0.019136479124427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062698167744188 nn.Linear: 0.065735051832317 nn.Linear: 0.045494526767102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031553871950326 nn.Linear: 0.055489612207168] nn.Sequential: [nn.Linear: 0.031484329832125 nn.Linear: 0.036829511369412]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54090595245361 nn.Linear: 0.26787972450256 nn.Linear: 0.21479491889477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35554775595665 nn.Linear: 0.58470511436462] nn.Sequential: [nn.Linear: 0.16746655106544 nn.Linear: 0.27448713779449]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096843771907212 nn.Linear: 0.0006381802388178 nn.Linear: 0.00033032034364707 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022740932887858 nn.Linear: 0.0036836197677617] nn.Sequential: [nn.Linear: 0.00012733643258178 nn.Linear: 0.0010773525721166]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0052311583422124 nn.Linear: 0.0094221159815788 nn.Linear: 0.010202545672655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013436528854072 nn.Linear: 0.028484726324677] nn.Sequential: [nn.Linear: 0.0096932323649526 nn.Linear: 0.012608568184078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062705990958723 nn.Linear: 0.065739826073439 nn.Linear: 0.045496322633153 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031554108120081 nn.Linear: 0.055518198094433] nn.Sequential: [nn.Linear: 0.031484661221467 nn.Linear: 0.036858178630494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54087525606155 nn.Linear: 0.26823329925537 nn.Linear: 0.21480895578861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35574150085449 nn.Linear: 0.58547019958496] nn.Sequential: [nn.Linear: 0.16733267903328 nn.Linear: 0.27492868900299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00097286741075922 nn.Linear: 0.0007223567305879 nn.Linear: 0.00045219770022963 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019693596258426 nn.Linear: 0.0020739374568626] nn.Sequential: [nn.Linear: 0.00020816463828504 nn.Linear: 0.0014449130199405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0082482052966952 nn.Linear: 0.0079005509614944 nn.Linear: 0.0069549586623907 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061729289591312 nn.Linear: 0.016493126749992] nn.Sequential: [nn.Linear: 0.0060142758302391 nn.Linear: 0.016989197582006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062702289021889 nn.Linear: 0.065739188936588 nn.Linear: 0.045496685532233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031554023727778 nn.Linear: 0.055517426298394] nn.Sequential: [nn.Linear: 0.031484744944458 nn.Linear: 0.036855481648751]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54032462835312 nn.Linear: 0.26834961771965 nn.Linear: 0.21496503055096 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35605785250664 nn.Linear: 0.58662170171738] nn.Sequential: [nn.Linear: 0.16789156198502 nn.Linear: 0.27536982297897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015199087065619 nn.Linear: 0.00085884130029887 nn.Linear: 0.00040415244261994 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016678829092253 nn.Linear: 0.0018586979519024] nn.Sequential: [nn.Linear: 0.0001882077657357 nn.Linear: 0.0015684299344066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010451777838171 nn.Linear: 0.01037868577987 nn.Linear: 0.0081946197897196 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081531908363104 nn.Linear: 0.011356961913407] nn.Sequential: [nn.Linear: 0.0096372086554766 nn.Linear: 0.017089368775487]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062703331161861 nn.Linear: 0.065743645178012 nn.Linear: 0.045498835049069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031554506061901 nn.Linear: 0.055537978971955] nn.Sequential: [nn.Linear: 0.031484900366067 nn.Linear: 0.03685517180977]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5407252907753 nn.Linear: 0.2683826982975 nn.Linear: 0.21491158008575 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35678407549858 nn.Linear: 0.58727371692657] nn.Sequential: [nn.Linear: 0.16829469799995 nn.Linear: 0.27554756402969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002123553928022 nn.Linear: 0.0013782367591232 nn.Linear: 0.00076366865612317 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030757288570068 nn.Linear: 0.003575139597586] nn.Sequential: [nn.Linear: 0.00028459265976981 nn.Linear: 0.0021515253973106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014479950070381 nn.Linear: 0.021575151011348 nn.Linear: 0.017508720979095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017221787944436 nn.Linear: 0.017224261537194] nn.Sequential: [nn.Linear: 0.0079323640093207 nn.Linear: 0.023228570818901]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062705311668973 nn.Linear: 0.0657473974058 nn.Linear: 0.045500249669193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031554912385071 nn.Linear: 0.055567168397431] nn.Sequential: [nn.Linear: 0.031484934827042 nn.Linear: 0.036866647121462]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5407737493515 nn.Linear: 0.26876151561737 nn.Linear: 0.21530498564243 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35735183954239 nn.Linear: 0.58816289901733] nn.Sequential: [nn.Linear: 0.1683294326067 nn.Linear: 0.27600306272507]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012300708412955 nn.Linear: 0.00065865220047407 nn.Linear: 0.00036941715272351 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020706555666203 nn.Linear: 0.0028694235179056] nn.Sequential: [nn.Linear: 0.00011552013619198 nn.Linear: 0.00092386802032399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090125789865851 nn.Linear: 0.0079129645600915 nn.Linear: 0.0099350269883871 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086766630411148 nn.Linear: 0.015446313656867] nn.Sequential: [nn.Linear: 0.0028152239974588 nn.Linear: 0.0094119627028704]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062703906574756 nn.Linear: 0.065748815235765 nn.Linear: 0.045501181944188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03155491481142 nn.Linear: 0.055574502404824] nn.Sequential: [nn.Linear: 0.031485134684232 nn.Linear: 0.036867174768715]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54131919145584 nn.Linear: 0.26909959316254 nn.Linear: 0.21545873582363 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35793763399124 nn.Linear: 0.58897513151169] nn.Sequential: [nn.Linear: 0.16822744905949 nn.Linear: 0.27641016244888]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00094425490032424 nn.Linear: 0.00052962487527851 nn.Linear: 0.00028188301897184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011494502767404 nn.Linear: 0.001436247590441] nn.Sequential: [nn.Linear: 0.00011639311723836 nn.Linear: 0.00078684536960992]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084789553657174 nn.Linear: 0.010923651047051 nn.Linear: 0.0072849248535931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092978812754154 nn.Linear: 0.0099545316770673] nn.Sequential: [nn.Linear: 0.0067303897812963 nn.Linear: 0.0068759643472731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716562430323 nn.Linear: 0.065755318041762 nn.Linear: 0.045503103269415 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031555020328808 nn.Linear: 0.055581661920428] nn.Sequential: [nn.Linear: 0.031485466344646 nn.Linear: 0.036891259205781]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54120129346848 nn.Linear: 0.2687996327877 nn.Linear: 0.21567849814892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35826730728149 nn.Linear: 0.58987599611282] nn.Sequential: [nn.Linear: 0.16848783195019 nn.Linear: 0.27696415781975]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021065640253614 nn.Linear: 0.0011164203212802 nn.Linear: 0.00051412692522069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018658054771562 nn.Linear: 0.0021587130317343] nn.Sequential: [nn.Linear: 0.00016110308196338 nn.Linear: 0.0012044775542231]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016331704333425 nn.Linear: 0.018501248210669 nn.Linear: 0.011906936764717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097309304401278 nn.Linear: 0.015693930909038] nn.Sequential: [nn.Linear: 0.0057089738547802 nn.Linear: 0.013361354358494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718442283936 nn.Linear: 0.065756903263865 nn.Linear: 0.045504740843203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031555137817785 nn.Linear: 0.055575344325703] nn.Sequential: [nn.Linear: 0.031485725542751 nn.Linear: 0.036907433038568]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54081571102142 nn.Linear: 0.26925855875015 nn.Linear: 0.21539081633091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35867658257484 nn.Linear: 0.5900884270668] nn.Sequential: [nn.Linear: 0.1687443703413 nn.Linear: 0.27712416648865]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021922830793382 nn.Linear: 0.00112307544413 nn.Linear: 0.00069175845136157 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032341705472291 nn.Linear: 0.0034616930927784] nn.Sequential: [nn.Linear: 0.00030383635308582 nn.Linear: 0.0023428748191152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01633184030652 nn.Linear: 0.017182057723403 nn.Linear: 0.015499885194004 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012474071234465 nn.Linear: 0.023322466760874] nn.Sequential: [nn.Linear: 0.012057453393936 nn.Linear: 0.026474690064788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	9990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062713982741289 nn.Linear: 0.065758736343917 nn.Linear: 0.045506094511516 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031555314188719 nn.Linear: 0.055599151549529] nn.Sequential: [nn.Linear: 0.0314859995203 nn.Linear: 0.036908490823073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54082727432251 nn.Linear: 0.26883944869041 nn.Linear: 0.21552348136902 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35869738459587 nn.Linear: 0.59028118848801] nn.Sequential: [nn.Linear: 0.16931857168674 nn.Linear: 0.2772122323513]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012930817222942 nn.Linear: 0.00073083124960593 nn.Linear: 0.00037316181266888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001580265720033 nn.Linear: 0.0020396921588836] nn.Sequential: [nn.Linear: 0.0001357356084913 nn.Linear: 0.0012661593924863]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088354218751192 nn.Linear: 0.0093168178573251 nn.Linear: 0.010299899615347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011755205690861 nn.Linear: 0.014968377538025] nn.Sequential: [nn.Linear: 0.0044472781009972 nn.Linear: 0.015855994075537]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718622579432 nn.Linear: 0.065769588744756 nn.Linear: 0.045507931917343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031555646527832 nn.Linear: 0.055644195597154] nn.Sequential: [nn.Linear: 0.031486319678894 nn.Linear: 0.036932055424662]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54041850566864 nn.Linear: 0.26842385530472 nn.Linear: 0.21593105792999 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35929074883461 nn.Linear: 0.59081417322159] nn.Sequential: [nn.Linear: 0.16942867636681 nn.Linear: 0.27743116021156]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015834112855209 nn.Linear: 0.0011118395437619 nn.Linear: 0.00055447608469101 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000217024578408 nn.Linear: 0.0022618729395545] nn.Sequential: [nn.Linear: 0.00021181806004546 nn.Linear: 0.0016016838857928]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010404956527054 nn.Linear: 0.016772976145148 nn.Linear: 0.013658313080668 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013678343966603 nn.Linear: 0.017985507845879] nn.Sequential: [nn.Linear: 0.0075726779177785 nn.Linear: 0.015194327570498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.076799965754151	TD error	0.016746875312179	Qmax	1	

Steps: 10000000 (frames: 40000000), score: 2223.81, higheset score: 6236, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1840fps, testing time: 88s, testing rate: 5649fps,  num. ep.: 354,  num. rewards: 18730	
   2   16    8    2
  16    8  256    8
  32   16    8   16
   4   64    2  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722809080505 nn.Linear: 0.065769502333542 nn.Linear: 0.045509384346885 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03155603348779 nn.Linear: 0.055655141933386] nn.Sequential: [nn.Linear: 0.031486551267527 nn.Linear: 0.036948819509576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54064559936523 nn.Linear: 0.2690797150135 nn.Linear: 0.21616694331169 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.35964268445969 nn.Linear: 0.59180235862732] nn.Sequential: [nn.Linear: 0.16943003237247 nn.Linear: 0.27790394425392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019755604452204 nn.Linear: 0.00091798947554437 nn.Linear: 0.00043163076871735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017617017118716 nn.Linear: 0.0020628235161153] nn.Sequential: [nn.Linear: 0.00018381389468787 nn.Linear: 0.0015609092274035]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014932998456061 nn.Linear: 0.014458507299423 nn.Linear: 0.018447179347277 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077089476399124 nn.Linear: 0.012333808466792] nn.Sequential: [nn.Linear: 0.006848368793726 nn.Linear: 0.018511831760406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062719074058994 nn.Linear: 0.065773558716961 nn.Linear: 0.045510460462394 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0315564726325 nn.Linear: 0.055714359679939] nn.Sequential: [nn.Linear: 0.031486450160169 nn.Linear: 0.036939141930299]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54054838418961 nn.Linear: 0.26933336257935 nn.Linear: 0.21629023551941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36014470458031 nn.Linear: 0.59195047616959] nn.Sequential: [nn.Linear: 0.16944873332977 nn.Linear: 0.27792131900787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096936450930006 nn.Linear: 0.00055389243733813 nn.Linear: 0.00032553560354743 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017716570095519 nn.Linear: 0.0024433365407628] nn.Sequential: [nn.Linear: 0.00015624918185203 nn.Linear: 0.0012548544038745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066489498130977 nn.Linear: 0.011004358530045 nn.Linear: 0.0108323097229 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0070360414683819 nn.Linear: 0.016749845817685] nn.Sequential: [nn.Linear: 0.0075181652791798 nn.Linear: 0.013971889391541]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06271867757406 nn.Linear: 0.065776116896494 nn.Linear: 0.045511029192072 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031556684235111 nn.Linear: 0.055724326629601] nn.Sequential: [nn.Linear: 0.031486517745844 nn.Linear: 0.036948436196529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54077750444412 nn.Linear: 0.26917520165443 nn.Linear: 0.21663628518581 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36053743958473 nn.Linear: 0.59255474805832] nn.Sequential: [nn.Linear: 0.16975277662277 nn.Linear: 0.27809447050095]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011640361862945 nn.Linear: 0.00067179236932254 nn.Linear: 0.00034899334525257 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015470519070786 nn.Linear: 0.0017648564549513] nn.Sequential: [nn.Linear: 0.00014573115690144 nn.Linear: 0.0013502570486655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01055858284235 nn.Linear: 0.0084456074982882 nn.Linear: 0.0073165418580174 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0057223457843065 nn.Linear: 0.012262443080544] nn.Sequential: [nn.Linear: 0.0056181149557233 nn.Linear: 0.0093972142785788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06271387152303 nn.Linear: 0.065772377336682 nn.Linear: 0.045510588200505 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031556575829579 nn.Linear: 0.055709107968653] nn.Sequential: [nn.Linear: 0.031486301824048 nn.Linear: 0.036955101573874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5405221581459 nn.Linear: 0.26964840292931 nn.Linear: 0.21689614653587 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36102560162544 nn.Linear: 0.59320801496506] nn.Sequential: [nn.Linear: 0.16974288225174 nn.Linear: 0.27827921509743]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012919366919678 nn.Linear: 0.00098960916659735 nn.Linear: 0.00048646138316463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025411313851053 nn.Linear: 0.0032507206002954] nn.Sequential: [nn.Linear: 0.00016146757707888 nn.Linear: 0.0010918134478666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0083532333374023 nn.Linear: 0.012133304029703 nn.Linear: 0.0078191198408604 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01634918525815 nn.Linear: 0.02599779702723] nn.Sequential: [nn.Linear: 0.0045960014685988 nn.Linear: 0.01123483851552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062712046614252 nn.Linear: 0.065773715583781 nn.Linear: 0.045511073993213 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031556490455997 nn.Linear: 0.05569680362089] nn.Sequential: [nn.Linear: 0.031486272898381 nn.Linear: 0.036947368195089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54107820987701 nn.Linear: 0.26973828673363 nn.Linear: 0.21727706491947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36138197779655 nn.Linear: 0.5930044054985] nn.Sequential: [nn.Linear: 0.16992215812206 nn.Linear: 0.27821078896523]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024464385275488 nn.Linear: 0.00133729619438 nn.Linear: 0.00055225286945895 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019219795765802 nn.Linear: 0.0021060595034923] nn.Sequential: [nn.Linear: 0.0002220744647025 nn.Linear: 0.0017695645122328]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014964036643505 nn.Linear: 0.025733295828104 nn.Linear: 0.013577233999968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011514782905579 nn.Linear: 0.01942596398294] nn.Sequential: [nn.Linear: 0.0072510289028287 nn.Linear: 0.017103480175138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062710746130562 nn.Linear: 0.065781453151504 nn.Linear: 0.045513094587445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031556717725044 nn.Linear: 0.055726640341554] nn.Sequential: [nn.Linear: 0.031486692021759 nn.Linear: 0.036960699286318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54121255874634 nn.Linear: 0.26940846443176 nn.Linear: 0.21747067570686 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36187505722046 nn.Linear: 0.59370499849319] nn.Sequential: [nn.Linear: 0.16950570046902 nn.Linear: 0.2784988284111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016659864586901 nn.Linear: 0.00084881618041974 nn.Linear: 0.00040390962939142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016272212227494 nn.Linear: 0.0018760546427668] nn.Sequential: [nn.Linear: 0.00012282521570094 nn.Linear: 0.00088862901144936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010263147763908 nn.Linear: 0.012829159386456 nn.Linear: 0.021558072417974 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084994928911328 nn.Linear: 0.015566500835121] nn.Sequential: [nn.Linear: 0.0049274074845016 nn.Linear: 0.010054691694677]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716293536741 nn.Linear: 0.065783978654631 nn.Linear: 0.045514299804493 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031556959074761 nn.Linear: 0.055764437200082] nn.Sequential: [nn.Linear: 0.031486402172903 nn.Linear: 0.036968632503262]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54048717021942 nn.Linear: 0.26938623189926 nn.Linear: 0.2175910025835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3621261715889 nn.Linear: 0.59414553642273] nn.Sequential: [nn.Linear: 0.16986398398876 nn.Linear: 0.27880629897118]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0063568092678486 nn.Linear: 0.0025003826245941 nn.Linear: 0.00091089721325327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025943922274045 nn.Linear: 0.0031177485113214] nn.Sequential: [nn.Linear: 0.00027977648090584 nn.Linear: 0.0022025236136177]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.058815356343985 nn.Linear: 0.05370819196105 nn.Linear: 0.075656644999981 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.026714643463492 nn.Linear: 0.025479834526777] nn.Sequential: [nn.Linear: 0.021339735016227 nn.Linear: 0.030574725940824]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062717984481134 nn.Linear: 0.065788866778752 nn.Linear: 0.045516061981477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031557194844174 nn.Linear: 0.055799911632391] nn.Sequential: [nn.Linear: 0.031486864686152 nn.Linear: 0.036971942991983]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54078179597855 nn.Linear: 0.27028706669807 nn.Linear: 0.21808883547783 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.362684071064 nn.Linear: 0.59496814012527] nn.Sequential: [nn.Linear: 0.17005336284637 nn.Linear: 0.27896976470947]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013182322851626 nn.Linear: 0.0008629096953913 nn.Linear: 0.00047383328554762 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015384797425096 nn.Linear: 0.001471995614055] nn.Sequential: [nn.Linear: 0.00018872444981568 nn.Linear: 0.0014675103294329]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076612741686404 nn.Linear: 0.012797953560948 nn.Linear: 0.010235813446343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010279335081577 nn.Linear: 0.011031247675419] nn.Sequential: [nn.Linear: 0.005236221011728 nn.Linear: 0.013200934976339]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718760900149 nn.Linear: 0.065794475860824 nn.Linear: 0.045517848826897 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031557600455095 nn.Linear: 0.055827201380595] nn.Sequential: [nn.Linear: 0.031487117320923 nn.Linear: 0.036995683332645]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54096764326096 nn.Linear: 0.27010866999626 nn.Linear: 0.21805337071419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36295112967491 nn.Linear: 0.59507375955582] nn.Sequential: [nn.Linear: 0.17019395530224 nn.Linear: 0.27909263968468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028546318253886 nn.Linear: 0.0014286674346119 nn.Linear: 0.00065305236249819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002412947317804 nn.Linear: 0.0026200355661475] nn.Sequential: [nn.Linear: 0.00021239078757063 nn.Linear: 0.0013142845607608]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017188083380461 nn.Linear: 0.021754903718829 nn.Linear: 0.017227113246918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099249901250005 nn.Linear: 0.021118562668562] nn.Sequential: [nn.Linear: 0.0054460531100631 nn.Linear: 0.011457442305982]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716656859345 nn.Linear: 0.065798448295986 nn.Linear: 0.045518463757031 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031557747293732 nn.Linear: 0.05584062987171] nn.Sequential: [nn.Linear: 0.031487120056499 nn.Linear: 0.036986748858298]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54042047262192 nn.Linear: 0.27034476399422 nn.Linear: 0.21832384169102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36328011751175 nn.Linear: 0.59547060728073] nn.Sequential: [nn.Linear: 0.16999210417271 nn.Linear: 0.27912551164627]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031149757779865 nn.Linear: 0.0014777991560064 nn.Linear: 0.00059689038782109 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018048202574915 nn.Linear: 0.0020468407470318] nn.Sequential: [nn.Linear: 0.00016509308225351 nn.Linear: 0.0012926913997192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020057734102011 nn.Linear: 0.021325198933482 nn.Linear: 0.014584080316126 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.025622244924307 nn.Linear: 0.013945439830422] nn.Sequential: [nn.Linear: 0.011544329114258 nn.Linear: 0.018691711127758]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722342261146 nn.Linear: 0.065800838715711 nn.Linear: 0.045520086925548 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031557966128518 nn.Linear: 0.055872532235583] nn.Sequential: [nn.Linear: 0.031487243246946 nn.Linear: 0.036990517250522]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54071122407913 nn.Linear: 0.2704656124115 nn.Linear: 0.21881146728992 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36373376846313 nn.Linear: 0.59588646888733] nn.Sequential: [nn.Linear: 0.17032605409622 nn.Linear: 0.27906364202499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012173022035078 nn.Linear: 0.0005469358499669 nn.Linear: 0.00024767487805539 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.3766097343731e-05 nn.Linear: 0.0011100308515319] nn.Sequential: [nn.Linear: 8.3127945874611e-05 nn.Linear: 0.00060132117528799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096011478453875 nn.Linear: 0.0087137585505843 nn.Linear: 0.014593422412872 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0054181874729693 nn.Linear: 0.0074208085425198] nn.Sequential: [nn.Linear: 0.0034004473127425 nn.Linear: 0.007202954031527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062721290502003 nn.Linear: 0.065804206591223 nn.Linear: 0.045520522221861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031558358260766 nn.Linear: 0.055896996158097] nn.Sequential: [nn.Linear: 0.031487249439561 nn.Linear: 0.036994021602529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54129761457443 nn.Linear: 0.27057760953903 nn.Linear: 0.2190754711628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36433255672455 nn.Linear: 0.59656703472137] nn.Sequential: [nn.Linear: 0.17035792768002 nn.Linear: 0.27930784225464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0035051946549738 nn.Linear: 0.0013223846802192 nn.Linear: 0.00044725721242736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016835623426136 nn.Linear: 0.0022000043723558] nn.Sequential: [nn.Linear: 9.0308452824348e-05 nn.Linear: 0.00054638636574095]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019645987078547 nn.Linear: 0.021736297756433 nn.Linear: 0.027420196682215 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011604298837483 nn.Linear: 0.020318092778325] nn.Sequential: [nn.Linear: 0.0059180380776525 nn.Linear: 0.0043770894408226]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062724761460451 nn.Linear: 0.065806204352605 nn.Linear: 0.045521297194482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031558494878705 nn.Linear: 0.055914114048306] nn.Sequential: [nn.Linear: 0.031487385933105 nn.Linear: 0.037011325460224]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54224401712418 nn.Linear: 0.27135717868805 nn.Linear: 0.21946269273758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36481419205666 nn.Linear: 0.59758234024048] nn.Sequential: [nn.Linear: 0.17059132456779 nn.Linear: 0.27956056594849]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00075236610255738 nn.Linear: 0.00053969356030137 nn.Linear: 0.0002398500178512 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010496714714709 nn.Linear: 0.0013479274599367] nn.Sequential: [nn.Linear: 9.4202826618064e-05 nn.Linear: 0.00062605193591799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066351261921227 nn.Linear: 0.0067520258016884 nn.Linear: 0.0060408073477447 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0047953273169696 nn.Linear: 0.010772996582091] nn.Sequential: [nn.Linear: 0.0030810805037618 nn.Linear: 0.007934900932014]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062721214301319 nn.Linear: 0.065808055018719 nn.Linear: 0.045522829120804 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031558730913072 nn.Linear: 0.05590999763038] nn.Sequential: [nn.Linear: 0.031487592909035 nn.Linear: 0.037017762754709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54148763418198 nn.Linear: 0.27130883932114 nn.Linear: 0.21969336271286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36501908302307 nn.Linear: 0.5978679060936] nn.Sequential: [nn.Linear: 0.17063193023205 nn.Linear: 0.27981027960777]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019614648240906 nn.Linear: 0.0011066334252803 nn.Linear: 0.00056837702538863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026293415560791 nn.Linear: 0.0034858645580207] nn.Sequential: [nn.Linear: 0.00022412156240854 nn.Linear: 0.0019010069830277]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013906253501773 nn.Linear: 0.016322342678905 nn.Linear: 0.016221927478909 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013527753762901 nn.Linear: 0.026503028348088] nn.Sequential: [nn.Linear: 0.0073259714990854 nn.Linear: 0.016232626512647]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06272030114263 nn.Linear: 0.065812389749287 nn.Linear: 0.045524550065508 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031558989759445 nn.Linear: 0.055907941094631] nn.Sequential: [nn.Linear: 0.031487875415062 nn.Linear: 0.037029668819198]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54181164503098 nn.Linear: 0.27153503894806 nn.Linear: 0.21993872523308 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36553198099136 nn.Linear: 0.59842348098755] nn.Sequential: [nn.Linear: 0.17088486254215 nn.Linear: 0.28004252910614]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013368747506006 nn.Linear: 0.00082646392860883 nn.Linear: 0.00038480860916996 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013025702329193 nn.Linear: 0.0014157599569903] nn.Sequential: [nn.Linear: 0.00014805196162179 nn.Linear: 0.0010683722505537]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0085608139634132 nn.Linear: 0.0086959274485707 nn.Linear: 0.011412334628403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007259982638061 nn.Linear: 0.0095425015315413] nn.Sequential: [nn.Linear: 0.0048445477150381 nn.Linear: 0.013750405982137]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062723457792988 nn.Linear: 0.065818313745107 nn.Linear: 0.045526396958784 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031559393537189 nn.Linear: 0.055954447693651] nn.Sequential: [nn.Linear: 0.031488026631742 nn.Linear: 0.037049005628452]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54173922538757 nn.Linear: 0.27120214700699 nn.Linear: 0.22023272514343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36603692173958 nn.Linear: 0.59924507141113] nn.Sequential: [nn.Linear: 0.17103269696236 nn.Linear: 0.28036910295486]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015767089759786 nn.Linear: 0.00083153407936108 nn.Linear: 0.00039746846017592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022814621571465 nn.Linear: 0.0031779856158783] nn.Sequential: [nn.Linear: 0.00015693125435699 nn.Linear: 0.0013536512431874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099503472447395 nn.Linear: 0.0091563565656543 nn.Linear: 0.0096297729760408 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012903848662972 nn.Linear: 0.023011794313788] nn.Sequential: [nn.Linear: 0.0065466715022922 nn.Linear: 0.01377641223371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062725444407874 nn.Linear: 0.065816961908388 nn.Linear: 0.045526809010225 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031559505764989 nn.Linear: 0.055955994373022] nn.Sequential: [nn.Linear: 0.031488025868804 nn.Linear: 0.037034832149467]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54152989387512 nn.Linear: 0.27149119973183 nn.Linear: 0.22013574838638 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3667825460434 nn.Linear: 0.599524974823] nn.Sequential: [nn.Linear: 0.1713045835495 nn.Linear: 0.28047409653664]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016290106931278 nn.Linear: 0.00076022684068857 nn.Linear: 0.00031456174962161 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011534835105756 nn.Linear: 0.0013358583112588] nn.Sequential: [nn.Linear: 0.00013640184340899 nn.Linear: 0.00094346572066244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011687237769365 nn.Linear: 0.010614816099405 nn.Linear: 0.0092277694493532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065049943514168 nn.Linear: 0.013256737962365] nn.Sequential: [nn.Linear: 0.0047078006900847 nn.Linear: 0.010717626661062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06272675227264 nn.Linear: 0.065825325542976 nn.Linear: 0.04552892464473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031559751166744 nn.Linear: 0.055981017559077] nn.Sequential: [nn.Linear: 0.031488304173146 nn.Linear: 0.037059988828312]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54187762737274 nn.Linear: 0.27147921919823 nn.Linear: 0.22063674032688 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36749839782715 nn.Linear: 0.6001051068306] nn.Sequential: [nn.Linear: 0.1713695526123 nn.Linear: 0.28076308965683]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091325315568355 nn.Linear: 0.00054015136603831 nn.Linear: 0.00031539734461981 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016076978047851 nn.Linear: 0.0018691201224439] nn.Sequential: [nn.Linear: 0.0001734006068534 nn.Linear: 0.0012520662377122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063724829815328 nn.Linear: 0.0073254387825727 nn.Linear: 0.0059183482080698 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059019671753049 nn.Linear: 0.012951272539794] nn.Sequential: [nn.Linear: 0.0064115668646991 nn.Linear: 0.011157820932567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732345763697 nn.Linear: 0.065827182112222 nn.Linear: 0.045530229870507 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560084035337 nn.Linear: 0.056008703631221] nn.Sequential: [nn.Linear: 0.031488599482213 nn.Linear: 0.037078150566078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5420138835907 nn.Linear: 0.27222523093224 nn.Linear: 0.22075292468071 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36819031834602 nn.Linear: 0.60085833072662] nn.Sequential: [nn.Linear: 0.17141704261303 nn.Linear: 0.28150504827499]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027908882079769 nn.Linear: 0.0016202978430098 nn.Linear: 0.00087437941814759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034182728443566 nn.Linear: 0.0039221701891394] nn.Sequential: [nn.Linear: 0.00026641689880342 nn.Linear: 0.0018647206365743]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018855985254049 nn.Linear: 0.024753032252192 nn.Linear: 0.028435463085771 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.028152707964182 nn.Linear: 0.028461134061217] nn.Sequential: [nn.Linear: 0.011077468283474 nn.Linear: 0.020271832123399]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062731550232388 nn.Linear: 0.065830606371486 nn.Linear: 0.045530930561606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560049852015 nn.Linear: 0.056002071220576] nn.Sequential: [nn.Linear: 0.031488936157347 nn.Linear: 0.037080495310453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54253953695297 nn.Linear: 0.27210268378258 nn.Linear: 0.22127433121204 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36868768930435 nn.Linear: 0.60150671005249] nn.Sequential: [nn.Linear: 0.1716190725565 nn.Linear: 0.28166046738625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031572842922548 nn.Linear: 0.0017437018421172 nn.Linear: 0.001008031455671 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00047291061907298 nn.Linear: 0.006269897430125] nn.Sequential: [nn.Linear: 0.00040100724119009 nn.Linear: 0.0036858432751427]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018571928143501 nn.Linear: 0.029509538784623 nn.Linear: 0.024473164230585 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031763304024935 nn.Linear: 0.042557086795568] nn.Sequential: [nn.Linear: 0.016583897173405 nn.Linear: 0.041550736874342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062730028312856 nn.Linear: 0.065832747182702 nn.Linear: 0.045531703974708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03156020960092 nn.Linear: 0.056014714482956] nn.Sequential: [nn.Linear: 0.031489134596045 nn.Linear: 0.037092153791066]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54286271333694 nn.Linear: 0.27279427647591 nn.Linear: 0.22210511565208 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3690513074398 nn.Linear: 0.60197389125824] nn.Sequential: [nn.Linear: 0.17197075486183 nn.Linear: 0.28199118375778]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016799534520296 nn.Linear: 0.0010761325740309 nn.Linear: 0.00051330214297538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022123574609968 nn.Linear: 0.0032869516471274] nn.Sequential: [nn.Linear: 0.00018408400227781 nn.Linear: 0.0015421370918392]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0093145305290818 nn.Linear: 0.014855969697237 nn.Linear: 0.0095621272921562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010540323331952 nn.Linear: 0.02227464877069] nn.Sequential: [nn.Linear: 0.0067518227733672 nn.Linear: 0.012636276893318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732257892648 nn.Linear: 0.065839113970909 nn.Linear: 0.045532329965684 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560106188817 nn.Linear: 0.056035349098238] nn.Sequential: [nn.Linear: 0.03148931297203 nn.Linear: 0.037090463509852]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54260170459747 nn.Linear: 0.27262049913406 nn.Linear: 0.22216838598251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36950498819351 nn.Linear: 0.60229730606079] nn.Sequential: [nn.Linear: 0.17149290442467 nn.Linear: 0.28215590119362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012373380174449 nn.Linear: 0.00061324820671979 nn.Linear: 0.00029734014025012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012795341744163 nn.Linear: 0.0016898800849936] nn.Sequential: [nn.Linear: 0.00012597130811282 nn.Linear: 0.00095122533323045]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0076031074859202 nn.Linear: 0.0093841589987278 nn.Linear: 0.005621213465929 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064963614568114 nn.Linear: 0.012444581836462] nn.Sequential: [nn.Linear: 0.0055577992461622 nn.Linear: 0.014161769300699]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06273085773634 nn.Linear: 0.065843576990401 nn.Linear: 0.045533796428152 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03156036465398 nn.Linear: 0.056045300534151] nn.Sequential: [nn.Linear: 0.031489243124128 nn.Linear: 0.037102211918763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54312825202942 nn.Linear: 0.27251109480858 nn.Linear: 0.22233666479588 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36984303593636 nn.Linear: 0.60259848833084] nn.Sequential: [nn.Linear: 0.17139086127281 nn.Linear: 0.28248611092567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014846617438282 nn.Linear: 0.00091127649373096 nn.Linear: 0.00046752716451125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020092178251155 nn.Linear: 0.0021758641357797] nn.Sequential: [nn.Linear: 0.0001745330248839 nn.Linear: 0.0011762737591238]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010070779360831 nn.Linear: 0.0097836591303349 nn.Linear: 0.010598509572446 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011552934534848 nn.Linear: 0.015469086356461] nn.Sequential: [nn.Linear: 0.0053550722077489 nn.Linear: 0.010755279101431]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062730751227699 nn.Linear: 0.065843575373532 nn.Linear: 0.04553495855504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560579445982 nn.Linear: 0.056085643726817] nn.Sequential: [nn.Linear: 0.031489123970051 nn.Linear: 0.03710132184883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54306709766388 nn.Linear: 0.27256739139557 nn.Linear: 0.22273103892803 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.36992025375366 nn.Linear: 0.60250753164291] nn.Sequential: [nn.Linear: 0.17143674194813 nn.Linear: 0.28260666131973]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028799257269655 nn.Linear: 0.0014192045109872 nn.Linear: 0.00064876894667812 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034664192886135 nn.Linear: 0.004982384255813] nn.Sequential: [nn.Linear: 0.00026670584410241 nn.Linear: 0.0019602549811948]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018304169178009 nn.Linear: 0.018555985763669 nn.Linear: 0.018263136968017 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.030273053795099 nn.Linear: 0.039395421743393] nn.Sequential: [nn.Linear: 0.014247369021177 nn.Linear: 0.027612291276455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062724943064937 nn.Linear: 0.065843423639856 nn.Linear: 0.045535894608856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560682249365 nn.Linear: 0.056103920577765] nn.Sequential: [nn.Linear: 0.031489475755655 nn.Linear: 0.037106546926632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54399663209915 nn.Linear: 0.27286049723625 nn.Linear: 0.22272761166096 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37021723389626 nn.Linear: 0.60256916284561] nn.Sequential: [nn.Linear: 0.17159095406532 nn.Linear: 0.28283229470253]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002370703068846 nn.Linear: 0.0011561217361091 nn.Linear: 0.00049860185756137 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021464119645885 nn.Linear: 0.0024862028593282] nn.Sequential: [nn.Linear: 0.00017637034997895 nn.Linear: 0.001265829206698]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017339611425996 nn.Linear: 0.01514967251569 nn.Linear: 0.017415093258023 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013577706180513 nn.Linear: 0.019676087424159] nn.Sequential: [nn.Linear: 0.00593699561432 nn.Linear: 0.014046062715352]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.078602931916714	TD error	0.016228344604373	Qmax	1	

Steps: 10250000 (frames: 41000000), score: 2187.89, higheset score: 6924, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1840fps, testing time: 88s, testing rate: 5657fps,  num. ep.: 329,  num. rewards: 17376	
   4    2    4    2
   2   16   32   16
  16   64  128    4
   4    8  256  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722847477781 nn.Linear: 0.065844682401093 nn.Linear: 0.045536618265704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560720925119 nn.Linear: 0.056093739582963] nn.Sequential: [nn.Linear: 0.031489655914552 nn.Linear: 0.037113398276102]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54397284984589 nn.Linear: 0.27291530370712 nn.Linear: 0.22298748791218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37059715390205 nn.Linear: 0.60333812236786] nn.Sequential: [nn.Linear: 0.17184002697468 nn.Linear: 0.28321608901024]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017422105913742 nn.Linear: 0.0010687296337075 nn.Linear: 0.00049899595168461 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021887444814911 nn.Linear: 0.0025647858613453] nn.Sequential: [nn.Linear: 0.00021800906532666 nn.Linear: 0.0016564141170196]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012352716177702 nn.Linear: 0.020265150815248 nn.Linear: 0.014922599308193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010404363274574 nn.Linear: 0.017326707020402] nn.Sequential: [nn.Linear: 0.0073013571090996 nn.Linear: 0.018858164548874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062724303601304 nn.Linear: 0.065850101117183 nn.Linear: 0.045538362616507 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560920479282 nn.Linear: 0.056130832815771] nn.Sequential: [nn.Linear: 0.031489696143281 nn.Linear: 0.037123560707275]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54416400194168 nn.Linear: 0.27313870191574 nn.Linear: 0.22308650612831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37089461088181 nn.Linear: 0.60337603092194] nn.Sequential: [nn.Linear: 0.17216505110264 nn.Linear: 0.28310918807983]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010690341871731 nn.Linear: 0.0006257577359602 nn.Linear: 0.00031210560934978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012231360592957 nn.Linear: 0.0012398101407907] nn.Sequential: [nn.Linear: 0.00013699292520853 nn.Linear: 0.0010504970990146]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009001150727272 nn.Linear: 0.010274898260832 nn.Linear: 0.0058839949779212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0096612488850951 nn.Linear: 0.0069672577083111] nn.Sequential: [nn.Linear: 0.005081354174763 nn.Linear: 0.011662577278912]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718346430377 nn.Linear: 0.065853977278582 nn.Linear: 0.045540837100651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031560878039576 nn.Linear: 0.056143868272656] nn.Sequential: [nn.Linear: 0.031490075777868 nn.Linear: 0.037136435272526]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54456961154938 nn.Linear: 0.27320408821106 nn.Linear: 0.22337429225445 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37146264314651 nn.Linear: 0.60406124591827] nn.Sequential: [nn.Linear: 0.17259511351585 nn.Linear: 0.28350722789764]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010347277496647 nn.Linear: 0.00070936793911653 nn.Linear: 0.00037290608220103 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018313278234181 nn.Linear: 0.0022152185803352] nn.Sequential: [nn.Linear: 0.00014519689521765 nn.Linear: 0.00094887733765942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088049303740263 nn.Linear: 0.01419435068965 nn.Linear: 0.008292842656374 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011772716417909 nn.Linear: 0.019662860780954] nn.Sequential: [nn.Linear: 0.0085679860785604 nn.Linear: 0.0099257240071893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062716087978926 nn.Linear: 0.065856014290475 nn.Linear: 0.045540669858062 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031561235272515 nn.Linear: 0.056155373438799] nn.Sequential: [nn.Linear: 0.031490066408059 nn.Linear: 0.037139020226157]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54436367750168 nn.Linear: 0.27285352349281 nn.Linear: 0.22373875975609 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37190276384354 nn.Linear: 0.60459899902344] nn.Sequential: [nn.Linear: 0.17288091778755 nn.Linear: 0.28370401263237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017434109537459 nn.Linear: 0.0011241668520865 nn.Linear: 0.00065478786995939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033485248926778 nn.Linear: 0.0037343557720409] nn.Sequential: [nn.Linear: 0.00022800989928738 nn.Linear: 0.0015192833260706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013754873536527 nn.Linear: 0.017860941588879 nn.Linear: 0.013788887299597 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01361246034503 nn.Linear: 0.02664290368557] nn.Sequential: [nn.Linear: 0.0047819651663303 nn.Linear: 0.01507664937526]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062717024315648 nn.Linear: 0.0658618313157 nn.Linear: 0.045542883376296 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031561561616857 nn.Linear: 0.05618457341393] nn.Sequential: [nn.Linear: 0.03149016280055 nn.Linear: 0.037142304428862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54477900266647 nn.Linear: 0.27324721217155 nn.Linear: 0.22361269593239 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37225666642189 nn.Linear: 0.60516405105591] nn.Sequential: [nn.Linear: 0.17273657023907 nn.Linear: 0.28403836488724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016491043224984 nn.Linear: 0.0010190396358524 nn.Linear: 0.00051350204244458 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021985913360013 nn.Linear: 0.002906060466921] nn.Sequential: [nn.Linear: 0.00020164778317585 nn.Linear: 0.0015500037763883]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010224514640868 nn.Linear: 0.018683826550841 nn.Linear: 0.011863996274769 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0087166968733072 nn.Linear: 0.020429521799088] nn.Sequential: [nn.Linear: 0.0076479827985168 nn.Linear: 0.017901247367263]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062713762342365 nn.Linear: 0.065863063536385 nn.Linear: 0.045543108483124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03156170187648 nn.Linear: 0.056188708959667] nn.Sequential: [nn.Linear: 0.031490207781705 nn.Linear: 0.037147580477325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54413068294525 nn.Linear: 0.2736174762249 nn.Linear: 0.2241142988205 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37250167131424 nn.Linear: 0.60544729232788] nn.Sequential: [nn.Linear: 0.17286866903305 nn.Linear: 0.28427562117577]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0057375074396108 nn.Linear: 0.0027798918602524 nn.Linear: 0.0011675382177607 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00044411035671186 nn.Linear: 0.0052751431038511] nn.Sequential: [nn.Linear: 0.00036236251195927 nn.Linear: 0.0028363662252628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.043566323816776 nn.Linear: 0.039621524512768 nn.Linear: 0.036528762429953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.027687329798937 nn.Linear: 0.028914723545313] nn.Sequential: [nn.Linear: 0.013539576902986 nn.Linear: 0.02674787119031]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062718702572935 nn.Linear: 0.065867590845067 nn.Linear: 0.045544808612532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031561915584613 nn.Linear: 0.056253396878674] nn.Sequential: [nn.Linear: 0.031490452696252 nn.Linear: 0.03715595281133]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54422008991241 nn.Linear: 0.27362284064293 nn.Linear: 0.22423510253429 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37300381064415 nn.Linear: 0.60593247413635] nn.Sequential: [nn.Linear: 0.17275401949883 nn.Linear: 0.28447487950325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002029289376556 nn.Linear: 0.0010061049812413 nn.Linear: 0.00047193663413949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000177334841992 nn.Linear: 0.0019717435104262] nn.Sequential: [nn.Linear: 0.00022054561865733 nn.Linear: 0.0020751797050491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012984110973775 nn.Linear: 0.015573915094137 nn.Linear: 0.012818045914173 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012891189195216 nn.Linear: 0.015820013359189] nn.Sequential: [nn.Linear: 0.0059987180866301 nn.Linear: 0.023899454623461]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06271712771323 nn.Linear: 0.065871706921521 nn.Linear: 0.045546321660439 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031562374984505 nn.Linear: 0.056310421022665] nn.Sequential: [nn.Linear: 0.031490591575211 nn.Linear: 0.037178423325726]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54361617565155 nn.Linear: 0.27371069788933 nn.Linear: 0.22415669262409 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37357559800148 nn.Linear: 0.60637021064758] nn.Sequential: [nn.Linear: 0.17286610603333 nn.Linear: 0.28461670875549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024600957889064 nn.Linear: 0.0014925939899976 nn.Linear: 0.00078136232951723 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003629253238553 nn.Linear: 0.0049657998538439] nn.Sequential: [nn.Linear: 0.00035742942210649 nn.Linear: 0.0029807498722568]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019029576331377 nn.Linear: 0.02138208784163 nn.Linear: 0.017492642626166 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014513626694679 nn.Linear: 0.031017437577248] nn.Sequential: [nn.Linear: 0.01135329157114 nn.Linear: 0.032542400062084]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062717604493307 nn.Linear: 0.06587253769601 nn.Linear: 0.045547375743387 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031562328762592 nn.Linear: 0.056320071982583] nn.Sequential: [nn.Linear: 0.031490686685639 nn.Linear: 0.037181058614843]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54331290721893 nn.Linear: 0.27403703331947 nn.Linear: 0.22489148378372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37394106388092 nn.Linear: 0.60665380954742] nn.Sequential: [nn.Linear: 0.17252217233181 nn.Linear: 0.2849505841732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017240734974534 nn.Linear: 0.0010256746476619 nn.Linear: 0.00054669141432304 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003775100830016 nn.Linear: 0.0057820074232379] nn.Sequential: [nn.Linear: 0.00025725262994679 nn.Linear: 0.0018879538556073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01065889839083 nn.Linear: 0.012153492309153 nn.Linear: 0.023756768554449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015490297228098 nn.Linear: 0.041052922606468] nn.Sequential: [nn.Linear: 0.0088557535782456 nn.Linear: 0.022991487756371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062720873681099 nn.Linear: 0.06587777521688 nn.Linear: 0.045548074333449 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03156252313881 nn.Linear: 0.056327149913955] nn.Sequential: [nn.Linear: 0.031490839362277 nn.Linear: 0.037180968122438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54406356811523 nn.Linear: 0.27441588044167 nn.Linear: 0.22520586848259 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37435877323151 nn.Linear: 0.6067687869072] nn.Sequential: [nn.Linear: 0.17271059751511 nn.Linear: 0.28514927625656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002906082426398 nn.Linear: 0.0013268808744575 nn.Linear: 0.00062962063325848 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026513703477254 nn.Linear: 0.0036416861200383] nn.Sequential: [nn.Linear: 0.00023758463966016 nn.Linear: 0.0018610996306081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017554806545377 nn.Linear: 0.022857189178467 nn.Linear: 0.019427673891187 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019683038815856 nn.Linear: 0.027926333248615] nn.Sequential: [nn.Linear: 0.012864871881902 nn.Linear: 0.017522033303976]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722045389418 nn.Linear: 0.065877710114918 nn.Linear: 0.045548390214046 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031562732362888 nn.Linear: 0.05634447373825] nn.Sequential: [nn.Linear: 0.031490824878079 nn.Linear: 0.037181768034471]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54410445690155 nn.Linear: 0.27508035302162 nn.Linear: 0.22505867481232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37464106082916 nn.Linear: 0.60736286640167] nn.Sequential: [nn.Linear: 0.1727396696806 nn.Linear: 0.28556296229362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019753652993577 nn.Linear: 0.0011442264836252 nn.Linear: 0.00053730478600526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022884167818946 nn.Linear: 0.0028746662239199] nn.Sequential: [nn.Linear: 0.00019146073964912 nn.Linear: 0.0015321071526346]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01241487916559 nn.Linear: 0.014409586787224 nn.Linear: 0.010433867573738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015051757916808 nn.Linear: 0.02174973487854] nn.Sequential: [nn.Linear: 0.0080205108970404 nn.Linear: 0.015095718204975]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062717687606918 nn.Linear: 0.065883600691911 nn.Linear: 0.045550723926723 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563158274163 nn.Linear: 0.056376345485774] nn.Sequential: [nn.Linear: 0.031491164417432 nn.Linear: 0.037199118851886]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54422563314438 nn.Linear: 0.27458646893501 nn.Linear: 0.22548191249371 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37504205107689 nn.Linear: 0.60772901773453] nn.Sequential: [nn.Linear: 0.17266926169395 nn.Linear: 0.28606224060059]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018735520941866 nn.Linear: 0.0012012474237971 nn.Linear: 0.00064227571024757 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017309650144105 nn.Linear: 0.0017235390129243] nn.Sequential: [nn.Linear: 0.00018380029034608 nn.Linear: 0.0014835755492432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012766658328474 nn.Linear: 0.021501231938601 nn.Linear: 0.022053621709347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017311519011855 nn.Linear: 0.01207548007369] nn.Sequential: [nn.Linear: 0.0056337132118642 nn.Linear: 0.015054470859468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062722095940317 nn.Linear: 0.065886004711749 nn.Linear: 0.045550699974452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563354078978 nn.Linear: 0.056401269392495] nn.Sequential: [nn.Linear: 0.031491288697277 nn.Linear: 0.037204484916117]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54329705238342 nn.Linear: 0.27401369810104 nn.Linear: 0.22552688419819 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37586671113968 nn.Linear: 0.6087372303009] nn.Sequential: [nn.Linear: 0.173294916749 nn.Linear: 0.28631666302681]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0068389550009095 nn.Linear: 0.0034806629130569 nn.Linear: 0.0012053939856601 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030759581762336 nn.Linear: 0.0034733685310115] nn.Sequential: [nn.Linear: 0.00031236618511736 nn.Linear: 0.002720651635148]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.051249001175165 nn.Linear: 0.057157780975103 nn.Linear: 0.078512959182262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031729023903608 nn.Linear: 0.028949744999409] nn.Sequential: [nn.Linear: 0.011804325506091 nn.Linear: 0.036365117877722]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062731151855743 nn.Linear: 0.065891381056639 nn.Linear: 0.045552733941281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563376335049 nn.Linear: 0.056397868581143] nn.Sequential: [nn.Linear: 0.031491577438658 nn.Linear: 0.037198891180856]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54306477308273 nn.Linear: 0.27375656366348 nn.Linear: 0.22552295029163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37630239129066 nn.Linear: 0.60912549495697] nn.Sequential: [nn.Linear: 0.17381937801838 nn.Linear: 0.28650417923927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013185760990377 nn.Linear: 0.0008135169645654 nn.Linear: 0.00047428886046643 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023445334812015 nn.Linear: 0.0030075396711766] nn.Sequential: [nn.Linear: 0.0002468235779184 nn.Linear: 0.001941841479226]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094263702630997 nn.Linear: 0.0096173482015729 nn.Linear: 0.0098066851496696 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010078696534038 nn.Linear: 0.022799398750067] nn.Sequential: [nn.Linear: 0.0089455991983414 nn.Linear: 0.016230084002018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062732891401487 nn.Linear: 0.065892925664171 nn.Linear: 0.04555406723514 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563666751059 nn.Linear: 0.056421924914503] nn.Sequential: [nn.Linear: 0.031491660300471 nn.Linear: 0.037212208415289]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54342263936996 nn.Linear: 0.27476134896278 nn.Linear: 0.22574101388454 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37641102075577 nn.Linear: 0.6090994477272] nn.Sequential: [nn.Linear: 0.17400759458542 nn.Linear: 0.28652945160866]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016962395662915 nn.Linear: 0.00081833790439439 nn.Linear: 0.0003839175009813 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013227913225079 nn.Linear: 0.0015109044426342] nn.Sequential: [nn.Linear: 0.00014823618527354 nn.Linear: 0.001158531754344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012867353856564 nn.Linear: 0.01295380294323 nn.Linear: 0.0067268148995936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082310643047094 nn.Linear: 0.013973803259432] nn.Sequential: [nn.Linear: 0.0061491532251239 nn.Linear: 0.013246513903141]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062734872814148 nn.Linear: 0.065895021584172 nn.Linear: 0.045554965463124 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563872802668 nn.Linear: 0.056418779922751] nn.Sequential: [nn.Linear: 0.031491941391004 nn.Linear: 0.037224348434529]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54361534118652 nn.Linear: 0.27530884742737 nn.Linear: 0.22610141336918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37650415301323 nn.Linear: 0.60931819677353] nn.Sequential: [nn.Linear: 0.17420707643032 nn.Linear: 0.28677532076836]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0034338596203838 nn.Linear: 0.001992446548154 nn.Linear: 0.00079080084218314 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002839484393143 nn.Linear: 0.003192206019107] nn.Sequential: [nn.Linear: 0.00033251059983409 nn.Linear: 0.0024630104343401]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019009055569768 nn.Linear: 0.022608632221818 nn.Linear: 0.01918257586658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024896115064621 nn.Linear: 0.031989436596632] nn.Sequential: [nn.Linear: 0.011422225274146 nn.Linear: 0.024557719007134]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062729631468892 nn.Linear: 0.065896549505342 nn.Linear: 0.045556321143733 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031563990090768 nn.Linear: 0.056442913283831] nn.Sequential: [nn.Linear: 0.031491950691054 nn.Linear: 0.037224445309327]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54348129034042 nn.Linear: 0.27499982714653 nn.Linear: 0.2264197319746 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37697577476501 nn.Linear: 0.60964041948318] nn.Sequential: [nn.Linear: 0.1742732077837 nn.Linear: 0.28684857487679]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010173157221824 nn.Linear: 0.00064190005606999 nn.Linear: 0.00031867406548553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017810280449842 nn.Linear: 0.0026278156874763] nn.Sequential: [nn.Linear: 0.00011742866252828 nn.Linear: 0.00096717236982628]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058305230922997 nn.Linear: 0.0078316293656826 nn.Linear: 0.0064011900685728 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.009428434073925 nn.Linear: 0.017126895487309] nn.Sequential: [nn.Linear: 0.0036930344067514 nn.Linear: 0.0085943294689059]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062737156607996 nn.Linear: 0.065900240842604 nn.Linear: 0.045557928424597 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0315642820043 nn.Linear: 0.05643815517584] nn.Sequential: [nn.Linear: 0.031492241668848 nn.Linear: 0.037230222970496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5437383055687 nn.Linear: 0.27522534132004 nn.Linear: 0.22627678513527 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37754848599434 nn.Linear: 0.61067920923233] nn.Sequential: [nn.Linear: 0.17443758249283 nn.Linear: 0.2872898876667]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019255402461352 nn.Linear: 0.0011162127441269 nn.Linear: 0.0006456723687188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026570016535111 nn.Linear: 0.0035115840500759] nn.Sequential: [nn.Linear: 0.00029441761649321 nn.Linear: 0.002302336377052]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016876507550478 nn.Linear: 0.019129883497953 nn.Linear: 0.017225982621312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0091876443475485 nn.Linear: 0.022020230069757] nn.Sequential: [nn.Linear: 0.0068962187506258 nn.Linear: 0.020464779809117]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062738007618789 nn.Linear: 0.065906346649838 nn.Linear: 0.045559067580402 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031564686300057 nn.Linear: 0.056476248645708] nn.Sequential: [nn.Linear: 0.031492345086938 nn.Linear: 0.037243488340251]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54407107830048 nn.Linear: 0.27549234032631 nn.Linear: 0.22667774558067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37778753042221 nn.Linear: 0.61135864257812] nn.Sequential: [nn.Linear: 0.1746032088995 nn.Linear: 0.2876258790493]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013082464364816 nn.Linear: 0.00067463149312962 nn.Linear: 0.00032019237788916 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017557052273225 nn.Linear: 0.0021726952532815] nn.Sequential: [nn.Linear: 0.00011736119416793 nn.Linear: 0.00070657629798641]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010607473552227 nn.Linear: 0.0096885859966278 nn.Linear: 0.006788001395762 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01024294923991 nn.Linear: 0.015461887232959] nn.Sequential: [nn.Linear: 0.0056190616451204 nn.Linear: 0.0070679723285139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062742050606263 nn.Linear: 0.065908143414857 nn.Linear: 0.04556055301877 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031564742096657 nn.Linear: 0.056478427873799] nn.Sequential: [nn.Linear: 0.03149253504716 nn.Linear: 0.037250209936666]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.544114112854 nn.Linear: 0.27545496821404 nn.Linear: 0.22651591897011 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37807103991508 nn.Linear: 0.61135172843933] nn.Sequential: [nn.Linear: 0.17495255172253 nn.Linear: 0.28755956888199]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001917366187835 nn.Linear: 0.0010679618951992 nn.Linear: 0.0005393145220649 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027482777835887 nn.Linear: 0.0030885070853321] nn.Sequential: [nn.Linear: 0.00023104972908521 nn.Linear: 0.0018772805027055]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012065652757883 nn.Linear: 0.015216993167996 nn.Linear: 0.018600208684802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.026670170947909 nn.Linear: 0.027013735845685] nn.Sequential: [nn.Linear: 0.018517531454563 nn.Linear: 0.021266128867865]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06275016384031 nn.Linear: 0.065909279269615 nn.Linear: 0.045560923395095 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031564781830066 nn.Linear: 0.056489129358511] nn.Sequential: [nn.Linear: 0.031492675580503 nn.Linear: 0.037267509605212]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54364883899689 nn.Linear: 0.27519237995148 nn.Linear: 0.22675536572933 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37828415632248 nn.Linear: 0.61225879192352] nn.Sequential: [nn.Linear: 0.17498902976513 nn.Linear: 0.28803545236588]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014021237750792 nn.Linear: 0.00078818873822511 nn.Linear: 0.00041644450167487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000211082547691 nn.Linear: 0.0027432372809537] nn.Sequential: [nn.Linear: 0.00014698815546718 nn.Linear: 0.00094045514898693]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097640361636877 nn.Linear: 0.011317328549922 nn.Linear: 0.007168251555413 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008137434720993 nn.Linear: 0.020401807501912] nn.Sequential: [nn.Linear: 0.0046364446170628 nn.Linear: 0.009922050870955]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062748380810893 nn.Linear: 0.065912369069467 nn.Linear: 0.045562735630648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031565015917112 nn.Linear: 0.056510746756985] nn.Sequential: [nn.Linear: 0.031492856068572 nn.Linear: 0.037275092508145]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54363459348679 nn.Linear: 0.27562674880028 nn.Linear: 0.2269676476717 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37845787405968 nn.Linear: 0.61252969503403] nn.Sequential: [nn.Linear: 0.17545720934868 nn.Linear: 0.28813144564629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027872820298576 nn.Linear: 0.0016532382078083 nn.Linear: 0.00079691185833138 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034137324612484 nn.Linear: 0.0048153226458464] nn.Sequential: [nn.Linear: 0.00030013447350168 nn.Linear: 0.0027615570558867]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0220185238868 nn.Linear: 0.032329864799976 nn.Linear: 0.028608234599233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.027507662773132 nn.Linear: 0.034667950123549] nn.Sequential: [nn.Linear: 0.020466497167945 nn.Linear: 0.033534947782755]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062749050368944 nn.Linear: 0.065917815357402 nn.Linear: 0.045564435482763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031565154545775 nn.Linear: 0.056526773931239] nn.Sequential: [nn.Linear: 0.031493386589432 nn.Linear: 0.037276879275081]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54414737224579 nn.Linear: 0.27614435553551 nn.Linear: 0.22741957008839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.37884011864662 nn.Linear: 0.61304938793182] nn.Sequential: [nn.Linear: 0.17549122869968 nn.Linear: 0.28825801610947]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00072831521309266 nn.Linear: 0.00037778647148997 nn.Linear: 0.00018361901212193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 6.2817298397528e-05 nn.Linear: 0.0005898475392539] nn.Sequential: [nn.Linear: 7.9656441022852e-05 nn.Linear: 0.00067934697254368]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049821413122118 nn.Linear: 0.0043039405718446 nn.Linear: 0.0036714801099151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00327322864905 nn.Linear: 0.0043594050221145] nn.Sequential: [nn.Linear: 0.0032427797559649 nn.Linear: 0.0070835296064615]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06275123420593 nn.Linear: 0.065921437578057 nn.Linear: 0.045565319056183 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031565354220895 nn.Linear: 0.05653661802171] nn.Sequential: [nn.Linear: 0.03149346303519 nn.Linear: 0.03728833937745]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54445898532867 nn.Linear: 0.27614364027977 nn.Linear: 0.22783702611923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3792205452919 nn.Linear: 0.613913834095] nn.Sequential: [nn.Linear: 0.17560864984989 nn.Linear: 0.28868240118027]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015737296261464 nn.Linear: 0.00084663274154791 nn.Linear: 0.00042668287284802 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020789323655153 nn.Linear: 0.0024720915763452] nn.Sequential: [nn.Linear: 0.00019387614423311 nn.Linear: 0.0014582521192873]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013112245127559 nn.Linear: 0.011976613663137 nn.Linear: 0.010551474988461 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011328153312206 nn.Linear: 0.015232981182635] nn.Sequential: [nn.Linear: 0.01037479378283 nn.Linear: 0.019406551495194]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062751216814494 nn.Linear: 0.065924147731986 nn.Linear: 0.045567538365442 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031565715798843 nn.Linear: 0.056544045465898] nn.Sequential: [nn.Linear: 0.03149378482415 nn.Linear: 0.037304577310768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54503017663956 nn.Linear: 0.27637606859207 nn.Linear: 0.22800329327583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3796511888504 nn.Linear: 0.61401510238647] nn.Sequential: [nn.Linear: 0.17564417421818 nn.Linear: 0.28862914443016]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013949198253968 nn.Linear: 0.00081552271654041 nn.Linear: 0.00046210834482569 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020462975107254 nn.Linear: 0.001843108822878] nn.Sequential: [nn.Linear: 0.00020185575185679 nn.Linear: 0.0015608011738025]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011538975872099 nn.Linear: 0.015022400766611 nn.Linear: 0.0092413565143943 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081349415704608 nn.Linear: 0.010420088656247] nn.Sequential: [nn.Linear: 0.0080566322430968 nn.Linear: 0.015466165728867]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.083311298057437	TD error	0.016635414134711	Qmax	1	

Steps: 10500000 (frames: 42000000), score: 2103.41, higheset score: 6720, epsilon: 0.05, lr: 0.0005, training time: 542s, training rate: 1842fps, testing time: 88s, testing rate: 5636fps,  num. ep.: 352,  num. rewards: 17367	
   2    4    8    2
   4    8  128   32
  16  512   32    2
   4   16    2  256
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06275620235489 nn.Linear: 0.065928164545095 nn.Linear: 0.045568438090657 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031565963317078 nn.Linear: 0.056573863776293] nn.Sequential: [nn.Linear: 0.031493579295021 nn.Linear: 0.03730239424625]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54482769966125 nn.Linear: 0.27680534124374 nn.Linear: 0.22823774814606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38002693653107 nn.Linear: 0.61426627635956] nn.Sequential: [nn.Linear: 0.1759941726923 nn.Linear: 0.28888177871704]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013916705371082 nn.Linear: 0.00079397842446714 nn.Linear: 0.00039904493119192 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015863790268652 nn.Linear: 0.0015663265924881] nn.Sequential: [nn.Linear: 0.00015789825055324 nn.Linear: 0.0012100804658434]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095725655555725 nn.Linear: 0.0091160889714956 nn.Linear: 0.0074108205735683 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0061588268727064 nn.Linear: 0.012306976132095] nn.Sequential: [nn.Linear: 0.0062600681558251 nn.Linear: 0.01185742020607]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062763721201025 nn.Linear: 0.065936591121283 nn.Linear: 0.045571455735459 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031566227474871 nn.Linear: 0.056619335726509] nn.Sequential: [nn.Linear: 0.03149423213538 nn.Linear: 0.037331948820514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54471772909164 nn.Linear: 0.27649250626564 nn.Linear: 0.2283219397068 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3802502155304 nn.Linear: 0.61489272117615] nn.Sequential: [nn.Linear: 0.17587052285671 nn.Linear: 0.28905200958252]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033415158632068 nn.Linear: 0.0017075783691343 nn.Linear: 0.00072051143189369 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025033771152437 nn.Linear: 0.0025780985912385] nn.Sequential: [nn.Linear: 0.00030654359172568 nn.Linear: 0.0021225281747351]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01875608228147 nn.Linear: 0.045448809862137 nn.Linear: 0.022337444126606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012997193261981 nn.Linear: 0.030697748064995] nn.Sequential: [nn.Linear: 0.011501312255859 nn.Linear: 0.022717488929629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062764662319338 nn.Linear: 0.065940930544622 nn.Linear: 0.045572685810209 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031566423152644 nn.Linear: 0.056657519384203] nn.Sequential: [nn.Linear: 0.03149420651715 nn.Linear: 0.037342833511054]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54512304067612 nn.Linear: 0.27730718255043 nn.Linear: 0.22852462530136 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38053071498871 nn.Linear: 0.6154083609581] nn.Sequential: [nn.Linear: 0.17595687508583 nn.Linear: 0.2892639040947]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013890299015559 nn.Linear: 0.00068900634311839 nn.Linear: 0.0003012206892887 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001529910277635 nn.Linear: 0.0018499231431789] nn.Sequential: [nn.Linear: 0.00010397566547496 nn.Linear: 0.00063964058863372]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0070953355170786 nn.Linear: 0.010459091514349 nn.Linear: 0.008216074667871 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015622097998857 nn.Linear: 0.019762521609664] nn.Sequential: [nn.Linear: 0.0062827956862748 nn.Linear: 0.005865965038538]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062771839473415 nn.Linear: 0.065947323152864 nn.Linear: 0.045573761725474 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031566422219954 nn.Linear: 0.056666445070505] nn.Sequential: [nn.Linear: 0.031494662793272 nn.Linear: 0.037361329303713]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5455407500267 nn.Linear: 0.27714046835899 nn.Linear: 0.22878935933113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38087391853333 nn.Linear: 0.6158674955368] nn.Sequential: [nn.Linear: 0.17639309167862 nn.Linear: 0.28938454389572]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014819803656155 nn.Linear: 0.00075921103873468 nn.Linear: 0.00037375673103675 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017041739650888 nn.Linear: 0.0022097508843941] nn.Sequential: [nn.Linear: 0.00011503229751306 nn.Linear: 0.00080157960008718]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098686860874295 nn.Linear: 0.011504540219903 nn.Linear: 0.0089255403727293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0066458927467465 nn.Linear: 0.01738839969039] nn.Sequential: [nn.Linear: 0.0053200111724436 nn.Linear: 0.0082125822082162]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062761863923413 nn.Linear: 0.065948592641286 nn.Linear: 0.045575093853631 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031566702801645 nn.Linear: 0.056642848951242] nn.Sequential: [nn.Linear: 0.031494360656729 nn.Linear: 0.037344785946335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54495340585709 nn.Linear: 0.27728390693665 nn.Linear: 0.22904369235039 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38105291128159 nn.Linear: 0.6162017583847] nn.Sequential: [nn.Linear: 0.17661395668983 nn.Linear: 0.28963887691498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00099997121772149 nn.Linear: 0.00064095062447801 nn.Linear: 0.00037483634580272 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013211774094906 nn.Linear: 0.0014718615763568] nn.Sequential: [nn.Linear: 0.00014982291009258 nn.Linear: 0.0011647777584197]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0060180369764566 nn.Linear: 0.01098364405334 nn.Linear: 0.0079858861863613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076262983493507 nn.Linear: 0.010378824546933] nn.Sequential: [nn.Linear: 0.0051962942816317 nn.Linear: 0.011774904094636]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062764871793036 nn.Linear: 0.065951598003657 nn.Linear: 0.045576958948392 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031566873312522 nn.Linear: 0.056668242832302] nn.Sequential: [nn.Linear: 0.031494873788344 nn.Linear: 0.037364902835072]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54511690139771 nn.Linear: 0.27775257825851 nn.Linear: 0.2295536249876 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38140672445297 nn.Linear: 0.6170340180397] nn.Sequential: [nn.Linear: 0.17643079161644 nn.Linear: 0.29019170999527]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017460878460182 nn.Linear: 0.00087308370278548 nn.Linear: 0.00040837670754637 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015801791904386 nn.Linear: 0.0018013717886253] nn.Sequential: [nn.Linear: 0.00015400176378563 nn.Linear: 0.00097876438849453]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0131756067276 nn.Linear: 0.012430303730071 nn.Linear: 0.010457182303071 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077613214962184 nn.Linear: 0.011076169088483] nn.Sequential: [nn.Linear: 0.0071643521077931 nn.Linear: 0.0087796645238996]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062766271616015 nn.Linear: 0.065953463624171 nn.Linear: 0.045578283267146 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031567172370213 nn.Linear: 0.056699332748735] nn.Sequential: [nn.Linear: 0.031495422914492 nn.Linear: 0.037381939833921]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54482936859131 nn.Linear: 0.27706605195999 nn.Linear: 0.22961308062077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.381960272789 nn.Linear: 0.61718362569809] nn.Sequential: [nn.Linear: 0.17669861018658 nn.Linear: 0.29038745164871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023823649837684 nn.Linear: 0.0011827258883221 nn.Linear: 0.00067301710898589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028691672570265 nn.Linear: 0.0034238349155492] nn.Sequential: [nn.Linear: 0.00029471758495357 nn.Linear: 0.0024767369211406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018783299252391 nn.Linear: 0.018181767314672 nn.Linear: 0.0135040236637 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019743086770177 nn.Linear: 0.041028026491404] nn.Sequential: [nn.Linear: 0.0149260237813 nn.Linear: 0.025646578520536]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062776834533139 nn.Linear: 0.0659612859173 nn.Linear: 0.045581027101998 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031567491353263 nn.Linear: 0.056749319601522] nn.Sequential: [nn.Linear: 0.031495800505543 nn.Linear: 0.037397335048331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54571551084518 nn.Linear: 0.27738305926323 nn.Linear: 0.22959080338478 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38216891884804 nn.Linear: 0.61768001317978] nn.Sequential: [nn.Linear: 0.17666445672512 nn.Linear: 0.2909052670002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093280465933739 nn.Linear: 0.00050433502610553 nn.Linear: 0.0003031452029258 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014476763680328 nn.Linear: 0.0019753387886954] nn.Sequential: [nn.Linear: 0.00012259651363597 nn.Linear: 0.0010329340162366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059949569404125 nn.Linear: 0.0080694491043687 nn.Linear: 0.0042948299087584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0055698473006487 nn.Linear: 0.011786174029112] nn.Sequential: [nn.Linear: 0.0038940359372646 nn.Linear: 0.013640224002302]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062777836896493 nn.Linear: 0.065962073868095 nn.Linear: 0.045582176838025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031567772953906 nn.Linear: 0.056754557020668] nn.Sequential: [nn.Linear: 0.031495450987618 nn.Linear: 0.037397091477691]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54539430141449 nn.Linear: 0.27771183848381 nn.Linear: 0.22974592447281 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3825366795063 nn.Linear: 0.61830759048462] nn.Sequential: [nn.Linear: 0.1769602894783 nn.Linear: 0.29099234938622]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015251305835765 nn.Linear: 0.00081060367340368 nn.Linear: 0.00041564731315856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024455259568245 nn.Linear: 0.0035808146435485] nn.Sequential: [nn.Linear: 0.0002174453500443 nn.Linear: 0.0020649036627967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011464792303741 nn.Linear: 0.01195973996073 nn.Linear: 0.012542634271085 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012085024267435 nn.Linear: 0.023850664496422] nn.Sequential: [nn.Linear: 0.0086810206994414 nn.Linear: 0.026786552742124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062783491640201 nn.Linear: 0.065963319271923 nn.Linear: 0.045583847731775 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031568202872463 nn.Linear: 0.056785272453112] nn.Sequential: [nn.Linear: 0.031495558855569 nn.Linear: 0.037411047719788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5461038351059 nn.Linear: 0.27815797924995 nn.Linear: 0.22995641827583 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38290831446648 nn.Linear: 0.61849653720856] nn.Sequential: [nn.Linear: 0.17685011029243 nn.Linear: 0.2911921441555]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00095615187722101 nn.Linear: 0.00060556289252987 nn.Linear: 0.00030186578644495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012761528178326 nn.Linear: 0.0014930294605013] nn.Sequential: [nn.Linear: 0.00013676868915842 nn.Linear: 0.001058557685264]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0058334465138614 nn.Linear: 0.008088631555438 nn.Linear: 0.0083168428391218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0062293284572661 nn.Linear: 0.010960156098008] nn.Sequential: [nn.Linear: 0.0051021748222411 nn.Linear: 0.0085868891328573]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062790773569868 nn.Linear: 0.065971312594271 nn.Linear: 0.045586277553555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031568516342889 nn.Linear: 0.05679508359492] nn.Sequential: [nn.Linear: 0.031496113948273 nn.Linear: 0.037425503201733]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54629009962082 nn.Linear: 0.27855914831161 nn.Linear: 0.2305028885603 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38337537646294 nn.Linear: 0.61912447214127] nn.Sequential: [nn.Linear: 0.177101790905 nn.Linear: 0.29124680161476]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013940037598562 nn.Linear: 0.00082920997167925 nn.Linear: 0.00039287194033032 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021442479917847 nn.Linear: 0.0029511741478194] nn.Sequential: [nn.Linear: 0.00018713118556686 nn.Linear: 0.0014504403491534]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088981268927455 nn.Linear: 0.010038324631751 nn.Linear: 0.0096269883215427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093133887276053 nn.Linear: 0.020409258082509] nn.Sequential: [nn.Linear: 0.010058993473649 nn.Linear: 0.020771350711584]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062793153916551 nn.Linear: 0.065976406535315 nn.Linear: 0.045588169228758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031568880521834 nn.Linear: 0.056851080694344] nn.Sequential: [nn.Linear: 0.031496263166407 nn.Linear: 0.037426605937763]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54655110836029 nn.Linear: 0.27894780039787 nn.Linear: 0.23060193657875 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38370785117149 nn.Linear: 0.62015682458878] nn.Sequential: [nn.Linear: 0.1768836081028 nn.Linear: 0.29154789447784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022304986102115 nn.Linear: 0.0013594634880772 nn.Linear: 0.00065505458982589 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026309756803837 nn.Linear: 0.0024588490641611] nn.Sequential: [nn.Linear: 0.00026368911676572 nn.Linear: 0.0018630694850165]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014821819029748 nn.Linear: 0.017718750983477 nn.Linear: 0.012170013971627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011179964989424 nn.Linear: 0.017706265673041] nn.Sequential: [nn.Linear: 0.0088399723172188 nn.Linear: 0.015592930838466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062797244263597 nn.Linear: 0.065977664219027 nn.Linear: 0.045589925532427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031569015700255 nn.Linear: 0.056865712075478] nn.Sequential: [nn.Linear: 0.031496386020993 nn.Linear: 0.037434902832673]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54612690210342 nn.Linear: 0.27876597642899 nn.Linear: 0.23058338463306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38416111469269 nn.Linear: 0.62085473537445] nn.Sequential: [nn.Linear: 0.17747408151627 nn.Linear: 0.29185780882835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018411933808776 nn.Linear: 0.00082981506231594 nn.Linear: 0.00038323544290939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017267315642876 nn.Linear: 0.0021370365403199] nn.Sequential: [nn.Linear: 0.00011469420588143 nn.Linear: 0.00075261798772383]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017211930826306 nn.Linear: 0.0128791667521 nn.Linear: 0.013157989829779 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014724801294506 nn.Linear: 0.015199257992208] nn.Sequential: [nn.Linear: 0.0032356751617044 nn.Linear: 0.0055069359950721]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062794304269461 nn.Linear: 0.065981784141725 nn.Linear: 0.045590711105556 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031569238054078 nn.Linear: 0.056899039306899] nn.Sequential: [nn.Linear: 0.031496508655113 nn.Linear: 0.037441360948363]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54657429456711 nn.Linear: 0.27893307805061 nn.Linear: 0.23101581633091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38456550240517 nn.Linear: 0.62137126922607] nn.Sequential: [nn.Linear: 0.17778836190701 nn.Linear: 0.29222971200943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017834798106584 nn.Linear: 0.00087977948337 nn.Linear: 0.00046187752704886 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019032083387198 nn.Linear: 0.0022135989250557] nn.Sequential: [nn.Linear: 0.00015726800396092 nn.Linear: 0.0010208019165884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012946606613696 nn.Linear: 0.013361188583076 nn.Linear: 0.0091082816943526 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016140563413501 nn.Linear: 0.017873072996736] nn.Sequential: [nn.Linear: 0.0053957938216627 nn.Linear: 0.010543190874159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062789771107834 nn.Linear: 0.065983670835981 nn.Linear: 0.045591427063164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031569509786374 nn.Linear: 0.056898601640796] nn.Sequential: [nn.Linear: 0.031496874307696 nn.Linear: 0.037462156172211]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54678517580032 nn.Linear: 0.27893802523613 nn.Linear: 0.23144094645977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38458329439163 nn.Linear: 0.62165999412537] nn.Sequential: [nn.Linear: 0.17807354032993 nn.Linear: 0.29229882359505]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010384433877626 nn.Linear: 0.00069018368205568 nn.Linear: 0.00039962038698425 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021667426945961 nn.Linear: 0.0030120945608305] nn.Sequential: [nn.Linear: 0.00014352614419201 nn.Linear: 0.0010170715688314]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095852576196194 nn.Linear: 0.010221900418401 nn.Linear: 0.007528624497354 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082574719563127 nn.Linear: 0.014784944243729] nn.Sequential: [nn.Linear: 0.0049679195508361 nn.Linear: 0.0099394386634231]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062786056567981 nn.Linear: 0.065985347807762 nn.Linear: 0.04559208809034 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031569386576084 nn.Linear: 0.056872731831788] nn.Sequential: [nn.Linear: 0.031497057849593 nn.Linear: 0.037471344713406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54663294553757 nn.Linear: 0.27899968624115 nn.Linear: 0.23178368806839 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38496914505959 nn.Linear: 0.62175786495209] nn.Sequential: [nn.Linear: 0.17803686857224 nn.Linear: 0.29241675138474]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025406586170115 nn.Linear: 0.0011480845369811 nn.Linear: 0.00052986272343141 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000190058932787 nn.Linear: 0.0021987493422558] nn.Sequential: [nn.Linear: 0.00016019641600711 nn.Linear: 0.00098527855436933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019930344074965 nn.Linear: 0.022243382409215 nn.Linear: 0.011066574603319 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012161429971457 nn.Linear: 0.021675426512957] nn.Sequential: [nn.Linear: 0.0087322071194649 nn.Linear: 0.017671138048172]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06278936038906 nn.Linear: 0.065990791827042 nn.Linear: 0.045593824760538 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031569787485335 nn.Linear: 0.056904240553436] nn.Sequential: [nn.Linear: 0.031497423820936 nn.Linear: 0.037470681821874]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54740798473358 nn.Linear: 0.27860587835312 nn.Linear: 0.23235087096691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38535830378532 nn.Linear: 0.62220776081085] nn.Sequential: [nn.Linear: 0.17784067988396 nn.Linear: 0.2927009165287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011460616155966 nn.Linear: 0.00085093136798751 nn.Linear: 0.00049749151904064 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023501771216138 nn.Linear: 0.0030605279122398] nn.Sequential: [nn.Linear: 0.00018628022691059 nn.Linear: 0.0014197931774139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012227514758706 nn.Linear: 0.011150347068906 nn.Linear: 0.010810193605721 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010549388825893 nn.Linear: 0.023607896640897] nn.Sequential: [nn.Linear: 0.0062550804577768 nn.Linear: 0.015975773334503]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062784604372116 nn.Linear: 0.065995639165134 nn.Linear: 0.045595886783119 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031570202032172 nn.Linear: 0.056917595504274] nn.Sequential: [nn.Linear: 0.031497647726583 nn.Linear: 0.037479393607917]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54817092418671 nn.Linear: 0.27860099077225 nn.Linear: 0.23260293900967 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38604500889778 nn.Linear: 0.62252420186996] nn.Sequential: [nn.Linear: 0.17790596187115 nn.Linear: 0.29266884922981]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027774580115574 nn.Linear: 0.0012567943544348 nn.Linear: 0.00051776738082712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001960241194299 nn.Linear: 0.0021901737734023] nn.Sequential: [nn.Linear: 0.00021777353287759 nn.Linear: 0.0018403138596164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019795451313257 nn.Linear: 0.017881203442812 nn.Linear: 0.011276658624411 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015936400741339 nn.Linear: 0.017068643122911] nn.Sequential: [nn.Linear: 0.013149969279766 nn.Linear: 0.027222158387303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062786159655802 nn.Linear: 0.06599989820411 nn.Linear: 0.045597632035303 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031570655912775 nn.Linear: 0.056933265256788] nn.Sequential: [nn.Linear: 0.031497899234582 nn.Linear: 0.037493923422041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54802215099335 nn.Linear: 0.27892369031906 nn.Linear: 0.23281908035278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38650956749916 nn.Linear: 0.62334764003754] nn.Sequential: [nn.Linear: 0.17786875367165 nn.Linear: 0.29304993152618]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001197626221069 nn.Linear: 0.00078480398070059 nn.Linear: 0.00037367812962754 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015856031129769 nn.Linear: 0.0018267057678831] nn.Sequential: [nn.Linear: 0.00016535053108565 nn.Linear: 0.0013587983215241]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007902248762548 nn.Linear: 0.0090794898569584 nn.Linear: 0.0075087305158377 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010196698829532 nn.Linear: 0.013423537835479] nn.Sequential: [nn.Linear: 0.0072616953402758 nn.Linear: 0.017025360837579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062782744420289 nn.Linear: 0.066007636019656 nn.Linear: 0.04560090435752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03157109946913 nn.Linear: 0.056962753497942] nn.Sequential: [nn.Linear: 0.031498196563649 nn.Linear: 0.037512952391246]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54794317483902 nn.Linear: 0.27961996197701 nn.Linear: 0.23265404999256 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38669362664223 nn.Linear: 0.62365353107452] nn.Sequential: [nn.Linear: 0.17819614708424 nn.Linear: 0.29317161440849]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018665494025044 nn.Linear: 0.0010308702074777 nn.Linear: 0.00048082219587861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019359636243775 nn.Linear: 0.0018984112367948] nn.Sequential: [nn.Linear: 0.00019713765998633 nn.Linear: 0.0011867613413367]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011358256451786 nn.Linear: 0.012483853846788 nn.Linear: 0.009208238683641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086645884439349 nn.Linear: 0.016059268265963] nn.Sequential: [nn.Linear: 0.0058027221821249 nn.Linear: 0.012018818408251]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062781681643751 nn.Linear: 0.066011492291963 nn.Linear: 0.045602221957512 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031571606621744 nn.Linear: 0.057012165333504] nn.Sequential: [nn.Linear: 0.031498251428643 nn.Linear: 0.037520864478811]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54827499389648 nn.Linear: 0.27961957454681 nn.Linear: 0.23276379704475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38703349232674 nn.Linear: 0.6242481470108] nn.Sequential: [nn.Linear: 0.17852440476418 nn.Linear: 0.29365199804306]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026467383327238 nn.Linear: 0.0017347904667197 nn.Linear: 0.00090922753972858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0003199087500223 nn.Linear: 0.0036438089360082] nn.Sequential: [nn.Linear: 0.00034325963619756 nn.Linear: 0.0025673505154869]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.023637527599931 nn.Linear: 0.037834879010916 nn.Linear: 0.026863601058722 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.026778940111399 nn.Linear: 0.027550730854273] nn.Sequential: [nn.Linear: 0.016072973608971 nn.Linear: 0.029890025034547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062780975249154 nn.Linear: 0.066013345966309 nn.Linear: 0.045602786079984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031571938511217 nn.Linear: 0.057043101435283] nn.Sequential: [nn.Linear: 0.031498089745412 nn.Linear: 0.037518087443679]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54794412851334 nn.Linear: 0.27954745292664 nn.Linear: 0.23303246498108 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38712790608406 nn.Linear: 0.62468940019608] nn.Sequential: [nn.Linear: 0.17904940247536 nn.Linear: 0.29357078671455]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00062686737939291 nn.Linear: 0.00035367154392802 nn.Linear: 0.00018585165507157 nn.ConcatTable: [nn.Sequential: [nn.Linear: 8.4152878907254e-05 nn.Linear: 0.00091568322132352] nn.Sequential: [nn.Linear: 7.796239680639e-05 nn.Linear: 0.00056027656584017]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0041916575282812 nn.Linear: 0.0053735710680485 nn.Linear: 0.0042874049395323 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0035102451220155 nn.Linear: 0.0074325948953629] nn.Sequential: [nn.Linear: 0.0056369197554886 nn.Linear: 0.0064868130721152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062784662009152 nn.Linear: 0.066020682761955 nn.Linear: 0.045604133761804 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031572391619317 nn.Linear: 0.057066740656865] nn.Sequential: [nn.Linear: 0.031498285643232 nn.Linear: 0.037527445170496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54855382442474 nn.Linear: 0.27960991859436 nn.Linear: 0.23353241384029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38743302226067 nn.Linear: 0.6257518529892] nn.Sequential: [nn.Linear: 0.17948067188263 nn.Linear: 0.29406324028969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022732755093786 nn.Linear: 0.0010389289772913 nn.Linear: 0.00041890094597218 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015840571526115 nn.Linear: 0.0018396954098545] nn.Sequential: [nn.Linear: 0.00011435235520194 nn.Linear: 0.00072534697774201]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.021278439089656 nn.Linear: 0.017195075750351 nn.Linear: 0.013984466902912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016523689031601 nn.Linear: 0.015262839384377] nn.Sequential: [nn.Linear: 0.0074798371642828 nn.Linear: 0.0065241982229054]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062786005538901 nn.Linear: 0.066022181923875 nn.Linear: 0.045605165801194 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031572354266665 nn.Linear: 0.057049512119534] nn.Sequential: [nn.Linear: 0.03149855364761 nn.Linear: 0.037536827863498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5486478805542 nn.Linear: 0.27981135249138 nn.Linear: 0.23411731421947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38798868656158 nn.Linear: 0.6261927485466] nn.Sequential: [nn.Linear: 0.17971193790436 nn.Linear: 0.2942436337471]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022994171850641 nn.Linear: 0.0013391772864504 nn.Linear: 0.00067326958549115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023768389261313 nn.Linear: 0.0027401825809026] nn.Sequential: [nn.Linear: 0.00019263013085254 nn.Linear: 0.0014274084107893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.026313195005059 nn.Linear: 0.018797606229782 nn.Linear: 0.027677308768034 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.040207520127296 nn.Linear: 0.01769501157105] nn.Sequential: [nn.Linear: 0.014185902662575 nn.Linear: 0.020278420299292]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062789657283252 nn.Linear: 0.066022063195743 nn.Linear: 0.045607463394983 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031572538449023 nn.Linear: 0.057060425898612] nn.Sequential: [nn.Linear: 0.031498806325677 nn.Linear: 0.037553017270658]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54906183481216 nn.Linear: 0.27982857823372 nn.Linear: 0.23436224460602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38853168487549 nn.Linear: 0.6269274353981] nn.Sequential: [nn.Linear: 0.17982850968838 nn.Linear: 0.294423609972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0052786632210651 nn.Linear: 0.002873900529693 nn.Linear: 0.0013666667537302 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00046222088148652 nn.Linear: 0.0054889839181539] nn.Sequential: [nn.Linear: 0.00043065369473624 nn.Linear: 0.0031572482513116]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.050683163106441 nn.Linear: 0.083231955766678 nn.Linear: 0.04957402870059 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.043337110430002 nn.Linear: 0.049400385469198] nn.Sequential: [nn.Linear: 0.03114034794271 nn.Linear: 0.046978201717138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.083248074144125	TD error	0.016003083176911	Qmax	1	

Steps: 10750000 (frames: 43000000), score: 1927.56, higheset score: 6804, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1841fps, testing time: 88s, testing rate: 5643fps,  num. ep.: 369,  num. rewards: 16904	
   2    8    2    4
   8   64  128   16
   4   32  512    2
   2    4    8  256
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062787023288043 nn.Linear: 0.066023115723879 nn.Linear: 0.045607575654394 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031572567970727 nn.Linear: 0.057065112126111] nn.Sequential: [nn.Linear: 0.031498929953916 nn.Linear: 0.037554886044495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54951167106628 nn.Linear: 0.27980560064316 nn.Linear: 0.23443655669689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38913887739182 nn.Linear: 0.62722039222717] nn.Sequential: [nn.Linear: 0.17981676757336 nn.Linear: 0.29482394456863]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019098951794573 nn.Linear: 0.00094658469354102 nn.Linear: 0.00045230594958704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022376339518494 nn.Linear: 0.0028449385862056] nn.Sequential: [nn.Linear: 0.00017957919857874 nn.Linear: 0.0013663777828244]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014225135557353 nn.Linear: 0.01449435763061 nn.Linear: 0.014386644586921 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020686123520136 nn.Linear: 0.030693415552378] nn.Sequential: [nn.Linear: 0.0080572115257382 nn.Linear: 0.012801231816411]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062789311965826 nn.Linear: 0.066026271682342 nn.Linear: 0.045608943330643 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031572601792819 nn.Linear: 0.057095087046623] nn.Sequential: [nn.Linear: 0.031499116105546 nn.Linear: 0.03757803795766]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54864090681076 nn.Linear: 0.28019016981125 nn.Linear: 0.23486845195293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.38966247439384 nn.Linear: 0.62747550010681] nn.Sequential: [nn.Linear: 0.18037977814674 nn.Linear: 0.29489558935165]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020494572339903 nn.Linear: 0.00098040522917717 nn.Linear: 0.00047693470385714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022901457080473 nn.Linear: 0.0025826271374312] nn.Sequential: [nn.Linear: 0.00020323286071683 nn.Linear: 0.0014536784946712]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01151449419558 nn.Linear: 0.016353199258447 nn.Linear: 0.01450966950506 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024886501953006 nn.Linear: 0.021032970398664] nn.Sequential: [nn.Linear: 0.019147457554936 nn.Linear: 0.014114963822067]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062797642547655 nn.Linear: 0.066029898993844 nn.Linear: 0.045609868490275 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03157290509851 nn.Linear: 0.057083289225957] nn.Sequential: [nn.Linear: 0.031499110899983 nn.Linear: 0.037573886834222]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54917860031128 nn.Linear: 0.27971050143242 nn.Linear: 0.23510213196278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39000794291496 nn.Linear: 0.6275252699852] nn.Sequential: [nn.Linear: 0.18039189279079 nn.Linear: 0.29501643776894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0036607854671566 nn.Linear: 0.0020590215086844 nn.Linear: 0.0010495770675763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00055694765216383 nn.Linear: 0.0089591144495871] nn.Sequential: [nn.Linear: 0.00050501077495051 nn.Linear: 0.0043615295269161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024439200758934 nn.Linear: 0.029737142845988 nn.Linear: 0.023666447028518 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.030077587813139 nn.Linear: 0.060486927628517] nn.Sequential: [nn.Linear: 0.014969147741795 nn.Linear: 0.045924492180347]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062810085184741 nn.Linear: 0.066042020483648 nn.Linear: 0.045612604084941 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03157346932801 nn.Linear: 0.057155677238939] nn.Sequential: [nn.Linear: 0.031499544410471 nn.Linear: 0.037586271434109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.54936724901199 nn.Linear: 0.28002575039864 nn.Linear: 0.23561128973961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39025005698204 nn.Linear: 0.62833374738693] nn.Sequential: [nn.Linear: 0.18031798303127 nn.Linear: 0.29535445570946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0041751535281741 nn.Linear: 0.0026931406398631 nn.Linear: 0.0010960970253738 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00037733594110607 nn.Linear: 0.005053604369022] nn.Sequential: [nn.Linear: 0.00039499955002208 nn.Linear: 0.003387838969233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.041235070675611 nn.Linear: 0.055928837507963 nn.Linear: 0.056227188557386 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024844625964761 nn.Linear: 0.051026679575443] nn.Sequential: [nn.Linear: 0.017578735947609 nn.Linear: 0.053789794445038]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062808753862923 nn.Linear: 0.066045299634833 nn.Linear: 0.045614611743211 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031574048328226 nn.Linear: 0.057197695472922] nn.Sequential: [nn.Linear: 0.031499896339422 nn.Linear: 0.037621483476655]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55052495002747 nn.Linear: 0.27995786070824 nn.Linear: 0.23587895929813 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39083075523376 nn.Linear: 0.62877535820007] nn.Sequential: [nn.Linear: 0.18084347248077 nn.Linear: 0.2956779897213]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013107260350206 nn.Linear: 0.0007451190012821 nn.Linear: 0.00040916698489338 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018964567281901 nn.Linear: 0.0020895885011853] nn.Sequential: [nn.Linear: 0.00018647822275478 nn.Linear: 0.0013929147205318]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011264164932072 nn.Linear: 0.011601835489273 nn.Linear: 0.0096063679084182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079964604228735 nn.Linear: 0.021119054406881] nn.Sequential: [nn.Linear: 0.0069326241500676 nn.Linear: 0.011771705932915]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062817054664435 nn.Linear: 0.066047243557816 nn.Linear: 0.045616589439752 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031574273378472 nn.Linear: 0.057229318099871] nn.Sequential: [nn.Linear: 0.031500084077029 nn.Linear: 0.03761347859394]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55122065544128 nn.Linear: 0.28009426593781 nn.Linear: 0.23587635159492 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3912760913372 nn.Linear: 0.62936466932297] nn.Sequential: [nn.Linear: 0.18138752877712 nn.Linear: 0.29595425724983]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0027006469707038 nn.Linear: 0.0013074536155935 nn.Linear: 0.00061465434730064 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025317030345136 nn.Linear: 0.0024512980384451] nn.Sequential: [nn.Linear: 0.00022590751531516 nn.Linear: 0.0015723534289962]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.02475549839437 nn.Linear: 0.020259024575353 nn.Linear: 0.022535346448421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012939085252583 nn.Linear: 0.014196287840605] nn.Sequential: [nn.Linear: 0.0078631360083818 nn.Linear: 0.014995638281107]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062811914328501 nn.Linear: 0.066050082505317 nn.Linear: 0.045616968274901 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031574595068389 nn.Linear: 0.057271603130999] nn.Sequential: [nn.Linear: 0.031500056190902 nn.Linear: 0.037628354194035]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55179738998413 nn.Linear: 0.28025883436203 nn.Linear: 0.23658257722855 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39176812767982 nn.Linear: 0.63015693426132] nn.Sequential: [nn.Linear: 0.18201339244843 nn.Linear: 0.29603058099747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018342935461727 nn.Linear: 0.00091332318922017 nn.Linear: 0.00039725295903619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014273864696157 nn.Linear: 0.0014726418609649] nn.Sequential: [nn.Linear: 0.00017399596262738 nn.Linear: 0.0012569141949881]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011657915078104 nn.Linear: 0.01146636530757 nn.Linear: 0.013201639987528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0084437346085906 nn.Linear: 0.0087899873033166] nn.Sequential: [nn.Linear: 0.0058910869993269 nn.Linear: 0.018294999375939]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062802079288255 nn.Linear: 0.066055648687791 nn.Linear: 0.045618482555182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031575028273868 nn.Linear: 0.057285139833681] nn.Sequential: [nn.Linear: 0.031500317275784 nn.Linear: 0.037652526114897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55254209041595 nn.Linear: 0.2803692817688 nn.Linear: 0.23669858276844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39189669489861 nn.Linear: 0.63091671466827] nn.Sequential: [nn.Linear: 0.18200725317001 nn.Linear: 0.2962261736393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028881715177177 nn.Linear: 0.0022503941833268 nn.Linear: 0.0010604002254353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00040165719770415 nn.Linear: 0.0046659106035323] nn.Sequential: [nn.Linear: 0.00034244468783805 nn.Linear: 0.0027762182360138]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.022422760725021 nn.Linear: 0.055187910795212 nn.Linear: 0.027146030217409 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.029306419193745 nn.Linear: 0.035515215247869] nn.Sequential: [nn.Linear: 0.013986027799547 nn.Linear: 0.037160698324442]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062794566238705 nn.Linear: 0.066056919084539 nn.Linear: 0.045619855324782 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031575044209548 nn.Linear: 0.057273019208878] nn.Sequential: [nn.Linear: 0.03150055206106 nn.Linear: 0.037641798284553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55325043201447 nn.Linear: 0.28037002682686 nn.Linear: 0.23695129156113 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39221185445786 nn.Linear: 0.63134723901749] nn.Sequential: [nn.Linear: 0.18222993612289 nn.Linear: 0.29650381207466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012689192366748 nn.Linear: 0.00066170072846956 nn.Linear: 0.00037518626078087 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018790657906956 nn.Linear: 0.0021879945460183] nn.Sequential: [nn.Linear: 0.00017992406387209 nn.Linear: 0.0015894148970617]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080874497070909 nn.Linear: 0.011663470417261 nn.Linear: 0.009548569098115 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014994126744568 nn.Linear: 0.021499840542674] nn.Sequential: [nn.Linear: 0.0096265375614166 nn.Linear: 0.018842997029424]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062794280689719 nn.Linear: 0.066060461153279 nn.Linear: 0.04562129642711 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031575250747736 nn.Linear: 0.057275844316507] nn.Sequential: [nn.Linear: 0.031501207427767 nn.Linear: 0.037655901303604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55264258384705 nn.Linear: 0.28040584921837 nn.Linear: 0.23719197511673 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39230605959892 nn.Linear: 0.63182324171066] nn.Sequential: [nn.Linear: 0.18180963397026 nn.Linear: 0.2966742515564]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013144522528328 nn.Linear: 0.00070963824096116 nn.Linear: 0.00037133401480532 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018714813005141 nn.Linear: 0.002106008795962] nn.Sequential: [nn.Linear: 0.00016066580015779 nn.Linear: 0.0011482385060612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008970744907856 nn.Linear: 0.010885910131037 nn.Linear: 0.014821810647845 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011514526791871 nn.Linear: 0.014912712387741] nn.Sequential: [nn.Linear: 0.0089629674330354 nn.Linear: 0.013861532323062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062801170143342 nn.Linear: 0.066062361904741 nn.Linear: 0.045622004476168 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031575521909178 nn.Linear: 0.057299225927878] nn.Sequential: [nn.Linear: 0.031500747665345 nn.Linear: 0.037650653933142]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55242735147476 nn.Linear: 0.28049391508102 nn.Linear: 0.23697926104069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39284095168114 nn.Linear: 0.63214915990829] nn.Sequential: [nn.Linear: 0.18189863860607 nn.Linear: 0.29663574695587]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011632676934953 nn.Linear: 0.00066139187254314 nn.Linear: 0.00036993247625086 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015919620078986 nn.Linear: 0.001709389159553] nn.Sequential: [nn.Linear: 0.00016696031640717 nn.Linear: 0.0011132900251845]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092061692848802 nn.Linear: 0.0087398225441575 nn.Linear: 0.0094895120710135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015803260728717 nn.Linear: 0.011112790554762] nn.Sequential: [nn.Linear: 0.0065812785178423 nn.Linear: 0.011089288629591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062809698833687 nn.Linear: 0.066066479785757 nn.Linear: 0.045623640790184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031575875001546 nn.Linear: 0.057331367509107] nn.Sequential: [nn.Linear: 0.031501020596104 nn.Linear: 0.037666491303093]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55267041921616 nn.Linear: 0.2803056538105 nn.Linear: 0.23701436817646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39322748780251 nn.Linear: 0.63248467445374] nn.Sequential: [nn.Linear: 0.18202808499336 nn.Linear: 0.29663181304932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013612416890602 nn.Linear: 0.00075054164145215 nn.Linear: 0.00039355234957596 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022235729290469 nn.Linear: 0.003134616899581] nn.Sequential: [nn.Linear: 0.00019523686762901 nn.Linear: 0.0015156102096773]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086040059104562 nn.Linear: 0.0095768393948674 nn.Linear: 0.0088343899697065 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017681587487459 nn.Linear: 0.025658078491688] nn.Sequential: [nn.Linear: 0.012452482245862 nn.Linear: 0.015749752521515]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	10880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062809685531416 nn.Linear: 0.066067787715243 nn.Linear: 0.045625484656339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031576135624193 nn.Linear: 0.057338506686023] nn.Sequential: [nn.Linear: 0.031501127046484 nn.Linear: 0.037676692738521]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55314183235168 nn.Linear: 0.28031793236732 nn.Linear: 0.23735603690147 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39367404580116 nn.Linear: 0.63304680585861] nn.Sequential: [nn.Linear: 0.18206015229225 nn.Linear: 0.29709428548813]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015326155551897 nn.Linear: 0.00090053852851333 nn.Linear: 0.00043699217298667 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018268623485092 nn.Linear: 0.0019548816609101] nn.Sequential: [nn.Linear: 0.00017886646024009 nn.Linear: 0.0014123915506356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092801544815302 nn.Linear: 0.011383974924684 nn.Linear: 0.0090716909617186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017165433615446 nn.Linear: 0.016730032861233] nn.Sequential: [nn.Linear: 0.0095266737043858 nn.Linear: 0.015888337045908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06280263501468 nn.Linear: 0.06607452743905 nn.Linear: 0.045628190955864 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03157648130104 nn.Linear: 0.057385571546064] nn.Sequential: [nn.Linear: 0.031501481812397 nn.Linear: 0.037683831661816]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55313062667847 nn.Linear: 0.28067123889923 nn.Linear: 0.23770843446255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.3941944539547 nn.Linear: 0.63380819559097] nn.Sequential: [nn.Linear: 0.18240247666836 nn.Linear: 0.29756081104279]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024874163518658 nn.Linear: 0.001796901957286 nn.Linear: 0.00091681210418969 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00038287774624639 nn.Linear: 0.0042982287573423] nn.Sequential: [nn.Linear: 0.00031862682863866 nn.Linear: 0.0025708717150478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014897536486387 nn.Linear: 0.026526609435678 nn.Linear: 0.02616080455482 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031683377921581 nn.Linear: 0.052480183541775] nn.Sequential: [nn.Linear: 0.016104614362121 nn.Linear: 0.034818176180124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062811098856791 nn.Linear: 0.066078862659504 nn.Linear: 0.0456297778756 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031576912221371 nn.Linear: 0.057408255383393] nn.Sequential: [nn.Linear: 0.031501625185766 nn.Linear: 0.03768904872101]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55329740047455 nn.Linear: 0.2806262075901 nn.Linear: 0.23802536725998 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39459735155106 nn.Linear: 0.6344193816185] nn.Sequential: [nn.Linear: 0.18287143111229 nn.Linear: 0.2980340719223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013496116220414 nn.Linear: 0.00071092531923852 nn.Linear: 0.00041317966559173 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023700828074922 nn.Linear: 0.0032870314942168] nn.Sequential: [nn.Linear: 0.00016110302408575 nn.Linear: 0.00099030087199847]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01244046818465 nn.Linear: 0.011503008194268 nn.Linear: 0.011972211301327 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012286422774196 nn.Linear: 0.02766745723784] nn.Sequential: [nn.Linear: 0.0046495427377522 nn.Linear: 0.0097843948751688]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062812896483649 nn.Linear: 0.066078871670748 nn.Linear: 0.045630261788617 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031577025557919 nn.Linear: 0.057424524057069] nn.Sequential: [nn.Linear: 0.031501561240471 nn.Linear: 0.037690669199494]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55294382572174 nn.Linear: 0.28148612380028 nn.Linear: 0.23828165233135 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39492753148079 nn.Linear: 0.6346846818924] nn.Sequential: [nn.Linear: 0.18303605914116 nn.Linear: 0.29810112714767]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001421232733084 nn.Linear: 0.00083190290213433 nn.Linear: 0.0004579678839435 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024800748546691 nn.Linear: 0.0032266658453241] nn.Sequential: [nn.Linear: 0.00021450609688015 nn.Linear: 0.0016319022176731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010766629129648 nn.Linear: 0.010202025994658 nn.Linear: 0.0083780195564032 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012511158362031 nn.Linear: 0.021364446729422] nn.Sequential: [nn.Linear: 0.0069275796413422 nn.Linear: 0.016711512580514]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062812549113233 nn.Linear: 0.066081682055338 nn.Linear: 0.045630563827339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031576904066036 nn.Linear: 0.057411773706008] nn.Sequential: [nn.Linear: 0.031501719152117 nn.Linear: 0.037691096194106]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55269986391068 nn.Linear: 0.28135403990746 nn.Linear: 0.2389745414257 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39558383822441 nn.Linear: 0.63581544160843] nn.Sequential: [nn.Linear: 0.18329440057278 nn.Linear: 0.29862973093987]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088720368535805 nn.Linear: 0.00056470047534259 nn.Linear: 0.00029771729650505 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016948393646663 nn.Linear: 0.002286188387346] nn.Sequential: [nn.Linear: 0.00011277201279568 nn.Linear: 0.00075829834481418]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059796110726893 nn.Linear: 0.0092282891273499 nn.Linear: 0.0054542142897844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0079870875924826 nn.Linear: 0.01639542914927] nn.Sequential: [nn.Linear: 0.0085794497281313 nn.Linear: 0.0064313858747482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062814535001094 nn.Linear: 0.066083002601367 nn.Linear: 0.045631610561545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031576988161458 nn.Linear: 0.057415587830121] nn.Sequential: [nn.Linear: 0.03150183205214 nn.Linear: 0.037692453073143]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5530281662941 nn.Linear: 0.28164690732956 nn.Linear: 0.23914700746536 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39607813954353 nn.Linear: 0.63628953695297] nn.Sequential: [nn.Linear: 0.18353988230228 nn.Linear: 0.29871580004692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017777446690503 nn.Linear: 0.00091972263019364 nn.Linear: 0.00051489858985693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029896909023665 nn.Linear: 0.0045217528572312] nn.Sequential: [nn.Linear: 0.00017528928221121 nn.Linear: 0.0014705438788522]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010702974162996 nn.Linear: 0.010962263680995 nn.Linear: 0.020332504063845 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014120545238256 nn.Linear: 0.029381696134806] nn.Sequential: [nn.Linear: 0.0065789208747447 nn.Linear: 0.015476765111089]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062826061808424 nn.Linear: 0.066088550661767 nn.Linear: 0.045633308210786 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031577546775218 nn.Linear: 0.057476024517996] nn.Sequential: [nn.Linear: 0.031502034960013 nn.Linear: 0.037715210331933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55256879329681 nn.Linear: 0.28125154972076 nn.Linear: 0.23940235376358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39644050598145 nn.Linear: 0.63697075843811] nn.Sequential: [nn.Linear: 0.18365123867989 nn.Linear: 0.29902529716492]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018973295633936 nn.Linear: 0.00097716327403856 nn.Linear: 0.00049755579010481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018802163225907 nn.Linear: 0.0020738508419509] nn.Sequential: [nn.Linear: 0.00022187269789354 nn.Linear: 0.0019304551590381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013174084015191 nn.Linear: 0.013184960000217 nn.Linear: 0.0075556570664048 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010778252966702 nn.Linear: 0.012348630465567] nn.Sequential: [nn.Linear: 0.0076192487031221 nn.Linear: 0.018193231895566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062831962912717 nn.Linear: 0.066095394915876 nn.Linear: 0.045635855728655 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031578150902147 nn.Linear: 0.057538544127198] nn.Sequential: [nn.Linear: 0.031502482568068 nn.Linear: 0.037724691690872]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55267149209976 nn.Linear: 0.28117743134499 nn.Linear: 0.23959073424339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39706230163574 nn.Linear: 0.63762718439102] nn.Sequential: [nn.Linear: 0.18372650444508 nn.Linear: 0.29918447136879]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00079099287610657 nn.Linear: 0.00041549006540619 nn.Linear: 0.00024865543141163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011961560912089 nn.Linear: 0.0014639852967785] nn.Sequential: [nn.Linear: 0.00015571480290609 nn.Linear: 0.0013716514015892]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0049610557034612 nn.Linear: 0.0051188822835684 nn.Linear: 0.0059684300795197 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.005579502787441 nn.Linear: 0.01321633066982] nn.Sequential: [nn.Linear: 0.0064641959033906 nn.Linear: 0.012150417082012]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062824367252548 nn.Linear: 0.066095464144783 nn.Linear: 0.0456366212801 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031578300765722 nn.Linear: 0.057570175497403] nn.Sequential: [nn.Linear: 0.031502393474833 nn.Linear: 0.037725325521456]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55228930711746 nn.Linear: 0.28113022446632 nn.Linear: 0.23974102735519 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39731249213219 nn.Linear: 0.63803565502167] nn.Sequential: [nn.Linear: 0.18422128260136 nn.Linear: 0.29939699172974]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019757889862123 nn.Linear: 0.0011119198503329 nn.Linear: 0.00048197235788759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017451536252654 nn.Linear: 0.0018926542950961] nn.Sequential: [nn.Linear: 0.00023796972574747 nn.Linear: 0.0022570890703943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018330965191126 nn.Linear: 0.013329682871699 nn.Linear: 0.01315901055932 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094798132777214 nn.Linear: 0.012795445509255] nn.Sequential: [nn.Linear: 0.012078470550478 nn.Linear: 0.027270121499896]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062826653648938 nn.Linear: 0.066100833398278 nn.Linear: 0.045638281572563 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031578343663188 nn.Linear: 0.057591632370247] nn.Sequential: [nn.Linear: 0.031502561273389 nn.Linear: 0.037740173617423]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55379343032837 nn.Linear: 0.28124862909317 nn.Linear: 0.23982167243958 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39783024787903 nn.Linear: 0.63844436407089] nn.Sequential: [nn.Linear: 0.18437176942825 nn.Linear: 0.29937660694122]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011234612960276 nn.Linear: 0.00066643614455904 nn.Linear: 0.00035145602007132 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012149723209705 nn.Linear: 0.0012187452240118] nn.Sequential: [nn.Linear: 0.00014313443144169 nn.Linear: 0.0010042361846675]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0081722680479288 nn.Linear: 0.010646951384842 nn.Linear: 0.0086968382820487 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0065857614390552 nn.Linear: 0.012124629691243] nn.Sequential: [nn.Linear: 0.0050314641557634 nn.Linear: 0.011320975609124]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062828538998265 nn.Linear: 0.066102884537478 nn.Linear: 0.045639315804879 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031578508297487 nn.Linear: 0.057601167167832] nn.Sequential: [nn.Linear: 0.031502748011158 nn.Linear: 0.037746063081601]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55445516109467 nn.Linear: 0.28079560399055 nn.Linear: 0.23989503085613 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39826861023903 nn.Linear: 0.63908904790878] nn.Sequential: [nn.Linear: 0.18437805771828 nn.Linear: 0.29954990744591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00085716475688219 nn.Linear: 0.00051614585480142 nn.Linear: 0.00029733645707069 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016934558387506 nn.Linear: 0.0021810015662194] nn.Sequential: [nn.Linear: 0.00010490403242937 nn.Linear: 0.00057934836374077]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0062240576371551 nn.Linear: 0.0068296007812023 nn.Linear: 0.0057102325372398 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093456543982029 nn.Linear: 0.014576806686819] nn.Sequential: [nn.Linear: 0.0042160297743976 nn.Linear: 0.0054350271821022]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	10990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062834403810125 nn.Linear: 0.066113947637628 nn.Linear: 0.045641600037255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031578950973874 nn.Linear: 0.057676186278968] nn.Sequential: [nn.Linear: 0.031503095663574 nn.Linear: 0.037763718756267]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55442446470261 nn.Linear: 0.2811453640461 nn.Linear: 0.24020107090473 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39849323034286 nn.Linear: 0.6394670009613] nn.Sequential: [nn.Linear: 0.18438430130482 nn.Linear: 0.29983708262444]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019984118313816 nn.Linear: 0.0010113766984191 nn.Linear: 0.00049119243222531 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019680393417963 nn.Linear: 0.0022243073978494] nn.Sequential: [nn.Linear: 0.00020823972468416 nn.Linear: 0.0016769989492192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017419684678316 nn.Linear: 0.015021662227809 nn.Linear: 0.015427649952471 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019665651023388 nn.Linear: 0.01941236667335] nn.Sequential: [nn.Linear: 0.014307152479887 nn.Linear: 0.017291257157922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062839587772326 nn.Linear: 0.066120287092087 nn.Linear: 0.045642894136785 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031579427343804 nn.Linear: 0.057720088025121] nn.Sequential: [nn.Linear: 0.03150342107695 nn.Linear: 0.037771927020991]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55441957712173 nn.Linear: 0.28115579485893 nn.Linear: 0.24065940082073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39899423718452 nn.Linear: 0.63996881246567] nn.Sequential: [nn.Linear: 0.1846449226141 nn.Linear: 0.30031222105026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024477100348053 nn.Linear: 0.0011813598267006 nn.Linear: 0.00056733546799863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023246727111449 nn.Linear: 0.0023707735676612] nn.Sequential: [nn.Linear: 0.00020331220884519 nn.Linear: 0.0011918121607009]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018319614231586 nn.Linear: 0.015737682580948 nn.Linear: 0.0099142445251346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094659132882953 nn.Linear: 0.017493596300483] nn.Sequential: [nn.Linear: 0.009019810706377 nn.Linear: 0.010630776174366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.083702284902334	TD error	0.016546213775873	Qmax	1	

Steps: 11000000 (frames: 44000000), score: 1928.47, higheset score: 6732, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1839fps, testing time: 88s, testing rate: 5638fps,  num. ep.: 397,  num. rewards: 17617	
   2    4    8    2
   4    8   16    4
  16   32  128    8
   2    8  256  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062840180233586 nn.Linear: 0.066121719682303 nn.Linear: 0.045644017279077 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031579545022294 nn.Linear: 0.057716537110878] nn.Sequential: [nn.Linear: 0.031503688710789 nn.Linear: 0.037791886386544]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55370873212814 nn.Linear: 0.2810332775116 nn.Linear: 0.24112364649773 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.39907687902451 nn.Linear: 0.64045304059982] nn.Sequential: [nn.Linear: 0.18496681749821 nn.Linear: 0.30060562491417]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010143738624052 nn.Linear: 0.0004966075773416 nn.Linear: 0.00024155496024832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.8213415518245e-05 nn.Linear: 0.0010066918643361] nn.Sequential: [nn.Linear: 8.4969673053061e-05 nn.Linear: 0.00056292489829862]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0073658120818436 nn.Linear: 0.0093858195468783 nn.Linear: 0.0063233599066734 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011030729860067 nn.Linear: 0.0079055754467845] nn.Sequential: [nn.Linear: 0.002947285072878 nn.Linear: 0.0062890066765249]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06283408479445 nn.Linear: 0.066123766198526 nn.Linear: 0.045645097429079 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0315796922884 nn.Linear: 0.057717732993524] nn.Sequential: [nn.Linear: 0.031503882104961 nn.Linear: 0.037783760533488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55392932891846 nn.Linear: 0.2803638279438 nn.Linear: 0.24125789105892 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.399439483881 nn.Linear: 0.64098465442657] nn.Sequential: [nn.Linear: 0.18492944538593 nn.Linear: 0.30109032988548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010000648269795 nn.Linear: 0.00062699553531851 nn.Linear: 0.00033240881350067 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020611953587231 nn.Linear: 0.0026579048428436] nn.Sequential: [nn.Linear: 0.00011296919925688 nn.Linear: 0.00077722086486459]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063830986618996 nn.Linear: 0.0073992051184177 nn.Linear: 0.0072335540316999 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01173438783735 nn.Linear: 0.019194653257728] nn.Sequential: [nn.Linear: 0.0043084034696221 nn.Linear: 0.0069058202207088]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062843438243291 nn.Linear: 0.066129599836375 nn.Linear: 0.045647335198671 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031579978520214 nn.Linear: 0.057751666187869] nn.Sequential: [nn.Linear: 0.031504252956953 nn.Linear: 0.037812285599026]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55453985929489 nn.Linear: 0.28106766939163 nn.Linear: 0.24112442135811 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40006640553474 nn.Linear: 0.64147472381592] nn.Sequential: [nn.Linear: 0.18514151871204 nn.Linear: 0.30122768878937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012679754860529 nn.Linear: 0.00076754097008091 nn.Linear: 0.00044553267931775 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018423588020094 nn.Linear: 0.0020631472313102] nn.Sequential: [nn.Linear: 0.00017414859835961 nn.Linear: 0.0011470365603637]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01256856508553 nn.Linear: 0.0082791447639465 nn.Linear: 0.0064914640970528 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010294820182025 nn.Linear: 0.019366178661585] nn.Sequential: [nn.Linear: 0.0046040709130466 nn.Linear: 0.014411468058825]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062839109417497 nn.Linear: 0.066133253853922 nn.Linear: 0.045648030123501 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031580388891418 nn.Linear: 0.057786425118479] nn.Sequential: [nn.Linear: 0.031504412691531 nn.Linear: 0.037819233256195]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55450958013535 nn.Linear: 0.28134030103683 nn.Linear: 0.24105888605118 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4004875421524 nn.Linear: 0.64214450120926] nn.Sequential: [nn.Linear: 0.1849784553051 nn.Linear: 0.30153128504753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0022389233718583 nn.Linear: 0.0011837574734195 nn.Linear: 0.00061826797412421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029700533287915 nn.Linear: 0.0031954315784996] nn.Sequential: [nn.Linear: 0.00027748356933815 nn.Linear: 0.0019458746779783]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020352816209197 nn.Linear: 0.018100410699844 nn.Linear: 0.019790604710579 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.027407104149461 nn.Linear: 0.023045660927892] nn.Sequential: [nn.Linear: 0.014825870282948 nn.Linear: 0.018248170614243]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062849245834321 nn.Linear: 0.066140338025342 nn.Linear: 0.045650067022491 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031580729321028 nn.Linear: 0.057831708342292] nn.Sequential: [nn.Linear: 0.031504811650475 nn.Linear: 0.037819670567779]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55493712425232 nn.Linear: 0.28082537651062 nn.Linear: 0.24143920838833 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40112859010696 nn.Linear: 0.64282870292664] nn.Sequential: [nn.Linear: 0.18529251217842 nn.Linear: 0.30178779363632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0040673678506113 nn.Linear: 0.0020780531264612 nn.Linear: 0.00082397798959551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029078162801819 nn.Linear: 0.0031521325385313] nn.Sequential: [nn.Linear: 0.00019521091876312 nn.Linear: 0.0011580563245744]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027224220335484 nn.Linear: 0.025145417079329 nn.Linear: 0.018590690568089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.025312641635537 nn.Linear: 0.026330487802625] nn.Sequential: [nn.Linear: 0.01146931014955 nn.Linear: 0.010620062239468]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062841496984272 nn.Linear: 0.066141727135023 nn.Linear: 0.045651012630759 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03158070051525 nn.Linear: 0.057823345785778] nn.Sequential: [nn.Linear: 0.031504696570931 nn.Linear: 0.037834371179742]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55495589971542 nn.Linear: 0.28125530481339 nn.Linear: 0.24129097163677 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40172979235649 nn.Linear: 0.64306688308716] nn.Sequential: [nn.Linear: 0.1853264272213 nn.Linear: 0.30161735415459]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010625591567065 nn.Linear: 0.00057380745104233 nn.Linear: 0.00031409476594421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014760626884995 nn.Linear: 0.0017402240897995] nn.Sequential: [nn.Linear: 0.00011927156527454 nn.Linear: 0.00076522778561642]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0080973105505109 nn.Linear: 0.0065940110944211 nn.Linear: 0.0054588839411736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0099369678646326 nn.Linear: 0.016486518085003] nn.Sequential: [nn.Linear: 0.0048659103922546 nn.Linear: 0.0079910568892956]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062847040548571 nn.Linear: 0.066145954460964 nn.Linear: 0.045653016911255 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031581336374979 nn.Linear: 0.057878806951464] nn.Sequential: [nn.Linear: 0.031504905959964 nn.Linear: 0.03783886593136]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.555284678936 nn.Linear: 0.28127232193947 nn.Linear: 0.24209582805634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40202158689499 nn.Linear: 0.64399880170822] nn.Sequential: [nn.Linear: 0.18561673164368 nn.Linear: 0.3019825220108]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00098904362844784 nn.Linear: 0.00052353640365305 nn.Linear: 0.00029147404707386 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014283668191094 nn.Linear: 0.001765859661786] nn.Sequential: [nn.Linear: 0.00012083807799514 nn.Linear: 0.00090514775401315]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010234686546028 nn.Linear: 0.0072522996924818 nn.Linear: 0.0065095564350486 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0093652009963989 nn.Linear: 0.017856445163488] nn.Sequential: [nn.Linear: 0.0075259497389197 nn.Linear: 0.0089802304282784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062845643607235 nn.Linear: 0.066148981701253 nn.Linear: 0.045653805592993 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031581544886205 nn.Linear: 0.057917609001549] nn.Sequential: [nn.Linear: 0.031504989307621 nn.Linear: 0.037846901785342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55508929491043 nn.Linear: 0.28115478157997 nn.Linear: 0.24222809076309 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40260913968086 nn.Linear: 0.64453083276749] nn.Sequential: [nn.Linear: 0.18573486804962 nn.Linear: 0.30244329571724]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010263936180352 nn.Linear: 0.00061465018290959 nn.Linear: 0.00033871032515295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014857084614575 nn.Linear: 0.0015412024020702] nn.Sequential: [nn.Linear: 0.00012147654586369 nn.Linear: 0.0007269865996831]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0063885771669447 nn.Linear: 0.0078366743400693 nn.Linear: 0.0078453375026584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014082383364439 nn.Linear: 0.013753172010183] nn.Sequential: [nn.Linear: 0.0060671018436551 nn.Linear: 0.0081650344654918]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062845018593744 nn.Linear: 0.066150840773922 nn.Linear: 0.045654711178638 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031581748485675 nn.Linear: 0.057927058160942] nn.Sequential: [nn.Linear: 0.031505106813856 nn.Linear: 0.037851913937488]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55559414625168 nn.Linear: 0.28202211856842 nn.Linear: 0.24225088953972 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40309453010559 nn.Linear: 0.64512598514557] nn.Sequential: [nn.Linear: 0.18599964678288 nn.Linear: 0.30248358845711]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019152178019523 nn.Linear: 0.0011333531920944 nn.Linear: 0.00068725833705834 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032818558913469 nn.Linear: 0.0036500761965517] nn.Sequential: [nn.Linear: 0.00029879767132232 nn.Linear: 0.0023266744439715]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013007660396397 nn.Linear: 0.017377516254783 nn.Linear: 0.013776557520032 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016529994085431 nn.Linear: 0.024983372539282] nn.Sequential: [nn.Linear: 0.0095204226672649 nn.Linear: 0.015708671882749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062846948623831 nn.Linear: 0.066154467505001 nn.Linear: 0.045656505780748 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031582138555596 nn.Linear: 0.057982477703831] nn.Sequential: [nn.Linear: 0.031505395800088 nn.Linear: 0.037869318475237]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55573117733002 nn.Linear: 0.28203418850899 nn.Linear: 0.24234016239643 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40368285775185 nn.Linear: 0.64591580629349] nn.Sequential: [nn.Linear: 0.18624673783779 nn.Linear: 0.30285423994064]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00096592036487472 nn.Linear: 0.00064541254013285 nn.Linear: 0.0003335308244347 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014095954990119 nn.Linear: 0.0015224439417099] nn.Sequential: [nn.Linear: 0.00014344038194096 nn.Linear: 0.00089144340271784]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.00678505981341 nn.Linear: 0.0091123804450035 nn.Linear: 0.0068626906722784 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.007899303920567 nn.Linear: 0.010441809892654] nn.Sequential: [nn.Linear: 0.0049537713639438 nn.Linear: 0.0080643063411117]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062844245536362 nn.Linear: 0.066160625851828 nn.Linear: 0.045657598385463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031582653605101 nn.Linear: 0.058058636711053] nn.Sequential: [nn.Linear: 0.03150542619475 nn.Linear: 0.037884975648575]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55697011947632 nn.Linear: 0.28255066275597 nn.Linear: 0.24210384488106 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40424564480782 nn.Linear: 0.64604651927948] nn.Sequential: [nn.Linear: 0.18636824190617 nn.Linear: 0.30300423502922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010356210941774 nn.Linear: 0.00061248824155366 nn.Linear: 0.00031883150556277 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017921321759297 nn.Linear: 0.0022009214033551] nn.Sequential: [nn.Linear: 0.00015280115621407 nn.Linear: 0.0010029436823185]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0067854262888432 nn.Linear: 0.0075378050096333 nn.Linear: 0.0062918169423938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0074054733850062 nn.Linear: 0.014498538337648] nn.Sequential: [nn.Linear: 0.0081132557243109 nn.Linear: 0.0087694618850946]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062860294983085 nn.Linear: 0.066164063086132 nn.Linear: 0.04565934982874 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031583072205218 nn.Linear: 0.05808809942647] nn.Sequential: [nn.Linear: 0.031505704140323 nn.Linear: 0.03789101475523]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55695271492004 nn.Linear: 0.28290089964867 nn.Linear: 0.24230487644672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40465369820595 nn.Linear: 0.6462949514389] nn.Sequential: [nn.Linear: 0.18612191081047 nn.Linear: 0.30287033319473]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019856549590455 nn.Linear: 0.001339182247642 nn.Linear: 0.00064237175750888 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030809064283897 nn.Linear: 0.0045517855329589] nn.Sequential: [nn.Linear: 0.00021230855546599 nn.Linear: 0.001457814173881]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.017867149785161 nn.Linear: 0.033732768148184 nn.Linear: 0.012991288676858 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01905895024538 nn.Linear: 0.044741421937943] nn.Sequential: [nn.Linear: 0.0084523549303412 nn.Linear: 0.012396440841258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062851342607738 nn.Linear: 0.066167004743222 nn.Linear: 0.045660276383981 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031583077949006 nn.Linear: 0.058096264702954] nn.Sequential: [nn.Linear: 0.031505828276664 nn.Linear: 0.037898145605571]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55701667070389 nn.Linear: 0.28243342041969 nn.Linear: 0.24242807924747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40509405732155 nn.Linear: 0.64696168899536] nn.Sequential: [nn.Linear: 0.18631662428379 nn.Linear: 0.30290034413338]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001002361532884 nn.Linear: 0.00062836459250644 nn.Linear: 0.00035056293407227 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016751448526598 nn.Linear: 0.0022425856930567] nn.Sequential: [nn.Linear: 0.00015639750321361 nn.Linear: 0.001101780890945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007850150577724 nn.Linear: 0.0087549099698663 nn.Linear: 0.0059259957633913 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077699325047433 nn.Linear: 0.013773869723082] nn.Sequential: [nn.Linear: 0.0054385690018535 nn.Linear: 0.011105803772807]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062845964758086 nn.Linear: 0.066168087089428 nn.Linear: 0.045660378605234 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031583129104975 nn.Linear: 0.058068935960534] nn.Sequential: [nn.Linear: 0.031505780407805 nn.Linear: 0.037891281165214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55740493535995 nn.Linear: 0.28194013237953 nn.Linear: 0.24274097383022 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40529406070709 nn.Linear: 0.64736109972] nn.Sequential: [nn.Linear: 0.18660707771778 nn.Linear: 0.30320262908936]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.003445610690997 nn.Linear: 0.0017025259072084 nn.Linear: 0.00091329288826735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00044043236281447 nn.Linear: 0.0068437389866389] nn.Sequential: [nn.Linear: 0.0002754278049143 nn.Linear: 0.001872556868258]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.02117913402617 nn.Linear: 0.028306307271123 nn.Linear: 0.022766645997763 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022732891142368 nn.Linear: 0.048483282327652] nn.Sequential: [nn.Linear: 0.012346191331744 nn.Linear: 0.021802695468068]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062852411312423 nn.Linear: 0.066173241308064 nn.Linear: 0.045662298772475 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031583772454587 nn.Linear: 0.05812152899307] nn.Sequential: [nn.Linear: 0.031506018227139 nn.Linear: 0.037904299680047]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55769270658493 nn.Linear: 0.28184759616852 nn.Linear: 0.24278904497623 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40563288331032 nn.Linear: 0.64804869890213] nn.Sequential: [nn.Linear: 0.18655070662498 nn.Linear: 0.30392813682556]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016191823799667 nn.Linear: 0.0010404471389278 nn.Linear: 0.00051731879409935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027859061111685 nn.Linear: 0.0037954648810645] nn.Sequential: [nn.Linear: 0.00022392138534975 nn.Linear: 0.0015873774602582]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010874532163143 nn.Linear: 0.014908508397639 nn.Linear: 0.01336345821619 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014869845472276 nn.Linear: 0.031131578609347] nn.Sequential: [nn.Linear: 0.007406912278384 nn.Linear: 0.013726815581322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062851264784302 nn.Linear: 0.066175065357117 nn.Linear: 0.045663712078384 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584050502804 nn.Linear: 0.05809183648006] nn.Sequential: [nn.Linear: 0.031506119835981 nn.Linear: 0.037908194095532]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55745893716812 nn.Linear: 0.28215727210045 nn.Linear: 0.24296739697456 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40600615739822 nn.Linear: 0.64838999509811] nn.Sequential: [nn.Linear: 0.18659625947475 nn.Linear: 0.30406424403191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011055087170491 nn.Linear: 0.00063436662718426 nn.Linear: 0.0003451853802632 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000132133065626 nn.Linear: 0.0014042944687293] nn.Sequential: [nn.Linear: 0.00013213410040689 nn.Linear: 0.0010067955399546]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0072188451886177 nn.Linear: 0.0084341177716851 nn.Linear: 0.011989161372185 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0075066806748509 nn.Linear: 0.011036792770028] nn.Sequential: [nn.Linear: 0.0063341138884425 nn.Linear: 0.011959350667894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06285529035606 nn.Linear: 0.066180896427539 nn.Linear: 0.045665082373767 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584255292724 nn.Linear: 0.058121153218451] nn.Sequential: [nn.Linear: 0.031506422920393 nn.Linear: 0.03793304388994]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55846697092056 nn.Linear: 0.28257042169571 nn.Linear: 0.24318586289883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40643745660782 nn.Linear: 0.64896041154861] nn.Sequential: [nn.Linear: 0.18719831109047 nn.Linear: 0.30417528748512]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017869839434316 nn.Linear: 0.001215010924092 nn.Linear: 0.00053750496641331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022399153892138 nn.Linear: 0.0025956683654558] nn.Sequential: [nn.Linear: 0.00021342466933558 nn.Linear: 0.0014735947115284]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0117367208004 nn.Linear: 0.018031135201454 nn.Linear: 0.018380425870419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013732327148318 nn.Linear: 0.020667590200901] nn.Sequential: [nn.Linear: 0.0079868733882904 nn.Linear: 0.017849158495665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062859791070088 nn.Linear: 0.06618295922267 nn.Linear: 0.045666258863503 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584195980275 nn.Linear: 0.058104442818546] nn.Sequential: [nn.Linear: 0.031506547603906 nn.Linear: 0.037928733161123]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55862009525299 nn.Linear: 0.28268700838089 nn.Linear: 0.24333544075489 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40677982568741 nn.Linear: 0.64929264783859] nn.Sequential: [nn.Linear: 0.18727140128613 nn.Linear: 0.30417883396149]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011904127003135 nn.Linear: 0.00073911715690636 nn.Linear: 0.00043987292316646 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024190093847188 nn.Linear: 0.0029589941457386] nn.Sequential: [nn.Linear: 0.00019525389292489 nn.Linear: 0.0013455782569799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010316383093596 nn.Linear: 0.0099081620573997 nn.Linear: 0.0064785163849592 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013986364006996 nn.Linear: 0.026175651699305] nn.Sequential: [nn.Linear: 0.0061407922767103 nn.Linear: 0.011766518466175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11190000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062873953685175 nn.Linear: 0.066189180126577 nn.Linear: 0.045668295488835 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584255072062 nn.Linear: 0.058116381616344] nn.Sequential: [nn.Linear: 0.031506810873819 nn.Linear: 0.037938766620933]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55880749225616 nn.Linear: 0.28263366222382 nn.Linear: 0.2436740398407 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40734887123108 nn.Linear: 0.6497323513031] nn.Sequential: [nn.Linear: 0.18746182322502 nn.Linear: 0.30444285273552]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018944757854242 nn.Linear: 0.00077209926771746 nn.Linear: 0.00037443103291906 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00014216225874829 nn.Linear: 0.0016563984528259] nn.Sequential: [nn.Linear: 0.00015954123031824 nn.Linear: 0.0010653794858498]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01447649858892 nn.Linear: 0.010332556441426 nn.Linear: 0.0063594090752304 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094635533168912 nn.Linear: 0.0099277030676603] nn.Sequential: [nn.Linear: 0.0084979254752398 nn.Linear: 0.0085256285965443]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11200000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062874051735646 nn.Linear: 0.066191577653481 nn.Linear: 0.045668877152554 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584569319606 nn.Linear: 0.058144318525194] nn.Sequential: [nn.Linear: 0.031506980815088 nn.Linear: 0.037950003361785]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5581750869751 nn.Linear: 0.28329834342003 nn.Linear: 0.24403518438339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40748026967049 nn.Linear: 0.65023666620255] nn.Sequential: [nn.Linear: 0.18744230270386 nn.Linear: 0.30459636449814]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0045780537889316 nn.Linear: 0.0026215664178205 nn.Linear: 0.0011303511686026 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00051420994470784 nn.Linear: 0.0064544905051514] nn.Sequential: [nn.Linear: 0.0004401048897122 nn.Linear: 0.0035220180885605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027678830549121 nn.Linear: 0.038503173738718 nn.Linear: 0.04933213442564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.037536904215813 nn.Linear: 0.051781423389912] nn.Sequential: [nn.Linear: 0.017088767141104 nn.Linear: 0.030480304732919]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11210000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062877418448682 nn.Linear: 0.066196406438897 nn.Linear: 0.045670745519634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031584865475126 nn.Linear: 0.058162911762182] nn.Sequential: [nn.Linear: 0.031507154853679 nn.Linear: 0.037955184555018]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55852353572845 nn.Linear: 0.28348672389984 nn.Linear: 0.24405574798584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40797737240791 nn.Linear: 0.65033584833145] nn.Sequential: [nn.Linear: 0.18776018917561 nn.Linear: 0.30459314584732]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018288738718963 nn.Linear: 0.0010995155321353 nn.Linear: 0.00054247345099012 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021503851548482 nn.Linear: 0.0028684160390963] nn.Sequential: [nn.Linear: 0.00018905829077945 nn.Linear: 0.0013183573557656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010457455180585 nn.Linear: 0.015872783958912 nn.Linear: 0.012459377758205 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012877410277724 nn.Linear: 0.022211078554392] nn.Sequential: [nn.Linear: 0.008029499091208 nn.Linear: 0.01355058606714]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11220000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062882960429184 nn.Linear: 0.066200010741723 nn.Linear: 0.04567279505435 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031585280466187 nn.Linear: 0.058228336051657] nn.Sequential: [nn.Linear: 0.031507235075288 nn.Linear: 0.03795306214534]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5595468878746 nn.Linear: 0.28394621610641 nn.Linear: 0.24435269832611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40824365615845 nn.Linear: 0.65104395151138] nn.Sequential: [nn.Linear: 0.18797968327999 nn.Linear: 0.30479928851128]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0097757592069471 nn.Linear: 0.0039841415426616 nn.Linear: 0.0014041471854606 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00039205487089058 nn.Linear: 0.0041991373687971] nn.Sequential: [nn.Linear: 0.00035781234424588 nn.Linear: 0.0031763464744478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.064852967858315 nn.Linear: 0.067508488893509 nn.Linear: 0.037139095366001 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.056583605706692 nn.Linear: 0.026481432840228] nn.Sequential: [nn.Linear: 0.01157187204808 nn.Linear: 0.040175389498472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11230000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889939001012 nn.Linear: 0.066205489697809 nn.Linear: 0.045674751842971 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031585860848656 nn.Linear: 0.058273896931098] nn.Sequential: [nn.Linear: 0.031507596854925 nn.Linear: 0.037970389272259]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.55966752767563 nn.Linear: 0.28391310572624 nn.Linear: 0.24470274150372 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40868684649467 nn.Linear: 0.6512833237648] nn.Sequential: [nn.Linear: 0.1883741915226 nn.Linear: 0.3052981197834]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012138949681874 nn.Linear: 0.00074512141524185 nn.Linear: 0.00042369491700788 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020064902662967 nn.Linear: 0.0021395497988452] nn.Sequential: [nn.Linear: 0.00017921747791924 nn.Linear: 0.0013988078548006]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011559813283384 nn.Linear: 0.0091969585046172 nn.Linear: 0.0077999802306294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0097539164125919 nn.Linear: 0.015252700075507] nn.Sequential: [nn.Linear: 0.0069544706493616 nn.Linear: 0.014161421917379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11240000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062882997387395 nn.Linear: 0.066208825540945 nn.Linear: 0.045676001106188 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031586058217207 nn.Linear: 0.0582957650835] nn.Sequential: [nn.Linear: 0.031508042340439 nn.Linear: 0.037988635985303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56051254272461 nn.Linear: 0.28462406992912 nn.Linear: 0.24511289596558 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40886822342873 nn.Linear: 0.6518714427948] nn.Sequential: [nn.Linear: 0.18826508522034 nn.Linear: 0.30562353134155]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001622164892717 nn.Linear: 0.00091880304241767 nn.Linear: 0.00042217226470969 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020130851478716 nn.Linear: 0.002352630968554] nn.Sequential: [nn.Linear: 0.00014478368878007 nn.Linear: 0.0009412571723591]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008991158567369 nn.Linear: 0.010904685594141 nn.Linear: 0.010134696029127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0094611132517457 nn.Linear: 0.021401099860668] nn.Sequential: [nn.Linear: 0.0055568967945874 nn.Linear: 0.0068665933795273]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11250000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062875194170124 nn.Linear: 0.06620644854119 nn.Linear: 0.045676056035709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031586291013576 nn.Linear: 0.058318486476821] nn.Sequential: [nn.Linear: 0.031508118284793 nn.Linear: 0.0380001753213]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56175071001053 nn.Linear: 0.28447881340981 nn.Linear: 0.24541492760181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40933626890182 nn.Linear: 0.65226352214813] nn.Sequential: [nn.Linear: 0.18834745883942 nn.Linear: 0.30572780966759]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021902853211299 nn.Linear: 0.0012797433814628 nn.Linear: 0.00056381643127949 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027810088924727 nn.Linear: 0.0037637027235401] nn.Sequential: [nn.Linear: 0.00018016380346156 nn.Linear: 0.0012937318338035]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013375569134951 nn.Linear: 0.018305622041225 nn.Linear: 0.016640214249492 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018348468467593 nn.Linear: 0.036743748933077] nn.Sequential: [nn.Linear: 0.0094933426007628 nn.Linear: 0.016178332269192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.090730461701751	TD error	0.016461256049573	Qmax	1	

Steps: 11250000 (frames: 45000000), score: 2132.36, higheset score: 6616, epsilon: 0.05, lr: 0.0005, training time: 537s, training rate: 1859fps, testing time: 88s, testing rate: 5675fps,  num. ep.: 322,  num. rewards: 17280	
   2    4    8    4
   4    8   16  256
   8   16   32  512
   2    4  128    4
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11260000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062869171187331 nn.Linear: 0.066210026085477 nn.Linear: 0.045676422066664 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031586283510221 nn.Linear: 0.058309824680862] nn.Sequential: [nn.Linear: 0.031508034664547 nn.Linear: 0.037996300816188]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56239175796509 nn.Linear: 0.2841599881649 nn.Linear: 0.24544927477837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.40961554646492 nn.Linear: 0.65279597043991] nn.Sequential: [nn.Linear: 0.18858152627945 nn.Linear: 0.30573207139969]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012503961701363 nn.Linear: 0.0007442547439697 nn.Linear: 0.00036003000204856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016211906458954 nn.Linear: 0.001857157379616] nn.Sequential: [nn.Linear: 0.0001332250441963 nn.Linear: 0.00091518748970922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.009020121768117 nn.Linear: 0.010910012759268 nn.Linear: 0.008857112377882 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013889563269913 nn.Linear: 0.014909445308149] nn.Sequential: [nn.Linear: 0.0044663576409221 nn.Linear: 0.0080053228884935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11270000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06287277141904 nn.Linear: 0.066215235562552 nn.Linear: 0.045678432518912 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03158649010319 nn.Linear: 0.058337006003853] nn.Sequential: [nn.Linear: 0.031508407407114 nn.Linear: 0.038013589105827]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56337332725525 nn.Linear: 0.28387695550919 nn.Linear: 0.24545753002167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41000124812126 nn.Linear: 0.65355354547501] nn.Sequential: [nn.Linear: 0.18849794566631 nn.Linear: 0.30632281303406]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018932570450073 nn.Linear: 0.0010337040540686 nn.Linear: 0.00054896390346251 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021542408178391 nn.Linear: 0.0023359114753993] nn.Sequential: [nn.Linear: 0.00020662838294333 nn.Linear: 0.0013843029593379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012084247544408 nn.Linear: 0.015230109915137 nn.Linear: 0.011199735105038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012492757290602 nn.Linear: 0.020191133022308] nn.Sequential: [nn.Linear: 0.0071235219947994 nn.Linear: 0.01559241861105]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11280000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062866665959375 nn.Linear: 0.066220304732207 nn.Linear: 0.045680438885968 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587084482913 nn.Linear: 0.058319429280118] nn.Sequential: [nn.Linear: 0.031508749067091 nn.Linear: 0.038019722471013]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56382954120636 nn.Linear: 0.28365349769592 nn.Linear: 0.24543778598309 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41026273369789 nn.Linear: 0.65400993824005] nn.Sequential: [nn.Linear: 0.18857453763485 nn.Linear: 0.30648329854012]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00093196542722435 nn.Linear: 0.00065197158234498 nn.Linear: 0.00030977256462875 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013201534829536 nn.Linear: 0.0013900831658359] nn.Sequential: [nn.Linear: 0.00010369158326471 nn.Linear: 0.00062987218531894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007335243280977 nn.Linear: 0.0097003541886806 nn.Linear: 0.0077495397999883 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0056374445557594 nn.Linear: 0.013076267205179] nn.Sequential: [nn.Linear: 0.0045423787087202 nn.Linear: 0.0092190150171518]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11290000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062868791834013 nn.Linear: 0.066223480399471 nn.Linear: 0.045681434465978 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587393318366 nn.Linear: 0.05837686699607] nn.Sequential: [nn.Linear: 0.031508634205058 nn.Linear: 0.03801949993835]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56452023983002 nn.Linear: 0.28391844034195 nn.Linear: 0.24559719860554 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41048491001129 nn.Linear: 0.6544816493988] nn.Sequential: [nn.Linear: 0.1884808242321 nn.Linear: 0.30668622255325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020007300500554 nn.Linear: 0.00094203307889822 nn.Linear: 0.00044870992754287 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00026022094918403 nn.Linear: 0.0038703587397026] nn.Sequential: [nn.Linear: 0.00018954836007841 nn.Linear: 0.0015548330263775]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014501591213048 nn.Linear: 0.014192086644471 nn.Linear: 0.013145952485502 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013524600304663 nn.Linear: 0.02302447706461] nn.Sequential: [nn.Linear: 0.015338096767664 nn.Linear: 0.021258074790239]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11300000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062871185148813 nn.Linear: 0.066227022250877 nn.Linear: 0.04568241952704 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587480939482 nn.Linear: 0.058373479428894] nn.Sequential: [nn.Linear: 0.031508811614833 nn.Linear: 0.038043706670461]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56443107128143 nn.Linear: 0.28352844715118 nn.Linear: 0.24567873775959 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41072818636894 nn.Linear: 0.65519613027573] nn.Sequential: [nn.Linear: 0.18888033926487 nn.Linear: 0.30711898207664]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0033509634722691 nn.Linear: 0.0014214699021165 nn.Linear: 0.00052235546497856 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025302577755663 nn.Linear: 0.0030956623855678] nn.Sequential: [nn.Linear: 0.00015521860885662 nn.Linear: 0.00093181045514808]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01688196323812 nn.Linear: 0.021096743643284 nn.Linear: 0.01548976637423 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014318653382361 nn.Linear: 0.021555855870247] nn.Sequential: [nn.Linear: 0.0077902381308377 nn.Linear: 0.0089365299791098]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11310000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062878900162617 nn.Linear: 0.066228370740061 nn.Linear: 0.045682890304294 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587424680281 nn.Linear: 0.058380499494092] nn.Sequential: [nn.Linear: 0.031509061018715 nn.Linear: 0.038041691456235]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56476557254791 nn.Linear: 0.28380414843559 nn.Linear: 0.24608351290226 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41083863377571 nn.Linear: 0.6555370092392] nn.Sequential: [nn.Linear: 0.18905164301395 nn.Linear: 0.30738806724548]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021883218640395 nn.Linear: 0.0011780212233359 nn.Linear: 0.00061982789422706 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033195284722486 nn.Linear: 0.0040379744740391] nn.Sequential: [nn.Linear: 0.00025879966424384 nn.Linear: 0.0020373929620788]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013701552525163 nn.Linear: 0.016812009736896 nn.Linear: 0.011030862107873 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020038850605488 nn.Linear: 0.036547433584929] nn.Sequential: [nn.Linear: 0.01161371357739 nn.Linear: 0.027798132970929]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11320000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062882949260625 nn.Linear: 0.066235519722031 nn.Linear: 0.0456845897156 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587722124015 nn.Linear: 0.058418662293093] nn.Sequential: [nn.Linear: 0.031509301259103 nn.Linear: 0.038045407672632]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56521326303482 nn.Linear: 0.28415447473526 nn.Linear: 0.2464298158884 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41099932789803 nn.Linear: 0.65594655275345] nn.Sequential: [nn.Linear: 0.18931940197945 nn.Linear: 0.307437479496]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010154595349977 nn.Linear: 0.00055194490405422 nn.Linear: 0.00031842499704986 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016321680365859 nn.Linear: 0.0020462891919236] nn.Sequential: [nn.Linear: 0.00012139668450088 nn.Linear: 0.00087181580877176]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0057205823250115 nn.Linear: 0.007932367734611 nn.Linear: 0.0070834197103977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010626969859004 nn.Linear: 0.021690491586924] nn.Sequential: [nn.Linear: 0.0044409320689738 nn.Linear: 0.010198197327554]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11330000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062880442307628 nn.Linear: 0.066238885064493 nn.Linear: 0.045685225034186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031587832338747 nn.Linear: 0.058445419119948] nn.Sequential: [nn.Linear: 0.031509450361639 nn.Linear: 0.038050338273923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56556439399719 nn.Linear: 0.2846519947052 nn.Linear: 0.24625742435455 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41135212779045 nn.Linear: 0.65624779462814] nn.Sequential: [nn.Linear: 0.18950556218624 nn.Linear: 0.30750170350075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026054372932467 nn.Linear: 0.0016876807195539 nn.Linear: 0.0006915864408832 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025320365471697 nn.Linear: 0.0030084965876096] nn.Sequential: [nn.Linear: 0.00026179418251524 nn.Linear: 0.0022892321640342]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015494903549552 nn.Linear: 0.034372694790363 nn.Linear: 0.020277617499232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015053914859891 nn.Linear: 0.036284424364567] nn.Sequential: [nn.Linear: 0.013101737014949 nn.Linear: 0.042242303490639]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11340000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889633648289 nn.Linear: 0.066241301143447 nn.Linear: 0.045686697574016 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031588080778648 nn.Linear: 0.058466455078815] nn.Sequential: [nn.Linear: 0.031509643334498 nn.Linear: 0.038057886642644]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56642162799835 nn.Linear: 0.28452321887016 nn.Linear: 0.24673554301262 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41171443462372 nn.Linear: 0.6566766500473] nn.Sequential: [nn.Linear: 0.18963858485222 nn.Linear: 0.30759388208389]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015447184276936 nn.Linear: 0.00081043080660975 nn.Linear: 0.00040657052213142 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018980732794308 nn.Linear: 0.0021349160712224] nn.Sequential: [nn.Linear: 0.00016366093869959 nn.Linear: 0.0011775695321142]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011121318675578 nn.Linear: 0.010658899322152 nn.Linear: 0.012195990420878 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011062282137573 nn.Linear: 0.022274868562818] nn.Sequential: [nn.Linear: 0.0052966987714171 nn.Linear: 0.013012183830142]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11350000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06289085591206 nn.Linear: 0.066245344930698 nn.Linear: 0.045686967970985 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031588491984688 nn.Linear: 0.058508134423846] nn.Sequential: [nn.Linear: 0.031509690034225 nn.Linear: 0.038068217123354]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56741774082184 nn.Linear: 0.2849397957325 nn.Linear: 0.24718897044659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41220793128014 nn.Linear: 0.6570788025856] nn.Sequential: [nn.Linear: 0.18980234861374 nn.Linear: 0.30803555250168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0032221156298221 nn.Linear: 0.0016507364762475 nn.Linear: 0.00069226648107744 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023519333646502 nn.Linear: 0.0024229662981439] nn.Sequential: [nn.Linear: 0.00018848758271938 nn.Linear: 0.001248419110478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027011683210731 nn.Linear: 0.037007041275501 nn.Linear: 0.0345294252038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.037236448377371 nn.Linear: 0.018000161275268] nn.Sequential: [nn.Linear: 0.0094452165067196 nn.Linear: 0.013453060761094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11360000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062887874593089 nn.Linear: 0.066245963526197 nn.Linear: 0.045688421636415 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031588569289873 nn.Linear: 0.058502586356056] nn.Sequential: [nn.Linear: 0.03150971184358 nn.Linear: 0.038067523634037]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56684839725494 nn.Linear: 0.28496843576431 nn.Linear: 0.24679246544838 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4123797416687 nn.Linear: 0.65754014253616] nn.Sequential: [nn.Linear: 0.19020241498947 nn.Linear: 0.3078245818615]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0047060752092462 nn.Linear: 0.0027522393984802 nn.Linear: 0.0012141810674499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00042508465968062 nn.Linear: 0.0043228969989819] nn.Sequential: [nn.Linear: 0.00046648957251777 nn.Linear: 0.004219947755438]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.031077614054084 nn.Linear: 0.042859740555286 nn.Linear: 0.048846531659365 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.027084685862064 nn.Linear: 0.040237046778202] nn.Sequential: [nn.Linear: 0.021043615415692 nn.Linear: 0.051006875932217]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11370000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062893329567487 nn.Linear: 0.066249769523242 nn.Linear: 0.045689274449331 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03158894512289 nn.Linear: 0.058517774283473] nn.Sequential: [nn.Linear: 0.031510198695625 nn.Linear: 0.038078254821665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56672179698944 nn.Linear: 0.28517827391624 nn.Linear: 0.24699127674103 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4126233458519 nn.Linear: 0.65826153755188] nn.Sequential: [nn.Linear: 0.19015508890152 nn.Linear: 0.30851557850838]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0042844977158652 nn.Linear: 0.0029103259795371 nn.Linear: 0.0014164042924844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00052710257264729 nn.Linear: 0.0060870690277701] nn.Sequential: [nn.Linear: 0.00045826099852655 nn.Linear: 0.0034843514894344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.029129303991795 nn.Linear: 0.081286750733852 nn.Linear: 0.062604047358036 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.036703012883663 nn.Linear: 0.04650753736496] nn.Sequential: [nn.Linear: 0.018893029540777 nn.Linear: 0.04467461630702]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11380000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889555660211 nn.Linear: 0.066256667769185 nn.Linear: 0.045691359070312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031589291153615 nn.Linear: 0.058503913939944] nn.Sequential: [nn.Linear: 0.031510449057324 nn.Linear: 0.038088927050348]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56807488203049 nn.Linear: 0.28462472558022 nn.Linear: 0.24724835157394 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41306212544441 nn.Linear: 0.65871697664261] nn.Sequential: [nn.Linear: 0.19002106785774 nn.Linear: 0.30852824449539]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017569210821272 nn.Linear: 0.0008041151974605 nn.Linear: 0.00037108886448229 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015900256756345 nn.Linear: 0.0017039650075777] nn.Sequential: [nn.Linear: 0.00016087691753486 nn.Linear: 0.0010874542399191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011400446295738 nn.Linear: 0.01050051767379 nn.Linear: 0.010307180695236 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0077293999493122 nn.Linear: 0.0090388134121895] nn.Sequential: [nn.Linear: 0.0090738125145435 nn.Linear: 0.011109725572169]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11390000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062884734665866 nn.Linear: 0.066257249164768 nn.Linear: 0.045691244234615 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031589331502989 nn.Linear: 0.058531669371078] nn.Sequential: [nn.Linear: 0.031510467201407 nn.Linear: 0.038089250787245]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56780570745468 nn.Linear: 0.28454035520554 nn.Linear: 0.24733108282089 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41337585449219 nn.Linear: 0.65926140546799] nn.Sequential: [nn.Linear: 0.18997317552567 nn.Linear: 0.30912911891937]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023640671798273 nn.Linear: 0.0010201535848957 nn.Linear: 0.00047506914732452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024727132866049 nn.Linear: 0.0032199552430193] nn.Sequential: [nn.Linear: 0.00016766064275492 nn.Linear: 0.0012699390492078]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011027350090444 nn.Linear: 0.014376045204699 nn.Linear: 0.02034205943346 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018192999064922 nn.Linear: 0.022245842963457] nn.Sequential: [nn.Linear: 0.010229583829641 nn.Linear: 0.017970614135265]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11400000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062880437769215 nn.Linear: 0.06625823440805 nn.Linear: 0.045691362606628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03158960318481 nn.Linear: 0.058526465152983] nn.Sequential: [nn.Linear: 0.031510648510612 nn.Linear: 0.038094786242771]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56749427318573 nn.Linear: 0.28484839200974 nn.Linear: 0.24745874106884 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41397094726562 nn.Linear: 0.65994799137115] nn.Sequential: [nn.Linear: 0.19014132022858 nn.Linear: 0.30921211838722]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019918637635745 nn.Linear: 0.00097126517008397 nn.Linear: 0.00048582048817648 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019347834645337 nn.Linear: 0.0020623221529348] nn.Sequential: [nn.Linear: 0.00020644923621839 nn.Linear: 0.0017023358681307]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01489516813308 nn.Linear: 0.017033386975527 nn.Linear: 0.012393892742693 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014389777556062 nn.Linear: 0.016390359029174] nn.Sequential: [nn.Linear: 0.013253758661449 nn.Linear: 0.018472082912922]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11410000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062884540274873 nn.Linear: 0.066264749614494 nn.Linear: 0.045692568995936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031589841631766 nn.Linear: 0.058530230632357] nn.Sequential: [nn.Linear: 0.031510535801011 nn.Linear: 0.038077491433205]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56858974695206 nn.Linear: 0.28473886847496 nn.Linear: 0.24775974452496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41422918438911 nn.Linear: 0.66009342670441] nn.Sequential: [nn.Linear: 0.19060696661472 nn.Linear: 0.30915632843971]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015085127762326 nn.Linear: 0.00085987908006815 nn.Linear: 0.00045084939141111 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022071639844929 nn.Linear: 0.002945821426257] nn.Sequential: [nn.Linear: 0.00015088236584203 nn.Linear: 0.0010455389139288]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010303800925612 nn.Linear: 0.01083309110254 nn.Linear: 0.01378582790494 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015771444886923 nn.Linear: 0.023342352360487] nn.Sequential: [nn.Linear: 0.0050002937205136 nn.Linear: 0.010902627371252]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11420000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062880252060288 nn.Linear: 0.066267283939728 nn.Linear: 0.04569496332341 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031590430758637 nn.Linear: 0.058593938590604] nn.Sequential: [nn.Linear: 0.03151051913001 nn.Linear: 0.038100903119223]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56897699832916 nn.Linear: 0.28451699018478 nn.Linear: 0.24778118729591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41455414891243 nn.Linear: 0.66062617301941] nn.Sequential: [nn.Linear: 0.19069157540798 nn.Linear: 0.30946570634842]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002117497767578 nn.Linear: 0.001406489081721 nn.Linear: 0.00061045302198075 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021637273397296 nn.Linear: 0.0023475714690484] nn.Sequential: [nn.Linear: 0.00024388388404253 nn.Linear: 0.0018532401026495]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015103579498827 nn.Linear: 0.024801881983876 nn.Linear: 0.020444748923182 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0098295407369733 nn.Linear: 0.013947253115475] nn.Sequential: [nn.Linear: 0.0079468870535493 nn.Linear: 0.018308559432626]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11430000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062879484451487 nn.Linear: 0.066269561052192 nn.Linear: 0.045695772092924 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031590493356069 nn.Linear: 0.058599064558393] nn.Sequential: [nn.Linear: 0.031510598039716 nn.Linear: 0.038124487306099]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56876522302628 nn.Linear: 0.28453415632248 nn.Linear: 0.24779000878334 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41519069671631 nn.Linear: 0.66113841533661] nn.Sequential: [nn.Linear: 0.19124539196491 nn.Linear: 0.30960193276405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014141719182961 nn.Linear: 0.00075399787954684 nn.Linear: 0.00038627924775301 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018127195429012 nn.Linear: 0.0020016770488173] nn.Sequential: [nn.Linear: 0.00016527132428895 nn.Linear: 0.0014240606336042]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012266488745809 nn.Linear: 0.011242359876633 nn.Linear: 0.0090201301500201 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.021861793473363 nn.Linear: 0.033207647502422] nn.Sequential: [nn.Linear: 0.010827393271029 nn.Linear: 0.01273088529706]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11440000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062890041804431 nn.Linear: 0.06627652399759 nn.Linear: 0.045697416368295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031590695249028 nn.Linear: 0.058641344461691] nn.Sequential: [nn.Linear: 0.031511095365364 nn.Linear: 0.038138918832322]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57047021389008 nn.Linear: 0.28452029824257 nn.Linear: 0.24840848147869 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4156858921051 nn.Linear: 0.66170716285706] nn.Sequential: [nn.Linear: 0.19143410027027 nn.Linear: 0.30980974435806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.003509140908646 nn.Linear: 0.0016453137533287 nn.Linear: 0.00082919018805931 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00031238534091623 nn.Linear: 0.0037346507230174] nn.Sequential: [nn.Linear: 0.00029509124887182 nn.Linear: 0.0022883415151611]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.025042541325092 nn.Linear: 0.033126290887594 nn.Linear: 0.030487742275 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02157718129456 nn.Linear: 0.035142205655575] nn.Sequential: [nn.Linear: 0.016743268817663 nn.Linear: 0.027044102549553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11450000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062887171842606 nn.Linear: 0.066280153305876 nn.Linear: 0.045699398774212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031590889887529 nn.Linear: 0.05869505164361] nn.Sequential: [nn.Linear: 0.031511456863383 nn.Linear: 0.038134443974178]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57003229856491 nn.Linear: 0.28406894207001 nn.Linear: 0.24873399734497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41603755950928 nn.Linear: 0.66212195158005] nn.Sequential: [nn.Linear: 0.19105163216591 nn.Linear: 0.31003871560097]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0051780744105008 nn.Linear: 0.0028832053901126 nn.Linear: 0.0016435056144114 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00051469765566172 nn.Linear: 0.0059533091623014] nn.Sequential: [nn.Linear: 0.00038405552137384 nn.Linear: 0.0029123871077161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.044549494981766 nn.Linear: 0.078872375190258 nn.Linear: 0.062231503427029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.064800091087818 nn.Linear: 0.057944923639297] nn.Sequential: [nn.Linear: 0.029292056336999 nn.Linear: 0.036208875477314]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11460000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062878717775671 nn.Linear: 0.066284407186571 nn.Linear: 0.045701342101339 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591046938343 nn.Linear: 0.058707260019901] nn.Sequential: [nn.Linear: 0.031511754060395 nn.Linear: 0.038144839824799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56978124380112 nn.Linear: 0.28440541028976 nn.Linear: 0.24898308515549 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41638350486755 nn.Linear: 0.66265898942947] nn.Sequential: [nn.Linear: 0.19154223799706 nn.Linear: 0.31017366051674]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013416722715655 nn.Linear: 0.00078887084304665 nn.Linear: 0.00041606140912602 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002046657525134 nn.Linear: 0.0028631023157348] nn.Sequential: [nn.Linear: 0.00019761751404235 nn.Linear: 0.0014908475458923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084511321038008 nn.Linear: 0.011878906749189 nn.Linear: 0.010218855924904 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016321927309036 nn.Linear: 0.03149638324976] nn.Sequential: [nn.Linear: 0.0097063472494483 nn.Linear: 0.013567359186709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11470000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06287434359461 nn.Linear: 0.066287697485371 nn.Linear: 0.045702612253729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591220099151 nn.Linear: 0.058696387829926] nn.Sequential: [nn.Linear: 0.031511628014678 nn.Linear: 0.038151676900023]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56948083639145 nn.Linear: 0.28442016243935 nn.Linear: 0.249292075634 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41684618592262 nn.Linear: 0.66375195980072] nn.Sequential: [nn.Linear: 0.19149440526962 nn.Linear: 0.31075918674469]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00088120763432033 nn.Linear: 0.00054330400081625 nn.Linear: 0.00028397209543656 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012642872245054 nn.Linear: 0.0012821915080278] nn.Sequential: [nn.Linear: 0.00012764948453673 nn.Linear: 0.0011497465602286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068421829491854 nn.Linear: 0.0076635559089482 nn.Linear: 0.0051553598605096 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0051689916290343 nn.Linear: 0.008086915127933] nn.Sequential: [nn.Linear: 0.0050117941573262 nn.Linear: 0.0079064704477787]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11480000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062872529915408 nn.Linear: 0.06629390584231 nn.Linear: 0.045703779706806 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591351393964 nn.Linear: 0.058712108516374] nn.Sequential: [nn.Linear: 0.031511844731656 nn.Linear: 0.038165106432286]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.56949299573898 nn.Linear: 0.2843132019043 nn.Linear: 0.24960647523403 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41708734631538 nn.Linear: 0.66429042816162] nn.Sequential: [nn.Linear: 0.19179053604603 nn.Linear: 0.31077408790588]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0030497292461263 nn.Linear: 0.0014939541737669 nn.Linear: 0.00071738172084791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027250450212158 nn.Linear: 0.0028549214918095] nn.Sequential: [nn.Linear: 0.0002462481136051 nn.Linear: 0.0016777698343154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.019778974354267 nn.Linear: 0.022128222510219 nn.Linear: 0.011822520755231 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017327141016722 nn.Linear: 0.018410347402096] nn.Sequential: [nn.Linear: 0.01142730936408 nn.Linear: 0.017512682825327]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11490000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06287677549049 nn.Linear: 0.066298469759765 nn.Linear: 0.045705192203652 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591407439125 nn.Linear: 0.058726684639268] nn.Sequential: [nn.Linear: 0.031511929160963 nn.Linear: 0.038164336740044]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57003551721573 nn.Linear: 0.28471425175667 nn.Linear: 0.24982757866383 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41724467277527 nn.Linear: 0.6643061041832] nn.Sequential: [nn.Linear: 0.19202163815498 nn.Linear: 0.31083106994629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010887113042421 nn.Linear: 0.00055218519456734 nn.Linear: 0.0002871672121514 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013594194478452 nn.Linear: 0.001560117404473] nn.Sequential: [nn.Linear: 0.00011462926921916 nn.Linear: 0.00097702442417968]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0088170766830444 nn.Linear: 0.0078086154535413 nn.Linear: 0.0063168164342642 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0133783435449 nn.Linear: 0.014838897623122] nn.Sequential: [nn.Linear: 0.0043423576280475 nn.Linear: 0.011426107957959]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11500000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062879347147595 nn.Linear: 0.066301329495314 nn.Linear: 0.045705941209186 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591659885378 nn.Linear: 0.058738158365884] nn.Sequential: [nn.Linear: 0.031512004817516 nn.Linear: 0.038179787322041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57104676961899 nn.Linear: 0.28442803025246 nn.Linear: 0.24987703561783 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41749253869057 nn.Linear: 0.66485595703125] nn.Sequential: [nn.Linear: 0.19194975495338 nn.Linear: 0.31134411692619]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00091623131237695 nn.Linear: 0.0004924261424255 nn.Linear: 0.00025841707509194 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.4890009761298e-05 nn.Linear: 0.0010098783214788] nn.Sequential: [nn.Linear: 0.00012402506902828 nn.Linear: 0.0010168544605048]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.008201508782804 nn.Linear: 0.0077021941542625 nn.Linear: 0.0051714819855988 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0072522656992078 nn.Linear: 0.014913926832378] nn.Sequential: [nn.Linear: 0.0046230712905526 nn.Linear: 0.010960794985294]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.082952437639236	TD error	0.01616419839859	Qmax	1	

Steps: 11500000 (frames: 46000000), score: 2176.39, higheset score: 6772, epsilon: 0.05, lr: 0.0005, training time: 536s, training rate: 1865fps, testing time: 86s, testing rate: 5809fps,  num. ep.: 351,  num. rewards: 17444	
   2    8   16    2
   4  512   64    8
   8    4  128    4
   2    8  256    2
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11510000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062880597199836 nn.Linear: 0.066306352509249 nn.Linear: 0.045707039755388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591916153466 nn.Linear: 0.058734197895546] nn.Sequential: [nn.Linear: 0.031512669010279 nn.Linear: 0.038198333648981]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57075226306915 nn.Linear: 0.28478235006332 nn.Linear: 0.24978151917458 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41779598593712 nn.Linear: 0.66536539793015] nn.Sequential: [nn.Linear: 0.19223700463772 nn.Linear: 0.31171107292175]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00092425038582041 nn.Linear: 0.00055924045969241 nn.Linear: 0.00029786497704793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001262863952736 nn.Linear: 0.0012126614423223] nn.Sequential: [nn.Linear: 0.00014063620364805 nn.Linear: 0.0012715618691605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066484096460044 nn.Linear: 0.0079077733680606 nn.Linear: 0.0073584904894233 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0050929556600749 nn.Linear: 0.0098172342404723] nn.Sequential: [nn.Linear: 0.0060360250063241 nn.Linear: 0.01432288531214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11520000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06288643477658 nn.Linear: 0.066304591225178 nn.Linear: 0.045707758225295 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591908630731 nn.Linear: 0.058738241785221] nn.Sequential: [nn.Linear: 0.031512816148199 nn.Linear: 0.038197877869152]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57072633504868 nn.Linear: 0.28474137187004 nn.Linear: 0.25027135014534 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41831809282303 nn.Linear: 0.66537773609161] nn.Sequential: [nn.Linear: 0.1923553198576 nn.Linear: 0.31184020638466]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015847130385079 nn.Linear: 0.00091580993455818 nn.Linear: 0.00041224739490766 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021975132387985 nn.Linear: 0.0029214098391107] nn.Sequential: [nn.Linear: 0.00014848805163394 nn.Linear: 0.00097939825098096]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0092188119888306 nn.Linear: 0.015997832641006 nn.Linear: 0.0066095115616918 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011765023693442 nn.Linear: 0.022738942876458] nn.Sequential: [nn.Linear: 0.0039935642853379 nn.Linear: 0.010065629146993]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11530000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889926036685 nn.Linear: 0.066305706230568 nn.Linear: 0.045709009037591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031591866651735 nn.Linear: 0.058766593562723] nn.Sequential: [nn.Linear: 0.031512837781771 nn.Linear: 0.038204524006073]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57069730758667 nn.Linear: 0.2849425971508 nn.Linear: 0.25061097741127 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41865566372871 nn.Linear: 0.66609567403793] nn.Sequential: [nn.Linear: 0.19283373653889 nn.Linear: 0.31210750341415]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0017517197569374 nn.Linear: 0.00090663589284677 nn.Linear: 0.00042003018320621 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017189654025241 nn.Linear: 0.0018039379810784] nn.Sequential: [nn.Linear: 0.00017640514524359 nn.Linear: 0.0013639942767987]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01054076757282 nn.Linear: 0.010212431661785 nn.Linear: 0.012729428708553 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076011251658201 nn.Linear: 0.010206209495664] nn.Sequential: [nn.Linear: 0.0057917023077607 nn.Linear: 0.015670977532864]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11540000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06288868665501 nn.Linear: 0.066313117091155 nn.Linear: 0.045711140464198 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031592067312356 nn.Linear: 0.058767334179777] nn.Sequential: [nn.Linear: 0.031513048087744 nn.Linear: 0.038207907699535]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57148730754852 nn.Linear: 0.2848336994648 nn.Linear: 0.25058379769325 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41903588175774 nn.Linear: 0.6666533946991] nn.Sequential: [nn.Linear: 0.19295373558998 nn.Linear: 0.31246137619019]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014839616065555 nn.Linear: 0.0008327753452452 nn.Linear: 0.00045680316096479 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00027588627967356 nn.Linear: 0.0037153517067194] nn.Sequential: [nn.Linear: 0.00015989108268569 nn.Linear: 0.0010642765639203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010810215957463 nn.Linear: 0.011064737103879 nn.Linear: 0.0083628054708242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013728571124375 nn.Linear: 0.024613235145807] nn.Sequential: [nn.Linear: 0.0057062264531851 nn.Linear: 0.0073562348261476]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11550000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889823853417 nn.Linear: 0.066315428677701 nn.Linear: 0.045712874353621 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031592767301782 nn.Linear: 0.05882452395258] nn.Sequential: [nn.Linear: 0.031513084493894 nn.Linear: 0.03822743186949]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57110005617142 nn.Linear: 0.28614953160286 nn.Linear: 0.25064420700073 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.41951680183411 nn.Linear: 0.66736876964569] nn.Sequential: [nn.Linear: 0.19295017421246 nn.Linear: 0.31285297870636]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019463281226629 nn.Linear: 0.0011264466311101 nn.Linear: 0.00051339783002808 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018481281904034 nn.Linear: 0.0018718165560543] nn.Sequential: [nn.Linear: 0.00022850913686472 nn.Linear: 0.001796871581094]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015970354899764 nn.Linear: 0.01091640535742 nn.Linear: 0.010764523409307 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015922129154205 nn.Linear: 0.019822061061859] nn.Sequential: [nn.Linear: 0.009672561660409 nn.Linear: 0.021628823131323]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11560000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889658406808 nn.Linear: 0.066316186295961 nn.Linear: 0.045713398570465 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031592835018071 nn.Linear: 0.058837003556789] nn.Sequential: [nn.Linear: 0.031512926677413 nn.Linear: 0.038235025246553]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57105553150177 nn.Linear: 0.28567099571228 nn.Linear: 0.25094673037529 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4198577105999 nn.Linear: 0.66803658008575] nn.Sequential: [nn.Linear: 0.19349691271782 nn.Linear: 0.31280991435051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002062646758391 nn.Linear: 0.001363840902889 nn.Linear: 0.00071631251892225 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00032367059013403 nn.Linear: 0.0039334820766637] nn.Sequential: [nn.Linear: 0.00027277587817165 nn.Linear: 0.0018759815098893]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014578415080905 nn.Linear: 0.017552791163325 nn.Linear: 0.016491057351232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015885062515736 nn.Linear: 0.040139827877283] nn.Sequential: [nn.Linear: 0.0094692436978221 nn.Linear: 0.015066902153194]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11570000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062886423277876 nn.Linear: 0.066320054719495 nn.Linear: 0.045714086843277 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031592881876499 nn.Linear: 0.058850130033733] nn.Sequential: [nn.Linear: 0.031513081221579 nn.Linear: 0.038240702956802]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57219660282135 nn.Linear: 0.28577530384064 nn.Linear: 0.25098448991776 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42004308104515 nn.Linear: 0.66813868284225] nn.Sequential: [nn.Linear: 0.19337879121304 nn.Linear: 0.31285074353218]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018815279911927 nn.Linear: 0.00090816080602997 nn.Linear: 0.00057588025670125 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025214538906195 nn.Linear: 0.0027382846068012] nn.Sequential: [nn.Linear: 0.00023420658324409 nn.Linear: 0.001681819089131]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014979590661824 nn.Linear: 0.014158598147333 nn.Linear: 0.014018753543496 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013019765727222 nn.Linear: 0.026626959443092] nn.Sequential: [nn.Linear: 0.01427801232785 nn.Linear: 0.014132445678115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11580000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062891415078504 nn.Linear: 0.06632555262202 nn.Linear: 0.045715738919545 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031592984116423 nn.Linear: 0.058853703050232] nn.Sequential: [nn.Linear: 0.031513564194139 nn.Linear: 0.038240890721942]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57242232561111 nn.Linear: 0.28570917248726 nn.Linear: 0.25123476982117 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42042744159698 nn.Linear: 0.66850501298904] nn.Sequential: [nn.Linear: 0.19298195838928 nn.Linear: 0.31307074427605]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012715677391617 nn.Linear: 0.00073220070485771 nn.Linear: 0.00041099480671902 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017007614753394 nn.Linear: 0.0020248946108898] nn.Sequential: [nn.Linear: 0.00017122785564705 nn.Linear: 0.0013072312577989]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007234042044729 nn.Linear: 0.010006546974182 nn.Linear: 0.0070441826246679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0088111571967602 nn.Linear: 0.014277316629887] nn.Sequential: [nn.Linear: 0.0076601728796959 nn.Linear: 0.016202969476581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11590000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889802485453 nn.Linear: 0.066327559876342 nn.Linear: 0.045716584087823 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031593447442749 nn.Linear: 0.058882501113061] nn.Sequential: [nn.Linear: 0.031513610321391 nn.Linear: 0.038248987755381]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5738832950592 nn.Linear: 0.28615227341652 nn.Linear: 0.25123789906502 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4206380546093 nn.Linear: 0.66855853796005] nn.Sequential: [nn.Linear: 0.19271925091743 nn.Linear: 0.31319525837898]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013263276163113 nn.Linear: 0.00083393106785356 nn.Linear: 0.00042476891130193 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.000173439730294 nn.Linear: 0.0019321496012877] nn.Sequential: [nn.Linear: 0.00023869982647391 nn.Linear: 0.0020100464395977]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098719038069248 nn.Linear: 0.011394917964935 nn.Linear: 0.0084905112162232 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015562014654279 nn.Linear: 0.012853915803134] nn.Sequential: [nn.Linear: 0.010808997787535 nn.Linear: 0.027275500819087]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11600000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062894225765663 nn.Linear: 0.066332617264794 nn.Linear: 0.045718511536078 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031593906851572 nn.Linear: 0.058910589455564] nn.Sequential: [nn.Linear: 0.031513783115946 nn.Linear: 0.038254136327988]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.574482858181 nn.Linear: 0.28589522838593 nn.Linear: 0.25145071744919 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42098689079285 nn.Linear: 0.6689036488533] nn.Sequential: [nn.Linear: 0.19244338572025 nn.Linear: 0.31329131126404]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0053243295718695 nn.Linear: 0.0026309261042232 nn.Linear: 0.001298575417203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00047232481308006 nn.Linear: 0.005917042431602] nn.Sequential: [nn.Linear: 0.00047182170968989 nn.Linear: 0.0037320058572671]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.029301149770617 nn.Linear: 0.063936449587345 nn.Linear: 0.037871580570936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.026014978066087 nn.Linear: 0.041130557656288] nn.Sequential: [nn.Linear: 0.022836754098535 nn.Linear: 0.05157858133316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11610000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062896215151863 nn.Linear: 0.066337816837652 nn.Linear: 0.045720451087837 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031594269887437 nn.Linear: 0.058955724133483] nn.Sequential: [nn.Linear: 0.03151387698971 nn.Linear: 0.038259942237135]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57517993450165 nn.Linear: 0.28516247868538 nn.Linear: 0.25182417035103 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42131963372231 nn.Linear: 0.66961318254471] nn.Sequential: [nn.Linear: 0.19262498617172 nn.Linear: 0.31332728266716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024139102928362 nn.Linear: 0.0012388191175444 nn.Linear: 0.00059653376961314 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023661021614675 nn.Linear: 0.002850049678957] nn.Sequential: [nn.Linear: 0.00024834469179483 nn.Linear: 0.0020381042733852]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.014445457607508 nn.Linear: 0.016763869673014 nn.Linear: 0.01882442086935 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013366882689297 nn.Linear: 0.039044070988894] nn.Sequential: [nn.Linear: 0.0091247037053108 nn.Linear: 0.020153861492872]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11620000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062888122046551 nn.Linear: 0.066339531433493 nn.Linear: 0.045720951868764 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031594095261542 nn.Linear: 0.058951780496571] nn.Sequential: [nn.Linear: 0.031513863103915 nn.Linear: 0.038256382097767]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57577186822891 nn.Linear: 0.28537556529045 nn.Linear: 0.25201255083084 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42162624001503 nn.Linear: 0.66961294412613] nn.Sequential: [nn.Linear: 0.19248621165752 nn.Linear: 0.31329765915871]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014644697754194 nn.Linear: 0.00074703611829524 nn.Linear: 0.00045424429313313 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022862387996366 nn.Linear: 0.0029990981521957] nn.Sequential: [nn.Linear: 0.00019111279334258 nn.Linear: 0.0015728781141193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011781916022301 nn.Linear: 0.011112664826214 nn.Linear: 0.0082937208935618 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011920038610697 nn.Linear: 0.024994214996696] nn.Sequential: [nn.Linear: 0.0071092336438596 nn.Linear: 0.013874494470656]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11630000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062885852852101 nn.Linear: 0.066342326200927 nn.Linear: 0.045722249184242 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031594377605323 nn.Linear: 0.058973590951297] nn.Sequential: [nn.Linear: 0.031513846078739 nn.Linear: 0.038265196236483]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5758376121521 nn.Linear: 0.28557002544403 nn.Linear: 0.25163176655769 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42195355892181 nn.Linear: 0.66981714963913] nn.Sequential: [nn.Linear: 0.1926557123661 nn.Linear: 0.31329718232155]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00073698675859775 nn.Linear: 0.00050144660547721 nn.Linear: 0.00023246023941522 nn.ConcatTable: [nn.Sequential: [nn.Linear: 9.3844252993191e-05 nn.Linear: 0.0010265509790049] nn.Sequential: [nn.Linear: 7.9185457950994e-05 nn.Linear: 0.00067107571638086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0054908790625632 nn.Linear: 0.0061836093664169 nn.Linear: 0.0047491313889623 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0063688033260405 nn.Linear: 0.0082763712853193] nn.Sequential: [nn.Linear: 0.0040140501223505 nn.Linear: 0.0098460298031569]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11640000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062889856881723 nn.Linear: 0.066349302233491 nn.Linear: 0.045725402345494 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031594852812254 nn.Linear: 0.058998632426125] nn.Sequential: [nn.Linear: 0.031514297854045 nn.Linear: 0.038278463715642]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57542508840561 nn.Linear: 0.28587055206299 nn.Linear: 0.25195580720901 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42237082123756 nn.Linear: 0.67053478956223] nn.Sequential: [nn.Linear: 0.19287939369678 nn.Linear: 0.31364968419075]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0021462469139128 nn.Linear: 0.001149357882835 nn.Linear: 0.00050898561488133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00019180018425934 nn.Linear: 0.001761503704778] nn.Sequential: [nn.Linear: 0.00024492060892424 nn.Linear: 0.0017506503406337]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013082112185657 nn.Linear: 0.014321758411825 nn.Linear: 0.008466899394989 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0089529594406486 nn.Linear: 0.011455925181508] nn.Sequential: [nn.Linear: 0.0076246936805546 nn.Linear: 0.018655110150576]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11650000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06288896260799 nn.Linear: 0.066350845350865 nn.Linear: 0.045727156176289 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031595178492343 nn.Linear: 0.059041677085531] nn.Sequential: [nn.Linear: 0.031514440862131 nn.Linear: 0.038286931584847]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57524305582047 nn.Linear: 0.28573274612427 nn.Linear: 0.25190380215645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42262390255928 nn.Linear: 0.67081427574158] nn.Sequential: [nn.Linear: 0.19331620633602 nn.Linear: 0.31359753012657]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0011042208337001 nn.Linear: 0.00070760499425518 nn.Linear: 0.00037893359529896 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016449564978221 nn.Linear: 0.0018849971264399] nn.Sequential: [nn.Linear: 0.00016257908213643 nn.Linear: 0.0012456018797002]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068732514046133 nn.Linear: 0.0084343645721674 nn.Linear: 0.0068260198459029 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0060903765261173 nn.Linear: 0.012293374165893] nn.Sequential: [nn.Linear: 0.0057746018283069 nn.Linear: 0.012739636935294]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11660000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062885082272683 nn.Linear: 0.066352230510805 nn.Linear: 0.04572755278712 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031595421770363 nn.Linear: 0.059051335761595] nn.Sequential: [nn.Linear: 0.031514486884894 nn.Linear: 0.038298771900881]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57558381557465 nn.Linear: 0.28538379073143 nn.Linear: 0.25238308310509 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42312023043633 nn.Linear: 0.67124629020691] nn.Sequential: [nn.Linear: 0.19310063123703 nn.Linear: 0.31402477622032]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024973658405375 nn.Linear: 0.0011158598880044 nn.Linear: 0.00040794356742419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018800832246853 nn.Linear: 0.0023629599423113] nn.Sequential: [nn.Linear: 0.00014890432202571 nn.Linear: 0.00097957746542731]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.020770506933331 nn.Linear: 0.013832257129252 nn.Linear: 0.012024595402181 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012058582156897 nn.Linear: 0.018313618376851] nn.Sequential: [nn.Linear: 0.0052078380249441 nn.Linear: 0.010935408063233]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11670000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062895987908089 nn.Linear: 0.066357010777954 nn.Linear: 0.04572885173102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031595631916777 nn.Linear: 0.059043709980415] nn.Sequential: [nn.Linear: 0.031514832831822 nn.Linear: 0.038315687869783]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57602494955063 nn.Linear: 0.28579127788544 nn.Linear: 0.25272470712662 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42320463061333 nn.Linear: 0.67148125171661] nn.Sequential: [nn.Linear: 0.19337604939938 nn.Linear: 0.31447318196297]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0042370364092628 nn.Linear: 0.0029136397042265 nn.Linear: 0.0015086781456417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00057042745077425 nn.Linear: 0.0064238516074937] nn.Sequential: [nn.Linear: 0.0004364878066347 nn.Linear: 0.003209375610583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.041304934769869 nn.Linear: 0.057544872164726 nn.Linear: 0.063011929392815 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.054433614015579 nn.Linear: 0.059347242116928] nn.Sequential: [nn.Linear: 0.020058207213879 nn.Linear: 0.050315242260695]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11680000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062906737441855 nn.Linear: 0.066365392792149 nn.Linear: 0.045730921484735 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031595867710844 nn.Linear: 0.059067997233782] nn.Sequential: [nn.Linear: 0.031515209957905 nn.Linear: 0.038305904165121]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57598388195038 nn.Linear: 0.28534519672394 nn.Linear: 0.25315442681313 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42354312539101 nn.Linear: 0.67210501432419] nn.Sequential: [nn.Linear: 0.19374477863312 nn.Linear: 0.31464570760727]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00081085023856491 nn.Linear: 0.0005235626730534 nn.Linear: 0.00028115471315413 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00013405007105881 nn.Linear: 0.0014499363626425] nn.Sequential: [nn.Linear: 0.00014196206027934 nn.Linear: 0.0010156151766287]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0055052805691957 nn.Linear: 0.010297292843461 nn.Linear: 0.0058459369465709 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0059338486753404 nn.Linear: 0.0092066656798124] nn.Sequential: [nn.Linear: 0.0046504382044077 nn.Linear: 0.0089893778786063]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11690000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062928107446787 nn.Linear: 0.066372641616298 nn.Linear: 0.045733754767793 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031596510443814 nn.Linear: 0.059126084397406] nn.Sequential: [nn.Linear: 0.031515453529225 nn.Linear: 0.038330999269074]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57669901847839 nn.Linear: 0.28536957502365 nn.Linear: 0.25330278277397 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42404526472092 nn.Linear: 0.67259865999222] nn.Sequential: [nn.Linear: 0.19414502382278 nn.Linear: 0.31526246666908]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00067911673555179 nn.Linear: 0.00043589863782495 nn.Linear: 0.00024761007194574 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010445926787315 nn.Linear: 0.00098130644774863] nn.Sequential: [nn.Linear: 9.3546106941566e-05 nn.Linear: 0.00059496481248331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048505431041121 nn.Linear: 0.005798764526844 nn.Linear: 0.0041859857738018 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.006473490037024 nn.Linear: 0.0090370280668139] nn.Sequential: [nn.Linear: 0.0082381851971149 nn.Linear: 0.005026285070926]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11700000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062927630330863 nn.Linear: 0.06637340072963 nn.Linear: 0.045734562791504 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031596474901382 nn.Linear: 0.059142616447659] nn.Sequential: [nn.Linear: 0.031515600551433 nn.Linear: 0.038348585714581]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57769155502319 nn.Linear: 0.28569108247757 nn.Linear: 0.25316765904427 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42456671595573 nn.Linear: 0.67293280363083] nn.Sequential: [nn.Linear: 0.19418889284134 nn.Linear: 0.31564491987228]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014408453671054 nn.Linear: 0.0008353829740271 nn.Linear: 0.00041883812888853 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018710546120164 nn.Linear: 0.0020135571137004] nn.Sequential: [nn.Linear: 0.00016478281775881 nn.Linear: 0.0012202848264923]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0094539523124695 nn.Linear: 0.015083856880665 nn.Linear: 0.012624465860426 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016924537718296 nn.Linear: 0.019933486357331] nn.Sequential: [nn.Linear: 0.0095366118475795 nn.Linear: 0.011438641697168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11710000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06292456729528 nn.Linear: 0.066381765092178 nn.Linear: 0.045736135445438 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031596768328223 nn.Linear: 0.059175100075507] nn.Sequential: [nn.Linear: 0.031515860768987 nn.Linear: 0.038351246957481]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57826143503189 nn.Linear: 0.28544297814369 nn.Linear: 0.25369995832443 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42492657899857 nn.Linear: 0.67303359508514] nn.Sequential: [nn.Linear: 0.19428123533726 nn.Linear: 0.31534591317177]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012256202678747 nn.Linear: 0.00064054838503433 nn.Linear: 0.00032823048390027 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021965111046972 nn.Linear: 0.0030443545661436] nn.Sequential: [nn.Linear: 0.00013235503367452 nn.Linear: 0.00089588353791325]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0099792014807463 nn.Linear: 0.0093120783567429 nn.Linear: 0.0070707332342863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011554280295968 nn.Linear: 0.022903546690941] nn.Sequential: [nn.Linear: 0.0054569225758314 nn.Linear: 0.0088651198893785]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11720000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062909525067471 nn.Linear: 0.066381313402244 nn.Linear: 0.045736552605716 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031596854495724 nn.Linear: 0.059160386674179] nn.Sequential: [nn.Linear: 0.03151583442712 nn.Linear: 0.038371866182203]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57711970806122 nn.Linear: 0.28520008921623 nn.Linear: 0.25346979498863 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42544230818748 nn.Linear: 0.67358911037445] nn.Sequential: [nn.Linear: 0.1941230148077 nn.Linear: 0.31563875079155]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001483754432338 nn.Linear: 0.00082535421241004 nn.Linear: 0.00050957717885902 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024266781448944 nn.Linear: 0.003057009176975] nn.Sequential: [nn.Linear: 0.0002213137630132 nn.Linear: 0.0019738870950725]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0098507134243846 nn.Linear: 0.012944216839969 nn.Linear: 0.015832541510463 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.023515947163105 nn.Linear: 0.021677495911717] nn.Sequential: [nn.Linear: 0.0062526189722121 nn.Linear: 0.02104115113616]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11730000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062922961243034 nn.Linear: 0.066387710699158 nn.Linear: 0.045739163131791 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03159717167418 nn.Linear: 0.059215025253415] nn.Sequential: [nn.Linear: 0.03151608069323 nn.Linear: 0.038371736763583]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57868766784668 nn.Linear: 0.285201638937 nn.Linear: 0.2539042532444 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42568281292915 nn.Linear: 0.67423790693283] nn.Sequential: [nn.Linear: 0.1945618391037 nn.Linear: 0.31544861197472]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012079366466979 nn.Linear: 0.00070399402537674 nn.Linear: 0.0003779927773697 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015783309545447 nn.Linear: 0.0020073273638941] nn.Sequential: [nn.Linear: 0.00021113667248487 nn.Linear: 0.0018577506076173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.010281275957823 nn.Linear: 0.011902029626071 nn.Linear: 0.0088006900623441 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008609602227807 nn.Linear: 0.014782505109906] nn.Sequential: [nn.Linear: 0.0077652670443058 nn.Linear: 0.024394391104579]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11740000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06291683138255 nn.Linear: 0.066390505231 nn.Linear: 0.045741686683691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031597349063716 nn.Linear: 0.059218783489786] nn.Sequential: [nn.Linear: 0.031516338302502 nn.Linear: 0.038392634385861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57936823368073 nn.Linear: 0.28521537780762 nn.Linear: 0.25420925021172 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42590808868408 nn.Linear: 0.67506992816925] nn.Sequential: [nn.Linear: 0.19458897411823 nn.Linear: 0.31574746966362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0050573124456322 nn.Linear: 0.003024474260799 nn.Linear: 0.0014648510355207 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00056131412283582 nn.Linear: 0.0068677809943982] nn.Sequential: [nn.Linear: 0.00052109317770142 nn.Linear: 0.0037403088297486]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.054533343762159 nn.Linear: 0.067375294864178 nn.Linear: 0.057737946510315 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.046149399131536 nn.Linear: 0.065663494169712] nn.Sequential: [nn.Linear: 0.041467923671007 nn.Linear: 0.055658772587776]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11750000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062920312067474 nn.Linear: 0.066397106075145 nn.Linear: 0.045743209594094 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031597646067029 nn.Linear: 0.059213913690293] nn.Sequential: [nn.Linear: 0.031516621143662 nn.Linear: 0.03838929387575]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5787838101387 nn.Linear: 0.28497764468193 nn.Linear: 0.25437188148499 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42663529515266 nn.Linear: 0.67569690942764] nn.Sequential: [nn.Linear: 0.19477568566799 nn.Linear: 0.31589269638062]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018068029234161 nn.Linear: 0.00092340347006418 nn.Linear: 0.00042831577540112 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022218367780755 nn.Linear: 0.0026416458105112] nn.Sequential: [nn.Linear: 0.0001571966029611 nn.Linear: 0.001024262940414]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097607169300318 nn.Linear: 0.015774706378579 nn.Linear: 0.0088517526164651 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.016568390652537 nn.Linear: 0.028449958190322] nn.Sequential: [nn.Linear: 0.0068310648202896 nn.Linear: 0.0081275859847665]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.086265944391489	TD error	0.017108463972807	Qmax	1	

Steps: 11750000 (frames: 47000000), score: 1997.32, higheset score: 5336, epsilon: 0.05, lr: 0.0005, training time: 531s, training rate: 1880fps, testing time: 87s, testing rate: 5730fps,  num. ep.: 367,  num. rewards: 17599	
   2   64    4   16
   4    8   16  512
   2   32  128    2
  16    2    8   32
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11760000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062922912501949 nn.Linear: 0.06640585282004 nn.Linear: 0.045745539010923 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031597966103206 nn.Linear: 0.059229150324001] nn.Sequential: [nn.Linear: 0.031517090849843 nn.Linear: 0.03839736054768]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57914227247238 nn.Linear: 0.28522968292236 nn.Linear: 0.25474953651428 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42695009708405 nn.Linear: 0.67586898803711] nn.Sequential: [nn.Linear: 0.19512493908405 nn.Linear: 0.3160140812397]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019311601344857 nn.Linear: 0.00085219870836813 nn.Linear: 0.00045440282380936 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017636037018267 nn.Linear: 0.0019185806581268] nn.Sequential: [nn.Linear: 0.00014836352881883 nn.Linear: 0.00092283094796651]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01249442435801 nn.Linear: 0.015278419479728 nn.Linear: 0.023052971810102 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018757067620754 nn.Linear: 0.015545613132417] nn.Sequential: [nn.Linear: 0.0089717535302043 nn.Linear: 0.015830807387829]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11770000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062926400435306 nn.Linear: 0.066408841632083 nn.Linear: 0.045746617778452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031598485905367 nn.Linear: 0.059298978850208] nn.Sequential: [nn.Linear: 0.031517257242197 nn.Linear: 0.038417579138567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.57940256595612 nn.Linear: 0.2850858271122 nn.Linear: 0.25452274084091 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4273521900177 nn.Linear: 0.67574489116669] nn.Sequential: [nn.Linear: 0.19557273387909 nn.Linear: 0.31592234969139]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00090270943838086 nn.Linear: 0.00044135934736587 nn.Linear: 0.0002467453547722 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012145370790177 nn.Linear: 0.0013593497095619] nn.Sequential: [nn.Linear: 9.3781695182727e-05 nn.Linear: 0.00064861454480603]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0068571991287172 nn.Linear: 0.0081559885293245 nn.Linear: 0.0045577720738947 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0076284529641271 nn.Linear: 0.011481060646474] nn.Sequential: [nn.Linear: 0.0058600660413504 nn.Linear: 0.007385281380266]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11780000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062925665421728 nn.Linear: 0.06641231445571 nn.Linear: 0.045747492910313 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031598690319071 nn.Linear: 0.05931067372412] nn.Sequential: [nn.Linear: 0.03151738726269 nn.Linear: 0.038431670975846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58022958040237 nn.Linear: 0.28476938605309 nn.Linear: 0.25468900799751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42767208814621 nn.Linear: 0.67604827880859] nn.Sequential: [nn.Linear: 0.19520227611065 nn.Linear: 0.3163979947567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.002176360740302 nn.Linear: 0.0012986054791908 nn.Linear: 0.00064068158468199 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00034917671882943 nn.Linear: 0.0040515735132929] nn.Sequential: [nn.Linear: 0.00028313204965322 nn.Linear: 0.0019341046478737]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013729067519307 nn.Linear: 0.028649445623159 nn.Linear: 0.023706989362836 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022414548322558 nn.Linear: 0.034132417291403] nn.Sequential: [nn.Linear: 0.01333383563906 nn.Linear: 0.01722645200789]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11790000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062930430943946 nn.Linear: 0.066419383325167 nn.Linear: 0.045748738594507 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031599449889574 nn.Linear: 0.059329265629103] nn.Sequential: [nn.Linear: 0.031517215966634 nn.Linear: 0.038420179640703]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58116185665131 nn.Linear: 0.28504821658134 nn.Linear: 0.25471299886703 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42785754799843 nn.Linear: 0.67646265029907] nn.Sequential: [nn.Linear: 0.19521167874336 nn.Linear: 0.31654605269432]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019128944521996 nn.Linear: 0.00093287190072312 nn.Linear: 0.00044680015090238 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00021126505790325 nn.Linear: 0.0026767263288012] nn.Sequential: [nn.Linear: 0.00015108897422715 nn.Linear: 0.00095611781927041]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01321346219629 nn.Linear: 0.011080444790423 nn.Linear: 0.0089166462421417 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015434510074556 nn.Linear: 0.019660891965032] nn.Sequential: [nn.Linear: 0.0082568069919944 nn.Linear: 0.011029312387109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11800000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062926939787689 nn.Linear: 0.066420426395236 nn.Linear: 0.045750187690387 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031599468619278 nn.Linear: 0.059331327168621] nn.Sequential: [nn.Linear: 0.031517712485725 nn.Linear: 0.038440024334609]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58155488967896 nn.Linear: 0.28452137112617 nn.Linear: 0.25498297810555 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42831262946129 nn.Linear: 0.67695397138596] nn.Sequential: [nn.Linear: 0.1953554302454 nn.Linear: 0.31695118546486]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025126519914832 nn.Linear: 0.0015275974384236 nn.Linear: 0.00070307047645691 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00033085822388288 nn.Linear: 0.0043097023269097] nn.Sequential: [nn.Linear: 0.0002436112975435 nn.Linear: 0.0015322512367254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015995215624571 nn.Linear: 0.017961103469133 nn.Linear: 0.02005922794342 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.02369587123394 nn.Linear: 0.03162432834506] nn.Sequential: [nn.Linear: 0.010497944429517 nn.Linear: 0.015187636017799]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11810000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062926694900124 nn.Linear: 0.066425334226173 nn.Linear: 0.045751286578351 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031599465771469 nn.Linear: 0.05933774005555] nn.Sequential: [nn.Linear: 0.031517903208335 nn.Linear: 0.038441782775992]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58153975009918 nn.Linear: 0.28438967466354 nn.Linear: 0.25506526231766 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42857465147972 nn.Linear: 0.67725384235382] nn.Sequential: [nn.Linear: 0.19598512351513 nn.Linear: 0.31705424189568]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023406587552714 nn.Linear: 0.0011565578600418 nn.Linear: 0.00044444769368614 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011573704546746 nn.Linear: 0.0011133231216673] nn.Sequential: [nn.Linear: 0.00012356801111545 nn.Linear: 0.00074228033639716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015320519916713 nn.Linear: 0.017247542738914 nn.Linear: 0.016473069787025 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01192735042423 nn.Linear: 0.009194771759212] nn.Sequential: [nn.Linear: 0.0087128272280097 nn.Linear: 0.0084814513102174]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11820000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062923782265506 nn.Linear: 0.066428912574169 nn.Linear: 0.045752216546861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031599737207338 nn.Linear: 0.059353125866155] nn.Sequential: [nn.Linear: 0.031518009251726 nn.Linear: 0.038438800074176]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58151978254318 nn.Linear: 0.28459593653679 nn.Linear: 0.25514736771584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42888331413269 nn.Linear: 0.67746883630753] nn.Sequential: [nn.Linear: 0.19621463119984 nn.Linear: 0.31710097193718]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015873080195096 nn.Linear: 0.00091041655075485 nn.Linear: 0.00041519626052977 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001978682952543 nn.Linear: 0.0025249089059212] nn.Sequential: [nn.Linear: 0.00013517919312004 nn.Linear: 0.001018998085861]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0084661971777678 nn.Linear: 0.012574508786201 nn.Linear: 0.011007725261152 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012006868608296 nn.Linear: 0.016829205676913] nn.Sequential: [nn.Linear: 0.0063309604302049 nn.Linear: 0.012297505512834]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11830000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062918050720201 nn.Linear: 0.066431917390913 nn.Linear: 0.045753599563184 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031600028357622 nn.Linear: 0.059370433744212] nn.Sequential: [nn.Linear: 0.031518300292142 nn.Linear: 0.03846156231753]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58251011371613 nn.Linear: 0.28475892543793 nn.Linear: 0.25522845983505 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42901468276978 nn.Linear: 0.67793548107147] nn.Sequential: [nn.Linear: 0.19613794982433 nn.Linear: 0.31734552979469]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015655401287452 nn.Linear: 0.00090884634411556 nn.Linear: 0.00043450634065321 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00018469107902326 nn.Linear: 0.0022885056600586] nn.Sequential: [nn.Linear: 0.0001460893420271 nn.Linear: 0.0010261052969309]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.015021303668618 nn.Linear: 0.014332395046949 nn.Linear: 0.0090197138488293 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.01497227139771 nn.Linear: 0.025535522028804] nn.Sequential: [nn.Linear: 0.0067074564285576 nn.Linear: 0.008647664450109]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11840000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062926121187545 nn.Linear: 0.066436386049474 nn.Linear: 0.045754866145778 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03160012883504 nn.Linear: 0.059372972119846] nn.Sequential: [nn.Linear: 0.031518255252892 nn.Linear: 0.038467613787692]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58287143707275 nn.Linear: 0.28450974822044 nn.Linear: 0.25525280833244 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.42938783764839 nn.Linear: 0.67829823493958] nn.Sequential: [nn.Linear: 0.19632241129875 nn.Linear: 0.31781378388405]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010831088969243 nn.Linear: 0.00066949399263464 nn.Linear: 0.00035431680954375 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012707191254299 nn.Linear: 0.0011926573370939] nn.Sequential: [nn.Linear: 0.00013257118663281 nn.Linear: 0.001072266979159]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0079049551859498 nn.Linear: 0.0091943647712469 nn.Linear: 0.0087958900257945 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.008549046702683 nn.Linear: 0.0093031190335751] nn.Sequential: [nn.Linear: 0.010476628318429 nn.Linear: 0.010626886971295]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11850000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062938857191309 nn.Linear: 0.066445500769138 nn.Linear: 0.045756908563974 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031600522781581 nn.Linear: 0.059386875006055] nn.Sequential: [nn.Linear: 0.031518803608704 nn.Linear: 0.038466554968643]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58370798826218 nn.Linear: 0.28498899936676 nn.Linear: 0.25530678033829 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4299350976944 nn.Linear: 0.6785803437233] nn.Sequential: [nn.Linear: 0.19641254842281 nn.Linear: 0.31774020195007]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0016927111948374 nn.Linear: 0.00084178953281695 nn.Linear: 0.00038839020387495 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00030011542391674 nn.Linear: 0.0044077681683913] nn.Sequential: [nn.Linear: 0.00017651674981711 nn.Linear: 0.0012912370645895]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011750645935535 nn.Linear: 0.011373028159142 nn.Linear: 0.008948196657002 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.015492269769311 nn.Linear: 0.025244001299143] nn.Sequential: [nn.Linear: 0.0075762709602714 nn.Linear: 0.013621410354972]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11860000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062940288070305 nn.Linear: 0.066447158902533 nn.Linear: 0.045758310283283 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031601084505038 nn.Linear: 0.05946248502989] nn.Sequential: [nn.Linear: 0.031519204756113 nn.Linear: 0.038489264784855]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58456575870514 nn.Linear: 0.28486910462379 nn.Linear: 0.25553938746452 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43009203672409 nn.Linear: 0.67877817153931] nn.Sequential: [nn.Linear: 0.19692929089069 nn.Linear: 0.31803745031357]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0024656679064585 nn.Linear: 0.001082130674865 nn.Linear: 0.00045587453404419 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016369169748477 nn.Linear: 0.0018642287811228] nn.Sequential: [nn.Linear: 0.00013446984211337 nn.Linear: 0.00088694699496778]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.024411972612143 nn.Linear: 0.016680277884007 nn.Linear: 0.020223280414939 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013091928325593 nn.Linear: 0.015549416653812] nn.Sequential: [nn.Linear: 0.0041573927737772 nn.Linear: 0.0085442112758756]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11870000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06294666164196 nn.Linear: 0.066449099080206 nn.Linear: 0.045759582816758 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031601616118319 nn.Linear: 0.059500049924522] nn.Sequential: [nn.Linear: 0.031519304153814 nn.Linear: 0.038504964477827]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58416795730591 nn.Linear: 0.28491368889809 nn.Linear: 0.25541904568672 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43038654327393 nn.Linear: 0.67960578203201] nn.Sequential: [nn.Linear: 0.19712397456169 nn.Linear: 0.31835821270943]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0061169085537974 nn.Linear: 0.0034883114154117 nn.Linear: 0.0013873713772343 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00045750294907761 nn.Linear: 0.0051171399922003] nn.Sequential: [nn.Linear: 0.00041975140747257 nn.Linear: 0.0033392573204344]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.050876837223768 nn.Linear: 0.077623665332794 nn.Linear: 0.047048460692167 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.041448153555393 nn.Linear: 0.078075833618641] nn.Sequential: [nn.Linear: 0.023556662723422 nn.Linear: 0.045777905732393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	11880000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062956228529083 nn.Linear: 0.066455116723275 nn.Linear: 0.045761532268778 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602018969643 nn.Linear: 0.059520133105096] nn.Sequential: [nn.Linear: 0.031519517685794 nn.Linear: 0.038515095000482]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58495026826859 nn.Linear: 0.28542202711105 nn.Linear: 0.25547310709953 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43097054958344 nn.Linear: 0.68013942241669] nn.Sequential: [nn.Linear: 0.19740642607212 nn.Linear: 0.31894823908806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0028077793916017 nn.Linear: 0.0014153917761956 nn.Linear: 0.00059236500326739 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029929266611749 nn.Linear: 0.004010559593541] nn.Sequential: [nn.Linear: 0.00017546033861905 nn.Linear: 0.0013316340069699]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01830487139523 nn.Linear: 0.015211935155094 nn.Linear: 0.026087235659361 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.022881053388119 nn.Linear: 0.025329099968076] nn.Sequential: [nn.Linear: 0.0049194302409887 nn.Linear: 0.018755311146379]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11890000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062959137098369 nn.Linear: 0.066459229492328 nn.Linear: 0.045762707104057 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602373703527 nn.Linear: 0.059554749693227] nn.Sequential: [nn.Linear: 0.031519653594582 nn.Linear: 0.038520677754899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58551073074341 nn.Linear: 0.28565523028374 nn.Linear: 0.2554624080658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43109905719757 nn.Linear: 0.68010574579239] nn.Sequential: [nn.Linear: 0.19750699400902 nn.Linear: 0.31903669238091]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00055706636764226 nn.Linear: 0.00035712413538795 nn.Linear: 0.00019777942762804 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010665733084116 nn.Linear: 0.0013096957697576] nn.Sequential: [nn.Linear: 8.5296752431072e-05 nn.Linear: 0.00060649433338154]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0037117069587111 nn.Linear: 0.0041670673526824 nn.Linear: 0.0040026577189565 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.004986958578229 nn.Linear: 0.0076362718828022] nn.Sequential: [nn.Linear: 0.0022728114854544 nn.Linear: 0.0048189857043326]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11900000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062961420341705 nn.Linear: 0.066466697483531 nn.Linear: 0.045765326246043 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602682666604 nn.Linear: 0.059576069910811] nn.Sequential: [nn.Linear: 0.031520286362385 nn.Linear: 0.038535304301366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5858239531517 nn.Linear: 0.2850269973278 nn.Linear: 0.25581952929497 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43115854263306 nn.Linear: 0.6804284453392] nn.Sequential: [nn.Linear: 0.19788600504398 nn.Linear: 0.31920725107193]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0031406734659206 nn.Linear: 0.0020500014075482 nn.Linear: 0.0010445769037969 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00045876936368311 nn.Linear: 0.0064515820057629] nn.Sequential: [nn.Linear: 0.00038131658007296 nn.Linear: 0.0026467297993986]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.042648952454329 nn.Linear: 0.05446295440197 nn.Linear: 0.026354299858212 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.055027112364769 nn.Linear: 0.062278471887112] nn.Sequential: [nn.Linear: 0.030348010361195 nn.Linear: 0.033246546983719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11910000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062962254055543 nn.Linear: 0.066467456091775 nn.Linear: 0.045765567115164 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602872912756 nn.Linear: 0.059579406905598] nn.Sequential: [nn.Linear: 0.031520330802978 nn.Linear: 0.03854270541723]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5852524638176 nn.Linear: 0.28531315922737 nn.Linear: 0.25596541166306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43124693632126 nn.Linear: 0.68039691448212] nn.Sequential: [nn.Linear: 0.19789786636829 nn.Linear: 0.31962335109711]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012695544807517 nn.Linear: 0.0010123516137322 nn.Linear: 0.00058330071493659 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028964122911288 nn.Linear: 0.003666554626517] nn.Sequential: [nn.Linear: 0.00022300806216799 nn.Linear: 0.0016283362280364]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0090847359970212 nn.Linear: 0.011206340976059 nn.Linear: 0.011121545918286 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011316606774926 nn.Linear: 0.029551099985838] nn.Sequential: [nn.Linear: 0.013871497474611 nn.Linear: 0.018689451739192]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11920000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062957755219709 nn.Linear: 0.066474209004129 nn.Linear: 0.045767469886748 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602921131139 nn.Linear: 0.059610878364779] nn.Sequential: [nn.Linear: 0.031520584497625 nn.Linear: 0.038552017724004]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58547353744507 nn.Linear: 0.28457096219063 nn.Linear: 0.2560832798481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43152371048927 nn.Linear: 0.68045210838318] nn.Sequential: [nn.Linear: 0.19820007681847 nn.Linear: 0.31990170478821]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015345296300898 nn.Linear: 0.00098788317823857 nn.Linear: 0.00044471224369358 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00015356396883955 nn.Linear: 0.0016537402727688] nn.Sequential: [nn.Linear: 0.00017326231537406 nn.Linear: 0.0014779887600403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0096594095230103 nn.Linear: 0.015521318651736 nn.Linear: 0.016196129843593 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0098999869078398 nn.Linear: 0.022883260622621] nn.Sequential: [nn.Linear: 0.0078634740784764 nn.Linear: 0.021842047572136]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11930000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062946266206387 nn.Linear: 0.066477078640292 nn.Linear: 0.045766830849961 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03160280424937 nn.Linear: 0.059558195053135] nn.Sequential: [nn.Linear: 0.03152068948778 nn.Linear: 0.038556802497932]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58490681648254 nn.Linear: 0.28495681285858 nn.Linear: 0.25610086321831 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43190810084343 nn.Linear: 0.68071162700653] nn.Sequential: [nn.Linear: 0.19818879663944 nn.Linear: 0.32012364268303]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0026065621205069 nn.Linear: 0.0016819283713042 nn.Linear: 0.00078836890114608 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025553172197112 nn.Linear: 0.0031400369123904] nn.Sequential: [nn.Linear: 0.00022818838830874 nn.Linear: 0.0018347494084896]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016799097880721 nn.Linear: 0.029415532946587 nn.Linear: 0.024965662509203 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031206866726279 nn.Linear: 0.025328859686852] nn.Sequential: [nn.Linear: 0.0098292334005237 nn.Linear: 0.030460905283689]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11940000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062946608122391 nn.Linear: 0.066477439187195 nn.Linear: 0.04576733681106 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602699834983 nn.Linear: 0.05953889771763] nn.Sequential: [nn.Linear: 0.031520736721022 nn.Linear: 0.038544643192557]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58566772937775 nn.Linear: 0.28499990701675 nn.Linear: 0.25625804066658 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43230944871902 nn.Linear: 0.68116557598114] nn.Sequential: [nn.Linear: 0.19836020469666 nn.Linear: 0.3202805519104]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014660021281421 nn.Linear: 0.00084417813185616 nn.Linear: 0.00049071859025662 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022899471472533 nn.Linear: 0.0020725223903963] nn.Sequential: [nn.Linear: 0.00023376834334673 nn.Linear: 0.0017295178832891]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011341175064445 nn.Linear: 0.0098149655386806 nn.Linear: 0.0080180447548628 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.013466767966747 nn.Linear: 0.011277652345598] nn.Sequential: [nn.Linear: 0.0059610311873257 nn.Linear: 0.019389512017369]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11950000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06295351705908 nn.Linear: 0.066481003121637 nn.Linear: 0.045768165113055 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602899385108 nn.Linear: 0.059546707623454] nn.Sequential: [nn.Linear: 0.031520880339311 nn.Linear: 0.038560034556593]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58570426702499 nn.Linear: 0.28500375151634 nn.Linear: 0.25609910488129 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43261286616325 nn.Linear: 0.68133622407913] nn.Sequential: [nn.Linear: 0.19815783202648 nn.Linear: 0.320571154356]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0019417967560627 nn.Linear: 0.00099209467808942 nn.Linear: 0.00045532573178899 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00024024439659739 nn.Linear: 0.0028349873305991] nn.Sequential: [nn.Linear: 0.00015583927226352 nn.Linear: 0.0010866046861191]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013566533103585 nn.Linear: 0.012271730229259 nn.Linear: 0.018903123214841 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020522609353065 nn.Linear: 0.022199949249625] nn.Sequential: [nn.Linear: 0.0090158581733704 nn.Linear: 0.010042638517916]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11960000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062942558537184 nn.Linear: 0.066479624481644 nn.Linear: 0.045767995621747 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602735628797 nn.Linear: 0.059491961011389] nn.Sequential: [nn.Linear: 0.031520649271654 nn.Linear: 0.038547109240574]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58587497472763 nn.Linear: 0.2852301299572 nn.Linear: 0.25598213076591 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43272045254707 nn.Linear: 0.68153542280197] nn.Sequential: [nn.Linear: 0.19823983311653 nn.Linear: 0.32081118226051]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0013044345740791 nn.Linear: 0.00062194801989849 nn.Linear: 0.0003191891026093 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00016998579078842 nn.Linear: 0.0021844405909763] nn.Sequential: [nn.Linear: 0.00012844039967619 nn.Linear: 0.00093909353498447]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0086052278056741 nn.Linear: 0.0092294011265039 nn.Linear: 0.0065563591197133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.012617879547179 nn.Linear: 0.017722260206938] nn.Sequential: [nn.Linear: 0.0044672177173197 nn.Linear: 0.011113895103335]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11970000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062943126233886 nn.Linear: 0.06648274428533 nn.Linear: 0.045769195335269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602783706234 nn.Linear: 0.059490111066751] nn.Sequential: [nn.Linear: 0.031520912823031 nn.Linear: 0.038552685026659]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58548152446747 nn.Linear: 0.28496247529984 nn.Linear: 0.25622829794884 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4330640733242 nn.Linear: 0.68172162771225] nn.Sequential: [nn.Linear: 0.19826143980026 nn.Linear: 0.32086792588234]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001057451490881 nn.Linear: 0.00049724404464605 nn.Linear: 0.00029095353817944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011589673562848 nn.Linear: 0.0011488205151284] nn.Sequential: [nn.Linear: 0.00011129095056507 nn.Linear: 0.00081538718763857]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0074936393648386 nn.Linear: 0.0077028940431774 nn.Linear: 0.0046150828711689 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0058278827928007 nn.Linear: 0.006892935372889] nn.Sequential: [nn.Linear: 0.0059390319511294 nn.Linear: 0.0081107309088111]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11980000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062932315534826 nn.Linear: 0.06647996426303 nn.Linear: 0.045768396467584 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602579787174 nn.Linear: 0.059452488048578] nn.Sequential: [nn.Linear: 0.031520847636419 nn.Linear: 0.038557846383039]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5859283208847 nn.Linear: 0.28537753224373 nn.Linear: 0.25628933310509 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43337029218674 nn.Linear: 0.682049036026] nn.Sequential: [nn.Linear: 0.19865915179253 nn.Linear: 0.32090112566948]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00079300065543762 nn.Linear: 0.00059531548824429 nn.Linear: 0.00032793573751621 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00020277321310561 nn.Linear: 0.0026871172464265] nn.Sequential: [nn.Linear: 0.00012115479728562 nn.Linear: 0.00082287230296382]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0048394110053778 nn.Linear: 0.01065122988075 nn.Linear: 0.0092422943562269 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0208948738873 nn.Linear: 0.026268050074577] nn.Sequential: [nn.Linear: 0.0051971981301904 nn.Linear: 0.0074571324512362]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	11990000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062924339345691 nn.Linear: 0.066477408921512 nn.Linear: 0.045769166578163 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602638239919 nn.Linear: 0.05941608800142] nn.Sequential: [nn.Linear: 0.031520734075614 nn.Linear: 0.038546669384086]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58647936582565 nn.Linear: 0.28498333692551 nn.Linear: 0.25631740689278 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4336856007576 nn.Linear: 0.68275809288025] nn.Sequential: [nn.Linear: 0.19886580109596 nn.Linear: 0.32124826312065]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0023381339002962 nn.Linear: 0.00095836974946629 nn.Linear: 0.00037604828222533 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0002072956219732 nn.Linear: 0.0026944835822529] nn.Sequential: [nn.Linear: 0.00015727372380533 nn.Linear: 0.0011485727453214]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.018576864153147 nn.Linear: 0.013461418449879 nn.Linear: 0.014533456414938 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.011127573437989 nn.Linear: 0.021431652829051] nn.Sequential: [nn.Linear: 0.0081056393682957 nn.Linear: 0.01180689688772]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12000000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06292143660524 nn.Linear: 0.066476043282763 nn.Linear: 0.045769393032282 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602625792906 nn.Linear: 0.059409549282762] nn.Sequential: [nn.Linear: 0.031520874927415 nn.Linear: 0.038553453493575]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58629965782166 nn.Linear: 0.28525426983833 nn.Linear: 0.25638854503632 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43395006656647 nn.Linear: 0.68283265829086] nn.Sequential: [nn.Linear: 0.19879931211472 nn.Linear: 0.32124003767967]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.015382889919532 nn.Linear: 0.006246894485773 nn.Linear: 0.0025849349278028 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00086126410521507 nn.Linear: 0.011241527139377] nn.Sequential: [nn.Linear: 0.00088581991113311 nn.Linear: 0.0073238499866131]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.10585796833038 nn.Linear: 0.11395070701838 nn.Linear: 0.10232868790627 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.071820214390755 nn.Linear: 0.16877625882626] nn.Sequential: [nn.Linear: 0.053107429295778 nn.Linear: 0.13000351190567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
V	0.086943671643734	TD error	0.016804101124406	Qmax	1	

Steps: 12000000 (frames: 48000000), score: 1787.52, higheset score: 6164, epsilon: 0.05, lr: 0.0005, training time: 543s, training rate: 1839fps, testing time: 88s, testing rate: 5638fps,  num. ep.: 285,  num. rewards: 13221	
   8    2   64    2
   2   32    2    8
   4    8  256   32
   2    4   16  512
[torch.FloatTensor of size 4x4]

Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	12010000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062927319433389 nn.Linear: 0.066482869716521 nn.Linear: 0.045770573587023 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031602927393224 nn.Linear: 0.059464481996033] nn.Sequential: [nn.Linear: 0.031520938602757 nn.Linear: 0.038552476356738]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58701342344284 nn.Linear: 0.28515288233757 nn.Linear: 0.25639677047729 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43435248732567 nn.Linear: 0.68298929929733] nn.Sequential: [nn.Linear: 0.19895638525486 nn.Linear: 0.32150158286095]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0012700231831747 nn.Linear: 0.00076291656267376 nn.Linear: 0.00042948444963453 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023789805756732 nn.Linear: 0.0031416034975842] nn.Sequential: [nn.Linear: 0.00018427024369929 nn.Linear: 0.0016097960811747]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0095652900636196 nn.Linear: 0.0091192899271846 nn.Linear: 0.0084870560094714 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.019647389650345 nn.Linear: 0.031379815191031] nn.Sequential: [nn.Linear: 0.0087484791874886 nn.Linear: 0.016594922170043]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12020000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062920300608674 nn.Linear: 0.066484731723862 nn.Linear: 0.045771746423765 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603112251816 nn.Linear: 0.059472298678767] nn.Sequential: [nn.Linear: 0.031521070975594 nn.Linear: 0.038568741398612]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58684676885605 nn.Linear: 0.28516352176666 nn.Linear: 0.25685206055641 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43469703197479 nn.Linear: 0.68353265523911] nn.Sequential: [nn.Linear: 0.19911409914494 nn.Linear: 0.32173481583595]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001431741151252 nn.Linear: 0.00060356898284477 nn.Linear: 0.00026057141554345 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010753413226148 nn.Linear: 0.0011446495168006] nn.Sequential: [nn.Linear: 0.00011494074905949 nn.Linear: 0.00073916872906716]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097121689468622 nn.Linear: 0.0065286979079247 nn.Linear: 0.01144546456635 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0064597525633872 nn.Linear: 0.0068710232153535] nn.Sequential: [nn.Linear: 0.0055991355329752 nn.Linear: 0.0062985764816403]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12030000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06292161321926 nn.Linear: 0.066487261320653 nn.Linear: 0.045773099757174 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603099231917 nn.Linear: 0.059446914648667] nn.Sequential: [nn.Linear: 0.031521124119145 nn.Linear: 0.03856763047216]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5878831744194 nn.Linear: 0.28536546230316 nn.Linear: 0.25685319304466 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43503341078758 nn.Linear: 0.68385803699493] nn.Sequential: [nn.Linear: 0.19899669289589 nn.Linear: 0.32181131839752]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015652815552783 nn.Linear: 0.00077666306618425 nn.Linear: 0.0004598483400542 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023844952665563 nn.Linear: 0.0027992565194834] nn.Sequential: [nn.Linear: 0.0001717552993138 nn.Linear: 0.001255196319254]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011257069185376 nn.Linear: 0.01133104134351 nn.Linear: 0.013493332080543 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.017420571297407 nn.Linear: 0.027777640148997] nn.Sequential: [nn.Linear: 0.0049646068364382 nn.Linear: 0.010097832418978]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12040000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062919440298088 nn.Linear: 0.066490150580917 nn.Linear: 0.045774420254611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603440456962 nn.Linear: 0.059493237439312] nn.Sequential: [nn.Linear: 0.031521268380666 nn.Linear: 0.038584181307853]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58801364898682 nn.Linear: 0.28539657592773 nn.Linear: 0.25732573866844 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4353015422821 nn.Linear: 0.68424290418625] nn.Sequential: [nn.Linear: 0.19921840727329 nn.Linear: 0.3223625421524]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015060785494402 nn.Linear: 0.00085849565358589 nn.Linear: 0.00048682885124572 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00023982552500735 nn.Linear: 0.0024994928007203] nn.Sequential: [nn.Linear: 0.0001888644877791 nn.Linear: 0.0011907568700316]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.013566785492003 nn.Linear: 0.01277466583997 nn.Linear: 0.01264635566622 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010171912610531 nn.Linear: 0.018801314756274] nn.Sequential: [nn.Linear: 0.006510466337204 nn.Linear: 0.010284535586834]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12050000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062915052782228 nn.Linear: 0.066490369297501 nn.Linear: 0.045774552535038 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603397347108 nn.Linear: 0.059516963345871] nn.Sequential: [nn.Linear: 0.031521336388136 nn.Linear: 0.038588862539899]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58870393037796 nn.Linear: 0.28534603118896 nn.Linear: 0.25751951336861 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43546426296234 nn.Linear: 0.68428480625153] nn.Sequential: [nn.Linear: 0.19942674040794 nn.Linear: 0.32256519794464]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00086702158284895 nn.Linear: 0.00054402226921262 nn.Linear: 0.00031534373263525 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011726658775487 nn.Linear: 0.0011607640563049] nn.Sequential: [nn.Linear: 0.00017949361319852 nn.Linear: 0.0014517381458945]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.007802854757756 nn.Linear: 0.0088094640523195 nn.Linear: 0.0051228418014944 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0092336386442184 nn.Linear: 0.010335231199861] nn.Sequential: [nn.Linear: 0.018588770180941 nn.Linear: 0.021022925153375]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12060000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062914612619799 nn.Linear: 0.06649099311222 nn.Linear: 0.045777078253644 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603822309259 nn.Linear: 0.059555873750835] nn.Sequential: [nn.Linear: 0.031521535191154 nn.Linear: 0.03860585275884]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58904057741165 nn.Linear: 0.28496873378754 nn.Linear: 0.25762519240379 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43575409054756 nn.Linear: 0.68455392122269] nn.Sequential: [nn.Linear: 0.19956322014332 nn.Linear: 0.32321578264236]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0037248905489977 nn.Linear: 0.0018926725737268 nn.Linear: 0.0007936218326348 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00028925600019789 nn.Linear: 0.0039890587247697] nn.Sequential: [nn.Linear: 0.00038160759032858 nn.Linear: 0.0029596396728161]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.026696890592575 nn.Linear: 0.033763151615858 nn.Linear: 0.028957530856133 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.047310281544924 nn.Linear: 0.045772671699524] nn.Sequential: [nn.Linear: 0.023716121912003 nn.Linear: 0.031342446804047]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12070000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062918685939374 nn.Linear: 0.066493701839866 nn.Linear: 0.045778917417625 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603741947756 nn.Linear: 0.059579407541008] nn.Sequential: [nn.Linear: 0.031521782436138 nn.Linear: 0.038601515085366]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58913362026215 nn.Linear: 0.28545805811882 nn.Linear: 0.2575455904007 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43608099222183 nn.Linear: 0.68465733528137] nn.Sequential: [nn.Linear: 0.19988618791103 nn.Linear: 0.32331296801567]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015315479476317 nn.Linear: 0.00082145697250137 nn.Linear: 0.00047796071166312 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00022070174420938 nn.Linear: 0.0026136888966475] nn.Sequential: [nn.Linear: 0.00019016673635689 nn.Linear: 0.0014463808303393]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.012489710003138 nn.Linear: 0.012361666187644 nn.Linear: 0.0093316333368421 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010756879113615 nn.Linear: 0.016050105914474] nn.Sequential: [nn.Linear: 0.0066392198204994 nn.Linear: 0.019197013229132]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12080000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062914110570912 nn.Linear: 0.066496524998305 nn.Linear: 0.045779750200988 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031603873249386 nn.Linear: 0.059617811780186] nn.Sequential: [nn.Linear: 0.031522018349871 nn.Linear: 0.038614396210371]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58986520767212 nn.Linear: 0.28537946939468 nn.Linear: 0.257807046175 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43630430102348 nn.Linear: 0.68483769893646] nn.Sequential: [nn.Linear: 0.19998668134212 nn.Linear: 0.32323947548866]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0020669804782225 nn.Linear: 0.001013713366949 nn.Linear: 0.00044171269026353 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001669659522804 nn.Linear: 0.0016481584848562] nn.Sequential: [nn.Linear: 0.00019956015844083 nn.Linear: 0.0013780618209719]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.01304526347667 nn.Linear: 0.012119843624532 nn.Linear: 0.01131082419306 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010427848435938 nn.Linear: 0.016402436420321] nn.Sequential: [nn.Linear: 0.0094137638807297 nn.Linear: 0.015210594981909]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12090000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062906679398699 nn.Linear: 0.066501895632256 nn.Linear: 0.045780470059183 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031604120768865 nn.Linear: 0.059638151936127] nn.Sequential: [nn.Linear: 0.031522196636107 nn.Linear: 0.038615477461547]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5905237197876 nn.Linear: 0.28569969534874 nn.Linear: 0.25787115097046 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43659034371376 nn.Linear: 0.68527138233185] nn.Sequential: [nn.Linear: 0.19998671114445 nn.Linear: 0.32331141829491]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010067867790318 nn.Linear: 0.00054133087378645 nn.Linear: 0.00028507283488477 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012793286706455 nn.Linear: 0.0012863071037724] nn.Sequential: [nn.Linear: 0.00019311889580288 nn.Linear: 0.0016355946240855]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0065164589323103 nn.Linear: 0.0090696373954415 nn.Linear: 0.0062432470731437 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0068272105418146 nn.Linear: 0.014897181652486] nn.Sequential: [nn.Linear: 0.011172858998179 nn.Linear: 0.024202616885304]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12100000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062902632854505 nn.Linear: 0.066497824022065 nn.Linear: 0.04578059467395 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031604350668703 nn.Linear: 0.059633555814855] nn.Sequential: [nn.Linear: 0.031522062439115 nn.Linear: 0.038606265879566]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.58986383676529 nn.Linear: 0.28592851758003 nn.Linear: 0.25778034329414 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43684524297714 nn.Linear: 0.68550020456314] nn.Sequential: [nn.Linear: 0.20025007426739 nn.Linear: 0.32354009151459]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0015742633925612 nn.Linear: 0.00068518963477344 nn.Linear: 0.00028867588700564 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00010913046647696 nn.Linear: 0.0010573130075109] nn.Sequential: [nn.Linear: 0.00010776895505946 nn.Linear: 0.00067434070530806]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.011009477078915 nn.Linear: 0.010674932971597 nn.Linear: 0.0076859868131578 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0083388360217214 nn.Linear: 0.012233448214829] nn.Sequential: [nn.Linear: 0.0057537350803614 nn.Linear: 0.0079404134303331]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12110000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062901713275257 nn.Linear: 0.066504729837314 nn.Linear: 0.045782653207254 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031604323902464 nn.Linear: 0.059632195196258] nn.Sequential: [nn.Linear: 0.031522018158359 nn.Linear: 0.038599901532173]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59002864360809 nn.Linear: 0.28586587309837 nn.Linear: 0.25826027989388 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43729996681213 nn.Linear: 0.68575370311737] nn.Sequential: [nn.Linear: 0.20038272440434 nn.Linear: 0.32353481650352]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0010770819365612 nn.Linear: 0.00052058306664746 nn.Linear: 0.00025372402584082 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00011411303928882 nn.Linear: 0.00137100515269] nn.Sequential: [nn.Linear: 8.4328755298683e-05 nn.Linear: 0.00054315307275164]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0064689288847148 nn.Linear: 0.0064368331804872 nn.Linear: 0.005129465367645 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0086672520264983 nn.Linear: 0.010320603847504] nn.Sequential: [nn.Linear: 0.0069820815697312 nn.Linear: 0.0045316931791604]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12120000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062898544233823 nn.Linear: 0.066504228021287 nn.Linear: 0.045782605819253 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031604998470096 nn.Linear: 0.059653077590362] nn.Sequential: [nn.Linear: 0.031521796544772 nn.Linear: 0.038607634595701]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59079134464264 nn.Linear: 0.28563871979713 nn.Linear: 0.25810453295708 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43764495849609 nn.Linear: 0.68622279167175] nn.Sequential: [nn.Linear: 0.2002781778574 nn.Linear: 0.32388356328011]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0043951513269321 nn.Linear: 0.0018752851649449 nn.Linear: 0.00081733432569751 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00029615845108248 nn.Linear: 0.0033181906405774] nn.Sequential: [nn.Linear: 0.00029959277512853 nn.Linear: 0.0024319848925668]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.027757719159126 nn.Linear: 0.031512077897787 nn.Linear: 0.039119552820921 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.024407031014562 nn.Linear: 0.036368053406477] nn.Sequential: [nn.Linear: 0.02315186150372 nn.Linear: 0.039745971560478]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Saved:	DQN3_0_1_2048_FULL_Y.t7	
Steps: 	12130000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06289839448452 nn.Linear: 0.066506634444615 nn.Linear: 0.045782697151292 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031605129019709 nn.Linear: 0.059654794869431] nn.Sequential: [nn.Linear: 0.031521923341602 nn.Linear: 0.038610111820846]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59101378917694 nn.Linear: 0.28627377748489 nn.Linear: 0.25836962461472 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43780416250229 nn.Linear: 0.68675398826599] nn.Sequential: [nn.Linear: 0.20021089911461 nn.Linear: 0.32399460673332]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0025234239888555 nn.Linear: 0.00098426653908068 nn.Linear: 0.00047285509279928 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017993229188991 nn.Linear: 0.0022067751975601] nn.Sequential: [nn.Linear: 0.0002030782074436 nn.Linear: 0.0016784831692897]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.016538061201572 nn.Linear: 0.017420465126634 nn.Linear: 0.03009631857276 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.014403624460101 nn.Linear: 0.02112034521997] nn.Sequential: [nn.Linear: 0.009519592858851 nn.Linear: 0.015698572620749]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12140000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062906499589574 nn.Linear: 0.066510940996446 nn.Linear: 0.04578402139799 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031605422400471 nn.Linear: 0.059656812748088] nn.Sequential: [nn.Linear: 0.031522007706756 nn.Linear: 0.038613376883227]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59067642688751 nn.Linear: 0.28648006916046 nn.Linear: 0.2586986720562 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43812793493271 nn.Linear: 0.68737292289734] nn.Sequential: [nn.Linear: 0.20034490525723 nn.Linear: 0.3243303000927]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.001350148918949 nn.Linear: 0.00078758843705063 nn.Linear: 0.00041212923775337 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00017108599334983 nn.Linear: 0.0019470827402563] nn.Sequential: [nn.Linear: 0.00017727510744115 nn.Linear: 0.0011833759221115]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0097308587282896 nn.Linear: 0.010951128788292 nn.Linear: 0.0073572834953666 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0082783596590161 nn.Linear: 0.015788465738297] nn.Sequential: [nn.Linear: 0.0091846380382776 nn.Linear: 0.021704370155931]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12150000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062901167423703 nn.Linear: 0.066513689292459 nn.Linear: 0.045785328716694 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031605557475817 nn.Linear: 0.059688222939684] nn.Sequential: [nn.Linear: 0.031522277318187 nn.Linear: 0.038617101039709]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59134215116501 nn.Linear: 0.28615155816078 nn.Linear: 0.25888305902481 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.4383071064949 nn.Linear: 0.68710601329803] nn.Sequential: [nn.Linear: 0.20040652155876 nn.Linear: 0.3245649933815]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00084742844925752 nn.Linear: 0.00048425195943719 nn.Linear: 0.0002483096592746 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00012394458648424 nn.Linear: 0.0014700965623107] nn.Sequential: [nn.Linear: 9.5933733875526e-05 nn.Linear: 0.00069374095061629]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0066870078444481 nn.Linear: 0.0051425080746412 nn.Linear: 0.0043995724990964 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0081589240580797 nn.Linear: 0.010523026809096] nn.Sequential: [nn.Linear: 0.007080277428031 nn.Linear: 0.0080150226131082]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12160000	
Weight norms:
nn.Sequential: [nn.Linear: 0.06290030650325 nn.Linear: 0.066510692046974 nn.Linear: 0.045785172259611 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031605635057165 nn.Linear: 0.05968312773885] nn.Sequential: [nn.Linear: 0.031521953803256 nn.Linear: 0.038622685760769]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59146976470947 nn.Linear: 0.2862576842308 nn.Linear: 0.25871598720551 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43860784173012 nn.Linear: 0.68720674514771] nn.Sequential: [nn.Linear: 0.2002919614315 nn.Linear: 0.32482904195786]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0018667820733159 nn.Linear: 0.0015187938520049 nn.Linear: 0.00092215144821151 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00043163175649505 nn.Linear: 0.0043618962926484] nn.Sequential: [nn.Linear: 0.00043639260594424 nn.Linear: 0.0032788827540549]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0199357829988 nn.Linear: 0.025083664804697 nn.Linear: 0.03016297891736 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.020894421264529 nn.Linear: 0.031396400183439] nn.Sequential: [nn.Linear: 0.023241773247719 nn.Linear: 0.04115167632699]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12170000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062901624979546 nn.Linear: 0.066517313124688 nn.Linear: 0.045786526850373 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.03160581473959 nn.Linear: 0.059678540673104] nn.Sequential: [nn.Linear: 0.031522373960635 nn.Linear: 0.038615421650935]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.5914968252182 nn.Linear: 0.28628244996071 nn.Linear: 0.25912722945213 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43888103961945 nn.Linear: 0.68754613399506] nn.Sequential: [nn.Linear: 0.20084251463413 nn.Linear: 0.32509890198708]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.00075537733790093 nn.Linear: 0.00050918809193782 nn.Linear: 0.00029935317252811 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.0001617477869877 nn.Linear: 0.0019784321451808] nn.Sequential: [nn.Linear: 0.00013031642331204 nn.Linear: 0.00080214307588894]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0059504956007004 nn.Linear: 0.006181342061609 nn.Linear: 0.006045556627214 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.010843707248569 nn.Linear: 0.012541894800961] nn.Sequential: [nn.Linear: 0.0087514966726303 nn.Linear: 0.012783939950168]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Steps: 	12180000	
Weight norms:
nn.Sequential: [nn.Linear: 0.062906775910804 nn.Linear: 0.06651950726159 nn.Linear: 0.045787475265973 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.031606044054504 nn.Linear: 0.0596822826059] nn.Sequential: [nn.Linear: 0.03152248044514 nn.Linear: 0.038642699865545]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight max:
nn.Sequential: [nn.Linear: 0.59175860881805 nn.Linear: 0.28697216510773 nn.Linear: 0.25932225584984 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.43925845623016 nn.Linear: 0.68834227323532] nn.Sequential: [nn.Linear: 0.20076052844524 nn.Linear: 0.32526651024818]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
Weight grad norms:
nn.Sequential: [nn.Linear: 0.0014065262824675 nn.Linear: 0.0010292900078496 nn.Linear: 0.00067517228210679 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.00025536139595897 nn.Linear: 0.0024619914501423] nn.Sequential: [nn.Linear: 0.00032841318428968 nn.Linear: 0.0024418093265948]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]
Weight grad max:
nn.Sequential: [nn.Linear: 0.0087395403534174 nn.Linear: 0.013602497987449 nn.Linear: 0.011115299537778 nn.ConcatTable: [nn.Sequential: [nn.Linear: 0.018510477617383 nn.Linear: 0.018866270780563] nn.Sequential: [nn.Linear: 0.013246772810817 nn.Linear: 0.035381503403187]] nn.Sequential: [nn.ParallelTable: [nn.Sequential: [nn.ConcatTable: [nn.Sequential: []] ]] ]]	
